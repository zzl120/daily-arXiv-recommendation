{"id": "2602.17848", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17848", "abs": "https://arxiv.org/abs/2602.17848", "authors": ["Cassandra L. Jacobs", "Morgan Grobol"], "title": "On the scaling relationship between cloze probabilities and language model next-token prediction", "comment": null, "summary": "Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u66f4\u5927\u8bed\u8a00\u6a21\u578b\u5728\u773c\u52a8\u548c\u9605\u8bfb\u65f6\u95f4\u6570\u636e\u9884\u6d4b\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5bf9\u4eba\u7c7b\u53cd\u5e94\u6982\u7387\u5206\u914d\u4e0d\u8db3\uff1b\u5927\u6a21\u578b\u5728\u5b8c\u5f62\u586b\u7a7a\u6570\u636e\u4e2d\u80fd\u63d0\u4f9b\u66f4\u9ad8\u8d28\u91cf\u7684\u4e0b\u4e00\u4e2a\u8bcd\u53ca\u5176\u4ea7\u751f\u6982\u7387\u4f30\u8ba1\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u8bcd\u6c47\u5171\u73b0\u7edf\u8ba1\u4e0d\u654f\u611f\uff0c\u4f46\u8bed\u4e49\u4e0a\u4e0e\u4eba\u7c7b\u5b8c\u5f62\u586b\u7a7a\u53cd\u5e94\u66f4\u4e00\u81f4\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u4eba\u7c7b\u773c\u52a8\u3001\u9605\u8bfb\u65f6\u95f4\u548c\u5b8c\u5f62\u586b\u7a7a\u53cd\u5e94\u65b9\u9762\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u7406\u89e3\u6a21\u578b\u89c4\u6a21\u5982\u4f55\u5f71\u54cd\u5176\u5bf9\u8bed\u8a00\u5904\u7406\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u7279\u522b\u662f\u5bf9\u8bed\u4e49\u548c\u8bcd\u6c47\u5c42\u9762\u4fe1\u606f\u7684\u654f\u611f\u6027\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u5728\u773c\u52a8\u6570\u636e\u3001\u9605\u8bfb\u65f6\u95f4\u6570\u636e\u548c\u5b8c\u5f62\u586b\u7a7a\u6570\u636e\u4e0a\u7684\u9884\u6d4b\u8868\u73b0\uff0c\u5206\u6790\u6a21\u578b\u5bf9\u4e0b\u4e00\u4e2a\u8bcd\u7684\u9884\u6d4b\u8d28\u91cf\u53ca\u5176\u4e0e\u4eba\u7c7b\u53cd\u5e94\u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u7279\u522b\u5173\u6ce8\u6a21\u578b\u5bf9\u8bcd\u6c47\u5171\u73b0\u7edf\u8ba1\u7684\u654f\u611f\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\u7a0b\u5ea6\u3002", "result": "\u66f4\u5927\u8bed\u8a00\u6a21\u578b\u5728\u773c\u52a8\u548c\u9605\u8bfb\u65f6\u95f4\u9884\u6d4b\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5bf9\u4eba\u7c7b\u53cd\u5e94\u6982\u7387\u5206\u914d\u4e0d\u8db3\uff1b\u5927\u6a21\u578b\u5728\u5b8c\u5f62\u586b\u7a7a\u4efb\u52a1\u4e2d\u80fd\u63d0\u4f9b\u66f4\u9ad8\u8d28\u91cf\u7684\u4e0b\u4e00\u4e2a\u8bcd\u53ca\u5176\u4ea7\u751f\u6982\u7387\u4f30\u8ba1\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u8bcd\u6c47\u5171\u73b0\u7edf\u8ba1\u4e0d\u654f\u611f\uff0c\u4f46\u8bed\u4e49\u4e0a\u4e0e\u4eba\u7c7b\u5b8c\u5f62\u586b\u7a7a\u53cd\u5e94\u66f4\u4e00\u81f4\u3002", "conclusion": "\u66f4\u5927\u6a21\u578b\u7684\u8bb0\u5fc6\u80fd\u529b\u5e2e\u52a9\u5b83\u4eec\u731c\u6d4b\u66f4\u8bed\u4e49\u5408\u9002\u7684\u8bcd\uff0c\u4f46\u4f7f\u5b83\u4eec\u5bf9\u4e0e\u8bcd\u6c47\u8bc6\u522b\u76f8\u5173\u7684\u4f4e\u5c42\u6b21\u4fe1\u606f\u4e0d\u654f\u611f\uff1b\u7814\u7a76\u7ed3\u679c\u652f\u6301\u4e86\u6a21\u578b\u89c4\u6a21\u589e\u52a0\u4f1a\u6539\u5584\u8bed\u4e49\u5bf9\u9f50\u4f46\u964d\u4f4e\u5bf9\u4f4e\u5c42\u6b21\u8bed\u8a00\u4fe1\u606f\u654f\u611f\u6027\u7684\u89c2\u70b9\u3002"}}
{"id": "2602.17881", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17881", "abs": "https://arxiv.org/abs/2602.17881", "authors": ["Joschka Braun"], "title": "Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations", "comment": "Master's Thesis, University of T\u00fcbingen. 89 pages, 34 figures. Portions of this work were published at the ICLR 2025 Workshop on Foundation Models in the Wild (see arXiv:2505.22637)", "summary": "Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u5411\u91cf\uff08steering vectors\uff09\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u5f15\u5bfc\u6548\u679c\u5728\u4e0d\u540c\u884c\u4e3a\u6837\u672c\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u8bad\u7ec3\u6fc0\u6d3b\u5dee\u5f02\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u548c\u884c\u4e3a\u8868\u793a\u7684\u53ef\u5206\u79bb\u6027\u6765\u8bca\u65ad\u5f15\u5bfc\u4e0d\u53ef\u9760\u6027\u3002", "motivation": "\u5f15\u5bfc\u5411\u91cf\u662f\u4e00\u79cd\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u5411\u6fc0\u6d3b\u6dfb\u52a0\u5b66\u4e60\u504f\u7f6e\u6765\u63a7\u5236\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u3002\u867d\u7136\u5e73\u5747\u6548\u679c\u6709\u6548\uff0c\u4f46\u5f15\u5bfc\u6548\u679c\u5728\u4e0d\u540c\u6837\u672c\u95f4\u53d8\u5316\u5f88\u5927\uff0c\u5bf9\u8bb8\u591a\u76ee\u6807\u884c\u4e3a\u4e0d\u53ef\u9760\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7a76\u5f15\u5bfc\u53ef\u9760\u6027\u5728\u4e0d\u540c\u884c\u4e3a\u95f4\u5dee\u5f02\u7684\u539f\u56e0\u53ca\u5176\u53d7\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5f15\u5bfc\u5411\u91cf\u8bad\u7ec3\u6570\u636e\u4e0e\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u6765\u63a2\u7a76\u95ee\u9898\uff1a1\uff09\u6d4b\u91cf\u8bad\u7ec3\u6fc0\u6d3b\u5dee\u5f02\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4e0e\u5f15\u5bfc\u53ef\u9760\u6027\u7684\u76f8\u5173\u6027\uff1b2\uff09\u8bc4\u4f30\u884c\u4e3a\u6570\u636e\u96c6\u4e2d\u6b63\u8d1f\u6fc0\u6d3b\u5728\u5f15\u5bfc\u65b9\u5411\u4e0a\u7684\u53ef\u5206\u79bb\u6027\uff1b3\uff09\u6bd4\u8f83\u4e0d\u540c\u63d0\u793a\u53d8\u4f53\u8bad\u7ec3\u7684\u5f15\u5bfc\u5411\u91cf\u7684\u65b9\u5411\u5dee\u5f02\u548c\u6027\u80fd\u8868\u73b0\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\uff1a1\uff09\u8bad\u7ec3\u6fc0\u6d3b\u5dee\u5f02\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8d8a\u9ad8\uff0c\u5f15\u5bfc\u8d8a\u53ef\u9760\uff1b2\uff09\u6b63\u8d1f\u6fc0\u6d3b\u5728\u5f15\u5bfc\u65b9\u5411\u4e0a\u5206\u79bb\u5ea6\u66f4\u597d\u7684\u884c\u4e3a\u6570\u636e\u96c6\u66f4\u6613\u88ab\u53ef\u9760\u5f15\u5bfc\uff1b3\uff09\u4e0d\u540c\u63d0\u793a\u53d8\u4f53\u8bad\u7ec3\u7684\u5f15\u5bfc\u5411\u91cf\u65b9\u5411\u4e0d\u540c\u4f46\u6027\u80fd\u76f8\u4f3c\uff0c\u4e14\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6548\u679c\u76f8\u5173\u3002\u8fd9\u8868\u660e\u5f53\u6f5c\u5728\u76ee\u6807\u884c\u4e3a\u8868\u793a\u65e0\u6cd5\u88ab\u7ebf\u6027\u5f15\u5bfc\u65b9\u5411\u6709\u6548\u8fd1\u4f3c\u65f6\uff0c\u5f15\u5bfc\u5411\u91cf\u4e0d\u53ef\u9760\u3002", "conclusion": "\u5f15\u5bfc\u5411\u91cf\u7684\u4e0d\u53ef\u9760\u6027\u6e90\u4e8e\u6f5c\u5728\u76ee\u6807\u884c\u4e3a\u8868\u793a\u65e0\u6cd5\u88ab\u7ebf\u6027\u65b9\u5411\u6709\u6548\u8fd1\u4f3c\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u8bca\u65ad\u5f15\u5bfc\u4e0d\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff0c\u5e76\u6fc0\u52b1\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u5f15\u5bfc\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5e94\u660e\u786e\u8003\u8651\u975e\u7ebf\u6027\u6f5c\u5728\u884c\u4e3a\u8868\u793a\u3002"}}
{"id": "2602.17667", "categories": ["cs.IR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17667", "abs": "https://arxiv.org/abs/2602.17667", "authors": ["Cheng cheng", "Chenxing Wang", "Aolin Li", "Haijun Wu", "Huiyun Hu", "Juyuan Wang"], "title": "When & How to Write for Personalized Demand-aware Query Rewriting in Video Search", "comment": null, "summary": "In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel \"Fake Recall\" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.", "AI": {"tldr": "WeWrite\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u9700\u6c42\u611f\u77e5\u7684\u67e5\u8be2\u91cd\u5199\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6316\u6398\u7b56\u7565\u3001\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\u548c\u5e76\u884c\u90e8\u7f72\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u89c6\u9891\u641c\u7d22\u7cfb\u7edf\u4e2d\u7528\u6237\u5386\u53f2\u884c\u4e3a\u5229\u7528\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u70b9\u51fb\u7387\u548c\u964d\u4f4e\u4e86\u67e5\u8be2\u91cd\u6784\u7387\u3002", "motivation": "\u4f20\u7edf\u89c6\u9891\u641c\u7d22\u7cfb\u7edf\u5229\u7528\u7528\u6237\u5386\u53f2\u884c\u4e3a\u7279\u5f81\u65f6\u5b58\u5728\u4fe1\u53f7\u7a00\u91ca\u548c\u5ef6\u8fdf\u53cd\u9988\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4e2a\u6027\u5316\u67e5\u8be2\u91cd\u5199\u65b9\u6cd5\u6765\u51c6\u786e\u8bc6\u522b\u641c\u7d22\u610f\u56fe\u548c\u6d88\u9664\u6b67\u4e49\u3002", "method": "\u63d0\u51faWeWrite\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a(1) \u57fa\u4e8e\u540e\u9a8c\u7684\u81ea\u52a8\u5316\u6316\u6398\u7b56\u7565\uff0c\u4ece\u7528\u6237\u65e5\u5fd7\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u8bc6\u522b\u771f\u6b63\u9700\u8981\u4e2a\u6027\u5316\u7684\u573a\u666f\uff1b(2) \u7ed3\u5408\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u7684\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\uff0c\u4f7fLLM\u8f93\u51fa\u98ce\u683c\u4e0e\u68c0\u7d22\u7cfb\u7edf\u5bf9\u9f50\uff1b(3) \u5e76\u884c\"\u865a\u5047\u53ec\u56de\"\u67b6\u6784\u786e\u4fdd\u4f4e\u5ef6\u8fdf\u90e8\u7f72\u3002", "result": "\u5728\u5927\u89c4\u6a21\u89c6\u9891\u5e73\u53f0\u4e0a\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0cWeWrite\u5c06\u70b9\u51fb\u89c2\u770b\u89c6\u9891\u91cf(VV>10s)\u63d0\u5347\u4e861.07%\uff0c\u5e76\u5c06\u67e5\u8be2\u91cd\u6784\u7387\u964d\u4f4e\u4e862.97%\u3002", "conclusion": "WeWrite\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u4e2a\u6027\u5316\u67e5\u8be2\u91cd\u5199\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u6709\u6548\u63d0\u5347\u4e86\u89c6\u9891\u641c\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u771f\u5b9e\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.17907", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17907", "abs": "https://arxiv.org/abs/2602.17907", "authors": ["Raymond Li", "Amirhossein Abaskohi", "Chuyuan Li", "Gabriel Murray", "Giuseppe Carenini"], "title": "Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions", "comment": "20 pages, 5 figures", "summary": "Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u8f6f\u6807\u7b7e\u6765\u8bad\u7ec3\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6295\u5f71\u4e0b\u4e00\u4e2atoken\u6982\u7387\u5230\u9884\u5b9a\u4e49\u8bcd\u6c47\u83b7\u5f97\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u4e3b\u9898\u8d28\u91cf\u548c\u6587\u6863\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\u901a\u5e38\u901a\u8fc7\u91cd\u6784\u6587\u6863\u7684\u8bcd\u888b\u8868\u793a\u8fdb\u884c\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e14\u96be\u4ee5\u5904\u7406\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u8bed\u8a00\u6a21\u578b\u4e30\u5bcc\u8bed\u4e49\u4fe1\u606f\u6765\u63d0\u5347\u4e3b\u9898\u8d28\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u8f6f\u6807\u7b7e\u76ee\u6807\uff1a\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u6761\u4ef6\u5316\uff0c\u6295\u5f71\u4e0b\u4e00\u4e2atoken\u7684\u6982\u7387\u5230\u9884\u5b9a\u4e49\u8bcd\u6c47\u4e0a\uff0c\u83b7\u5f97\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u76d1\u7763\u4fe1\u53f7\u3002\u7136\u540e\u8bad\u7ec3\u4e3b\u9898\u6a21\u578b\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u6765\u91cd\u6784\u8fd9\u4e9b\u8f6f\u6807\u7b7e\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u7eaf\u5ea6\u65b9\u9762\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\u3002\u5f15\u5165\u7684\u57fa\u4e8e\u68c0\u7d22\u7684\u6307\u6807\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u8bed\u4e49\u76f8\u4f3c\u6587\u6863\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u68c0\u7d22\u5bfc\u5411\u7684\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u5229\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u8f6f\u6807\u7b7e\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\u7684\u8d28\u91cf\uff0c\u4ea7\u751f\u66f4\u7b26\u5408\u8bed\u6599\u5e95\u5c42\u4e3b\u9898\u7ed3\u6784\u7684\u9ad8\u8d28\u91cf\u4e3b\u9898\uff0c\u5e76\u5728\u6587\u6863\u68c0\u7d22\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.17826", "categories": ["cs.AI", "cs.LG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.17826", "abs": "https://arxiv.org/abs/2602.17826", "authors": ["Marcelo Labre"], "title": "Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge", "comment": "Submitted to NeuS 2026. Supplementary materials and code: https://doi.org/10.5281/zenodo.18665030", "summary": "Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u5f62\u5f0f\u5316\u9886\u57df\u672c\u4f53\uff08\u7279\u522b\u662fOpenMath\u672c\u4f53\uff09\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6765\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u672c\u4f53\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u5728\u68c0\u7d22\u8d28\u91cf\u9ad8\u65f6\u80fd\u6539\u5584\u6027\u80fd\uff0c\u4f46\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u3001\u8106\u5f31\u6027\u548c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u57fa\u7840\u7b49\u6839\u672c\u6027\u9650\u5236\uff0c\u8fd9\u4e9b\u9650\u5236\u5728\u9700\u8981\u53ef\u9a8c\u8bc1\u63a8\u7406\u7684\u9ad8\u98ce\u9669\u4e13\u4e1a\u9886\u57df\uff08\u5982\u6570\u5b66\uff09\u4e2d\u5c24\u4e3a\u6210\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f62\u5f0f\u5316\u9886\u57df\u672c\u4f53\u662f\u5426\u80fd\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6765\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u7ba1\u9053\uff0c\u5229\u7528OpenMath\u672c\u4f53\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002\u4f7f\u7528\u6df7\u5408\u68c0\u7d22\uff08hybrid retrieval\uff09\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\uff08cross-encoder reranking\uff09\u6280\u672f\uff0c\u5c06\u76f8\u5173\u5b9a\u4e49\u6ce8\u5165\u6a21\u578b\u63d0\u793a\u4e2d\u3002\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u4e86\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u5f53\u68c0\u7d22\u8d28\u91cf\u9ad8\u65f6\uff0c\u672c\u4f53\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u80fd\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff1b\u4f46\u5f53\u68c0\u7d22\u5230\u65e0\u5173\u4e0a\u4e0b\u6587\u65f6\uff0c\u6027\u80fd\u4f1a\u663e\u8457\u4e0b\u964d\u3002\u8fd9\u7a81\u663e\u4e86\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7684\u6f5c\u529b\u548c\u6311\u6218\u3002", "conclusion": "\u5f62\u5f0f\u5316\u9886\u57df\u672c\u4f53\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u53ef\u9760\u6027\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u68c0\u7d22\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u635f\u5bb3\u6027\u80fd\uff0c\u8868\u660e\u9700\u8981\u66f4\u7cbe\u786e\u7684\u68c0\u7d22\u673a\u5236\u6765\u5145\u5206\u53d1\u6325\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.17687", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17687", "abs": "https://arxiv.org/abs/2602.17687", "authors": ["Connor Shorten", "Augustas Skaburskas", "Daniel M. Jones", "Charles Pierse", "Roberto Esposito", "John Trengrove", "Etienne Dilocker", "Bob van Luijt"], "title": "IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering", "comment": "23 pages, 6 figures", "summary": "AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.", "AI": {"tldr": "IRPAPERS\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u89c6\u89c9\u6587\u6863\u5904\u7406\u4e2d\u57fa\u4e8e\u56fe\u50cf\u548c\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u4e0e\u95ee\u7b54\u7cfb\u7edf\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u6df7\u5408\u641c\u7d22\u4f18\u4e8e\u5355\u4e00\u6a21\u6001\uff0c\u56fe\u50cf\u5d4c\u5165\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8d8a\u6587\u672c\u5d4c\u5165\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6587\u672c\u548c\u5173\u7cfb\u6570\u636e\u5904\u7406\u4e0a\u53d6\u5f97\u663e\u8457\u6210\u529f\uff0c\u4f46\u89c6\u89c9\u6587\u6863\u5904\u7406\u76f8\u5bf9\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4f20\u7edf\u7cfb\u7edf\u9700\u8981OCR\u8f6c\u5f55\u5c06\u89c6\u89c9\u6587\u6863\u8f6c\u6362\u4e3a\u6587\u672c\u548c\u5143\u6570\u636e\uff0c\u800c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u76f4\u63a5\u4ece\u6587\u6863\u56fe\u50cf\u8fdb\u884c\u68c0\u7d22\u548c\u751f\u6210\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u57fa\u4e8e\u56fe\u50cf\u7684\u7cfb\u7edf\u4e0e\u5df2\u5efa\u7acb\u7684\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u76f8\u6bd4\u5982\u4f55\uff1f", "method": "\u5f15\u5165IRPAPERS\u57fa\u51c6\uff0c\u5305\u542b166\u7bc7\u79d1\u5b66\u8bba\u6587\u76843,230\u9875\uff0c\u6bcf\u9875\u90fd\u6709\u56fe\u50cf\u548cOCR\u8f6c\u5f55\u3002\u4f7f\u7528180\u4e2a\"\u5927\u6d77\u635e\u9488\"\u95ee\u9898\uff0c\u6bd4\u8f83\u57fa\u4e8e\u56fe\u50cf\u548c\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u4e0e\u95ee\u7b54\u7cfb\u7edf\u3002\u8bc4\u4f30\u4e86\u591a\u79cd\u68c0\u7d22\u65b9\u6cd5\uff08Arctic 2.0\u5d4c\u5165\u3001BM25\u3001\u6df7\u5408\u641c\u7d22\uff09\u3001\u591a\u6a21\u6001\u6df7\u5408\u641c\u7d22\u3001\u6548\u7387-\u6027\u80fd\u6743\u8861\uff08MUVERA\uff09\u4ee5\u53ca\u591a\u4e2a\u591a\u5411\u91cf\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\u3002\u5bf9\u4e8e\u95ee\u7b54\u7cfb\u7edf\uff0c\u8bc4\u4f30\u4e86\u57fa\u4e8e\u6587\u672c\u548c\u57fa\u4e8e\u56fe\u50cf\u7684RAG\u7cfb\u7edf\u3002", "result": "\u6587\u672c\u68c0\u7d22\u8fbe\u523046% Recall@1\u300178% Recall@5\u548c91% Recall@20\uff0c\u56fe\u50cf\u68c0\u7d22\u8fbe\u523043%\u300178%\u548c93%\u3002\u4e24\u79cd\u6a21\u6001\u8868\u73b0\u51fa\u4e92\u8865\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u4f7f\u591a\u6a21\u6001\u6df7\u5408\u641c\u7d22\u4f18\u4e8e\u4efb\u4e00\u5355\u4e00\u6a21\u6001\uff0849% Recall@1\u300181% Recall@5\u300195% Recall@20\uff09\u3002\u5728\u95ed\u6e90\u6a21\u578b\u4e2d\uff0cCohere Embed v4\u9875\u9762\u56fe\u50cf\u5d4c\u5165\u4f18\u4e8eVoyage 3 Large\u6587\u672c\u5d4c\u5165\u548c\u6240\u6709\u6d4b\u8bd5\u7684\u5f00\u6e90\u6a21\u578b\uff0858% Recall@1\u300187% Recall@5\u300197% Recall@20\uff09\u3002\u5bf9\u4e8e\u95ee\u7b54\uff0c\u57fa\u4e8e\u6587\u672c\u7684RAG\u7cfb\u7edf\u6bd4\u57fa\u4e8e\u56fe\u50cf\u7684\u7cfb\u7edf\u5177\u6709\u66f4\u9ad8\u7684\u771f\u5b9e\u5bf9\u9f50\u5ea6\uff080.82 vs. 0.71\uff09\uff0c\u4e24\u8005\u90fd\u4ece\u589e\u52a0\u68c0\u7d22\u6df1\u5ea6\u4e2d\u663e\u8457\u53d7\u76ca\u3002", "conclusion": "\u7814\u7a76\u5206\u6790\u4e86\u5355\u6a21\u6001\u6587\u672c\u548c\u56fe\u50cf\u8868\u793a\u7684\u4e92\u8865\u5c40\u9650\u6027\uff0c\u5e76\u786e\u5b9a\u4e86\u9700\u8981\u4e00\u79cd\u6a21\u6001\u800c\u975e\u53e6\u4e00\u79cd\u7684\u95ee\u9898\u7c7b\u578b\u3002\u591a\u6a21\u6001\u6df7\u5408\u641c\u7d22\u5728\u89c6\u89c9\u6587\u6863\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u56fe\u50cf\u5d4c\u5165\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u8d85\u8d8a\u6587\u672c\u5d4c\u5165\u3002IRPAPERS\u6570\u636e\u96c6\u548c\u6240\u6709\u5b9e\u9a8c\u4ee3\u7801\u5df2\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2602.17911", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17911", "abs": "https://arxiv.org/abs/2602.17911", "authors": ["Jash Rajesh Parekh", "Wonbin Kweon", "Joey Chan", "Rezarta Islamaj", "Robert Leaman", "Pengcheng Jiang", "Chih-Hsuan Wei", "Zhizheng Wang", "Zhiyong Lu", "Jiawei Han"], "title": "Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering", "comment": null, "summary": "Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.", "AI": {"tldr": "CondMedQA\u662f\u9996\u4e2a\u6761\u4ef6\u751f\u7269\u533b\u5b66\u95ee\u7b54\u57fa\u51c6\uff0c\u63d0\u51fa\u6761\u4ef6\u95e8\u63a7\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u6761\u4ef6\u611f\u77e5\u77e5\u8bc6\u56fe\u8c31\u548c\u9009\u62e9\u6027\u6fc0\u6d3b\u63a8\u7406\u8def\u5f84\u6765\u63d0\u5347\u6761\u4ef6\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u533b\u5b66\u95ee\u7b54\u7cfb\u7edf\u5047\u8bbe\u533b\u5b66\u77e5\u8bc6\u666e\u904d\u9002\u7528\uff0c\u4f46\u771f\u5b9e\u4e34\u5e8a\u63a8\u7406\u672c\u8d28\u4e0a\u662f\u6761\u4ef6\u6027\u7684\u2014\u2014\u51e0\u4e4e\u6240\u6709\u51b3\u7b56\u90fd\u4f9d\u8d56\u4e8e\u60a3\u8005\u7279\u5b9a\u56e0\u7d20\u3002\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u8bc4\u4f30\u6b64\u7c7b\u6761\u4ef6\u63a8\u7406\uff0c\u68c0\u7d22\u589e\u5f3a\u6216\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u7f3a\u4e4f\u786e\u4fdd\u68c0\u7d22\u77e5\u8bc6\u9002\u7528\u4e8e\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u7684\u660e\u786e\u673a\u5236\u3002", "method": "\u63d0\u51fa\u6761\u4ef6\u95e8\u63a7\u63a8\u7406\u6846\u67b6\uff1a1) \u6784\u5efa\u6761\u4ef6\u611f\u77e5\u77e5\u8bc6\u56fe\u8c31\uff1b2) \u57fa\u4e8e\u67e5\u8be2\u6761\u4ef6\u9009\u62e9\u6027\u6fc0\u6d3b\u6216\u526a\u679d\u63a8\u7406\u8def\u5f84\u3002\u540c\u65f6\u521b\u5efaCondMedQA\u57fa\u51c6\uff0c\u5305\u542b\u7b54\u6848\u968f\u60a3\u8005\u6761\u4ef6\u53d8\u5316\u7684\u591a\u8df3\u95ee\u9898\u3002", "result": "CGR\u6846\u67b6\u5728\u53ef\u9760\u9009\u62e9\u6761\u4ef6\u9002\u5f53\u7b54\u6848\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u5728\u751f\u7269\u533b\u5b66\u95ee\u7b54\u57fa\u51c6\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7a81\u663e\u663e\u5f0f\u5efa\u6a21\u6761\u4ef6\u6027\u5bf9\u7a33\u5065\u533b\u5b66\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u6761\u4ef6\u6027\u5bf9\u4e8e\u7a33\u5065\u533b\u5b66\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0cCondMedQA\u57fa\u51c6\u548cCGR\u6846\u67b6\u4e3a\u89e3\u51b3\u751f\u7269\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u6761\u4ef6\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.17831", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17831", "abs": "https://arxiv.org/abs/2602.17831", "authors": ["Simon Henniger", "Gabriel Poesia"], "title": "The Token Games: Evaluating Language Model Reasoning with Puzzle Duels", "comment": "Project website: https://token-games.ai/", "summary": "Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.", "AI": {"tldr": "TTG\u662f\u4e00\u4e2a\u57fa\u4e8e16\u4e16\u7eaa\u6570\u5b66\u51b3\u6597\u542f\u53d1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u76f8\u4e92\u521b\u5efa\u7f16\u7a0b\u8c1c\u9898\u6765\u6311\u6218\u5bf9\u65b9\uff0c\u4ece\u800c\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u9762\u4e34\u6311\u6218\uff1a\u4eba\u5de5\u6807\u6ce8\u9ad8\u8d28\u91cf\u96be\u9898\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u96be\u4ee5\u786e\u5b9a\u6a21\u578b\u662f\u5426\u771f\u6b63\u63a8\u7406\u8fd8\u662f\u4ec5\u89c1\u8fc7\u7c7b\u4f3c\u8bad\u7ec3\u6570\u636e\u3002\u9700\u8981\u4e00\u79cd\u65e0\u6cd5\u901a\u8fc7\u8bbe\u8ba1\u9971\u548c\u3001\u80fd\u6d4b\u8bd5\u771f\u5b9e\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u53d716\u4e16\u7eaa\u6570\u5b66\u51b3\u6597\u542f\u53d1\uff0c\u8bbe\u8ba1Token Games\u6846\u67b6\uff1a\u6a21\u578b\u901a\u8fc7\u521b\u5efa\u7f16\u7a0b\u8c1c\u9898\u76f8\u4e92\u6311\u6218\uff08\u7ed9\u5b9a\u8fd4\u56de\u5e03\u5c14\u503c\u7684Python\u51fd\u6570\uff0c\u5bfb\u627e\u4f7f\u5176\u8fd4\u56deTrue\u7684\u8f93\u5165\uff09\u3002\u4f7f\u7528\u4e24\u4e24\u5bf9\u51b3\u7ed3\u679c\u8ba1\u7b97Elo\u8bc4\u5206\uff0c\u76f8\u5bf9\u6bd4\u8f83\u6a21\u578b\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u4e8610\u4e2a\u524d\u6cbf\u6a21\u578b\uff0cTTG\u6392\u540d\u4e0e\u73b0\u6709\u57fa\u51c6\uff08\u5982Humanity's Last Exam\uff09\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u521b\u5efa\u8c1c\u9898\u3002\u53d1\u73b0\u521b\u5efa\u9ad8\u8d28\u91cf\u8c1c\u9898\u5bf9\u5f53\u524d\u6a21\u578b\u4ecd\u6781\u5177\u6311\u6218\uff0c\u8fd9\u662f\u5148\u524d\u57fa\u51c6\u672a\u6d4b\u91cf\u7684\u80fd\u529b\u3002", "conclusion": "TTG\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6cd5\u901a\u8fc7\u8bbe\u8ba1\u9971\u548c\u7684\u63a8\u7406\u8bc4\u4f30\u65b0\u8303\u5f0f\uff0c\u80fd\u591f\u540c\u65f6\u6d4b\u8bd5\u6a21\u578b\u7684\u95ee\u9898\u89e3\u51b3\u3001\u521b\u9020\u529b\u548c\u4efb\u52a1\u521b\u5efa\u80fd\u529b\uff0c\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.17856", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17856", "abs": "https://arxiv.org/abs/2602.17856", "authors": ["Hamideh Ghanadian", "Amin Kamali", "Mohammad Hossein Tekieh"], "title": "Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems", "comment": null, "summary": "This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5411\u91cf\u548c\u56fe\u6570\u636e\u5e93\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u5728\u79d1\u5b66\u6587\u732e\u804a\u5929\u673a\u5668\u4eba\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u6df7\u5408\u68c0\u7d22\u65b9\u6cd5\u63d0\u5347\u79d1\u5b66\u77e5\u8bc6\u83b7\u53d6\u6548\u7387", "motivation": "\u65e8\u5728\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u63d0\u5347\u79d1\u5b66\u6587\u732e\u804a\u5929\u673a\u5668\u4eba\u7684\u6027\u80fd\uff0c\u6539\u5584\u79d1\u5b66\u77e5\u8bc6\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u7684\u51b3\u7b56\u5236\u5b9a", "method": "\u63d0\u51fa\u7ed3\u5408\u7ed3\u6784\u5316(\u56fe)\u548c\u975e\u7ed3\u6784\u5316(\u5411\u91cf)\u6570\u636e\u5e93\u7684\u6df7\u5408RAG\u7cfb\u7edf\uff0c\u8bbe\u8ba1\u4e24\u79cd\u4f7f\u7528\u573a\u666f\uff1a\u5355\u6587\u6863\u68c0\u7d22\u548c\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u68c0\u7d22\uff0c\u4f7f\u7528GPT\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u96c6\u5e76\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\u8bc4\u4f30", "result": "\u6bd4\u8f83\u5206\u6790\u663e\u793a\u6df7\u5408RAG\u7cfb\u7edf\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u54cd\u5e94\u76f8\u5173\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u591f\u6839\u636e\u7814\u7a76\u76ee\u6807\u6709\u6548\u7b5b\u9009\u79d1\u5b66\u6587\u732e\u548c\u7070\u8272\u6587\u732e\u6765\u6e90", "conclusion": "\u6df7\u5408RAG\u7cfb\u7edf\u5728\u63d0\u5347\u79d1\u5b66\u77e5\u8bc6\u53ef\u8bbf\u95ee\u6027\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u652f\u6301\u8bc1\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4e3a\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u65b9\u6848"}}
{"id": "2602.17937", "categories": ["cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.17937", "abs": "https://arxiv.org/abs/2602.17937", "authors": ["Xiaotang Du", "Giwon Hong", "Wai-Chung Kwan", "Rohit Saxena", "Ivan Titov", "Pasquale Minervini", "Emily Allaway"], "title": "Analyzing LLM Instruction Optimization for Tabular Fact Verification", "comment": null, "summary": "Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u57fa\u4e8eDSPy\u4f18\u5316\u6846\u67b6\u7684\u6307\u4ee4\u4f18\u5316\u65b9\u6cd5\u5728\u8868\u683c\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u63d0\u793a\u6280\u672f\uff0c\u53d1\u73b0\u6307\u4ee4\u4f18\u5316\u80fd\u6301\u7eed\u63d0\u5347\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u4e0d\u540c\u4f18\u5316\u5668\u5bf9\u4e0d\u540c\u63d0\u793a\u6280\u672f\u6709\u7279\u5b9a\u4f18\u52bf\u3002", "motivation": "\u6307\u4ee4\u4f18\u5316\u4e3a\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6027\u80fd\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8868\u683c\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u6307\u4ee4\u4f18\u5316\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u7814\u7a76\uff0c\u7279\u522b\u662f\u57fa\u4e8eDSPy\u6846\u67b6\u7684\u4f18\u5316\u65b9\u6cd5\u5728\u4e0d\u540c\u63d0\u793a\u6280\u672f\u548c\u6a21\u578b\u89c4\u6a21\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u57fa\u4e8eDSPy\u4f18\u5316\u6846\u67b6\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u63d0\u793a\u6280\u672f\uff1a\u76f4\u63a5\u9884\u6d4b\u3001\u601d\u7ef4\u94fe(CoT)\u3001\u4f7f\u7528SQL\u5de5\u5177\u7684ReAct\u3001\u4f7f\u7528Python\u6267\u884c\u7684CodeAct\u3002\u7814\u7a76\u4e86DSPy\u6846\u67b6\u4e2d\u7684\u4e09\u79cd\u4f18\u5316\u5668\u2014\u2014COPRO\u3001MiPROv2\u548cSIMBA\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e09\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u6307\u4ee4\u4f18\u5316\u6301\u7eed\u63d0\u5347\u9a8c\u8bc1\u51c6\u786e\u7387\uff1aMiPROv2\u5728CoT\u4e0a\u83b7\u5f97\u6700\u7a33\u5b9a\u7684\u589e\u76ca\uff0cSIMBA\u4e3aReAct\u667a\u80fd\u4f53\u63d0\u4f9b\u6700\u5927\u6536\u76ca\uff0c\u7279\u522b\u662f\u5728\u8f83\u5927\u6a21\u578b\u89c4\u6a21\u4e0b\u3002\u884c\u4e3a\u5206\u6790\u663e\u793aSIMBA\u901a\u8fc7\u5e94\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u9f13\u52b1\u66f4\u76f4\u63a5\u7684\u63a8\u7406\u8def\u5f84\uff0c\u4ece\u800c\u63d0\u5347CoT\u63a8\u7406\u4e2d\u7684\u6570\u503c\u6bd4\u8f83\u80fd\u529b\uff0c\u5e76\u5e2e\u52a9ReAct\u667a\u80fd\u4f53\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5de5\u5177\u8c03\u7528\u3002", "conclusion": "\u5bf9\u4e8e\u8868\u683c\u4e8b\u5b9e\u68c0\u67e5\uff0cCoT\u4ecd\u7136\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u8f83\u5c0f\u6a21\u578b\u4e2d\u3002\u867d\u7136\u4f7f\u7528\u8f83\u5927\u6a21\u578b\u6784\u5efa\u7684ReAct\u667a\u80fd\u4f53\u53ef\u4ee5\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u7684\u6307\u4ee4\u4f18\u5316\u3002\u4e0d\u540c\u4f18\u5316\u5668\u5bf9\u4e0d\u540c\u63d0\u793a\u6280\u672f\u6709\u7279\u5b9a\u4f18\u52bf\uff0cSIMBA\u5728\u9f13\u52b1\u76f4\u63a5\u63a8\u7406\u8def\u5f84\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2602.18107", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18107", "abs": "https://arxiv.org/abs/2602.18107", "authors": ["Andrew Parry", "Debasis Ganguly", "Sean MacAvaney"], "title": "SuiteEval: Simplifying Retrieval Benchmarks", "comment": "5 pages, 3 figures, 2 tables, Accepted as a Demonstration to ECIR 2026", "summary": "Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.", "AI": {"tldr": "SuiteEval\u662f\u4e00\u4e2a\u7edf\u4e00\u7684IR\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u4f9b\u81ea\u52a8\u7aef\u5230\u7aef\u8bc4\u4f30\u3001\u52a8\u6001\u7d22\u5f15\u91cd\u7528\u4ee5\u51cf\u5c11\u78c1\u76d8\u4f7f\u7528\uff0c\u5e76\u652f\u6301\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3IR\u8bc4\u4f30\u4e2d\u788e\u7247\u5316\u5b9e\u8df5\u7684\u95ee\u9898\u3002", "motivation": "\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u5b58\u5728\u788e\u7247\u5316\u5b9e\u8df5\u95ee\u9898\uff0c\u5305\u62ec\u4e0d\u540c\u7684\u6570\u636e\u96c6\u5b50\u96c6\u3001\u805a\u5408\u65b9\u6cd5\u548c\u7ba1\u9053\u914d\u7f6e\uff0c\u8fd9\u635f\u5bb3\u4e86\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6bd4\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u5f3a\u5927\u8de8\u57df\u6027\u80fd\u7684\u57fa\u7840\u5d4c\u5165\u6a21\u578b\u3002", "method": "\u63d0\u51faSuiteEval\u6846\u67b6\uff0c\u63d0\u4f9b\u81ea\u52a8\u7aef\u5230\u7aef\u8bc4\u4f30\u3001\u52a8\u6001\u7d22\u5f15\u91cd\u7528\u78c1\u76d8\u7d22\u5f15\u4ee5\u6700\u5c0f\u5316\u78c1\u76d8\u4f7f\u7528\uff0c\u5185\u7f6e\u652f\u6301\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\uff08BEIR\u3001LoTTE\u3001MS MARCO\u3001NanoBEIR\u548cBRIGHT\uff09\u3002\u7528\u6237\u53ea\u9700\u63d0\u4f9b\u7ba1\u9053\u751f\u6210\u5668\uff0c\u6846\u67b6\u5904\u7406\u6570\u636e\u52a0\u8f7d\u3001\u7d22\u5f15\u3001\u6392\u5e8f\u3001\u6307\u6807\u8ba1\u7b97\u548c\u7ed3\u679c\u805a\u5408\u3002", "result": "SuiteEval\u51cf\u5c11\u4e86\u6837\u677f\u4ee3\u7801\u5e76\u6807\u51c6\u5316\u4e86\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4fc3\u8fdb\u4e86\u53ef\u91cd\u73b0\u7684IR\u7814\u7a76\uff0c\u6ee1\u8db3\u4e86\u65e5\u76ca\u589e\u957f\u7684\u66f4\u5e7f\u6cdb\u57fa\u51c6\u6d4b\u8bd5\u9700\u6c42\u3002", "conclusion": "SuiteEval\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u89e3\u51b3\u4e86IR\u8bc4\u4f30\u4e2d\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u3001\u53ef\u91cd\u73b0\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u652f\u6301\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\uff0c\u51cf\u5c11\u4e86\u7814\u7a76\u4eba\u5458\u7684\u91cd\u590d\u5de5\u4f5c\u3002"}}
{"id": "2602.17949", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17949", "abs": "https://arxiv.org/abs/2602.17949", "authors": ["Victoria Blake", "Mathew Miller", "Jamie Novak", "Sze-yuan Ooi", "Blanca Gallego"], "title": "CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications", "comment": "30 pages, 6 figures, 4 tables", "summary": "Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.", "AI": {"tldr": "CUICurate\uff1a\u57fa\u4e8e\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684UMLS\u6982\u5ff5\u96c6\u81ea\u52a8\u6784\u5efa\u6846\u67b6\uff0c\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u4e0eLLM\u63a8\u7406\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf", "motivation": "\u4e34\u5e8a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u5de5\u5177\u901a\u5e38\u5c06\u81ea\u7531\u6587\u672c\u6620\u5c04\u5230UMLS\u6982\u5ff5\u552f\u4e00\u6807\u8bc6\u7b26(CUIs)\uff0c\u4f46\u8bb8\u591a\u4e0b\u6e38\u4efb\u52a1\u9700\u8981\u7684\u662f\u5305\u542b\u76f8\u5173\u540c\u4e49\u8bcd\u3001\u5b50\u7c7b\u578b\u548c\u8d85\u7c7b\u578b\u7684\u6982\u5ff5\u96c6\u3002\u76ee\u524d\u6784\u5efa\u8fd9\u7c7b\u6982\u5ff5\u96c6\u52b3\u52a8\u5bc6\u96c6\u3001\u6267\u884c\u4e0d\u4e00\u81f4\uff0c\u4e14\u73b0\u6709\u5de5\u5177\u652f\u6301\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u76f4\u63a5\u5728UMLS CUIs\u4e0a\u64cd\u4f5c\u7684NLP\u7ba1\u9053\u3002", "method": "\u63d0\u51faCUICurate\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff1a1)\u6784\u5efa\u5e76\u5d4c\u5165UMLS\u77e5\u8bc6\u56fe\u8c31\u7528\u4e8e\u8bed\u4e49\u68c0\u7d22\uff1b2)\u9488\u5bf9\u6bcf\u4e2a\u76ee\u6807\u6982\u5ff5\uff0c\u4ece\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u5019\u9009CUIs\uff1b3)\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8fc7\u6ee4\u548c\u5206\u7c7b\uff0c\u6bd4\u8f83\u4e86GPT-5\u548cGPT-5-mini\u4e24\u79cd\u6a21\u578b\u3002", "result": "\u5728\u4e94\u4e2a\u8bcd\u6c47\u5f02\u8d28\u6027\u4e34\u5e8a\u6982\u5ff5\u4e0a\u8bc4\u4f30\uff0cCUICurate\u751f\u6210\u7684\u6982\u5ff5\u96c6\u6bd4\u4eba\u5de5\u57fa\u51c6\u66f4\u5927\u66f4\u5b8c\u6574\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u7cbe\u786e\u5ea6\u3002GPT-5-mini\u5728\u8fc7\u6ee4\u9636\u6bb5\u53ec\u56de\u7387\u66f4\u9ad8\uff0cGPT-5\u7684\u5206\u7c7b\u7ed3\u679c\u66f4\u7b26\u5408\u4e34\u5e8a\u533b\u751f\u5224\u65ad\u3002\u8f93\u51fa\u5728\u91cd\u590d\u8fd0\u884c\u4e2d\u7a33\u5b9a\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "CUICurate\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\u6765\u652f\u6301UMLS\u6982\u5ff5\u96c6\u6784\u5efa\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u4e0eLLM\u63a8\u7406\uff0c\u8be5\u6846\u67b6\u751f\u6210\u805a\u7126\u7684\u5019\u9009\u6982\u5ff5\u96c6\uff0c\u53ef\u9002\u5e94\u4e0d\u540c\u8868\u578b\u548c\u5206\u6790\u9700\u6c42\u7684\u4e34\u5e8aNLP\u7ba1\u9053\u3002"}}
{"id": "2602.18206", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18206", "abs": "https://arxiv.org/abs/2602.18206", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Ronghua Li", "Guoren Wang"], "title": "A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering", "comment": null, "summary": "Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.", "AI": {"tldr": "\u63d0\u51faPSP-NS\u8d1f\u91c7\u6837\u63d2\u4ef6\uff0c\u901a\u8fc7\u589e\u5f3a\u6b63\u6837\u672c\u76d1\u7763\u4fe1\u53f7\u6765\u6539\u8fdb\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u6b63\u6837\u672c\u63a2\u7d22\u548c\u7528\u6237\u6d3b\u8dc3\u5ea6\u504f\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u9ad8\u8d28\u91cf\u8d1f\u6837\u672c\u8bbe\u8ba1\uff0c\u4f46\u5ffd\u89c6\u4e86\u6b63\u6837\u672c\u7684\u63a2\u7d22\u3002\u867d\u7136\u4e00\u4e9b\u53bb\u566a\u63a8\u8350\u65b9\u6cd5\u53ef\u7528\u4e8e\u9690\u5f0fCF\uff0c\u4f46\u5f80\u5f80\u4f1a\u7a00\u758f\u5316\u6b63\u6837\u672c\u76d1\u7763\u4fe1\u53f7\uff0c\u5e76\u4e14\u666e\u904d\u5ffd\u7565\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7528\u6237\u6d3b\u8dc3\u5ea6\u504f\u5dee\uff0c\u5bfc\u81f4\u5bf9\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u5b66\u4e60\u4e0d\u8db3\u3002", "method": "\u63d0\u51faPSP-NS\u8d1f\u91c7\u6837\u63d2\u4ef6\uff1a1\uff09\u6784\u5efa\u7528\u6237-\u7269\u54c1\u4e8c\u90e8\u56fe\uff0c\u8fb9\u6743\u91cd\u8868\u793a\u57fa\u4e8e\u5168\u5c40\u548c\u5c40\u90e8\u6a21\u5f0f\u63a8\u65ad\u7684\u4ea4\u4e92\u7f6e\u4fe1\u5ea6\uff1b2\uff09\u901a\u8fc7\u57fa\u4e8e\u590d\u5236\u7684\u91cd\u52a0\u6743\u751f\u6210\u6b63\u6837\u672c\u5bf9\u4ee5\u589e\u5f3a\u6b63\u4fe1\u53f7\uff1b3\uff09\u91c7\u7528\u6d3b\u52a8\u611f\u77e5\u52a0\u6743\u65b9\u6848\u6709\u6548\u5b66\u4e60\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u504f\u597d\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660ePSP-NS\u7684\u4f18\u8d8a\u6027\u3002\u4f8b\u5982\uff0c\u5728Yelp\u6570\u636e\u96c6\u4e0a\uff0cPSP-NS\u5c06Recall@30\u548cPrecision@30\u5206\u522b\u63d0\u9ad8\u4e8632.11%\u548c22.90%\uff08\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\uff09\u3002PSP-NS\u53ef\u4e0e\u5404\u79cd\u9690\u5f0fCF\u63a8\u8350\u5668\u6216\u8d1f\u91c7\u6837\u65b9\u6cd5\u96c6\u6210\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "PSP-NS\u662f\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u8d1f\u91c7\u6837\u63d2\u4ef6\uff0c\u901a\u8fc7\u589e\u5f3a\u6b63\u6837\u672c\u76d1\u7763\u4fe1\u53f7\u548c\u8003\u8651\u7528\u6237\u6d3b\u8dc3\u5ea6\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u7684\u6392\u5e8f\u8d28\u91cf\uff0c\u4e3a\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.17981", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17981", "abs": "https://arxiv.org/abs/2602.17981", "authors": ["Amine Kobeissi", "Philippe Langlais"], "title": "Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering", "comment": null, "summary": "Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u91d1\u878d\u95ee\u7b54\u4e2d\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u5931\u8d25\u6a21\u5f0f\uff1a\u6b63\u786e\u6587\u6863\u88ab\u68c0\u7d22\u5230\uff0c\u4f46\u5305\u542b\u7b54\u6848\u7684\u5177\u4f53\u9875\u9762\u6216\u5757\u88ab\u9057\u6f0f\uff0c\u5bfc\u81f4\u751f\u6210\u5668\u57fa\u4e8e\u4e0d\u5b8c\u6574\u4e0a\u4e0b\u6587\u8fdb\u884c\u63a8\u65ad\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u9886\u57df\u5fae\u8c03\u7684\u9875\u9762\u8bc4\u5206\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9875\u9762\u53ec\u56de\u7387\u548c\u5757\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5728\u91d1\u878d\u76d1\u7ba1\u6587\u4ef6\u95ee\u7b54\u4e2d\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u867d\u7136\u5e38\u7528\uff0c\u4f46\u5176\u53ef\u9760\u6027\u4f9d\u8d56\u4e8e\u68c0\u7d22\u5230\u786e\u5207\u7684\u4e0a\u4e0b\u6587\u6765\u652f\u6301\u7b54\u6848\u3002\u4f5c\u8005\u5173\u6ce8\u4e00\u4e2a\u5e38\u89c1\u7684\u5931\u8d25\u6a21\u5f0f\uff1a\u6b63\u786e\u6587\u6863\u88ab\u68c0\u7d22\u5230\uff0c\u4f46\u5305\u542b\u7b54\u6848\u7684\u5177\u4f53\u9875\u9762\u6216\u5757\u88ab\u9057\u6f0f\uff0c\u5bfc\u81f4\u751f\u6210\u5668\u57fa\u4e8e\u4e0d\u5b8c\u6574\u4e0a\u4e0b\u6587\u8fdb\u884c\u63a8\u65ad\u3002\u5c3d\u7ba1\u8fd9\u79cd\u6587\u6863\u5185\u68c0\u7d22\u5931\u8d25\u6a21\u5f0f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u5728\u91d1\u878d\u95ee\u7b54\u6587\u732e\u4e2d\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002", "method": "1. \u5728FinanceBench\u7684150\u4e2a\u95ee\u9898\u5b50\u96c6\u4e0a\u8bc4\u4f30\u591a\u7c92\u5ea6\u68c0\u7d22\uff08\u6587\u6863\u3001\u9875\u9762\u3001\u5757\u7ea7\u522b\uff09\uff1b2. \u5f15\u5165\u57fa\u4e8eoracle\u7684\u5206\u6790\u6765\u63d0\u4f9b\u68c0\u7d22\u548c\u751f\u6210\u6027\u80fd\u7684\u7ecf\u9a8c\u4e0a\u754c\uff1b3. \u590d\u73b0\u548c\u6bd4\u8f83\u591a\u79cd\u68c0\u7d22\u7b56\u7565\uff08\u5bc6\u96c6\u3001\u7a00\u758f\u3001\u6df7\u5408\u3001\u5206\u5c42\u65b9\u6cd5\uff0c\u5305\u62ec\u91cd\u6392\u5e8f\u548c\u67e5\u8be2\u91cd\u6784\uff09\uff1b4. \u63d0\u51fa\u9886\u57df\u5fae\u8c03\u7684\u9875\u9762\u8bc4\u5206\u5668\uff0c\u5c06\u9875\u9762\u4f5c\u4e3a\u6587\u6863\u548c\u5757\u4e4b\u95f4\u7684\u4e2d\u95f4\u68c0\u7d22\u5355\u5143\uff0c\u4e13\u95e8\u9488\u5bf9\u91d1\u878d\u6587\u4ef6\u5fae\u8c03\u53cc\u7f16\u7801\u5668\u4ee5\u8bc4\u4f30\u9875\u9762\u7ea7\u76f8\u5173\u6027\u3002", "result": "1. \u8de8\u65b9\u6cd5\u5206\u6790\u663e\u793a\uff0c\u6587\u6863\u53d1\u73b0\u7387\u7684\u63d0\u5347\u5f80\u5f80\u8f6c\u5316\u4e3a\u66f4\u5f3a\u7684\u9875\u9762\u53ec\u56de\u7387\uff1b2. Oracle\u6027\u80fd\u8868\u660e\u9875\u9762\u548c\u5757\u7ea7\u68c0\u7d22\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff1b3. \u63d0\u51fa\u7684\u9886\u57df\u5fae\u8c03\u9875\u9762\u8bc4\u5206\u5668\u663e\u8457\u63d0\u5347\u4e86\u9875\u9762\u53ec\u56de\u7387\u548c\u5757\u68c0\u7d22\u6027\u80fd\uff1b4. \u5229\u7528\u9875\u9762\u7684\u8bed\u4e49\u8fde\u8d2f\u6027\uff0c\u5728\u91d1\u878d\u6587\u4ef6\u4e0a\u4e13\u95e8\u5fae\u8c03\u7684\u53cc\u7f16\u7801\u5668\u4f18\u4e8e\u5148\u524d\u57fa\u4e8e\u6bb5\u843d\u7684\u5206\u5c42\u68c0\u7d22\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86\u91d1\u878d\u95ee\u7b54\u4e2d\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6587\u6863\u5185\u68c0\u7d22\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5f15\u5165\u9886\u57df\u5fae\u8c03\u7684\u9875\u9762\u8bc4\u5206\u5668\uff0c\u663e\u8457\u6539\u5584\u4e86\u9875\u9762\u7ea7\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u9ad8\u98ce\u9669\u7684\u91d1\u878d\u95ee\u7b54\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u91d1\u878d\u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u4f18\u5316\u4e2d\u95f4\u7c92\u5ea6\u68c0\u7d22\u5355\u5143\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.17990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17990", "abs": "https://arxiv.org/abs/2602.17990", "authors": ["Madhav Kanda", "Pedro Las-Casas", "Alok Gautam Kumbhare", "Rodrigo Fonseca", "Sharad Agarwal"], "title": "WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics", "comment": null, "summary": "LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.", "AI": {"tldr": "WorkflowPerturb\uff1a\u4e00\u4e2a\u7528\u4e8e\u7814\u7a76\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6307\u6807\u7684\u53d7\u63a7\u57fa\u51c6\uff0c\u901a\u8fc7\u5bf9\u9ec4\u91d1\u5de5\u4f5c\u6d41\u5e94\u7528\u73b0\u5b9e\u6270\u52a8\u6765\u8bc4\u4f30\u6307\u6807\u654f\u611f\u6027\u548c\u6821\u51c6\u5ea6", "motivation": "LLM\u751f\u6210\u7684\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u8bc4\u4f30\u56f0\u96be\uff0c\u56e0\u4e3a\u6307\u6807\u5206\u6570\u901a\u5e38\u672a\u6821\u51c6\uff0c\u4e14\u5206\u6570\u53d8\u5316\u4e0d\u80fd\u76f4\u63a5\u53cd\u6620\u5de5\u4f5c\u6d41\u9000\u5316\u7684\u4e25\u91cd\u7a0b\u5ea6", "method": "\u521b\u5efa\u5305\u542b4,973\u4e2a\u9ec4\u91d1\u5de5\u4f5c\u6d41\u548c44,757\u4e2a\u6270\u52a8\u53d8\u4f53\u7684\u57fa\u51c6\uff0c\u5e94\u7528\u4e09\u79cd\u6270\u52a8\u7c7b\u578b\uff08\u7f3a\u5931\u6b65\u9aa4\u3001\u538b\u7f29\u6b65\u9aa4\u3001\u63cf\u8ff0\u53d8\u5316\uff09\uff0c\u6bcf\u79cd\u572810%\u300130%\u300150%\u4e25\u91cd\u7ea7\u522b\u4e0a\u5b9e\u65bd\uff0c\u7136\u540e\u8bc4\u4f30\u591a\u4e2a\u6307\u6807\u5bb6\u65cf\u7684\u654f\u611f\u6027\u548c\u6821\u51c6\u5ea6", "result": "\u7ed3\u679c\u63ed\u793a\u4e86\u4e0d\u540c\u6307\u6807\u5bb6\u65cf\u95f4\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u652f\u6301\u57fa\u4e8e\u4e25\u91cd\u7a0b\u5ea6\u7684\u5de5\u4f5c\u6d41\u8bc4\u4f30\u5206\u6570\u89e3\u91ca\uff0c\u6570\u636e\u96c6\u5c06\u5728\u63a5\u53d7\u540e\u53d1\u5e03", "conclusion": "WorkflowPerturb\u4e3a\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6307\u6807\u63d0\u4f9b\u4e86\u53d7\u63a7\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6307\u6807\u654f\u611f\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u652f\u6301\u66f4\u51c6\u786e\u7684\u5de5\u4f5c\u6d41\u8d28\u91cf\u8bc4\u4f30"}}
{"id": "2602.18221", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18221", "abs": "https://arxiv.org/abs/2602.18221", "authors": ["Teddy Lazebnik"], "title": "The Economical-Ecological Benefits of Matching Non-matching Socks", "comment": null, "summary": "Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \\say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u4e86\u914d\u5bf9\u4e0d\u5339\u914d\u7684\"\u5b64\u513f\"\u889c\u5b50\u7684\u7ecf\u6d4e\u751f\u6001\u4ef7\u503c\uff0c\u5206\u6790\u4e86\u963b\u788d\u8fd9\u79cd\u884c\u4e3a\u7684\u793e\u4f1a\u6210\u672c\uff0c\u901a\u8fc7\u5efa\u6a21\u548c\u5b9e\u9a8c\u8bc1\u660e\u5bb9\u5fcd\u4e00\u5b9a\u7a0b\u5ea6\u7684\u4e0d\u5339\u914d\u6bd4\u4e25\u683c\u914d\u5bf9\u66f4\u8282\u7ea6\u8d44\u6e90\u3002", "motivation": "\u889c\u5b50\u7684\u5927\u89c4\u6a21\u751f\u4ea7\u548c\u66f4\u6362\u5bfc\u81f4\u4e25\u91cd\u6d6a\u8d39\uff0c\u7531\u4e8e\u889c\u5b50\u6210\u5bf9\u4f7f\u7528\uff0c\u5355\u53ea\u4e22\u5931\u4f1a\u4f7f\u53e6\u4e00\u53ea\u53ef\u7528\u889c\u5b50\u95f2\u7f6e\u5e76\u89e6\u53d1\u8fc7\u65e9\u66f4\u6362\uff0c\u9700\u8981\u91cf\u5316\u914d\u5bf9\u4e0d\u5339\u914d\u889c\u5b50\u7684\u4ef7\u503c\u53ca\u963b\u788d\u8fd9\u79cd\u884c\u4e3a\u7684\u793e\u4f1a\u6210\u672c\u3002", "method": "\u5c06\u889c\u5b50\u6240\u6709\u6743\u5efa\u6a21\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u889c\u5b50\u5728\u4f7f\u7528\u548c\u6d17\u6da4\u8fc7\u7a0b\u4e2d\u968f\u673a\u78e8\u635f\u548c\u4e22\u5931\uff0c\u516c\u5f00\u66b4\u9732\u5f15\u5165\u4e2a\u4eba\u7279\u5b9a\u7684\u4e0d\u5339\u914d\u60e9\u7f5a\uff1b\u901a\u8fc7\u73b0\u573a\u7814\u7a76\u4f30\u8ba1\u4e0d\u5339\u914d\u654f\u611f\u6027\u548c\u591a\u6837\u6027\u504f\u597d\uff1b\u4f7f\u7528\u8ba1\u7b97\u673a\u6a21\u62df\u8bc4\u4f30\u53ef\u89e3\u91ca\u7684\u914d\u5bf9\u7b56\u7565\u3002", "result": "\u4e25\u683c\u914d\u5bf9\u770b\u4f3c\u8282\u7ea6\u8d44\u6e90\u4e3b\u8981\u662f\u56e0\u4e3a\u4ea7\u751f\u4e86\u8bb8\u591a\u65e0\u889c\u53ef\u7a7f\u7684\u65e5\u5b50\uff0c\u800c\u63a7\u5236\u5bb9\u5fcd\u4e0d\u5339\u914d\u53ef\u4ee5\u7ef4\u6301\u670d\u52a1\u5e76\u51cf\u5c11\u4e0d\u540c\u4e22\u5931\u60c5\u51b5\u4e0b\u7684\u95f2\u7f6e\u5bb9\u91cf\uff1b\u7814\u7a76\u5efa\u7acb\u4e86\u914d\u5bf9\u4e0d\u5339\u914d\u889c\u5b50\u7684\u53ef\u884c\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5176\u5c40\u9650\u6027\u548c\u6311\u6218\u3002", "conclusion": "\u5bb9\u5fcd\u4e00\u5b9a\u7a0b\u5ea6\u7684\u4e0d\u5339\u914d\u6bd4\u4e25\u683c\u914d\u5bf9\u66f4\u8282\u7ea6\u8d44\u6e90\uff0c\u80fd\u591f\u7ef4\u6301\u889c\u5b50\u670d\u52a1\u5e76\u51cf\u5c11\u6d6a\u8d39\uff0c\u4f46\u9700\u8981\u8003\u8651\u4e2a\u4eba\u5bf9\u4e0d\u5339\u914d\u7684\u654f\u611f\u6027\u548c\u591a\u6837\u6027\u504f\u597d\uff0c\u914d\u5bf9\u4e0d\u5339\u914d\u889c\u5b50\u5177\u6709\u53ef\u884c\u6027\u4f46\u5b58\u5728\u5b9e\u9645\u6311\u6218\u3002"}}
{"id": "2602.18025", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.18025", "abs": "https://arxiv.org/abs/2602.18025", "authors": ["Haruki Abe", "Takayuki Osa", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets", "comment": "ICLR 2026", "summary": "Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.", "AI": {"tldr": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u8de8\u5177\u8eab\u5b66\u4e60\u7ed3\u5408\uff0c\u5229\u7528\u4e13\u5bb6\u548c\u6b21\u4f18\u6570\u636e\u9884\u8bad\u7ec3\u673a\u5668\u4eba\u7b56\u7565\uff0c\u901a\u8fc7\u5f62\u6001\u76f8\u4f3c\u6027\u5206\u7ec4\u51cf\u5c11\u68af\u5ea6\u51b2\u7a81", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u7b56\u7565\u9884\u8bad\u7ec3\u4e2d\u9ad8\u8d28\u91cf\u6f14\u793a\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u7ed3\u5408\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u8de8\u5177\u8eab\u5b66\u4e60\u6765\u5229\u7528\u5f02\u6784\u673a\u5668\u4eba\u8f68\u8ff9\u83b7\u53d6\u901a\u7528\u63a7\u5236\u5148\u9a8c", "method": "1) \u6784\u5efa\u5305\u542b16\u79cd\u673a\u5668\u4eba\u5e73\u53f0\u7684\u8fd0\u52a8\u6570\u636e\u96c6\uff1b2) \u5206\u6790\u79bb\u7ebfRL\u4e0e\u8de8\u5177\u8eab\u5b66\u4e60\u8303\u5f0f\uff1b3) \u63d0\u51fa\u57fa\u4e8e\u5177\u8eab\u76f8\u4f3c\u6027\u7684\u5206\u7ec4\u7b56\u7565\uff0c\u5c06\u5f62\u6001\u76f8\u4f3c\u7684\u673a\u5668\u4eba\u805a\u7c7b\uff0c\u4f7f\u7528\u7ec4\u68af\u5ea6\u66f4\u65b0\u6a21\u578b", "result": "1) \u7ed3\u5408\u65b9\u6cd5\u5728\u6b21\u4f18\u8f68\u8ff9\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7eaf\u884c\u4e3a\u514b\u9686\uff1b2) \u6b21\u4f18\u6570\u636e\u6bd4\u4f8b\u548c\u673a\u5668\u4eba\u7c7b\u578b\u589e\u52a0\u4f1a\u5bfc\u81f4\u8de8\u5f62\u6001\u68af\u5ea6\u51b2\u7a81\uff1b3) \u9759\u6001\u5206\u7ec4\u7b56\u7565\u663e\u8457\u51cf\u5c11\u673a\u5668\u4eba\u95f4\u51b2\u7a81\uff0c\u4f18\u4e8e\u73b0\u6709\u51b2\u7a81\u89e3\u51b3\u65b9\u6cd5", "conclusion": "\u79bb\u7ebfRL\u4e0e\u8de8\u5177\u8eab\u5b66\u4e60\u7ed3\u5408\u662f\u6709\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u8de8\u5f62\u6001\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\uff1b\u57fa\u4e8e\u5f62\u6001\u76f8\u4f3c\u6027\u7684\u7b80\u5355\u9759\u6001\u5206\u7ec4\u662f\u6709\u6548\u7684\u51b2\u7a81\u7f13\u89e3\u7b56\u7565"}}
{"id": "2602.18249", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18249", "abs": "https://arxiv.org/abs/2602.18249", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering", "comment": null, "summary": "Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.\n  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.\n  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.\n  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).\n  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.\n  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.\n  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.", "AI": {"tldr": "\u63d0\u51faDTL-NS\u65b9\u6cd5\uff0c\u4e00\u79cd\u65e0\u9700\u6587\u672c\u4fe1\u606f\u548c\u5fae\u8c03\u7684\u53cc\u6811LLM\u589e\u5f3a\u8d1f\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u5047\u8d1f\u4f8b\u8bc6\u522b\u548c\u591a\u89c6\u89d2\u786c\u8d1f\u4f8b\u91c7\u6837\u63d0\u5347\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u6027\u80fd", "motivation": "\u5f53\u524dLLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8d1f\u91c7\u6837\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\u548c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u901a\u7528\u7684LLM\u589e\u5f3a\u8d1f\u91c7\u6837\u65b9\u6cd5", "method": "\u63d0\u51faDTL-NS\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a1) \u79bb\u7ebf\u5047\u8d1f\u4f8b\u8bc6\u522b\u6a21\u5757\uff0c\u5229\u7528\u5206\u5c42\u7d22\u5f15\u6811\u5c06\u534f\u4f5c\u7ed3\u6784\u548c\u6f5c\u5728\u8bed\u4e49\u4fe1\u606f\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9879\u76eeID\u7f16\u7801\u4f9bLLM\u63a8\u7406\uff1b2) \u591a\u89c6\u89d2\u786c\u8d1f\u4f8b\u91c7\u6837\u6a21\u5757\uff0c\u7ed3\u5408\u7528\u6237-\u9879\u76ee\u504f\u597d\u5206\u6570\u548c\u9879\u76ee-\u9879\u76ee\u5206\u5c42\u76f8\u4f3c\u6027\u6316\u6398\u9ad8\u8d28\u91cf\u786c\u8d1f\u4f8b", "result": "\u5728Amazon-sports\u6570\u636e\u96c6\u4e0a\uff0cDTL-NS\u5728Recall@20\u548cNDCG@20\u6307\u6807\u4e0a\u5206\u522b\u4f18\u4e8e\u6700\u5f3a\u57fa\u7ebf10.64%\u548c19.12%\uff0c\u4e14\u80fd\u96c6\u6210\u5230\u591a\u79cd\u9690\u5f0fCF\u6a21\u578b\u548c\u8d1f\u91c7\u6837\u65b9\u6cd5\u4e2d\uff0c\u6301\u7eed\u63d0\u5347\u6027\u80fd", "conclusion": "DTL-NS\u662f\u4e00\u79cd\u6709\u6548\u7684\u6587\u672c\u65e0\u5173\u3001\u65e0\u9700\u5fae\u8c03\u7684LLM\u589e\u5f3a\u8d1f\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u6811\u7ed3\u6784\u51c6\u786e\u8bc6\u522b\u5047\u8d1f\u4f8b\u5e76\u6316\u6398\u786c\u8d1f\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6a21\u578b\u6027\u80fd\uff0c\u5177\u6709\u826f\u597d\u901a\u7528\u6027\u548c\u5b9e\u7528\u6027"}}
{"id": "2602.18092", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18092", "abs": "https://arxiv.org/abs/2602.18092", "authors": ["Matthew DiGiuseppe", "Joshua Robison"], "title": "Perceived Political Bias in LLMs Reduces Persuasive Abilities", "comment": "39 pages, 10 figures", "summary": "Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u7528\u6237\u8ba4\u4e3a\u804a\u5929AI\u5b58\u5728\u515a\u6d3e\u504f\u89c1\u65f6\uff0c\u5176\u7ea0\u6b63\u9519\u8bef\u89c2\u5ff5\u7684\u8bf4\u670d\u529b\u4f1a\u663e\u8457\u4e0b\u964d28%\uff0c\u8868\u660eAI\u8bf4\u670d\u6548\u679c\u53d7\u653f\u6cbb\u4e2d\u7acb\u6027\u611f\u77e5\u5f71\u54cd", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u8ba8\u7cbe\u82f1\u9636\u5c42\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u515a\u6d3e\u504f\u89c1\u6307\u63a7\u662f\u5426\u4f1a\u5f71\u54cd\u5176\u4f5c\u4e3a\u7ea0\u6b63\u516c\u5171\u9519\u8bef\u89c2\u5ff5\u5de5\u5177\u7684\u6709\u6548\u6027\u3002\u968f\u7740LLM\u8fdb\u5165\u515a\u6d3e\u51b2\u7a81\u9886\u57df\uff0c\u4e86\u89e3\u5176\u8bf4\u670d\u529b\u662f\u5426\u53d7\u653f\u6cbb\u4e2d\u7acb\u6027\u611f\u77e5\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u9884\u6ce8\u518c\u7684\u7f8e\u56fd\u8c03\u67e5\u5b9e\u9a8c\uff08N=2144\uff09\uff0c\u53c2\u4e0e\u8005\u4e0eChatGPT\u8fdb\u884c\u4e09\u8f6e\u5173\u4e8e\u4e2a\u4eba\u6301\u6709\u7684\u7ecf\u6d4e\u653f\u7b56\u9519\u8bef\u89c2\u5ff5\u7684\u5bf9\u8bdd\u3002\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u6027\u5bf9\u7167\u7ec4\u548c\u5b9e\u9a8c\u7ec4\uff08\u5b9e\u9a8c\u7ec4\u6536\u5230\u7b80\u77ed\u4fe1\u606f\u8868\u660eLLM\u5bf9\u53c2\u4e0e\u8005\u6240\u5c5e\u515a\u6d3e\u5b58\u5728\u504f\u89c1\uff09\u3002\u901a\u8fc7\u8f6c\u5f55\u5206\u6790\u7814\u7a76\u8b66\u544a\u4fe1\u606f\u5982\u4f55\u6539\u53d8\u4e92\u52a8\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4e2d\u6027\u5bf9\u7167\u7ec4\u76f8\u6bd4\uff0c\u6536\u5230LLM\u5b58\u5728\u515a\u6d3e\u504f\u89c1\u8b66\u544a\u7684\u5b9e\u9a8c\u7ec4\u4e2d\uff0cChatGPT\u7684\u8bf4\u670d\u529b\u4e0b\u964d\u4e8628%\u3002\u8f6c\u5f55\u5206\u6790\u8868\u660e\uff0c\u8b66\u544a\u6539\u53d8\u4e86\u4e92\u52a8\u8fc7\u7a0b\uff1a\u53d7\u8bbf\u8005\u66f4\u9891\u7e41\u5730\u53cd\u9a73\uff0c\u4e14\u63a5\u53d7\u5ea6\u66f4\u4f4e\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u8bdd\u5f0fAI\u7684\u8bf4\u670d\u6548\u679c\u5177\u6709\u653f\u6cbb\u6761\u4ef6\u6027\uff0c\u53d7\u515a\u6d3e\u4e00\u81f4\u6027\u611f\u77e5\u7684\u9650\u5236\u3002\u7cbe\u82f1\u9636\u5c42\u5bf9LLM\u7684\u515a\u6d3e\u504f\u89c1\u6307\u63a7\u4f1a\u663e\u8457\u524a\u5f31\u5176\u7ea0\u6b63\u9519\u8bef\u89c2\u5ff5\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9AI\u4f5c\u4e3a\u516c\u5171\u4fe1\u606f\u4f20\u64ad\u5de5\u5177\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.18137", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18137", "abs": "https://arxiv.org/abs/2602.18137", "authors": ["Vincent Grari", "Ciprian Tomoiaga", "Sylvain Lamprier", "Tatsunori Hashimoto", "Marcin Detyniecki"], "title": "Agentic Adversarial QA for Improving Domain-Specific LLMs", "comment": "9 pages, 1 Figure", "summary": "Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u6297\u6027\u95ee\u7b54\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u76ee\u6807\u6a21\u578b\u4e0e\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\uff0c\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49\u6311\u6218\u6027\u95ee\u9898\uff0c\u5728\u4e13\u4e1a\u9886\u57df\u5fae\u8c03\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u548c\u66f4\u5c11\u6837\u672c\u9700\u6c42", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u9002\u5e94\u80fd\u529b\u6709\u9650\uff0c\u73b0\u6709\u5fae\u8c03\u65b9\u6cd5\u9762\u4e34\u9ad8\u8d28\u91cf\u4efb\u52a1\u76f8\u5173\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u4f20\u7edf\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff08\u5982\u6539\u5199\u6216\u77e5\u8bc6\u63d0\u53d6\uff09\u867d\u7136\u64c5\u957f\u4e8b\u5b9e\u56de\u5fc6\u548c\u6982\u5ff5\u77e5\u8bc6\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u7f3a\u9677\uff1a1) \u5bf9\u4e13\u4e1a\u9886\u57df\u89e3\u91ca\u6027\u63a8\u7406\u80fd\u529b\u652f\u6301\u4e0d\u8db3\uff1b2) \u751f\u6210\u7684\u5408\u6210\u8bed\u6599\u5e93\u901a\u5e38\u8fc7\u5927\u4e14\u5197\u4f59\uff0c\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u5bf9\u6297\u6027\u95ee\u7b54\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u9a71\u52a8\u8fc7\u7a0b\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49\u6311\u6218\u6027\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u6bd4\u8f83\u5f85\u9002\u5e94\u6a21\u578b\u4e0e\u57fa\u4e8e\u53c2\u8003\u6587\u6863\u7684\u7a33\u5065\u4e13\u5bb6\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u8bc6\u522b\u5e76\u89e3\u51b3\u7406\u89e3\u5dee\u8ddd\u3002\u5177\u4f53\u6d41\u7a0b\u5305\u62ec\uff1a1) \u4f7f\u7528\u4e13\u5bb6\u6a21\u578b\u751f\u6210\u53c2\u8003\u7b54\u6848\uff1b2) \u5bf9\u6bd4\u76ee\u6807\u6a21\u578b\u8f93\u51fa\u4e0e\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\uff1b3) \u8bc6\u522b\u7406\u89e3\u5dee\u8ddd\u5e76\u751f\u6210\u9488\u5bf9\u6027\u6311\u6218\u95ee\u9898\uff1b4) \u8fed\u4ee3\u4f18\u5316\u95ee\u9898\u751f\u6210\u3002", "result": "\u5728LegalBench\u8bed\u6599\u5e93\u7684\u4e13\u4e1a\u5b50\u96c6\u4e0a\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u663e\u8457\u51cf\u5c11\u5408\u6210\u6837\u672c\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002\u76f8\u6bd4\u4f20\u7edf\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u672c\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5bf9\u6297\u6027\u95ee\u7b54\u751f\u6210\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4e13\u4e1a\u9886\u57df\u5fae\u8c03\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u6837\u672c\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49\u6311\u6218\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u7684\u9002\u5e94\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.18201", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18201", "abs": "https://arxiv.org/abs/2602.18201", "authors": ["Joseph Bingham", "Netanel Arussy", "Dvir Aran"], "title": "SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps", "comment": "10 pages, 2 figures, preprint", "summary": "Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \\textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime", "code_url": "https://github.com/JosephBingham/SOMtime", "code_stars": 0, "code_last_update": "2026-02-18", "AI": {"tldr": "SOMtime\u65b9\u6cd5\u63ed\u793a\u65e0\u76d1\u7763\u8868\u793a\u4f1a\u81ea\u53d1\u7f16\u7801\u88ab\u6392\u9664\u7684\u654f\u611f\u5c5e\u6027\uff0c\u6311\u6218\u4e86\"\u516c\u5e73\u901a\u8fc7\u65e0\u77e5\"\u7684\u5047\u8bbe", "motivation": "\u6311\u6218\u65e0\u76d1\u7763\u8868\u793a\u5bf9\u654f\u611f\u5c5e\u6027\u4fdd\u6301\u4e2d\u6027\u7684\u666e\u904d\u5047\u8bbe\uff0c\u8bc1\u660e\u5373\u4f7f\u660e\u786e\u6392\u9664\u654f\u611f\u5c5e\u6027\uff0c\u5b83\u4eec\u4ecd\u4f1a\u5728\u8868\u793a\u4e2d\u81ea\u53d1\u51fa\u73b0", "method": "\u4f7f\u7528SOMtime\uff08\u57fa\u4e8e\u9ad8\u5bb9\u91cf\u81ea\u7ec4\u7ec7\u6620\u5c04\u7684\u62d3\u6251\u4fdd\u6301\u8868\u793a\u65b9\u6cd5\uff09\uff0c\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\uff08\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u548c\u4eba\u53e3\u666e\u67e5\u6536\u5165\u6570\u636e\u96c6\uff09\u4e0a\u5206\u6790\u65e0\u76d1\u7763\u8868\u793a\u4e2d\u654f\u611f\u5c5e\u6027\u7684\u51fa\u73b0", "result": "SOMtime\u6062\u590d\u51fa\u4e0e\u88ab\u6392\u9664\u654f\u611f\u5c5e\u6027\u5bf9\u9f50\u7684\u5355\u8c03\u6392\u5e8f\uff0cSpearman\u76f8\u5173\u6027\u9ad8\u8fbe0.85\uff0c\u800cPCA\u3001UMAP\u3001t-SNE\u548c\u81ea\u7f16\u7801\u5668\u901a\u5e38\u4f4e\u4e8e0.34\uff1b\u65e0\u76d1\u7763\u5206\u5272\u4ea7\u751f\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u659c\u7684\u805a\u7c7b", "conclusion": "\"\u516c\u5e73\u901a\u8fc7\u65e0\u77e5\"\u5728\u8868\u793a\u5c42\u9762\u5bf9\u5e8f\u6570\u654f\u611f\u5c5e\u6027\u5931\u6548\uff0c\u516c\u5e73\u5ba1\u8ba1\u5fc5\u987b\u6269\u5c55\u5230\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u7684\u65e0\u76d1\u7763\u7ec4\u4ef6"}}
{"id": "2602.18288", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18288", "abs": "https://arxiv.org/abs/2602.18288", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering", "comment": null, "summary": "Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.", "AI": {"tldr": "TPSC-FO\uff1a\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u611f\u77e5\u7684\u6b63\u6837\u672c\u96c6\u6784\u5efa\u548c\u7279\u5f81\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5047\u9634\u6027\u6837\u672c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u6b63\u6837\u672c\uff0c\u89e3\u51b3\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u4e2d\u7684\u5047\u9634\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8d1f\u91c7\u6837\u65b9\u6cd5\u5728\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u4e2d\u5b58\u5728\u5047\u9634\u6027\u95ee\u9898\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u5f53\u524d\u8868\u793a\u80fd\u529b\uff0c\u4e14\u672a\u80fd\u5229\u7528\u5047\u9634\u6027\u4f5c\u4e3a\u6f5c\u5728\u6b63\u6837\u672c\u7684\u6f5c\u529b\u6765\u66f4\u51c6\u786e\u6307\u5bfc\u7528\u6237\u504f\u597d\u5b66\u4e60\u3002", "method": "\u63d0\u51faTPSC-FO\u65b9\u6cd5\uff1a1\uff09\u62d3\u6251\u611f\u77e5\u6b63\u6837\u672c\u96c6\u6784\u5efa\u6a21\u5757\uff0c\u4f7f\u7528\u5dee\u5206\u793e\u533a\u68c0\u6d4b\u7b56\u7565\u6355\u83b7\u9690\u5f0f\u53cd\u9988\u4e2d\u7684\u62d3\u6251\u793e\u533a\u7ed3\u6784\uff0c\u7ed3\u5408\u4e2a\u6027\u5316\u566a\u58f0\u8fc7\u6ee4\u53ef\u9760\u8bc6\u522b\u5047\u9634\u6027\u5e76\u8f6c\u5316\u4e3a\u6b63\u6837\u672c\uff1b2\uff09\u90bb\u57df\u5f15\u5bfc\u7279\u5f81\u4f18\u5316\u6a21\u5757\uff0c\u901a\u8fc7\u878d\u5165\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u90bb\u57df\u7279\u5f81\u6765\u7cbe\u70bc\u6b63\u6837\u672c\u7279\u5f81\uff0c\u6709\u6548\u7f13\u89e3\u6b63\u6837\u672c\u4e2d\u7684\u566a\u58f0\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TPSC-FO\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u9690\u5f0f\u53cd\u9988\u4e2d\u7684\u62d3\u6251\u793e\u533a\u7ed3\u6784\u80fd\u6709\u6548\u8bc6\u522b\u5047\u9634\u6027\uff0cTPSC-FO\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u6b63\u6837\u672c\u96c6\u6784\u5efa\u548c\u7279\u5f81\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u7684\u6027\u80fd\u3002"}}
{"id": "2602.18145", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18145", "abs": "https://arxiv.org/abs/2602.18145", "authors": ["Siya Qi", "Yudong Chen", "Runcong Zhao", "Qinglin Zhu", "Zhanghao Hu", "Wei Liu", "Yulan He", "Zheng Yuan", "Lin Gui"], "title": "Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention", "comment": "25 pages, 10 figures", "summary": "Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9891\u7387\u5206\u6790\u7684\u6ce8\u610f\u529b\u673a\u5236\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6ce8\u610f\u529b\u5206\u5e03\u7684\u9ad8\u9891\u6210\u5206\u6765\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7c97\u7c92\u5ea6\u6c47\u603b\uff0c\u65e0\u6cd5\u6355\u6349\u6ce8\u610f\u529b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u4e0d\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u5206\u6790\u65b9\u6cd5", "method": "\u5c06\u6ce8\u610f\u529b\u5206\u5e03\u5efa\u6a21\u4e3a\u79bb\u6563\u4fe1\u53f7\uff0c\u63d0\u53d6\u53cd\u6620\u6ce8\u610f\u529b\u5feb\u901f\u5c40\u90e8\u53d8\u5316\u7684\u9ad8\u9891\u6210\u5206\uff0c\u57fa\u4e8e\u9ad8\u9891\u6ce8\u610f\u529b\u7279\u5f81\u6784\u5efa\u8f7b\u91cf\u7ea7\u5e7b\u89c9\u68c0\u6d4b\u5668", "result": "\u5728RAGTruth\u548cHalluRAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u8de8\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u57fa\u4e8e\u9a8c\u8bc1\u3001\u5185\u90e8\u8868\u793a\u548c\u6ce8\u610f\u529b\u7684\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u6ce8\u610f\u529b\u5206\u5e03\u7684\u9ad8\u9891\u6210\u5206\u80fd\u6709\u6548\u53cd\u6620\u5e7b\u89c9\u76f8\u5173\u7684\u788e\u7247\u5316\u548c\u4e0d\u7a33\u5b9a\u63a5\u5730\u884c\u4e3a\uff0c\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u4fe1\u53f7\u5904\u7406\u89c6\u89d2"}}
{"id": "2602.18291", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18291", "abs": "https://arxiv.org/abs/2602.18291", "authors": ["Zhuoran Li", "Hai Zhong", "Xun Wang", "Qingxin Xia", "Lihua Zhang", "Longbo Huang"], "title": "Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies", "comment": null, "summary": "Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \\underline{O}nline off-policy \\underline{MA}RL framework using \\underline{D}iffusion policies (\\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\\times$ to $5\\times$ improvement in sample efficiency.", "AI": {"tldr": "OMAD\uff1a\u9996\u4e2a\u5728\u7ebf\u79bb\u7b56\u7565\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u6269\u6563\u7b56\u7565\u534f\u8c03\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u677e\u5f1b\u7b56\u7565\u76ee\u6807\u6700\u5927\u5316\u8054\u5408\u71b5\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22\uff0c\u5728MPE\u548cMAMuJoCo\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u6269\u6563\u751f\u6210\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u548c\u79bb\u7ebf\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u591a\u6a21\u6001\u8868\u793a\u80fd\u529b\uff0c\u4f46\u5728\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u4e3b\u8981\u969c\u788d\u662f\u6269\u6563\u6a21\u578b\u7684\u4e0d\u53ef\u5904\u7406\u4f3c\u7136\u6027\u963b\u788d\u4e86\u57fa\u4e8e\u71b5\u7684\u63a2\u7d22\u548c\u534f\u8c03\u3002", "method": "\u63d0\u51faOMAD\u6846\u67b6\uff1a1\uff09\u677e\u5f1b\u7b56\u7565\u76ee\u6807\u6700\u5927\u5316\u7f29\u653e\u8054\u5408\u71b5\uff0c\u5b9e\u73b0\u65e0\u9700\u53ef\u5904\u7406\u4f3c\u7136\u7684\u63a2\u7d22\uff1b2\uff09\u5728CTDE\u8303\u5f0f\u4e0b\u4f7f\u7528\u8054\u5408\u5206\u5e03\u503c\u51fd\u6570\u4f18\u5316\u5206\u6563\u6269\u6563\u7b56\u7565\uff1b3\uff09\u5229\u7528\u53ef\u5904\u7406\u7684\u71b5\u589e\u5f3a\u76ee\u6807\u6307\u5bfc\u6269\u6563\u7b56\u7565\u540c\u6b65\u66f4\u65b0\uff0c\u786e\u4fdd\u7a33\u5b9a\u534f\u8c03\u3002", "result": "\u5728MPE\u548cMAMuJoCo\u768410\u4e2a\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u5efa\u7acb\u65b0\u7684SOTA\uff0c\u6837\u672c\u6548\u7387\u663e\u8457\u63d0\u9ad82.5\u500d\u52305\u500d\u3002", "conclusion": "OMAD\u6210\u529f\u5c06\u6269\u6563\u7b56\u7565\u5e94\u7528\u4e8e\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u71b5\u6700\u5927\u5316\u65b9\u6cd5\u548c\u8054\u5408\u503c\u51fd\u6570\u4f18\u5316\uff0c\u514b\u670d\u4e86\u6269\u6563\u6a21\u578b\u5728\u5728\u7ebfMARL\u4e2d\u7684\u5173\u952e\u969c\u788d\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u534f\u8c03\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2602.18152", "categories": ["cs.CL", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.18152", "abs": "https://arxiv.org/abs/2602.18152", "authors": ["Ortal Hadad", "Edoardo Loru", "Jacopo Nudo", "Niccol\u00f2 Di Marco", "Matteo Cinelli", "Walter Quattrociocchi"], "title": "The Statistical Signature of LLMs", "comment": null, "summary": "Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u65e0\u635f\u538b\u7f29\u4f5c\u4e3a\u6a21\u578b\u65e0\u5173\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86LLM\u751f\u6210\u6587\u672c\u4e0e\u4eba\u7c7b\u5199\u4f5c\u5728\u7edf\u8ba1\u89c4\u5f8b\u6027\u4e0a\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff1aLLM\u6587\u672c\u901a\u5e38\u5177\u6709\u66f4\u9ad8\u7684\u7ed3\u6784\u89c4\u5f8b\u6027\u548c\u53ef\u538b\u7f29\u6027\uff0c\u4f46\u5728\u5c0f\u5c3a\u5ea6\u788e\u7247\u5316\u4ea4\u4e92\u73af\u5883\u4e2d\u8fd9\u79cd\u5dee\u5f02\u4f1a\u51cf\u5f31\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u6982\u7387\u91c7\u6837\u751f\u6210\u6587\u672c\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u5982\u4f55\u91cd\u5851\u8bed\u8a00\u7684\u7ed3\u6784\u7edf\u8ba1\u7ec4\u7ec7\u5c1a\u672a\u5b8c\u5168\u8868\u5f81\u3002\u7814\u7a76\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u7b80\u5355\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u751f\u6210\u7cfb\u7edf\u5982\u4f55\u91cd\u5851\u6587\u672c\u751f\u4ea7\uff0c\u63d0\u4f9b\u5173\u4e8e\u901a\u4fe1\u590d\u6742\u6027\u6f14\u5316\u7684\u7ed3\u6784\u89c6\u89d2\u3002", "method": "\u4f7f\u7528\u65e0\u635f\u538b\u7f29\u4f5c\u4e3a\u7edf\u8ba1\u89c4\u5f8b\u6027\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5206\u6790\u4e09\u4e2a\u6e10\u8fdb\u590d\u6742\u7684\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\uff1a1) \u53d7\u63a7\u7684\u4eba\u7c7b-LLM\u5ef6\u7eed\u4efb\u52a1\uff1b2) \u77e5\u8bc6\u57fa\u7840\u8bbe\u65bd\u7684\u751f\u6210\u4e2d\u4ecb\uff08\u7ef4\u57fa\u767e\u79d1 vs. Grokipedia\uff09\uff1b3) \u5b8c\u5168\u5408\u6210\u7684\u793e\u4ea4\u4e92\u52a8\u73af\u5883\uff08Moltbook vs. Reddit\uff09\u3002\u8be5\u65b9\u6cd5\u76f4\u63a5\u4ece\u8868\u9762\u6587\u672c\u89c2\u5bdf\u538b\u7f29\u884c\u4e3a\uff0c\u4e0d\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u6216\u8bed\u4e49\u8bc4\u4f30\u3002", "result": "\u538b\u7f29\u63ed\u793a\u4e86\u6982\u7387\u751f\u6210\u7684\u7ed3\u6784\u7279\u5f81\uff1a\u5728\u53d7\u63a7\u548c\u4e2d\u4ecb\u73af\u5883\u4e2d\uff0cLLM\u751f\u6210\u7684\u8bed\u8a00\u6bd4\u4eba\u7c7b\u5199\u4f5c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7ed3\u6784\u89c4\u5f8b\u6027\u548c\u53ef\u538b\u7f29\u6027\uff0c\u8868\u660e\u8f93\u51fa\u96c6\u4e2d\u5728\u9ad8\u5ea6\u5faa\u73af\u7684\u7edf\u8ba1\u6a21\u5f0f\u4e2d\u3002\u4f46\u8fd9\u79cd\u7279\u5f81\u5177\u6709\u5c3a\u5ea6\u4f9d\u8d56\u6027\uff1a\u5728\u788e\u7247\u5316\u4ea4\u4e92\u73af\u5883\u4e2d\uff0c\u5206\u79bb\u51cf\u5f31\uff0c\u8868\u660e\u5728\u5c0f\u5c3a\u5ea6\u4e0a\u8868\u9762\u53ef\u533a\u5206\u6027\u5b58\u5728\u57fa\u672c\u9650\u5236\u3002\u8fd9\u79cd\u57fa\u4e8e\u53ef\u538b\u7f29\u6027\u7684\u5206\u79bb\u5728\u4e0d\u540c\u6a21\u578b\u3001\u4efb\u52a1\u548c\u9886\u57df\u4e2d\u4e00\u81f4\u51fa\u73b0\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u7a33\u5065\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u751f\u6210\u7cfb\u7edf\u5982\u4f55\u91cd\u5851\u6587\u672c\u751f\u4ea7\uff0c\u4e3a\u7406\u89e3\u901a\u4fe1\u590d\u6742\u6027\u6f14\u5316\u63d0\u4f9b\u4e86\u7ed3\u6784\u89c6\u89d2\u3002\u65e0\u635f\u538b\u7f29\u4f5c\u4e3a\u6a21\u578b\u65e0\u5173\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u80fd\u591f\u76f4\u63a5\u4ece\u8868\u9762\u6587\u672c\u533a\u5206LLM\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u5199\u4f5c\uff0c\u4f46\u5728\u5c0f\u5c3a\u5ea6\u4ea4\u4e92\u73af\u5883\u4e2d\u8fd9\u79cd\u533a\u5206\u80fd\u529b\u6709\u9650\u3002"}}
{"id": "2602.18425", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18425", "abs": "https://arxiv.org/abs/2602.18425", "authors": ["Deniz Qian", "Hung-Ting Chen", "Eunsol Choi"], "title": "RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering", "comment": "18 pages, 12 figures, 12 tables", "summary": "Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.", "AI": {"tldr": "RVR\u662f\u4e00\u79cd\u591a\u8f6e\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22-\u9a8c\u8bc1-\u68c0\u7d22\u7684\u8fed\u4ee3\u8fc7\u7a0b\u6700\u5927\u5316\u7b54\u6848\u8986\u76d6\u7387\uff0c\u5728QAMPARI\u6570\u636e\u96c6\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u81f3\u5c1110%\u7684\u76f8\u5bf9\u589e\u76ca\u548c3%\u7684\u7edd\u5bf9\u589e\u76ca\u3002", "motivation": "\u9488\u5bf9\u9700\u8981\u5e7f\u6cdb\u6709\u6548\u7b54\u6848\u7684\u67e5\u8be2\uff0c\u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u8986\u76d6\u6240\u6709\u53ef\u80fd\u7684\u7b54\u6848\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6700\u5927\u5316\u7b54\u6848\u8986\u76d6\u7387\u7684\u68c0\u7d22\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u68c0\u7d22-\u9a8c\u8bc1-\u68c0\u7d22\uff08RVR\uff09\u6846\u67b6\uff1a\u7b2c\u4e00\u8f6e\u68c0\u7d22\u5668\u63a5\u6536\u539f\u59cb\u67e5\u8be2\u8fd4\u56de\u5019\u9009\u6587\u6863\u96c6\uff0c\u9a8c\u8bc1\u5668\u8bc6\u522b\u9ad8\u8d28\u91cf\u5b50\u96c6\uff1b\u540e\u7eed\u8f6e\u6b21\u5c06\u67e5\u8be2\u4e0e\u5df2\u9a8c\u8bc1\u6587\u6863\u7ed3\u5408\uff0c\u53d1\u73b0\u4e4b\u524d\u672a\u8986\u76d6\u7684\u7b54\u6848\uff1b\u652f\u6301\u4f7f\u7528\u73b0\u6210\u68c0\u7d22\u5668\uff0c\u4e5f\u53ef\u901a\u8fc7\u5fae\u8c03\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u5728QAMPARI\u591a\u7b54\u6848\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\uff0cRVR\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff08\u5305\u62ec\u667a\u80fd\u641c\u7d22\u65b9\u6cd5\uff09\u83b7\u5f97\u81f3\u5c1110%\u76f8\u5bf9\u589e\u76ca\u548c3%\u7edd\u5bf9\u589e\u76ca\u7684\u5b8c\u5168\u53ec\u56de\u7387\u63d0\u5347\uff1b\u5728QUEST\u548cWebQuestionsSP\u4e24\u4e2a\u57df\u5916\u6570\u636e\u96c6\u4e0a\u4e5f\u89c2\u5bdf\u5230\u4e00\u81f4\u589e\u76ca\u3002", "conclusion": "RVR\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5668\u548c\u9002\u5e94\u65b0\u63a8\u7406\u573a\u666f\u7684\u68c0\u7d22\u5668\u6765\u5b9e\u73b0\u5168\u9762\u7684\u7b54\u6848\u53ec\u56de\uff0c\u4e3a\u5168\u9762\u68c0\u7d22\u591a\u6837\u5316\u6587\u6863\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.18154", "categories": ["cs.CL", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.18154", "abs": "https://arxiv.org/abs/2602.18154", "authors": ["Mirae Kim", "Seonghun Jeong", "Youngjun Kwak"], "title": "FENCE: A Financial and Multimodal Jailbreak Detection Dataset", "comment": "lrec 2026 accepted paper", "summary": "Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.", "AI": {"tldr": "FENCE\u662f\u4e00\u4e2a\u7528\u4e8e\u91d1\u878d\u9886\u57df\u591a\u6a21\u6001\u8d8a\u72f1\u68c0\u6d4b\u7684\u53cc\u8bed\uff08\u97e9\u8bed-\u82f1\u8bed\uff09\u6570\u636e\u96c6\uff0c\u5305\u542b\u91d1\u878d\u76f8\u5173\u67e5\u8be2\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u5a01\u80c1\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u8d8a\u72f1\u68c0\u6d4b\u5668\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u5bf9\u90e8\u7f72\u6784\u6210\u91cd\u5927\u98ce\u9669\uff0c\u7279\u522b\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\u6587\u672c\u548c\u56fe\u50cf\uff0c\u653b\u51fb\u9762\u66f4\u5e7f\u3002\u91d1\u878d\u9886\u57df\u7f3a\u4e4f\u8d8a\u72f1\u68c0\u6d4b\u8d44\u6e90\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u96c6\u6765\u5e94\u5bf9\u8fd9\u4e00\u5b89\u5168\u6311\u6218\u3002", "method": "\u521b\u5efaFENCE\u53cc\u8bed\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b\u91d1\u878d\u76f8\u5173\u67e5\u8be2\u548c\u56fe\u50cf\u57fa\u7840\u5a01\u80c1\uff0c\u5f3a\u8c03\u9886\u57df\u771f\u5b9e\u6027\u3002\u4f7f\u7528\u5546\u4e1a\u548c\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u6f0f\u6d1e\uff0c\u5e76\u8bad\u7ec3\u57fa\u7ebf\u68c0\u6d4b\u5668\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5546\u4e1a\u548c\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e00\u81f4\u7684\u6f0f\u6d1e\uff0cGPT-4o\u663e\u793a\u51fa\u53ef\u6d4b\u91cf\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5f00\u6e90\u6a21\u578b\u66b4\u9732\u66f4\u5927\u3002\u57fa\u4e8eFENCE\u8bad\u7ec3\u7684\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u523099%\u7684\u5206\u5e03\u5185\u51c6\u786e\u7387\uff0c\u5e76\u5728\u5916\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u5f3a\u5927\u6027\u80fd\u3002", "conclusion": "FENCE\u4e3a\u91d1\u878d\u9886\u57df\u591a\u6a21\u6001\u8d8a\u72f1\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e13\u6ce8\u8d44\u6e90\uff0c\u652f\u6301\u5728\u654f\u611f\u9886\u57df\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u7684AI\u7cfb\u7edf\u3002\u6570\u636e\u96c6\u5c55\u793a\u4e86\u8bad\u7ec3\u53ef\u9760\u68c0\u6d4b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.18429", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18429", "abs": "https://arxiv.org/abs/2602.18429", "authors": ["Harshul Raj Surana", "Arijit Maji", "Aryan Vats", "Akash Ghosh", "Sriparna Saha", "Amit Sheth"], "title": "VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning", "comment": null, "summary": "Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.", "AI": {"tldr": "VIRAASAT\u662f\u4e00\u4e2a\u9488\u5bf9\u5370\u5ea6\u6587\u5316\u7684\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u7b26\u53f7\u94fe\u5f0f\u64cd\u4f5c\u6846\u67b6\u63d0\u5347LLMs\u5728\u6587\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "motivation": "\u73b0\u6709LLMs\u5728\u9700\u8981\u4e30\u5bcc\u793e\u4f1a\u6587\u5316\u77e5\u8bc6\u548c\u672c\u5730\u80cc\u666f\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u6d89\u53ca\u5370\u5ea6\u6587\u5316\u7684\u4efb\u52a1\u3002\u73b0\u6709\u7684\u6587\u5316\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(1) \u4eba\u5de5\u6784\u5efa\uff0c(2) \u4ec5\u5305\u542b\u6d4b\u8bd5\u4e8b\u5b9e\u8bb0\u5fc6\u7684\u5355\u8df3\u95ee\u9898\uff0c(3) \u6269\u5c55\u6210\u672c\u8fc7\u9ad8\uff0c\u5bfc\u81f4\u8fd9\u4e00\u7f3a\u9677\u672a\u88ab\u5145\u5206\u8861\u91cf\u3002", "method": "\u63d0\u51fa\u4e86VIRAASAT\u534a\u81ea\u52a8\u5316\u591a\u8df3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5305\u542b700\u591a\u4e2a\u4e13\u5bb6\u7b56\u5212\u6587\u5316\u5b9e\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u6db5\u76d6\u5370\u5ea6\u6587\u5316\u768413\u4e2a\u5173\u952e\u5c5e\u6027\u3002\u8be5\u65b9\u6cd5\u751f\u62103200\u591a\u4e2a\u591a\u8df3\u95ee\u9898\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u7b26\u53f7\u94fe\u5f0f\u64cd\u4f5c(SCoM)\u6846\u67b6\uff0c\u8bad\u7ec3\u6a21\u578b\u5728\u5185\u90e8\u6a21\u62df\u77e5\u8bc6\u56fe\u8c31\u7684\u539f\u5b50\u64cd\u4f5c\uff0c\u53ef\u9760\u5730\u904d\u5386\u56fe\u8c31\u7684\u62d3\u6251\u7ed3\u6784\u3002", "result": "\u5728\u76d1\u7763\u5fae\u8c03\u5b9e\u9a8c\u4e2d\uff0cSCoM\u6846\u67b6\u6bd4\u6807\u51c6\u7684\u601d\u7ef4\u94fe\u57fa\u51c6\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe20%\u3002VIRAASAT\u6570\u636e\u96c6\u8986\u76d6\u4e86\u5370\u5ea6\u6240\u670928\u4e2a\u90a6\u548c8\u4e2a\u4e2d\u592e\u76f4\u8f96\u533a\u3002", "conclusion": "VIRAASAT\u4e3a\u6784\u5efa\u6587\u5316\u611f\u77e5\u63a8\u7406\u6a21\u578b\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5f53\u524dSOTA LLMs\u5728\u6587\u5316\u63a8\u7406\u4e2d\u7684\u5173\u952e\u9650\u5236\uff0c\u7279\u522b\u662f\u601d\u7ef4\u94fe\u5fae\u8c03\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4f4e\u6982\u7387\u4e8b\u5b9e\u7684\u5408\u6210\u4e0e\u57fa\u7840\u3002SCoM\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u64cd\u4f5c\u6a21\u62df\u663e\u8457\u63d0\u5347\u4e86\u6587\u5316\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.18171", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18171", "abs": "https://arxiv.org/abs/2602.18171", "authors": ["Wojciech Michaluk", "Tymoteusz Urban", "Mateusz Kubita", "Soveatin Kuntur", "Anna Wroblewska"], "title": "Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models", "comment": null, "summary": "Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408Transformer\u6587\u672c\u5d4c\u5165\u4e0e\u8bed\u8a00\u5b66\u7279\u5f81\u4fe1\u606f\u7684\u6df7\u5408\u65b9\u6cd5\u7528\u4e8e\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\uff0cXGBoost\u6a21\u578b\u5728\u589e\u5f3a\u7279\u5f81\u4e0a\u8fbe\u523091% F1\u5206\u6570", "motivation": "\u70b9\u51fb\u8bf1\u9975\u6807\u9898\u964d\u4f4e\u5728\u7ebf\u4fe1\u606f\u8d28\u91cf\u5e76\u635f\u5bb3\u7528\u6237\u4fe1\u4efb\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5", "method": "\u6df7\u5408\u65b9\u6cd5\uff1a\u7ed3\u5408Transformer\u6587\u672c\u5d4c\u5165\u4e0e15\u4e2a\u8bed\u8a00\u5b66\u7279\u5f81\u4fe1\u606f\u7279\u5f81\uff08\u5982\u7b2c\u4e8c\u4eba\u79f0\u4ee3\u8bcd\u3001\u6700\u9ad8\u7ea7\u3001\u6570\u5b57\u3001\u6ce8\u610f\u529b\u5bfc\u5411\u6807\u70b9\uff09\uff0c\u4f7f\u7528XGBoost\u5206\u7c7b\u5668", "result": "\u6700\u4f73\u6a21\u578bXGBoost\u5728\u589e\u5f3a\u7279\u5f81\u4e0a\u8fbe\u523091% F1\u5206\u6570\uff0c\u4f18\u4e8eTF-IDF\u3001Word2Vec\u3001GloVe\u3001LLM\u63d0\u793a\u5206\u7c7b\u548c\u7eaf\u7279\u5f81\u57fa\u7ebf", "conclusion": "\u63d0\u51fa\u7684\u7279\u5f81\u96c6\u901a\u8fc7\u7a81\u51fa\u663e\u6027\u8bed\u8a00\u5b66\u7ebf\u7d22\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u73b0\u4e86\u900f\u660e\u4e14\u6821\u51c6\u826f\u597d\u7684\u70b9\u51fb\u8bf1\u9975\u9884\u6d4b\uff0c\u5e76\u53d1\u5e03\u4e86\u4ee3\u7801\u548c\u8bad\u7ec3\u6a21\u578b"}}
{"id": "2602.18176", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18176", "abs": "https://arxiv.org/abs/2602.18176", "authors": ["Kaisen Yang", "Jayden Teoh", "Kaicheng Yang", "Yitong Zhang", "Alex Lamb"], "title": "Improving Sampling for Masked Diffusion Models via Information Gain", "comment": "https://github.com/yks23/Information-Gain-Sampler", "summary": "Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.", "code_url": "https://github.com/yks23/Information-Gain-Sampler", "code_stars": 0, "code_last_update": "2026-02-20", "AI": {"tldr": "\u63d0\u51faInfo-Gain Sampler\uff0c\u4e00\u79cd\u7528\u4e8e\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u5373\u65f6\u4e0d\u786e\u5b9a\u6027\u548c\u5bf9\u672a\u6765\u63a9\u7801\u6807\u8bb0\u7684\u4fe1\u606f\u589e\u76ca\uff0c\u89e3\u51b3\u73b0\u6709\u8d2a\u5a6a\u91c7\u6837\u5668\u5ffd\u89c6\u5f53\u524d\u89e3\u7801\u51b3\u7b56\u5bf9\u540e\u7eed\u6b65\u9aa4\u5f71\u54cd\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709MDM\u91c7\u6837\u5668\u901a\u5e38\u91c7\u7528\u8d2a\u5a6a\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4f18\u5148\u89e3\u7801\u5c40\u90e8\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u4f4d\u7f6e\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff1a\u5ffd\u89c6\u5f53\u524d\u89e3\u7801\u9009\u62e9\u5bf9\u540e\u7eed\u6b65\u9aa4\u7684\u4e0b\u6e38\u5f71\u54cd\uff0c\u672a\u80fd\u6700\u5c0f\u5316\u7d2f\u79ef\u4e0d\u786e\u5b9a\u6027\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528MDMs\u7684\u975e\u56e0\u679c\u7279\u6027\u3002", "method": "\u63d0\u51faInfo-Gain Sampler\u89e3\u7801\u6846\u67b6\uff0c\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u539f\u7406\uff0c\u5728\u6bcf\u4e00\u6b65\u89e3\u7801\u65f6\u4e0d\u4ec5\u8003\u8651\u5f53\u524d\u4f4d\u7f6e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd8\u8bc4\u4f30\u5f53\u524d\u89e3\u7801\u51b3\u7b56\u5982\u4f55\u91cd\u5851\u6240\u6709\u5269\u4f59\u63a9\u7801\u4f4d\u7f6e\u7684\u6807\u8bb0\u6982\u7387/\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u5e73\u8861\u5373\u65f6\u4e0d\u786e\u5b9a\u6027\u4e0e\u5bf9\u672a\u6765\u63a9\u7801\u6807\u8bb0\u7684\u4fe1\u606f\u589e\u76ca\u3002", "result": "\u5728\u591a\u6837\u5316\u67b6\u6784\u548c\u4efb\u52a1\uff08\u63a8\u7406\u3001\u7f16\u7801\u3001\u521b\u610f\u5199\u4f5c\u3001\u56fe\u50cf\u751f\u6210\uff09\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cInfo-Gain Sampler\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709MDM\u91c7\u6837\u5668\u3002\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53473.6%\uff0c\u521b\u610f\u5199\u4f5c\u4efb\u52a1\u4e0a\u80dc\u7387\u8fbe\u523063.1%\uff0c\u63a8\u7406\u4efb\u52a1\u7684\u7d2f\u79ef\u4e0d\u786e\u5b9a\u6027\u4ece78.4\u964d\u81f348.6\u3002", "conclusion": "Info-Gain Sampler\u901a\u8fc7\u5229\u7528MDMs\u7684\u975e\u56e0\u679c\u7279\u6027\uff0c\u7cfb\u7edf\u6027\u5730\u8003\u8651\u89e3\u7801\u51b3\u7b56\u5bf9\u540e\u7eed\u6b65\u9aa4\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u7684\u89e3\u7801\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86MDMs\u7684\u751f\u6210\u8d28\u91cf\u548c\u6027\u80fd\u3002"}}
{"id": "2602.18217", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18217", "abs": "https://arxiv.org/abs/2602.18217", "authors": ["Kohei Kajikawa", "Shinnosuke Isono", "Ethan Gotlieb Wilcox"], "title": "Information-Theoretic Storage Cost in Sentence Comprehension", "comment": null, "summary": "Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u53e5\u5b50\u7406\u89e3\u5de5\u4f5c\u8bb0\u5fc6\u8d1f\u8377\u6d4b\u91cf\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u7b26\u53f7\u8bed\u6cd5\u7684\u79bb\u6563\u6210\u672c\u5ea6\u91cf", "motivation": "\u5b9e\u65f6\u53e5\u5b50\u7406\u89e3\u5bf9\u5de5\u4f5c\u8bb0\u5fc6\u8d1f\u8377\u5f88\u5927\uff0c\u4f46\u73b0\u6709\u6d4b\u91cf\u4e3b\u8981\u57fa\u4e8e\u7b26\u53f7\u8bed\u6cd5\uff0c\u4f7f\u7528\u79bb\u6563\u7edf\u4e00\u7684\u53e5\u6cd5\u9884\u6d4b\u6210\u672c\uff0c\u9700\u8981\u66f4\u8fde\u7eed\u3001\u7406\u8bba\u4e2d\u7acb\u7684\u65b9\u6cd5", "method": "\u57fa\u4e8e\u4fe1\u606f\u8bba\u63d0\u51fa\u5904\u7406\u5b58\u50a8\u6210\u672c\u6d4b\u91cf\uff1a\u5148\u524d\u8bcd\u8bed\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u5bf9\u672a\u6765\u4e0a\u4e0b\u6587\u643a\u5e26\u7684\u4fe1\u606f\u91cf\uff0c\u53ef\u4ece\u9884\u8bad\u7ec3\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u4f30\u8ba1", "result": "\u5728\u82f1\u8bed\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff1a(1)\u6062\u590d\u4e86\u4e2d\u5fc3\u5d4c\u5957\u548c\u5173\u7cfb\u4ece\u53e5\u4e2d\u7684\u5df2\u77e5\u5904\u7406\u4e0d\u5bf9\u79f0\u6027\uff1b(2)\u4e0e\u8bed\u6cd5\u6807\u6ce8\u8bed\u6599\u5e93\u4e2d\u7684\u8bed\u6cd5\u5b58\u50a8\u6210\u672c\u76f8\u5173\uff1b(3)\u5728\u4e24\u5927\u81ea\u7136\u6570\u636e\u96c6\u4e0a\u9884\u6d4b\u9605\u8bfb\u65f6\u95f4\u65b9\u5dee\uff0c\u4f18\u4e8e\u4f20\u7edf\u4fe1\u606f\u9884\u6d4b\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u63d0\u51fa\u7684\u4fe1\u606f\u8bba\u6d4b\u91cf\u65b9\u6cd5\u4e3a\u53e5\u5b50\u7406\u89e3\u7684\u5de5\u4f5c\u8bb0\u5fc6\u8d1f\u8377\u63d0\u4f9b\u4e86\u8fde\u7eed\u3001\u7406\u8bba\u4e2d\u7acb\u7684\u91cf\u5316\u5de5\u5177\uff0c\u53ef\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u7b26\u53f7\u8bed\u6cd5\u7684\u79bb\u6563\u5ea6\u91cf"}}
{"id": "2602.18232", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18232", "abs": "https://arxiv.org/abs/2602.18232", "authors": ["Lexiang Tang", "Weihao Gao", "Bingchen Zhao", "Lu Ma", "Qiao jin", "Bang Yang", "Yuexian Zou"], "title": "Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning", "comment": null, "summary": "Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.", "code_url": "https://github.com/bolo-web/CCD", "code_stars": 0, "code_last_update": "2026-01-02", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u7684\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u4f4e\u7f6e\u4fe1\u5ea6\u6807\u8bb0\u5e76\u9009\u62e9\u6027\u5e72\u9884\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u53ef\u9760\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u8f93\u51fa\u957f\u5ea6", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5206\u914d\u66f4\u591a\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u80fd\u5747\u5300\u63d0\u5347\u6b63\u786e\u6027\uff0c\u4f46\u7814\u7a76\u8868\u660e\u63a8\u7406\u4e0d\u786e\u5b9a\u6027\u9ad8\u5ea6\u5c40\u90e8\u5316\uff1a\u5c11\u6570\u4f4e\u7f6e\u4fe1\u5ea6\u6807\u8bb0\u5bf9\u63a8\u7406\u9519\u8bef\u548c\u4e0d\u5fc5\u8981\u8f93\u51fa\u6269\u5c55\u8d21\u732e\u4e0d\u6210\u6bd4\u4f8b", "method": "\u63d0\u51faThinking by Subtraction\u65b9\u6cd5\uff0c\u91c7\u7528\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u7684\u5bf9\u6bd4\u89e3\u7801\uff0c\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u68c0\u6d4b\u4f4e\u7f6e\u4fe1\u5ea6\u6807\u8bb0\u5e76\u9009\u62e9\u6027\u5e72\u9884\uff0c\u901a\u8fc7\u7528\u6700\u5c0f\u5360\u4f4d\u7b26\u66ff\u6362\u9ad8\u7f6e\u4fe1\u5ea6\u6807\u8bb0\u6784\u5efa\u5bf9\u6bd4\u53c2\u8003\uff0c\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u4f4d\u7f6e\u901a\u8fc7\u51cf\u53bb\u53c2\u8003\u5206\u5e03\u6765\u7cbe\u70bc\u9884\u6d4b", "result": "CCD\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u8f93\u51fa\u957f\u5ea6\uff0c\u4ec5\u5e26\u6765\u6700\u5c0f\u7684KV\u7f13\u5b58\u5f00\u9500", "conclusion": "\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0cCCD\u901a\u8fc7\u9488\u5bf9\u6027\u7684\u4f4e\u7f6e\u4fe1\u5ea6\u5e72\u9884\u63d0\u5347\u4e86\u63a8\u7406\u53ef\u9760\u6027\uff0c\u907f\u514d\u4e86\u8ba1\u7b97\u5197\u4f59"}}
{"id": "2602.18262", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18262", "abs": "https://arxiv.org/abs/2602.18262", "authors": ["Aaron Louis Eidt", "Nils Feldhus"], "title": "Simplifying Outcomes of Language Model Component Analyses with ELIA", "comment": "EACL 2026 System Demonstrations. GitHub: https://github.com/aaron0eidt/ELIA", "summary": "While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.", "AI": {"tldr": "ELIA\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0fWeb\u5e94\u7528\uff0c\u901a\u8fc7\u6574\u5408\u4e09\u79cd\u53ef\u89e3\u91ca\u6027\u5206\u6790\u6280\u672f\u5e76\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u964d\u4f4e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5206\u6790\u7684\u95e8\u69db\uff0c\u4f7f\u975e\u4e13\u5bb6\u4e5f\u80fd\u7406\u89e3\u590d\u6742\u7684\u6a21\u578b\u5185\u90e8\u5de5\u4f5c\u539f\u7406\u3002", "motivation": "\u673a\u5236\u53ef\u89e3\u91ca\u6027\u9886\u57df\u867d\u7136\u5f00\u53d1\u4e86\u5f3a\u5927\u7684\u5de5\u5177\u6765\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u5de5\u4f5c\u539f\u7406\uff0c\u4f46\u5176\u590d\u6742\u6027\u9020\u6210\u4e86\u53ef\u8bbf\u95ee\u6027\u5dee\u8ddd\uff0c\u9650\u5236\u4e86\u8fd9\u4e9b\u5de5\u5177\u53ea\u80fd\u88ab\u4e13\u5bb6\u4f7f\u7528\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u8ba9\u66f4\u5e7f\u6cdb\u7684\u53d7\u4f17\u80fd\u591f\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7ec4\u4ef6\u5206\u6790\u7684\u7ed3\u679c\u3002", "method": "\u8bbe\u8ba1\u3001\u6784\u5efa\u548c\u8bc4\u4f30ELIA\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u6574\u5408\u4e86\u4e09\u79cd\u5173\u952e\u6280\u672f\uff1a\u5f52\u56e0\u5206\u6790\u3001\u51fd\u6570\u5411\u91cf\u5206\u6790\u548c\u7535\u8def\u8ffd\u8e2a\u3002\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u65b9\u6cd5\uff1a\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3a\u8fd9\u4e9b\u65b9\u6cd5\u4ea7\u751f\u7684\u590d\u6742\u53ef\u89c6\u5316\u81ea\u52a8\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7684\u7528\u6237\u7814\u7a76\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7528\u6237\u7814\u7a76\u663e\u793a\uff0c\u7528\u6237\u660e\u663e\u504f\u597d\u4ea4\u4e92\u5f0f\u3001\u53ef\u63a2\u7d22\u7684\u754c\u9762\u800c\u975e\u7b80\u5355\u7684\u9759\u6001\u53ef\u89c6\u5316\u3002\u5173\u952e\u53d1\u73b0\u662fAI\u751f\u6210\u7684\u89e3\u91ca\u5e2e\u52a9\u975e\u4e13\u5bb6\u5f25\u5408\u4e86\u77e5\u8bc6\u5dee\u8ddd\uff1b\u7edf\u8ba1\u5206\u6790\u663e\u793a\u7528\u6237\u7684\u5148\u9a8cLLM\u7ecf\u9a8c\u4e0e\u5176\u7406\u89e3\u5206\u6570\u4e4b\u95f4\u6ca1\u6709\u663e\u8457\u76f8\u5173\u6027\uff0c\u8868\u660e\u8be5\u7cfb\u7edf\u964d\u4f4e\u4e86\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u7528\u6237\u7684\u8ba4\u77e5\u969c\u788d\u3002", "conclusion": "AI\u7cfb\u7edf\u786e\u5b9e\u53ef\u4ee5\u7b80\u5316\u590d\u6742\u7684\u6a21\u578b\u5206\u6790\uff0c\u4f46\u5176\u771f\u6b63\u6f5c\u529b\u5728\u4e8e\u4e0e\u6df1\u601d\u719f\u8651\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u76f8\u7ed3\u5408\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u4f18\u5148\u8003\u8651\u4ea4\u4e92\u6027\u3001\u5177\u4f53\u6027\u548c\u53d9\u4e8b\u6307\u5bfc\uff0c\u4ece\u800c\u89e3\u9501\u7cfb\u7edf\u7684\u5168\u90e8\u80fd\u529b\u3002"}}
{"id": "2602.18324", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18324", "abs": "https://arxiv.org/abs/2602.18324", "authors": ["Alexandra Ciobotaru", "Ana-Maria Bucur", "Liviu P. Dinu"], "title": "PsihoRo: Depression and Anxiety Romanian Text Corpus", "comment": "This article was accepted at LREC 2026", "summary": "Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.", "AI": {"tldr": "\u521b\u5efa\u4e86\u9996\u4e2a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u6291\u90c1\u548c\u7126\u8651\u8bed\u6599\u5e93PsihoRo\uff0c\u5305\u542b205\u540d\u53d7\u8bbf\u8005\u7684\u5f00\u653e\u5f0f\u95ee\u9898\u56de\u7b54\u548c\u6807\u51c6\u5316\u7b5b\u67e5\u95ee\u5377\uff0c\u586b\u8865\u4e86\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u5fc3\u7406\u5065\u5eb7NLP\u8d44\u6e90\u7684\u7a7a\u767d\u3002", "motivation": "\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u76ee\u524d\u6ca1\u6709\u5f00\u6e90\u7684\u5fc3\u7406\u5065\u5eb7\u8bed\u6599\u5e93\uff0c\u800c\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u4ece\u793e\u4ea4\u5a92\u4f53\u6536\u96c6\u5b58\u5728\u5047\u8bbe\u504f\u5dee\u95ee\u9898\u3002\u9700\u8981\u66f4\u5b9e\u7528\u7684\u6570\u636e\u6536\u96c6\u7b56\u7565\u6765\u586b\u8865\u8fd9\u4e00\u8bed\u8a00\u8d44\u6e90\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5305\u542b6\u4e2a\u5f00\u653e\u5f0f\u95ee\u9898\u7684\u8868\u5355\u6536\u96c6\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u6807\u51c6\u5316\u7684PHQ-9\u548cGAD-7\u7b5b\u67e5\u95ee\u5377\u3002\u5bf9205\u540d\u53d7\u8bbf\u8005\u7684\u6587\u672c\u91c7\u7528\u7edf\u8ba1\u5206\u6790\u3001\u7f57\u9a6c\u5c3c\u4e9a\u8bedLIWC\u6587\u672c\u5206\u6790\u3001\u60c5\u7eea\u68c0\u6d4b\u548c\u4e3b\u9898\u5efa\u6a21\u7b49\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u9996\u4e2a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u6291\u90c1\u548c\u7126\u8651\u8bed\u6599\u5e93PsihoRo\uff0c\u867d\u7136\u89c4\u6a21\u8f83\u5c0f\uff08205\u540d\u53d7\u8bbf\u8005\uff09\uff0c\u4f46\u4e3a\u5206\u6790\u7f57\u9a6c\u5c3c\u4e9a\u4eba\u53e3\u5fc3\u7406\u5065\u5eb7\u6587\u672c\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\u3002", "conclusion": "PsihoRo\u662f\u7406\u89e3\u548c\u5206\u6790\u7f57\u9a6c\u5c3c\u4e9a\u4eba\u53e3\u5fc3\u7406\u5065\u5eb7\u6587\u672c\u7684\u7b2c\u4e00\u6b65\uff0c\u901a\u8fc7\u591a\u79cd\u5206\u6790\u65b9\u6cd5\u5c55\u793a\u4e86\u8fd9\u4e00\u65b0\u8d44\u6e90\u7684\u91cd\u8981\u7279\u5f81\uff0c\u4e3a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u5fc3\u7406\u5065\u5eb7NLP\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.18346", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18346", "abs": "https://arxiv.org/abs/2602.18346", "authors": ["Pavithra PM Nair", "Preethu Rose Anish"], "title": "Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System", "comment": null, "summary": "In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.", "AI": {"tldr": "Vichara\u662f\u4e00\u4e2a\u9488\u5bf9\u5370\u5ea6\u53f8\u6cd5\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u89e3\u91ca\u4e0a\u8bc9\u5224\u51b3\uff0c\u901a\u8fc7\u5c06\u6848\u4ef6\u6587\u6863\u5206\u89e3\u4e3a\u51b3\u7b56\u70b9\uff0c\u91c7\u7528\u7c7b\u4f3cIRAC\u7684\u7ed3\u6784\u5316\u89e3\u91ca\uff0c\u5728\u591a\u4e2aLLM\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5370\u5ea6\u6cd5\u9662\u9762\u4e34\u5927\u91cf\u6848\u4ef6\u79ef\u538b\uff0c\u7279\u522b\u662f\u4e0a\u8bc9\u6848\u4ef6\uff0c\u9700\u8981\u5229\u7528\u4eba\u5de5\u667a\u80fd\u8fdb\u884c\u5224\u51b3\u9884\u6d4b\u4ee5\u63d0\u9ad8\u53f8\u6cd5\u6548\u7387\u3002\u4e0a\u8bc9\u6848\u4ef6\u4f5c\u4e3a\u9ad8\u7b49\u6cd5\u9662\u5bf9\u4e0b\u7ea7\u6cd5\u9662\u88c1\u51b3\u7684\u6b63\u5f0f\u5ba1\u67e5\u51b3\u5b9a\uff0c\u662f\u79ef\u538b\u6848\u4ef6\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002", "method": "Vichara\u6846\u67b6\u5904\u7406\u82f1\u6587\u4e0a\u8bc9\u6848\u4ef6\u7a0b\u5e8f\u6587\u6863\uff0c\u5c06\u5176\u5206\u89e3\u4e3a\u51b3\u7b56\u70b9\u2014\u2014\u5305\u542b\u6cd5\u5f8b\u95ee\u9898\u3001\u88c1\u51b3\u673a\u6784\u3001\u7ed3\u679c\u3001\u63a8\u7406\u548c\u65f6\u95f4\u80cc\u666f\u7684\u79bb\u6563\u6cd5\u5f8b\u51b3\u5b9a\u3002\u91c7\u7528\u7ed3\u6784\u5316\u8868\u793a\u5206\u79bb\u6838\u5fc3\u51b3\u5b9a\u53ca\u5176\u4e0a\u4e0b\u6587\uff0c\u9884\u6d4b\u89e3\u91ca\u9075\u5faa\u7c7b\u4f3cIRAC\u6846\u67b6\u4f46\u9002\u5e94\u5370\u5ea6\u6cd5\u5f8b\u63a8\u7406\u7684\u7ed3\u6784\u5316\u683c\u5f0f\u3002", "result": "\u5728PredEx\u548cILDC_expert\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528GPT-4o mini\u3001Llama-3.1-8B\u3001Mistral-7B\u548cQwen2.5-7B\u56db\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u3002Vichara\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u90fd\u8d85\u8d8a\u4e86\u73b0\u6709\u5224\u51b3\u9884\u6d4b\u57fa\u51c6\uff0cGPT-4o mini\u8868\u73b0\u6700\u4f73\uff08PredEx F1: 81.5\uff0cILDC_expert F1: 80.3\uff09\uff0cLlama-3.1-8B\u6b21\u4e4b\u3002\u4eba\u7c7b\u8bc4\u4f30\u663e\u793aGPT-4o mini\u5728\u6e05\u6670\u5ea6\u3001\u5173\u8054\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u89e3\u91ca\u80fd\u529b\u6700\u5f3a\u3002", "conclusion": "Vichara\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u51b3\u7b56\u70b9\u8868\u793a\u548c\u7c7b\u4f3cIRAC\u7684\u89e3\u91ca\u683c\u5f0f\uff0c\u4e3a\u5370\u5ea6\u53f8\u6cd5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u51c6\u786e\u53ef\u89e3\u91ca\u7684\u4e0a\u8bc9\u5224\u51b3\u9884\u6d4b\uff0c\u5728\u591a\u4e2aLLM\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cGPT-4o mini\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u65b9\u9762\u5747\u8868\u73b0\u6700\u4f73\u3002"}}
{"id": "2602.18351", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18351", "abs": "https://arxiv.org/abs/2602.18351", "authors": ["Jordan Robinson", "Angus R. Williams", "Katie Atkinson", "Anthony G. Cohn"], "title": "Validating Political Position Predictions of Arguments", "comment": "13 pages, 6 figures, 6 tables. Under review", "summary": "Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \\textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $\u03b1=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($\u03b1=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u5c3a\u5ea6\u9a8c\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u9010\u70b9\u4e0e\u6210\u5bf9\u4eba\u5de5\u6807\u6ce8\uff0c\u7528\u4e8e\u653f\u6cbb\u7acb\u573a\u9884\u6d4b\u7684\u4e3b\u89c2\u8fde\u7eed\u77e5\u8bc6\u8868\u793a\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u8bba\u8bc1\u77e5\u8bc6\u5e93\u5e76\u9a8c\u8bc1\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u8868\u793a\u5e38\u9700\u6355\u6349\u4e3b\u89c2\u8fde\u7eed\u5c5e\u6027\uff08\u5982\u653f\u6cbb\u7acb\u573a\uff09\uff0c\u8fd9\u4e0e\u5e7f\u6cdb\u63a5\u53d7\u7684\u6210\u5bf9\u9a8c\u8bc1\u9ec4\u91d1\u6807\u51c6\u76f8\u51b2\u7a81\u3002\u9700\u8981\u89e3\u51b3\u4e3b\u89c2\u8fde\u7eed\u77e5\u8bc6\u9a8c\u8bc1\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u53cc\u5c3a\u5ea6\u9a8c\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u9010\u70b9\uff08pointwise\uff09\u548c\u6210\u5bf9\uff08pairwise\uff09\u4eba\u5de5\u6807\u6ce8\u3002\u4f7f\u752822\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u6784\u5efa\u5305\u542b23,228\u4e2a\u8bba\u8bc1\u7684\u5927\u89c4\u6a21\u653f\u6cbb\u7acb\u573a\u9884\u6d4b\u77e5\u8bc6\u5e93\uff0c\u6570\u636e\u6765\u81ea\u82f1\u56fd\u653f\u6cbb\u7535\u89c6\u8282\u76ee\u300aQuestion Time\u300b\u768430\u573a\u8fa9\u8bba\u3002", "result": "\u9010\u70b9\u8bc4\u4f30\u663e\u793a\u4e2d\u7b49\u6c34\u5e73\u7684\u4eba\u673a\u4e00\u81f4\u6027\uff08Krippendorff's \u03b1=0.578\uff09\uff0c\u53cd\u6620\u5185\u5728\u4e3b\u89c2\u6027\uff1b\u6210\u5bf9\u9a8c\u8bc1\u663e\u793a\u4eba\u673a\u6392\u540d\u5bf9\u9f50\u663e\u8457\u66f4\u5f3a\uff08\u6700\u4f73\u6a21\u578b\u03b1=0.86\uff09\u3002\u6210\u529f\u6784\u5efa\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u7ed3\u6784\u5316\u8bba\u8bc1\u77e5\u8bc6\u5e93\u3002", "conclusion": "\u63d0\u51fa\u5b9e\u7528\u7684\u4e3b\u89c2\u8fde\u7eed\u77e5\u8bc6\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5e73\u8861\u53ef\u6269\u5c55\u6027\u4e0e\u53ef\u9760\u6027\uff1b\u6784\u5efa\u652f\u6301\u57fa\u4e8e\u56fe\u63a8\u7406\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u653f\u6cbb\u9886\u57df\u77e5\u8bc6\u5e93\uff1b\u8bc1\u660e\u53ef\u4ece\u70b9\u5f0f\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u4e2d\u63d0\u53d6\u5e8f\u6570\u7ed3\u6784\uff0c\u63a8\u8fdb\u4f20\u7edf\u7b26\u53f7\u6216\u5206\u7c7b\u65b9\u6cd5\u4e0d\u8db3\u9886\u57df\u7684\u77e5\u8bc6\u8868\u793a\u80fd\u529b\u3002"}}
