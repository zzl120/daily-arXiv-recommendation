{"id": "2602.16034", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16034", "abs": "https://arxiv.org/abs/2602.16034", "authors": ["Xinrui He", "Ting-Wei Li", "Tianxin Wei", "Xuying Ning", "Xinyu He", "Wenxuan Bao", "Hanghang Tong", "Jingrui He"], "title": "FeDecider: An LLM-Based Framework for Federated Cross-Domain Recommendation", "comment": "Accepted to The Web Conference (WWW) 2026", "summary": "Federated cross-domain recommendation (Federated CDR) aims to collaboratively learn personalized recommendation models across heterogeneous domains while preserving data privacy. Recently, large language model (LLM)-based recommendation models have demonstrated impressive performance by leveraging LLMs' strong reasoning capabilities and broad knowledge. However, adopting LLM-based recommendation models in Federated CDR scenarios introduces new challenges. First, there exists a risk of overfitting with domain-specific local adapters. The magnitudes of locally optimized parameter updates often vary across domains, causing biased aggregation and overfitting toward domain-specific distributions. Second, unlike traditional recommendation models (e.g., collaborative filtering, bipartite graph-based methods) that learn explicit and comparable user/item representations, LLMs encode knowledge implicitly through autoregressive text generation training. This poses additional challenges for effectively measuring the cross-domain similarities under heterogeneity. To address these challenges, we propose an LLM-based framework for federated cross-domain recommendation, FeDecider. Specifically, FeDecider tackles the challenge of scale-specific noise by disentangling each client's low-rank updates and sharing only their directional components. To handle the need for flexible and effective integration, each client further learns personalized weights that achieve the data-aware integration of updates from other domains. Extensive experiments across diverse datasets validate the effectiveness of our proposed FeDecider."}
{"id": "2602.16124", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16124", "abs": "https://arxiv.org/abs/2602.16124", "authors": ["Jiang Zhang", "Yubo Wang", "Wei Chang", "Lu Han", "Xingying Cheng", "Feng Zhang", "Min Li", "Songhao Jiang", "Wei Zheng", "Harry Tran", "Zhen Wang", "Lei Chen", "Yueming Wang", "Benyu Zhang", "Xiangjun Fan", "Bi Xue", "Qifan Wang"], "title": "Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System", "comment": null, "summary": "Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\\%, cold-content delivery by up to 57.29\\%, and semantic relevance by 13.5\\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency."}
{"id": "2602.16136", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16136", "abs": "https://arxiv.org/abs/2602.16136", "authors": ["Hongyeon Yu", "Dongchan Kim", "Young-Bum Kim"], "title": "Retrieval Collapses When AI Pollutes the Web", "comment": "4 pages, Proceedings of The Web Conference 2026 (WWW '26)", "summary": "The rapid proliferation of AI-generated content on the Web presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG) systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates search results, eroding source diversity, and (2) low-quality or adversarial content infiltrates the retrieval pipeline. We analyzed this dynamic through controlled experiments involving both high-quality SEO-style content and adversarially crafted content. In the SEO scenario, a 67\\% pool contamination led to over 80\\% exposure contamination, creating a homogenized yet deceptively healthy state where answer accuracy remains stable despite the reliance on synthetic sources. Conversely, under adversarial contamination, baselines like BM25 exposed $\\sim$19\\% of harmful content, whereas LLM-based rankers demonstrated stronger suppression capabilities. These findings highlight the risk of retrieval pipelines quietly shifting toward synthetic evidence and the need for retrieval-aware strategies to prevent a self-reinforcing cycle of quality decline in Web-grounded systems."}
{"id": "2602.16299", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16299", "abs": "https://arxiv.org/abs/2602.16299", "authors": ["Mathias Vast", "Victor Morand", "Basile van Cooten", "Laure Soulier", "Josiane Mothe", "Benjamin Piwowarski"], "title": "MICE: Minimal Interaction Cross-Encoders for efficient Re-ranking", "comment": "9 pages, 5 figures", "summary": "Cross-encoders deliver state-of-the-art ranking effectiveness in information retrieval, but have a high inference cost. This prevents them from being used as first-stage rankers, but also incurs a cost when re-ranking documents. Prior work has addressed this bottleneck from two largely separate directions: accelerating cross-encoder inference by sparsifying the attention process or improving first-stage retrieval effectiveness using more complex models, e.g. late-interaction ones. In this work, we propose to bridge these two approaches, based on an in-depth understanding of the internal mechanisms of cross-encoders. Starting from cross-encoders, we show that it is possible to derive a new late-interaction-like architecture by carefully removing detrimental or unnecessary interactions. We name this architecture MICE (Minimal Interaction Cross-Encoders). We extensively evaluate MICE across both in-domain (ID) and out-of-domain (OOD) datasets. MICE decreases fourfold the inference latency compared to standard cross-encoders, matching late-interaction models like ColBERT while retaining most of cross-encoder ID effectiveness and demonstrating superior generalization abilities in OOD."}
{"id": "2602.16315", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16315", "abs": "https://arxiv.org/abs/2602.16315", "authors": ["Gabriele Barlacchi", "Margherita Lalli", "Emanuele Ferragina", "Fosca Giannotti", "Dino Pedreschi", "Luca Pappalardo"], "title": "The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems", "comment": null, "summary": "Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems."}
{"id": "2602.16375", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16375", "abs": "https://arxiv.org/abs/2602.16375", "authors": ["Kirill Khrylchenko"], "title": "Variable-Length Semantic IDs for Recommender Systems", "comment": null, "summary": "Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem.\n  However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems.\n  In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods."}
{"id": "2602.16541", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16541", "abs": "https://arxiv.org/abs/2602.16541", "authors": ["Santiago de Leon-Martinez", "Robert Moro", "Branislav Kveton", "Maria Bielikova"], "title": "From Latent to Observable Position-Based Click Models in Carousel Interfaces", "comment": null, "summary": "Click models are a central component of learning and evaluation in recommender systems, yet most existing models are designed for single ranked-list interfaces. In contrast, modern recommender platforms increasingly use complex interfaces such as carousels, which consist of multiple swipeable lists that enable complex user browsing behaviors.\n  In this paper, we study position-based click models in carousel interfaces and examine optimization methods, model structure, and alignment with user behavior. We propose three novel position-based models tailored to carousels, including the first position-based model without latent variables that incorporates observed examination signals derived from eye tracking data, called the Observed Examination Position-Based Model (OEPBM). We develop a general implementation of these carousel click models, supporting multiple optimization techniques and conduct experiments comparing gradient-based methods with classical approaches, namely expectation-maximization and maximum likelihood estimation.\n  Our results show that gradient-based optimization consistently achieve better click likelihoods. Among the evaluated models, the OEPBM achieves the strongest performance in click prediction and produces examination patterns that most closely align to user behavior. However, we also demonstrate that strong click fit does not imply realistic modeling of user examination and browsing patterns. This reveals a fundamental limitation of click-only models in complex interfaces and the need for incorporating additional behavioral signals when designing click models for carousel-based recommender systems."}
{"id": "2602.16587", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16587", "abs": "https://arxiv.org/abs/2602.16587", "authors": ["Luankang Zhang", "Yonghao Huang", "Hang Lv", "Mingjia Yin", "Liangyue Li", "Zulong Chen", "Hao Wang", "Enhong Chen"], "title": "Why Thinking Hurts? Diagnosing and Rectifying the Reasoning Shift in Foundation Recommender Models", "comment": null, "summary": "Integrating Chain-of-Thought (CoT) reasoning into Semantic ID-based recommendation foundation models (such as OpenOneRec) often paradoxically degrades recommendation performance. We identify the root cause as textual inertia from the General Subspace, where verbose reasoning dominates inference and causes the model to neglect critical Semantic ID. To address this, we propose a training-free Inference-Time Subspace Alignment framework. By compressing reasoning chains and applying bias-subtracted contrastive decoding, our approach mitigates ungrounded textual drift. Experiments show this effectively calibrates inference, allowing foundation models to leverage reasoning without sacrificing ID-grounded accuracy."}
