<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 22]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [On the scaling relationship between cloze probabilities and language model next-token prediction](https://arxiv.org/abs/2602.17848)
*Cassandra L. Jacobs,Morgan Grobol*

Main category: cs.CL

TL;DR: 研究发现更大语言模型在眼动和阅读时间数据预测上表现更好，但对人类反应概率分配不足；大模型在完形填空数据中能提供更高质量的下一个词及其产生概率估计，因为它们对词汇共现统计不敏感，但语义上与人类完形填空反应更一致。


<details>
  <summary>Details</summary>
Motivation: 探索不同规模语言模型在预测人类眼动、阅读时间和完形填空反应方面的表现差异，理解模型规模如何影响其对语言处理的预测能力，特别是对语义和词汇层面信息的敏感性。

Method: 通过比较不同规模的语言模型在眼动数据、阅读时间数据和完形填空数据上的预测表现，分析模型对下一个词的预测质量及其与人类反应的匹配程度，特别关注模型对词汇共现统计的敏感性和语义对齐程度。

Result: 更大语言模型在眼动和阅读时间预测上表现更好，但对人类反应概率分配不足；大模型在完形填空任务中能提供更高质量的下一个词及其产生概率估计，因为它们对词汇共现统计不敏感，但语义上与人类完形填空反应更一致。

Conclusion: 更大模型的记忆能力帮助它们猜测更语义合适的词，但使它们对与词汇识别相关的低层次信息不敏感；研究结果支持了模型规模增加会改善语义对齐但降低对低层次语言信息敏感性的观点。

Abstract: Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.

</details>


### [2] [Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations](https://arxiv.org/abs/2602.17881)
*Joschka Braun*

Main category: cs.CL

TL;DR: 该论文研究了语言模型引导向量（steering vectors）的可靠性问题，发现引导效果在不同行为样本间存在差异，并提出通过训练激活差异的余弦相似度和行为表示的可分离性来诊断引导不可靠性。


<details>
  <summary>Details</summary>
Motivation: 引导向量是一种通过在推理时向激活添加学习偏置来控制语言模型行为的轻量级方法。虽然平均效果有效，但引导效果在不同样本间变化很大，对许多目标行为不可靠。论文旨在探究引导可靠性在不同行为间差异的原因及其受训练数据的影响。

Method: 研究通过分析引导向量训练数据与可靠性之间的关系来探究问题：1）测量训练激活差异的余弦相似度与引导可靠性的相关性；2）评估行为数据集中正负激活在引导方向上的可分离性；3）比较不同提示变体训练的引导向量的方向差异和性能表现。

Result: 主要发现：1）训练激活差异的余弦相似度越高，引导越可靠；2）正负激活在引导方向上分离度更好的行为数据集更易被可靠引导；3）不同提示变体训练的引导向量方向不同但性能相似，且在不同数据集上的效果相关。这表明当潜在目标行为表示无法被线性引导方向有效近似时，引导向量不可靠。

Conclusion: 引导向量的不可靠性源于潜在目标行为表示无法被线性方向有效近似。研究结果为诊断引导不可靠性提供了实用方法，并激励开发更鲁棒的引导方法，这些方法应明确考虑非线性潜在行为表示。

Abstract: Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

</details>


### [3] [Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions](https://arxiv.org/abs/2602.17907)
*Raymond Li,Amirhossein Abaskohi,Chuyuan Li,Gabriel Murray,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出一种利用语言模型生成语义软标签来训练神经主题模型的新方法，通过投影下一个token概率到预定义词汇获得上下文丰富的监督信号，显著提升主题质量和文档检索效果。


<details>
  <summary>Details</summary>
Motivation: 传统神经主题模型通常通过重构文档的词袋表示进行优化，忽略了上下文信息且难以处理数据稀疏性问题。需要一种能够利用语言模型丰富语义信息来提升主题质量的方法。

Method: 使用语言模型生成语义软标签目标：通过专门设计的提示词条件化，投影下一个token的概率到预定义词汇上，获得上下文丰富的监督信号。然后训练主题模型使用语言模型的隐藏状态来重构这些软标签。

Result: 在三个数据集上的实验表明，该方法在主题连贯性和纯度方面相比现有基线有显著提升。引入的基于检索的指标显示，该方法在识别语义相似文档方面明显优于现有方法，特别适用于检索导向的应用。

Conclusion: 提出的利用语言模型生成语义软标签的方法能够有效提升神经主题模型的质量，产生更符合语料底层主题结构的高质量主题，并在文档检索应用中表现出色。

Abstract: Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

</details>


### [4] [Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering](https://arxiv.org/abs/2602.17911)
*Jash Rajesh Parekh,Wonbin Kweon,Joey Chan,Rezarta Islamaj,Robert Leaman,Pengcheng Jiang,Chih-Hsuan Wei,Zhizheng Wang,Zhiyong Lu,Jiawei Han*

Main category: cs.CL

TL;DR: CondMedQA是首个条件生物医学问答基准，提出条件门控推理框架，通过构建条件感知知识图谱和选择性激活推理路径来提升条件推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前生物医学问答系统假设医学知识普遍适用，但真实临床推理本质上是条件性的——几乎所有决策都依赖于患者特定因素。现有基准无法评估此类条件推理，检索增强或基于图的方法缺乏确保检索知识适用于给定上下文的明确机制。

Method: 提出条件门控推理框架：1) 构建条件感知知识图谱；2) 基于查询条件选择性激活或剪枝推理路径。同时创建CondMedQA基准，包含答案随患者条件变化的多跳问题。

Result: CGR框架在可靠选择条件适当答案方面表现更优，同时在生物医学问答基准上达到或超越最先进性能，突显显式建模条件性对稳健医学推理的重要性。

Conclusion: 显式建模条件性对于稳健医学推理至关重要，CondMedQA基准和CGR框架为解决生物医学问答中的条件推理问题提供了有效方案。

Abstract: Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

</details>


### [5] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 该论文首次系统比较了基于DSPy优化框架的指令优化方法在表格事实验证任务中的应用，评估了四种提示技术，发现指令优化能持续提升验证准确率，不同优化器对不同提示技术有特定优势。


<details>
  <summary>Details</summary>
Motivation: 指令优化为提升大型语言模型推理性能提供了一种轻量级、模型无关的方法。目前缺乏对表格事实验证任务中指令优化的系统性比较研究，特别是基于DSPy框架的优化方法在不同提示技术和模型规模下的表现差异。

Method: 基于DSPy优化框架，评估了四种提示技术：直接预测、思维链(CoT)、使用SQL工具的ReAct、使用Python执行的CodeAct。研究了DSPy框架中的三种优化器——COPRO、MiPROv2和SIMBA，在四个基准测试和三个模型家族上进行实验。

Result: 指令优化持续提升验证准确率：MiPROv2在CoT上获得最稳定的增益，SIMBA为ReAct智能体提供最大收益，特别是在较大模型规模下。行为分析显示SIMBA通过应用启发式方法鼓励更直接的推理路径，从而提升CoT推理中的数值比较能力，并帮助ReAct智能体避免不必要的工具调用。

Conclusion: 对于表格事实检查，CoT仍然有效，特别是在较小模型中。虽然使用较大模型构建的ReAct智能体可以达到竞争性性能，但需要仔细的指令优化。不同优化器对不同提示技术有特定优势，SIMBA在鼓励直接推理路径方面表现突出。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


### [6] [CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications](https://arxiv.org/abs/2602.17949)
*Victoria Blake,Mathew Miller,Jamie Novak,Sze-yuan Ooi,Blanca Gallego*

Main category: cs.CL

TL;DR: CUICurate：基于图检索增强生成的UMLS概念集自动构建框架，结合知识图谱检索与LLM推理，显著减少人工工作量


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别工具通常将自由文本映射到UMLS概念唯一标识符(CUIs)，但许多下游任务需要的是包含相关同义词、子类型和超类型的概念集。目前构建这类概念集劳动密集、执行不一致，且现有工具支持不足，特别是对于直接在UMLS CUIs上操作的NLP管道。

Method: 提出CUICurate框架，采用基于图的检索增强生成方法：1)构建并嵌入UMLS知识图谱用于语义检索；2)针对每个目标概念，从知识图谱检索候选CUIs；3)使用大型语言模型进行过滤和分类，比较了GPT-5和GPT-5-mini两种模型。

Result: 在五个词汇异质性临床概念上评估，CUICurate生成的概念集比人工基准更大更完整，同时保持与人类相当的精确度。GPT-5-mini在过滤阶段召回率更高，GPT-5的分类结果更符合临床医生判断。输出在重复运行中稳定且计算成本低。

Conclusion: CUICurate提供了一种可扩展且可重复的方法来支持UMLS概念集构建，显著减少人工工作量。通过结合基于图的检索与LLM推理，该框架生成聚焦的候选概念集，可适应不同表型和分析需求的临床NLP管道。

Abstract: Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

</details>


### [7] [Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering](https://arxiv.org/abs/2602.17981)
*Amine Kobeissi,Philippe Langlais*

Main category: cs.CL

TL;DR: 该论文研究了金融问答中检索增强生成的失败模式：正确文档被检索到，但包含答案的具体页面或块被遗漏，导致生成器基于不完整上下文进行推断。作者提出了领域微调的页面评分器，显著提升了页面召回率和块检索性能。


<details>
  <summary>Details</summary>
Motivation: 在金融监管文件问答中，检索增强生成虽然常用，但其可靠性依赖于检索到确切的上下文来支持答案。作者关注一个常见的失败模式：正确文档被检索到，但包含答案的具体页面或块被遗漏，导致生成器基于不完整上下文进行推断。尽管这种文档内检索失败模式在实际应用中很重要，但在金融问答文献中缺乏系统研究。

Method: 1. 在FinanceBench的150个问题子集上评估多粒度检索（文档、页面、块级别）；2. 引入基于oracle的分析来提供检索和生成性能的经验上界；3. 复现和比较多种检索策略（密集、稀疏、混合、分层方法，包括重排序和查询重构）；4. 提出领域微调的页面评分器，将页面作为文档和块之间的中间检索单元，专门针对金融文件微调双编码器以评估页面级相关性。

Result: 1. 跨方法分析显示，文档发现率的提升往往转化为更强的页面召回率；2. Oracle性能表明页面和块级检索仍有改进空间；3. 提出的领域微调页面评分器显著提升了页面召回率和块检索性能；4. 利用页面的语义连贯性，在金融文件上专门微调的双编码器优于先前基于段落的分层检索方法。

Conclusion: 该研究系统分析了金融问答中检索增强生成的文档内检索失败模式，并提出了有效的解决方案。通过引入领域微调的页面评分器，显著改善了页面级检索性能，为高风险的金融问答应用提供了更可靠的检索增强生成框架。研究强调了在金融领域特定上下文中优化中间粒度检索单元的重要性。

Abstract: Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

</details>


### [8] [Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092)
*Matthew DiGiuseppe,Joshua Robison*

Main category: cs.CL

TL;DR: 研究发现，当用户认为聊天AI存在党派偏见时，其纠正错误观念的说服力会显著下降28%，表明AI说服效果受政治中立性感知影响


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨精英阶层对大型语言模型（LLM）的党派偏见指控是否会影响其作为纠正公共错误观念工具的有效性。随着LLM进入党派冲突领域，了解其说服力是否受政治中立性感知的影响至关重要。

Method: 采用预注册的美国调查实验（N=2144），参与者与ChatGPT进行三轮关于个人持有的经济政策错误观念的对话。实验设置中性对照组和实验组（实验组收到简短信息表明LLM对参与者所属党派存在偏见）。通过转录分析研究警告信息如何改变互动过程。

Result: 实验结果显示，与中性对照组相比，收到LLM存在党派偏见警告的实验组中，ChatGPT的说服力下降了28%。转录分析表明，警告改变了互动过程：受访者更频繁地反驳，且接受度更低。

Conclusion: 研究表明，对话式AI的说服效果具有政治条件性，受党派一致性感知的限制。精英阶层对LLM的党派偏见指控会显著削弱其纠正错误观念的能力，这对AI作为公共信息传播工具的应用具有重要意义。

Abstract: Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.

</details>


### [9] [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137)
*Vincent Grari,Ciprian Tomoiaga,Sylvain Lamprier,Tatsunori Hashimoto,Marcin Detyniecki*

Main category: cs.CL

TL;DR: 提出对抗性问答生成框架，通过对比目标模型与专家模型输出，生成紧凑的语义挑战性问题，在专业领域微调中实现更高准确率和更少样本需求


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域适应能力有限，现有微调方法面临高质量任务相关数据稀缺的问题。传统合成数据生成方法（如改写或知识提取）虽然擅长事实回忆和概念知识，但存在两个关键缺陷：1) 对专业领域解释性推理能力支持不足；2) 生成的合成语料库通常过大且冗余，样本效率低下。

Method: 提出对抗性问答生成框架，通过迭代反馈驱动过程生成紧凑的语义挑战性问题。该方法比较待适应模型与基于参考文档的稳健专家模型的输出，识别并解决理解差距。具体流程包括：1) 使用专家模型生成参考答案；2) 对比目标模型输出与专家模型输出；3) 识别理解差距并生成针对性挑战问题；4) 迭代优化问题生成。

Result: 在LegalBench语料库的专业子集上评估表明，该方法在显著减少合成样本数量的情况下实现了更高的准确率。相比传统合成数据生成方法，本方法在样本效率方面表现更优。

Conclusion: 对抗性问答生成框架有效解决了专业领域微调中的数据稀缺和样本效率问题，通过生成紧凑的语义挑战性问题，显著提升了大语言模型在专业领域的适应能力和推理能力。

Abstract: Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

</details>


### [10] [Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention](https://arxiv.org/abs/2602.18145)
*Siya Qi,Yudong Chen,Runcong Zhao,Qinglin Zhu,Zhanghao Hu,Wei Liu,Yulan He,Zheng Yuan,Lin Gui*

Main category: cs.CL

TL;DR: 提出基于频率分析的注意力机制检测方法，通过分析注意力分布的高频成分来识别大语言模型生成中的幻觉现象


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力的幻觉检测方法通常依赖粗粒度汇总，无法捕捉注意力中的细粒度不稳定性，需要更精细的分析方法

Method: 将注意力分布建模为离散信号，提取反映注意力快速局部变化的高频成分，基于高频注意力特征构建轻量级幻觉检测器

Result: 在RAGTruth和HalluRAG基准测试中，该方法在跨模型和任务上超越了基于验证、内部表示和注意力的现有方法

Conclusion: 注意力分布的高频成分能有效反映幻觉相关的碎片化和不稳定接地行为，为幻觉检测提供了新的信号处理视角

Abstract: Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

</details>


### [11] [The Statistical Signature of LLMs](https://arxiv.org/abs/2602.18152)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Niccolò Di Marco,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CL

TL;DR: 该研究使用无损压缩作为模型无关的度量方法，揭示了LLM生成文本与人类写作在统计规律性上的系统性差异：LLM文本通常具有更高的结构规律性和可压缩性，但在小尺度碎片化交互环境中这种差异会减弱。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过概率采样生成文本，但这一过程如何重塑语言的结构统计组织尚未完全表征。研究者希望找到一种简单、模型无关的方法来量化生成系统如何重塑文本生产，提供关于通信复杂性演化的结构视角。

Method: 使用无损压缩作为统计规律性的度量方法，分析三个渐进复杂的信息生态系统：1) 受控的人类-LLM延续任务；2) 知识基础设施的生成中介（维基百科 vs. Grokipedia）；3) 完全合成的社交互动环境（Moltbook vs. Reddit）。该方法直接从表面文本观察压缩行为，不依赖模型内部或语义评估。

Result: 压缩揭示了概率生成的结构特征：在受控和中介环境中，LLM生成的语言比人类写作表现出更高的结构规律性和可压缩性，表明输出集中在高度循环的统计模式中。但这种特征具有尺度依赖性：在碎片化交互环境中，分离减弱，表明在小尺度上表面可区分性存在基本限制。这种基于可压缩性的分离在不同模型、任务和领域中一致出现。

Conclusion: 研究提出了一个简单而稳健的框架，用于量化生成系统如何重塑文本生产，为理解通信复杂性演化提供了结构视角。无损压缩作为模型无关的度量方法，能够直接从表面文本区分LLM生成内容与人类写作，但在小尺度交互环境中这种区分能力有限。

Abstract: Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

</details>


### [12] [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425)
*Deniz Qian,Hung-Ting Chen,Eunsol Choi*

Main category: cs.CL

TL;DR: RVR是一种多轮检索框架，通过检索-验证-检索的迭代过程最大化答案覆盖率，在QAMPARI数据集上比基线方法获得至少10%的相对增益和3%的绝对增益。


<details>
  <summary>Details</summary>
Motivation: 针对需要广泛有效答案的查询，现有检索方法难以全面覆盖所有可能的答案，需要一种能够最大化答案覆盖率的检索框架。

Method: 提出检索-验证-检索（RVR）框架：第一轮检索器接收原始查询返回候选文档集，验证器识别高质量子集；后续轮次将查询与已验证文档结合，发现之前未覆盖的答案；支持使用现成检索器，也可通过微调进一步优化。

Result: 在QAMPARI多答案检索数据集上，RVR比基线方法（包括智能搜索方法）获得至少10%相对增益和3%绝对增益的完全召回率提升；在QUEST和WebQuestionsSP两个域外数据集上也观察到一致增益。

Conclusion: RVR提供了一种有前景的迭代方法，通过验证器和适应新推理场景的检索器来实现全面的答案召回，为全面检索多样化文档提供了有效框架。

Abstract: Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

</details>


### [13] [FENCE: A Financial and Multimodal Jailbreak Detection Dataset](https://arxiv.org/abs/2602.18154)
*Mirae Kim,Seonghun Jeong,Youngjun Kwak*

Main category: cs.CL

TL;DR: FENCE是一个用于金融领域多模态越狱检测的双语（韩语-英语）数据集，包含金融相关查询和基于图像的威胁，用于训练和评估越狱检测器。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型的越狱攻击对部署构成重大风险，特别是视觉语言模型处理文本和图像，攻击面更广。金融领域缺乏越狱检测资源，需要专门的数据集来应对这一安全挑战。

Method: 创建FENCE双语多模态数据集，包含金融相关查询和图像基础威胁，强调领域真实性。使用商业和开源视觉语言模型进行实验评估漏洞，并训练基线检测器。

Result: 实验显示商业和开源视觉语言模型存在一致的漏洞，GPT-4o显示出可测量的攻击成功率，开源模型暴露更大。基于FENCE训练的基线检测器达到99%的分布内准确率，并在外部基准测试中保持强大性能。

Conclusion: FENCE为金融领域多模态越狱检测提供了专注资源，支持在敏感领域开发更安全可靠的AI系统。数据集展示了训练可靠检测模型的鲁棒性。

Abstract: Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

</details>


### [14] [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429)
*Harshul Raj Surana,Arijit Maji,Aryan Vats,Akash Ghosh,Sriparna Saha,Amit Sheth*

Main category: cs.CL

TL;DR: VIRAASAT是一个针对印度文化的多跳问答数据集生成方法，通过知识图谱和符号链式操作框架提升LLMs在文化推理任务上的表现


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在需要丰富社会文化知识和本地背景的任务中表现不佳，特别是涉及印度文化的任务。现有的文化基准测试存在三个主要问题：(1) 人工构建，(2) 仅包含测试事实记忆的单跳问题，(3) 扩展成本过高，导致这一缺陷未被充分衡量。

Method: 提出了VIRAASAT半自动化多跳方法，基于包含700多个专家策划文化实体的知识图谱，涵盖印度文化的13个关键属性。该方法生成3200多个多跳问题。同时提出了符号链式操作(SCoM)框架，训练模型在内部模拟知识图谱的原子操作，可靠地遍历图谱的拓扑结构。

Result: 在监督微调实验中，SCoM框架比标准的思维链基准方法性能提升高达20%。VIRAASAT数据集覆盖了印度所有28个邦和8个中央直辖区。

Conclusion: VIRAASAT为构建文化感知推理模型奠定了坚实基础，揭示了当前SOTA LLMs在文化推理中的关键限制，特别是思维链微调无法有效处理低概率事实的合成与基础。SCoM框架通过知识图谱操作模拟显著提升了文化推理能力。

Abstract: Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

</details>


### [15] [Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models](https://arxiv.org/abs/2602.18171)
*Wojciech Michaluk,Tymoteusz Urban,Mateusz Kubita,Soveatin Kuntur,Anna Wroblewska*

Main category: cs.CL

TL;DR: 提出结合Transformer文本嵌入与语言学特征信息的混合方法用于点击诱饵检测，XGBoost模型在增强特征上达到91% F1分数


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题降低在线信息质量并损害用户信任，需要有效的检测方法

Method: 混合方法：结合Transformer文本嵌入与15个语言学特征信息特征（如第二人称代词、最高级、数字、注意力导向标点），使用XGBoost分类器

Result: 最佳模型XGBoost在增强特征上达到91% F1分数，优于TF-IDF、Word2Vec、GloVe、LLM提示分类和纯特征基线

Conclusion: 提出的特征集通过突出显性语言学线索增强了可解释性，实现了透明且校准良好的点击诱饵预测，并发布了代码和训练模型

Abstract: Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

</details>


### [16] [Improving Sampling for Masked Diffusion Models via Information Gain](https://arxiv.org/abs/2602.18176)
*Kaisen Yang,Jayden Teoh,Kaicheng Yang,Yitong Zhang,Alex Lamb*

Main category: cs.CL

TL;DR: 提出Info-Gain Sampler，一种用于掩码扩散模型（MDMs）的采样方法，通过平衡即时不确定性和对未来掩码标记的信息增益，解决现有贪婪采样器忽视当前解码决策对后续步骤影响的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MDM采样器通常采用贪婪启发式方法，优先解码局部确定性最高的位置，但这种方法存在根本性局限：忽视当前解码选择对后续步骤的下游影响，未能最小化累积不确定性，且未充分利用MDMs的非因果特性。

Method: 提出Info-Gain Sampler解码框架，基于信息增益原理，在每一步解码时不仅考虑当前位置的不确定性，还评估当前解码决策如何重塑所有剩余掩码位置的标记概率/不确定性，从而平衡即时不确定性与对未来掩码标记的信息增益。

Result: 在多样化架构和任务（推理、编码、创意写作、图像生成）上的广泛评估表明，Info-Gain Sampler始终优于现有MDM采样器。在推理任务上平均准确率提升3.6%，创意写作任务上胜率达到63.1%，推理任务的累积不确定性从78.4降至48.6。

Conclusion: Info-Gain Sampler通过利用MDMs的非因果特性，系统性地考虑解码决策对后续步骤的影响，提供了一种原则性的解码框架，显著提升了MDMs的生成质量和性能。

Abstract: Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

</details>


### [17] [Information-Theoretic Storage Cost in Sentence Comprehension](https://arxiv.org/abs/2602.18217)
*Kohei Kajikawa,Shinnosuke Isono,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 提出基于信息论的句子理解工作记忆负荷测量方法，替代传统基于符号语法的离散成本度量


<details>
  <summary>Details</summary>
Motivation: 实时句子理解对工作记忆负荷很大，但现有测量主要基于符号语法，使用离散统一的句法预测成本，需要更连续、理论中立的方法

Method: 基于信息论提出处理存储成本测量：先前词语在不确定性条件下对未来上下文携带的信息量，可从预训练神经语言模型估计

Result: 在英语中验证了方法的有效性：(1)恢复了中心嵌套和关系从句中的已知处理不对称性；(2)与语法标注语料库中的语法存储成本相关；(3)在两大自然数据集上预测阅读时间方差，优于传统信息预测基线模型

Conclusion: 提出的信息论测量方法为句子理解的工作记忆负荷提供了连续、理论中立的量化工具，可替代传统基于符号语法的离散度量

Abstract: Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

</details>


### [18] [Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning](https://arxiv.org/abs/2602.18232)
*Lexiang Tang,Weihao Gao,Bingchen Zhao,Lu Ma,Qiao jin,Bang Yang,Yuexian Zou*

Main category: cs.CL

TL;DR: 提出了一种基于置信度驱动的对比解码方法，通过检测低置信度标记并选择性干预来提升大语言模型推理可靠性，同时减少输出长度


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法通常假设分配更多推理时间计算能均匀提升正确性，但研究表明推理不确定性高度局部化：少数低置信度标记对推理错误和不必要输出扩展贡献不成比例

Method: 提出Thinking by Subtraction方法，采用置信度驱动的对比解码，在解码过程中检测低置信度标记并选择性干预，通过用最小占位符替换高置信度标记构建对比参考，在低置信度位置通过减去参考分布来精炼预测

Result: CCD显著提升了数学推理基准的准确性，同时大幅减少了输出长度，仅带来最小的KV缓存开销

Conclusion: 作为一种无需训练的方法，CCD通过针对性的低置信度干预提升了推理可靠性，避免了计算冗余

Abstract: Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.

</details>


### [19] [Simplifying Outcomes of Language Model Component Analyses with ELIA](https://arxiv.org/abs/2602.18262)
*Aaron Louis Eidt,Nils Feldhus*

Main category: cs.CL

TL;DR: ELIA是一个交互式Web应用，通过整合三种可解释性分析技术并使用视觉语言模型自动生成自然语言解释，降低了大型语言模型机制可解释性分析的门槛，使非专家也能理解复杂的模型内部工作原理。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性领域虽然开发了强大的工具来分析大型语言模型的内部工作原理，但其复杂性造成了可访问性差距，限制了这些工具只能被专家使用。作者旨在解决这一挑战，让更广泛的受众能够理解语言模型组件分析的结果。

Method: 设计、构建和评估ELIA系统，该系统整合了三种关键技术：归因分析、函数向量分析和电路追踪。引入了一种新颖方法：使用视觉语言模型为这些方法产生的复杂可视化自动生成自然语言解释。通过混合方法的用户研究实证验证了该方法的有效性。

Result: 用户研究显示，用户明显偏好交互式、可探索的界面而非简单的静态可视化。关键发现是AI生成的解释帮助非专家弥合了知识差距；统计分析显示用户的先验LLM经验与其理解分数之间没有显著相关性，表明该系统降低了不同经验水平用户的认知障碍。

Conclusion: AI系统确实可以简化复杂的模型分析，但其真正潜力在于与深思熟虑、以用户为中心的设计相结合，这种设计优先考虑交互性、具体性和叙事指导，从而解锁系统的全部能力。

Abstract: While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.

</details>


### [20] [PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324)
*Alexandra Ciobotaru,Ana-Maria Bucur,Liviu P. Dinu*

Main category: cs.CL

TL;DR: 创建了首个罗马尼亚语抑郁和焦虑语料库PsihoRo，包含205名受访者的开放式问题回答和标准化筛查问卷，填补了罗马尼亚语心理健康NLP资源的空白。


<details>
  <summary>Details</summary>
Motivation: 罗马尼亚语目前没有开源的心理健康语料库，而心理健康数据从社交媒体收集存在假设偏差问题。需要更实用的数据收集策略来填补这一语言资源空白。

Method: 通过包含6个开放式问题的表单收集数据，并结合标准化的PHQ-9和GAD-7筛查问卷。对205名受访者的文本采用统计分析、罗马尼亚语LIWC文本分析、情绪检测和主题建模等方法。

Result: 成功创建了首个罗马尼亚语抑郁和焦虑语料库PsihoRo，虽然规模较小（205名受访者），但为分析罗马尼亚人口心理健康文本提供了基础资源。

Conclusion: PsihoRo是理解和分析罗马尼亚人口心理健康文本的第一步，通过多种分析方法展示了这一新资源的重要特征，为罗马尼亚语心理健康NLP研究奠定了基础。

Abstract: Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

</details>


### [21] [Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346)
*Pavithra PM Nair,Preethu Rose Anish*

Main category: cs.CL

TL;DR: Vichara是一个针对印度司法系统的框架，用于预测和解释上诉判决，通过将案件文档分解为决策点，采用类似IRAC的结构化解释，在多个LLM评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 印度法院面临大量案件积压，特别是上诉案件，需要利用人工智能进行判决预测以提高司法效率。上诉案件作为高等法院对下级法院裁决的正式审查决定，是积压案件的重要组成部分。

Method: Vichara框架处理英文上诉案件程序文档，将其分解为决策点——包含法律问题、裁决机构、结果、推理和时间背景的离散法律决定。采用结构化表示分离核心决定及其上下文，预测解释遵循类似IRAC框架但适应印度法律推理的结构化格式。

Result: 在PredEx和ILDC_expert数据集上评估，使用GPT-4o mini、Llama-3.1-8B、Mistral-7B和Qwen2.5-7B四个大语言模型。Vichara在两个数据集上都超越了现有判决预测基准，GPT-4o mini表现最佳（PredEx F1: 81.5，ILDC_expert F1: 80.3），Llama-3.1-8B次之。人类评估显示GPT-4o mini在清晰度、关联性和实用性方面解释能力最强。

Conclusion: Vichara框架通过结构化决策点表示和类似IRAC的解释格式，为印度司法系统提供了准确可解释的上诉判决预测，在多个LLM评估中表现优异，GPT-4o mini在预测准确性和解释质量方面均表现最佳。

Abstract: In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

</details>


### [22] [Validating Political Position Predictions of Arguments](https://arxiv.org/abs/2602.18351)
*Jordan Robinson,Angus R. Williams,Katie Atkinson,Anthony G. Cohn*

Main category: cs.CL

TL;DR: 提出双尺度验证框架，结合逐点与成对人工标注，用于政治立场预测的主观连续知识表示，构建大规模论证知识库并验证语言模型能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识表示常需捕捉主观连续属性（如政治立场），这与广泛接受的成对验证黄金标准相冲突。需要解决主观连续知识验证的挑战。

Method: 采用双尺度验证框架，结合逐点（pointwise）和成对（pairwise）人工标注。使用22个语言模型，构建包含23,228个论证的大规模政治立场预测知识库，数据来自英国政治电视节目《Question Time》的30场辩论。

Result: 逐点评估显示中等水平的人机一致性（Krippendorff's α=0.578），反映内在主观性；成对验证显示人机排名对齐显著更强（最佳模型α=0.86）。成功构建了经过验证的结构化论证知识库。

Conclusion: 提出实用的主观连续知识验证方法，平衡可扩展性与可靠性；构建支持基于图推理和检索增强生成的政治领域知识库；证明可从点式语言模型预测中提取序数结构，推进传统符号或分类方法不足领域的知识表示能力。

Abstract: Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 该研究探讨了使用形式化领域本体（特别是OpenMath本体）通过检索增强生成来提升语言模型在数学推理任务中的可靠性，发现本体引导的上下文在检索质量高时能改善性能，但无关上下文会降低性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本性限制，这些限制在需要可验证推理的高风险专业领域（如数学）中尤为成问题。研究旨在探索形式化领域本体是否能通过检索增强生成来增强语言模型的可靠性。

Method: 采用神经符号混合管道，利用OpenMath本体进行检索增强生成。使用混合检索（hybrid retrieval）和交叉编码器重排序（cross-encoder reranking）技术，将相关定义注入模型提示中。在MATH基准测试上评估了三个开源模型。

Result: 评估显示，当检索质量高时，本体引导的上下文能提高模型性能；但当检索到无关上下文时，性能会显著下降。这突显了神经符号方法的潜力和挑战。

Conclusion: 形式化领域本体在提升语言模型可靠性方面具有潜力，但检索质量至关重要。无关上下文会损害性能，表明需要更精确的检索机制来充分发挥神经符号方法的优势。

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [24] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一个基于16世纪数学决斗启发的评估框架，让大语言模型通过相互创建编程谜题来挑战对方，从而评估推理能力，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型推理能力面临挑战：人工标注高质量难题成本高昂，且难以确定模型是否真正推理还是仅见过类似训练数据。需要一种无法通过设计饱和、能测试真实推理能力的评估方法。

Method: 受16世纪数学决斗启发，设计Token Games框架：模型通过创建编程谜题相互挑战（给定返回布尔值的Python函数，寻找使其返回True的输入）。使用两两对决结果计算Elo评分，相对比较模型能力。

Result: 评估了10个前沿模型，TTG排名与现有基准（如Humanity's Last Exam）高度一致，且无需人工创建谜题。发现创建高质量谜题对当前模型仍极具挑战，这是先前基准未测量的能力。

Conclusion: TTG提出了一种无法通过设计饱和的推理评估新范式，能够同时测试模型的问题解决、创造力和任务创建能力，为评估大语言模型开辟了新方向。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [25] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: WorkflowPerturb：一个用于研究工作流评估指标的受控基准，通过对黄金工作流应用现实扰动来评估指标敏感性和校准度


<details>
  <summary>Details</summary>
Motivation: LLM生成的结构化工作流评估困难，因为指标分数通常未校准，且分数变化不能直接反映工作流退化的严重程度

Method: 创建包含4,973个黄金工作流和44,757个扰动变体的基准，应用三种扰动类型（缺失步骤、压缩步骤、描述变化），每种在10%、30%、50%严重级别上实施，然后评估多个指标家族的敏感性和校准度

Result: 结果揭示了不同指标家族间的系统性差异，支持基于严重程度的工作流评估分数解释，数据集将在接受后发布

Conclusion: WorkflowPerturb为工作流评估指标提供了受控基准，有助于理解指标敏感性和校准度，支持更准确的工作流质量评估

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [26] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 离线强化学习与跨具身学习结合，利用专家和次优数据预训练机器人策略，通过形态相似性分组减少梯度冲突


<details>
  <summary>Details</summary>
Motivation: 解决机器人策略预训练中高质量演示数据收集成本高的问题，结合离线强化学习和跨具身学习来利用异构机器人轨迹获取通用控制先验

Method: 1) 构建包含16种机器人平台的运动数据集；2) 分析离线RL与跨具身学习范式；3) 提出基于具身相似性的分组策略，将形态相似的机器人聚类，使用组梯度更新模型

Result: 1) 结合方法在次优轨迹丰富的数据集上优于纯行为克隆；2) 次优数据比例和机器人类型增加会导致跨形态梯度冲突；3) 静态分组策略显著减少机器人间冲突，优于现有冲突解决方法

Conclusion: 离线RL与跨具身学习结合是有效的预训练方法，但需要解决跨形态梯度冲突问题；基于形态相似性的简单静态分组是有效的冲突缓解策略

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [27] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: SOMtime方法揭示无监督表示会自发编码被排除的敏感属性，挑战了"公平通过无知"的假设


<details>
  <summary>Details</summary>
Motivation: 挑战无监督表示对敏感属性保持中性的普遍假设，证明即使明确排除敏感属性，它们仍会在表示中自发出现

Method: 使用SOMtime（基于高容量自组织映射的拓扑保持表示方法），在两个大规模真实数据集（世界价值观调查和人口普查收入数据集）上分析无监督表示中敏感属性的出现

Result: SOMtime恢复出与被排除敏感属性对齐的单调排序，Spearman相关性高达0.85，而PCA、UMAP、t-SNE和自编码器通常低于0.34；无监督分割产生人口统计学偏斜的聚类

Conclusion: "公平通过无知"在表示层面对序数敏感属性失效，公平审计必须扩展到机器学习管道的无监督组件

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [28] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD：首个在线离策略多智能体强化学习框架，使用扩散策略协调智能体，通过松弛策略目标最大化联合熵实现高效探索，在MPE和MAMuJoCo任务上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型在图像生成和离线设置中表现出卓越的表达能力和多模态表示能力，但在在线多智能体强化学习中的应用尚未充分探索。主要障碍是扩散模型的不可处理似然性阻碍了基于熵的探索和协调。

Method: 提出OMAD框架：1）松弛策略目标最大化缩放联合熵，实现无需可处理似然的探索；2）在CTDE范式下使用联合分布值函数优化分散扩散策略；3）利用可处理的熵增强目标指导扩散策略同步更新，确保稳定协调。

Result: 在MPE和MAMuJoCo的10个多样化任务上建立新的SOTA，样本效率显著提高2.5倍到5倍。

Conclusion: OMAD成功将扩散策略应用于在线多智能体强化学习，通过创新的熵最大化方法和联合值函数优化，克服了扩散模型在在线MARL中的关键障碍，实现了卓越的协调性能和样本效率。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [29] [When & How to Write for Personalized Demand-aware Query Rewriting in Video Search](https://arxiv.org/abs/2602.17667)
*Cheng cheng,Chenxing Wang,Aolin Li,Haijun Wu,Huiyun Hu,Juyuan Wang*

Main category: cs.IR

TL;DR: WeWrite是一个个性化需求感知的查询重写框架，通过自动化挖掘策略、混合训练范式和并行部署架构，解决了视频搜索系统中用户历史行为利用的挑战，显著提升了点击率和降低了查询重构率。


<details>
  <summary>Details</summary>
Motivation: 传统视频搜索系统利用用户历史行为特征时存在信号稀释和延迟反馈问题，需要更有效的个性化查询重写方法来准确识别搜索意图和消除歧义。

Method: 提出WeWrite框架，包含三个关键技术：(1) 基于后验的自动化挖掘策略，从用户日志中提取高质量样本，识别真正需要个性化的场景；(2) 结合监督微调(SFT)和组相对策略优化(GRPO)的混合训练范式，使LLM输出风格与检索系统对齐；(3) 并行"虚假召回"架构确保低延迟部署。

Result: 在大规模视频平台上的在线A/B测试显示，WeWrite将点击观看视频量(VV>10s)提升了1.07%，并将查询重构率降低了2.97%。

Conclusion: WeWrite通过系统性地解决个性化查询重写中的关键挑战，有效提升了视频搜索系统的性能，证明了其在真实工业场景中的实用价值。

Abstract: In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel "Fake Recall" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.

</details>


### [30] [IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering](https://arxiv.org/abs/2602.17687)
*Connor Shorten,Augustas Skaburskas,Daniel M. Jones,Charles Pierse,Roberto Esposito,John Trengrove,Etienne Dilocker,Bob van Luijt*

Main category: cs.IR

TL;DR: IRPAPERS基准测试比较视觉文档处理中基于图像和基于文本的检索与问答系统，发现多模态混合搜索优于单一模态，图像嵌入在某些情况下超越文本嵌入。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在文本和关系数据处理上取得显著成功，但视觉文档处理相对未被充分探索。传统系统需要OCR转录将视觉文档转换为文本和元数据，而多模态基础模型可以直接从文档图像进行检索和生成。这引发了一个关键问题：基于图像的系统与已建立的基于文本的方法相比如何？

Method: 引入IRPAPERS基准，包含166篇科学论文的3,230页，每页都有图像和OCR转录。使用180个"大海捞针"问题，比较基于图像和基于文本的检索与问答系统。评估了多种检索方法（Arctic 2.0嵌入、BM25、混合搜索）、多模态混合搜索、效率-性能权衡（MUVERA）以及多个多向量图像嵌入模型。对于问答系统，评估了基于文本和基于图像的RAG系统。

Result: 文本检索达到46% Recall@1、78% Recall@5和91% Recall@20，图像检索达到43%、78%和93%。两种模态表现出互补的失败模式，使多模态混合搜索优于任一单一模态（49% Recall@1、81% Recall@5、95% Recall@20）。在闭源模型中，Cohere Embed v4页面图像嵌入优于Voyage 3 Large文本嵌入和所有测试的开源模型（58% Recall@1、87% Recall@5、97% Recall@20）。对于问答，基于文本的RAG系统比基于图像的系统具有更高的真实对齐度（0.82 vs. 0.71），两者都从增加检索深度中显著受益。

Conclusion: 研究分析了单模态文本和图像表示的互补局限性，并确定了需要一种模态而非另一种的问题类型。多模态混合搜索在视觉文档处理中表现出优越性，图像嵌入在某些情况下可以超越文本嵌入。IRPAPERS数据集和所有实验代码已公开可用。

Abstract: AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.

</details>


### [31] [Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems](https://arxiv.org/abs/2602.17856)
*Hamideh Ghanadian,Amin Kamali,Mohammad Hossein Tekieh*

Main category: cs.IR

TL;DR: 该研究评估了基于向量和图数据库的检索增强生成(RAG)系统在科学文献聊天机器人中的应用，通过混合检索方法提升科学知识获取效率


<details>
  <summary>Details</summary>
Motivation: 旨在通过检索增强生成技术提升科学文献聊天机器人的性能，改善科学知识的可访问性，支持基于证据的决策制定

Method: 提出结合结构化(图)和非结构化(向量)数据库的混合RAG系统，设计两种使用场景：单文档检索和大规模语料库检索，使用GPT生成基准测试集并进行人工标注评估

Result: 比较分析显示混合RAG系统在检索准确性和响应相关性方面具有优势，能够根据研究目标有效筛选科学文献和灰色文献来源

Conclusion: 混合RAG系统在提升科学知识可访问性方面具有潜力，能够支持证据驱动的决策过程，为科学文献检索提供了有效的技术方案

Abstract: This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.

</details>


### [32] [SuiteEval: Simplifying Retrieval Benchmarks](https://arxiv.org/abs/2602.18107)
*Andrew Parry,Debasis Ganguly,Sean MacAvaney*

Main category: cs.IR

TL;DR: SuiteEval是一个统一的IR评估框架，提供自动端到端评估、动态索引重用以减少磁盘使用，并支持主要基准测试，旨在解决IR评估中碎片化实践的问题。


<details>
  <summary>Details</summary>
Motivation: 信息检索评估存在碎片化实践问题，包括不同的数据集子集、聚合方法和管道配置，这损害了可重现性和可比性，特别是对于需要强大跨域性能的基础嵌入模型。

Method: 提出SuiteEval框架，提供自动端到端评估、动态索引重用磁盘索引以最小化磁盘使用，内置支持主要基准测试（BEIR、LoTTE、MS MARCO、NanoBEIR和BRIGHT）。用户只需提供管道生成器，框架处理数据加载、索引、排序、指标计算和结果聚合。

Result: SuiteEval减少了样板代码并标准化了评估流程，促进了可重现的IR研究，满足了日益增长的更广泛基准测试需求。

Conclusion: SuiteEval通过统一框架解决了IR评估中的碎片化问题，提供标准化、可重现的评估流程，支持主要基准测试，减少了研究人员的重复工作。

Abstract: Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.

</details>


### [33] [A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18206)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Ronghua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 提出PSP-NS负采样插件，通过增强正样本监督信号来改进隐式协同过滤模型，解决现有方法忽视正样本探索和用户活跃度偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有隐式协同过滤模型主要关注高质量负样本设计，但忽视了正样本的探索。虽然一些去噪推荐方法可用于隐式CF，但往往会稀疏化正样本监督信号，并且普遍忽略了训练过程中的用户活跃度偏差，导致对不活跃用户的学习不足。

Method: 提出PSP-NS负采样插件：1）构建用户-物品二部图，边权重表示基于全局和局部模式推断的交互置信度；2）通过基于复制的重加权生成正样本对以增强正信号；3）采用活动感知加权方案有效学习不活跃用户的偏好。

Result: 在四个真实世界数据集上进行广泛实验，证明PSP-NS的优越性。例如，在Yelp数据集上，PSP-NS将Recall@30和Precision@30分别提高了32.11%和22.90%（相比最强基线）。PSP-NS可与各种隐式CF推荐器或负采样方法集成以提升性能。

Conclusion: PSP-NS是一个简单有效的负采样插件，通过增强正样本监督信号和考虑用户活跃度偏差，显著提升了隐式协同过滤模型的排序质量，为改进推荐系统提供了新的视角。

Abstract: Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.

</details>


### [34] [The Economical-Ecological Benefits of Matching Non-matching Socks](https://arxiv.org/abs/2602.18221)
*Teddy Lazebnik*

Main category: cs.IR

TL;DR: 研究量化了配对不匹配的"孤儿"袜子的经济生态价值，分析了阻碍这种行为的社会成本，通过建模和实验证明容忍一定程度的不匹配比严格配对更节约资源。


<details>
  <summary>Details</summary>
Motivation: 袜子的大规模生产和更换导致严重浪费，由于袜子成对使用，单只丢失会使另一只可用袜子闲置并触发过早更换，需要量化配对不匹配袜子的价值及阻碍这种行为的社会成本。

Method: 将袜子所有权建模为不确定性下的序列决策问题，袜子在使用和洗涤过程中随机磨损和丢失，公开暴露引入个人特定的不匹配惩罚；通过现场研究估计不匹配敏感性和多样性偏好；使用计算机模拟评估可解释的配对策略。

Result: 严格配对看似节约资源主要是因为产生了许多无袜可穿的日子，而控制容忍不匹配可以维持服务并减少不同丢失情况下的闲置容量；研究建立了配对不匹配袜子的可行性，同时指出了其局限性和挑战。

Conclusion: 容忍一定程度的不匹配比严格配对更节约资源，能够维持袜子服务并减少浪费，但需要考虑个人对不匹配的敏感性和多样性偏好，配对不匹配袜子具有可行性但存在实际挑战。

Abstract: Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.

</details>


### [35] [Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18249)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 提出DTL-NS方法，一种无需文本信息和微调的双树LLM增强负采样方法，通过离线假负例识别和多视角硬负例采样提升隐式协同过滤推荐性能


<details>
  <summary>Details</summary>
Motivation: 当前LLM在推荐系统中的负采样研究不足，现有方法过度依赖文本信息和任务特定微调，限制了实际应用性，需要开发更通用的LLM增强负采样方法

Method: 提出DTL-NS方法，包含两个模块：1) 离线假负例识别模块，利用分层索引树将协作结构和潜在语义信息转化为结构化项目ID编码供LLM推理；2) 多视角硬负例采样模块，结合用户-项目偏好分数和项目-项目分层相似性挖掘高质量硬负例

Result: 在Amazon-sports数据集上，DTL-NS在Recall@20和NDCG@20指标上分别优于最强基线10.64%和19.12%，且能集成到多种隐式CF模型和负采样方法中，持续提升性能

Conclusion: DTL-NS是一种有效的文本无关、无需微调的LLM增强负采样方法，通过双树结构准确识别假负例并挖掘硬负例，显著提升推荐模型性能，具有良好通用性和实用性

Abstract: Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.
  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.
  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.
  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).
  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.
  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.
  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.

</details>


### [36] [A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18288)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: TPSC-FO：一种基于拓扑感知的正样本集构建和特征优化方法，通过识别假阴性样本并将其转化为正样本，解决隐式协同过滤中的假阴性问题。


<details>
  <summary>Details</summary>
Motivation: 现有负采样方法在隐式协同过滤中存在假阴性问题，这些方法过度依赖模型当前表示能力，且未能利用假阴性作为潜在正样本的潜力来更准确指导用户偏好学习。

Method: 提出TPSC-FO方法：1）拓扑感知正样本集构建模块，使用差分社区检测策略捕获隐式反馈中的拓扑社区结构，结合个性化噪声过滤可靠识别假阴性并转化为正样本；2）邻域引导特征优化模块，通过融入嵌入空间中的邻域特征来精炼正样本特征，有效缓解正样本中的噪声。

Result: 在五个真实世界数据集和两个合成数据集上的广泛实验验证了TPSC-FO的有效性。

Conclusion: 隐式反馈中的拓扑社区结构能有效识别假阴性，TPSC-FO通过拓扑感知的正样本集构建和特征优化，显著提升了隐式协同过滤的性能。

Abstract: Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.

</details>
