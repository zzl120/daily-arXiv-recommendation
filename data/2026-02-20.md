<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 11]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [RankEvolve: Automating the Discovery of Retrieval Algorithms via LLM-Driven Evolution](https://arxiv.org/abs/2602.16932)
*Jinming Nian,Fangchen Li,Dae Hoon Park,Yi Fang*

Main category: cs.IR

TL;DR: 使用基于AlphaEvolve的程序进化框架RankEvolve，通过大语言模型引导的进化搜索自动发现改进的词法检索算法，从BM25和查询似然等基础算法出发，在12个IR数据集上进化出新颖有效的检索算法。


<details>
  <summary>Details</summary>
Motivation: 传统检索算法如BM25和带Dirichlet平滑的查询似然虽然仍是强大高效的一阶段排序器，但其改进主要依赖参数调优和人类直觉。研究探索是否可以通过大语言模型引导的进化搜索自动发现改进的词法检索算法。

Method: 提出RankEvolve程序进化框架，基于AlphaEvolve，将候选排序算法表示为可执行代码，通过变异、重组和选择迭代进化。从BM25和带Dirichlet平滑的查询似然两个种子程序开始，在BEIR和BRIGHT的12个IR数据集上基于检索性能进行进化。

Result: 进化出的算法具有新颖性且有效，在完整的BEIR和BRIGHT基准测试以及TREC DL 19和20上显示出良好的迁移能力。结果表明评估器引导的LLM程序进化是自动发现新颖排序算法的可行路径。

Conclusion: 评估器引导的大语言模型程序进化是自动发现新颖排序算法的实用方法，能够从传统检索算法出发进化出具有良好迁移性能的新算法。

Abstract: Retrieval algorithms like BM25 and query likelihood with Dirichlet smoothing remain strong and efficient first-stage rankers, yet improvements have mostly relied on parameter tuning and human intuition. We investigate whether a large language model, guided by an evaluator and evolutionary search, can automatically discover improved lexical retrieval algorithms. We introduce RankEvolve, a program evolution setup based on AlphaEvolve, in which candidate ranking algorithms are represented as executable code and iteratively mutated, recombined, and selected based on retrieval performance across 12 IR datasets from BEIR and BRIGHT. RankEvolve starts from two seed programs: BM25 and query likelihood with Dirichlet smoothing. The evolved algorithms are novel, effective, and show promising transfer to the full BEIR and BRIGHT benchmarks as well as TREC DL 19 and 20. Our results suggest that evaluator-guided LLM program evolution is a practical path towards automatic discovery of novel ranking algorithms.

</details>


### [2] [Beyond Chunk-Then-Embed: A Comprehensive Taxonomy and Evaluation of Document Chunking Strategies for Information Retrieval](https://arxiv.org/abs/2602.16974)
*Yongjie Zhou,Shuai Wang,Bevan Koopman,Guido Zuccon*

Main category: cs.IR

TL;DR: 本文系统评估了文档分块策略，发现最优分块方法具有任务依赖性：简单结构方法在语料库检索中表现最佳，而LLM引导方法在文档内检索中效果最好。


<details>
  <summary>Details</summary>
Motivation: 密集检索系统中的文档分块策略设计空间尚未被充分理解，现有方法独立发展且在不同基准上评估，难以进行直接比较。需要建立一个统一框架来系统评估不同分块策略。

Method: 提出了一个系统框架，从两个维度统一现有分块策略：(1) 分割方法（结构基、语义感知、LLM引导）；(2) 嵌入范式（预嵌入分块 vs. 上下文分块）。在两个检索设置中复现评估：文档内检索和语料库检索。

Result: 最优分块策略具有任务依赖性：简单结构方法在语料库检索中优于LLM引导方法；LumberChunker在文档内检索中表现最佳。上下文分块提高语料库检索效果但降低文档内检索效果。分块大小与文档内检索效果中度相关，与语料库检索效果弱相关。

Conclusion: 文档分块策略的选择应基于具体检索任务，没有单一最优方法。简单结构方法在标准信息检索任务中足够有效，而LLM引导方法在文档内检索场景中更有价值。分割方法的差异不完全由分块大小驱动。

Abstract: Document chunking is a critical preprocessing step in dense retrieval systems, yet the design space of chunking strategies remains poorly understood. Recent research has proposed several concurrent approaches, including LLM-guided methods (e.g., DenseX and LumberChunker) and contextualized strategies(e.g., Late Chunking), which generate embeddings before segmentation to preserve contextual information. However, these methods emerged independently and were evaluated on benchmarks with minimal overlap, making direct comparisons difficult.
  This paper reproduces prior studies in document chunking and presents a systematic framework that unifies existing strategies along two key dimensions: (1) segmentation methods, including structure-based methods (fixed-size, sentence-based, and paragraph-based) as well as semantically-informed and LLM-guided methods; and (2) embedding paradigms, which determine the timing of chunking relative to embedding (pre-embedding chunking vs. contextualized chunking). Our reproduction evaluates these approaches in two distinct retrieval settings established in previous work: in-document retrieval (needle-in-a-haystack) and in-corpus retrieval (the standard information retrieval task).
  Our comprehensive evaluation reveals that optimal chunking strategies are task-dependent: simple structure-based methods outperform LLM-guided alternatives for in-corpus retrieval, while LumberChunker performs best for in-document retrieval. Contextualized chunking improves in-corpus effectiveness but degrades in-document retrieval. We also find that chunk size correlates moderately with in-document but weakly with in-corpus effectiveness, suggesting segmentation method differences are not purely driven by chunk size. Our code and evaluation benchmarks are publicly available at (Anonymoused).

</details>


### [3] [Bending the Scaling Law Curve in Large-Scale Recommendation Systems](https://arxiv.org/abs/2602.16986)
*Qin Ding,Kevin Course,Linjian Ma,Jianhui Sun,Rouchen Liu,Zhao Zhu,Chunxing Yin,Wei Li,Dai Li,Yu Shi,Xuan Cao,Ze Yang,Han Li,Xing Liu,Bi Xue,Hongwei Li,Rui Jian,Daisy Shi He,Jing Qian,Matt Ma,Qunshu Zhang,Rui Li*

Main category: cs.IR

TL;DR: ULTRA-HSTU：通过端到端模型与系统协同设计的新型序列推荐模型，在保持高质量推荐的同时实现5倍训练扩展和21倍推理扩展效率提升，已大规模部署服务数十亿用户。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的序列推荐方法过度依赖交叉注意力机制来解决二次计算瓶颈，这限制了自注意力的表征能力，需要在模型质量和效率之间取得更好平衡。

Method: 通过端到端模型与系统协同设计，创新性地改进输入序列设计、稀疏注意力机制和模型拓扑结构，构建ULTRA-HSTU序列推荐模型。

Result: ULTRA-HSTU实现了显著的扩展效率提升：相比传统模型，训练扩展快5倍以上，推理扩展快21倍，同时提供更优的推荐质量；已大规模部署，服务数十亿用户，在实际生产环境中带来4%-8%的消费和参与度提升。

Conclusion: ULTRA-HSTU通过创新的模型架构和系统设计，成功解决了序列推荐中质量与效率的平衡问题，实现了大规模部署的实际商业价值，为序列推荐系统的发展提供了新方向。

Abstract: Learning from user interaction history through sequential models has become a cornerstone of large-scale recommender systems. Recent advances in large language models have revealed promising scaling laws, sparking a surge of research into long-sequence modeling and deeper architectures for recommendation tasks. However, many recent approaches rely heavily on cross-attention mechanisms to address the quadratic computational bottleneck in sequential modeling, which can limit the representational power gained from self-attention. We present ULTRA-HSTU, a novel sequential recommendation model developed through end-to-end model and system co-design. By innovating in the design of input sequences, sparse attention mechanisms, and model topology, ULTRA-HSTU achieves substantial improvements in both model quality and efficiency. Comprehensive benchmarking demonstrates that ULTRA-HSTU achieves remarkable scaling efficiency gains -- over 5x faster training scaling and 21x faster inference scaling compared to conventional models -- while delivering superior recommendation quality. Our solution is fully deployed at scale, serving billions of users daily and driving significant 4% to 8% consumption and engagement improvements in real-world production environments.

</details>


### [4] [WSDM Cup 2026 Multilingual Retrieval: A Low-Cost Multi-Stage Retrieval Pipeline](https://arxiv.org/abs/2602.16989)
*Chentong Hao,Minmao Wang*

Main category: cs.IR

TL;DR: 提出一个低成本的多语言检索系统，采用四阶段流程：LLM查询扩展+BM25候选检索+稠密排序+重排序，在WSDM Cup 2026任务中取得nDCG@20=0.403和Judged@20=0.95的成绩。


<details>
  <summary>Details</summary>
Motivation: 针对WSDM Cup 2026多语言检索任务，需要从约1000万篇中文、波斯语和俄语新闻文章中检索相关文档，并在有限计算预算下实现高效检索。

Method: 采用四阶段流水线：1) 基于LLM的GRF风格查询扩展；2) BM25候选检索；3) 使用jina-embeddings-v4长文本表示的稠密排序；4) 对前20个候选使用Qwen3-Reranker-4B进行点式重排序，其余保持稠密排序顺序。

Result: 在官方评估中，系统达到nDCG@20=0.403和Judged@20=0.95。通过消融实验量化了各阶段的贡献，分析了查询扩展、稠密排序和top-k重排序在有限计算预算下的有效性。

Conclusion: 提出的低成本检索系统在多语言检索任务中表现良好，四阶段流水线设计有效平衡了检索质量和计算效率，为资源受限环境下的多语言检索提供了实用解决方案。

Abstract: We present a low-cost retrieval system for the WSDM Cup 2026 multilingual retrieval task, where English queries are used to retrieve relevant documents from a collection of approximately ten million news articles in Chinese, Persian, and Russian, and to output the top-1000 ranked results for each query. We follow a four-stage pipeline that combines LLM-based GRF-style query expansion with BM25 candidate retrieval, dense ranking using long-text representations from jina-embeddings-v4, and pointwise re-ranking of the top-20 candidates using Qwen3-Reranker-4B while preserving the dense order for the remaining results. On the official evaluation, the system achieves nDCG@20 of 0.403 and Judged@20 of 0.95. We further conduct extensive ablation experiments to quantify the contribution of each stage and to analyze the effectiveness of query expansion, dense ranking, and top-$k$ reranking under limited compute budgets.

</details>


### [5] [LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation](https://arxiv.org/abs/2602.17036)
*Rong Fu,Zijian Zhang,Haiyun Wei,Jiekai Wu,Kun Liu,Xianda Li,Haoyu Zhao,Yang Li,Yongtai Liu,Ziming Wang,Rui Lu,Simon Fong*

Main category: cs.IR

TL;DR: LiveGraph是一种新颖的主动结构神经重排序框架，通过图表示增强策略解决学生参与长尾分布问题，动态重排序机制提升内容多样性，在预测准确性和练习多样性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数字学习环境的持续扩展催生了能够提供个性化教育内容的智能系统需求。当前练习推荐框架虽取得进展，但常面临学生参与长尾分布问题和无法适应个性化学习轨迹的障碍。

Method: LiveGraph采用基于图的表示增强策略来弥合活跃与非活跃学生间的信息差距，同时集成动态重排序机制以促进内容多样性。该模型通过优先考虑学习历史中的结构关系，有效平衡推荐精度与教学多样性。

Result: 在多个真实世界数据集上的综合实验评估表明，LiveGraph在预测准确性和练习多样性广度方面均超越了当代基线方法。

Conclusion: LiveGraph框架成功解决了教育推荐系统中的长尾分布和个性化适应问题，通过图表示增强和动态重排序实现了精度与多样性的平衡，为个性化教育内容推荐提供了有效解决方案。

Abstract: The continuous expansion of digital learning environments has catalyzed the demand for intelligent systems capable of providing personalized educational content. While current exercise recommendation frameworks have made significant strides, they frequently encounter obstacles regarding the long-tailed distribution of student engagement and the failure to adapt to idiosyncratic learning trajectories. We present LiveGraph, a novel active-structure neural re-ranking framework designed to overcome these limitations. Our approach utilizes a graph-based representation enhancement strategy to bridge the information gap between active and inactive students while integrating a dynamic re-ranking mechanism to foster content diversity. By prioritizing the structural relationships within learning histories, the proposed model effectively balances recommendation precision with pedagogical variety. Comprehensive experimental evaluations conducted on multiple real-world datasets demonstrate that LiveGraph surpasses contemporary baselines in both predictive accuracy and the breadth of exercise diversity.

</details>


### [6] [On the Reliability of User-Centric Evaluation of Conversational Recommender Systems](https://arxiv.org/abs/2602.17264)
*Michael Müller,Amir Reza Mohammadi,Andreas Peintner,Beatriz Barroso Gstrein,Günther Specht,Eva Zangerle*

Main category: cs.IR

TL;DR: 该研究通过大规模实证分析发现，基于静态对话日志的第三方标注在对话推荐系统评估中存在可靠性问题，功利性维度相对可靠而社会性维度不可靠，且存在强烈的光环效应。


<details>
  <summary>Details</summary>
Motivation: 随着对话推荐系统评估日益依赖第三方对静态对话日志的标注（众包工作者或大语言模型），这种做法的可靠性尚未得到充分检验。研究者旨在通过实证研究验证这种评估方法的可靠性和结构。

Method: 采用大规模实证研究方法：收集124名众包工作者对200个ReDial对话的1,053个标注，使用18维CRS-Que框架；运用随机效应可靠性模型和相关性分析，量化各维度的稳定性及其相互依赖性。

Result: 结果显示：功利性和结果导向的维度（如准确性、有用性、满意度）在聚合后达到中等可靠性；而社会性维度（如人性化、融洽度）可靠性显著较低；许多维度坍缩为单一的全局质量信号，表明第三方判断存在强烈光环效应。

Conclusion: 研究挑战了单一标注者和基于LLM的评估协议的有效性，强调了在离线CRS评估中需要多标注者聚合和维度降维的必要性。

Abstract: User-centric evaluation has become a key paradigm for assessing Conversational Recommender Systems (CRS), aiming to capture subjective qualities such as satisfaction, trust, and rapport. To enable scalable evaluation, recent work increasingly relies on third-party annotations of static dialogue logs by crowd workers or large language models. However, the reliability of this practice remains largely unexamined. In this paper, we present a large-scale empirical study investigating the reliability and structure of user-centric CRS evaluation on static dialogue transcripts. We collected 1,053 annotations from 124 crowd workers on 200 ReDial dialogues using the 18-dimensional CRS-Que framework. Using random-effects reliability models and correlation analysis, we quantify the stability of individual dimensions and their interdependencies. Our results show that utilitarian and outcome-oriented dimensions such as accuracy, usefulness, and satisfaction achieve moderate reliability under aggregation, whereas socially grounded constructs such as humanness and rapport are substantially less reliable. Furthermore, many dimensions collapse into a single global quality signal, revealing a strong halo effect in third-party judgments. These findings challenge the validity of single-annotator and LLM-based evaluation protocols and motivate the need for multi-rater aggregation and dimension reduction in offline CRS evaluation.

</details>


### [7] [WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval](https://arxiv.org/abs/2602.17327)
*Michael Dinzinger,Laura Caspari,Ali Salman,Irvin Topi,Jelena Mitrović,Michael Granitzer*

Main category: cs.IR

TL;DR: WebFAQ 2.0是FAQ数据集的新版本，包含198M个多语言问答对，覆盖108种语言，是最大的FAQ资源，提供14.3M双语对齐QA对和1.25M查询的困难负例数据集。


<details>
  <summary>Details</summary>
Motivation: 构建更大规模、更多样化的多语言FAQ数据集，改进数据收集策略，响应社区需求提供困难负例数据集，支持密集检索器的训练，并建立长期可持续的数据资源。

Method: 采用新颖的直接爬取和提取网页内容的数据收集策略；使用两阶段检索管道挖掘困难负例；通过Open Web Index定期发布结构化FAQ；支持对比学习（MultipleNegativesRanking损失）和知识蒸馏（MarginMSE损失）两种微调策略。

Result: 创建了包含198M个FAQ问答对、覆盖108种语言的最大FAQ资源；提供14.3M双语对齐QA对；生成1.25M查询的困难负例数据集（每查询200个负例含交叉编码器分数）；数据集通过GitHub和HuggingFace公开。

Conclusion: WebFAQ 2.0显著扩展了多语言覆盖和规模，提供了更丰富的数据资源，支持密集检索器的训练和研究，并建立了可持续的数据发布机制，促进了多语言和跨语言信息检索的发展。

Abstract: We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.

</details>


### [8] [Training-free Graph-based Imputation of Missing Modalities in Multimodal Recommendation](https://arxiv.org/abs/2602.17354)
*Daniele Malitesta,Emanuele Rossi,Claudio Pomo,Tommaso Di Noia,Fragkiskos D. Malliaros*

Main category: cs.IR

TL;DR: 提出四种基于图结构的训练免费方法，通过项目-项目共购图传播多模态特征来填补缺失模态，保持或扩大多模态推荐系统与传统系统的性能差距


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统中项目可能缺少某些模态数据，现有方法通常直接丢弃这些项目，导致数据浪费。需要解决多模态推荐中缺失模态的问题，并建立正式的问题形式化

Method: 1) 形式化多模态推荐中的缺失模态问题；2) 将缺失多模态信息重构为项目-项目共购图上的图特征插值问题；3) 提出四种基于图的训练免费方法，通过图传播可用多模态特征来填补缺失特征

Result: 实验表明：1) 方法可无缝集成到现有多模态推荐系统和基准框架；2) 保持甚至扩大多模态与传统推荐系统的性能差距；3) 基于图的方法在不同缺失模态设置下优于传统机器学习插值方法；4) 首次分析项目-项目图上的特征同质性对图基插值的影响

Conclusion: 基于图的方法能有效处理多模态推荐中的缺失模态问题，通过项目-项目图结构传播特征，优于传统插值方法，且首次揭示了特征同质性对图基插值的影响

Abstract: Multimodal recommender systems (RSs) represent items in the catalog through multimodal data (e.g., product images and descriptions) that, in some cases, might be noisy or (even worse) missing. In those scenarios, the common practice is to drop items with missing modalities and train the multimodal RSs on a subsample of the original dataset. To date, the problem of missing modalities in multimodal recommendation has still received limited attention in the literature, lacking a precise formalisation as done with missing information in traditional machine learning. In this work, we first provide a problem formalisation for missing modalities in multimodal recommendation. Second, by leveraging the user-item graph structure, we re-cast the problem of missing multimodal information as a problem of graph features interpolation on the item-item co-purchase graph. On this basis, we propose four training-free approaches that propagate the available multimodal features throughout the item-item graph to impute the missing features. Extensive experiments on popular multimodal recommendation datasets demonstrate that our solutions can be seamlessly plugged into any existing multimodal RS and benchmarking framework while still preserving (or even widen) the performance gap between multimodal and traditional RSs. Moreover, we show that our graph-based techniques can perform better than traditional imputations in machine learning under different missing modalities settings. Finally, we analyse (for the first time in multimodal RSs) how feature homophily calculated on the item-item graph can influence our graph-based imputations.

</details>


### [9] [Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers](https://arxiv.org/abs/2602.17410)
*Bingqian Li,Bowen Zheng,Xiaolei Wang,Long Zhang,Jinpeng Wang,Sheng Chen,Wayne Xin Zhao,Ji-rong Wen*

Main category: cs.IR

TL;DR: ILRec：基于LLM的推荐系统偏好微调框架，利用中间层自硬负信号改进偏好学习


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法依赖序列级、离线生成的负样本，在大型负物品空间中缺乏区分性和信息性，需要更有效的负监督信号

Method: 提出ILRec框架：1）从中间层识别自硬负标记作为细粒度负监督；2）设计跨层偏好优化和跨层偏好蒸馏两阶段框架；3）引入轻量级协同过滤模型分配标记级奖励

Result: 在三个数据集上的实验证明ILRec能有效提升基于LLM的推荐系统性能

Conclusion: ILRec通过利用中间层自硬负信号，为LLM推荐系统提供了更有效的偏好学习框架，解决了传统方法在大型负物品空间中的局限性

Abstract: Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.

</details>


### [10] [A Picture of Agentic Search](https://arxiv.org/abs/2602.17518)
*Francesca Pezzuti,Ophir Frieder,Fabrizio Silvestri,Sean MacAvaney,Nicola Tonellotto*

Main category: cs.IR

TL;DR: 论文提出Agentic Search Queryset (ASQ)数据集，用于解决信息检索系统面临自动化系统查询时缺乏相关数据的问题。


<details>
  <summary>Details</summary>
Motivation: 随着自动化系统与人类并行发出搜索查询，信息检索面临重大转变。当前IR系统、评估指标、用户模型和数据集仍围绕人类查询和行为设计，导致实际假设不再成立，影响系统性能和优化。缺乏捕捉智能体搜索行为的数据集是IR领域的关键缺口。

Method: 开发了一种收集智能体检索增强系统在回答查询时产生和消费的所有数据的方法论。创建了Agentic Search Queryset (ASQ)数据集，包含HotpotQA、Researchy Questions和MS MARCO中推理诱导的查询、检索文档和思考过程，涵盖3种不同智能体和2种检索管道。提供配套工具包支持扩展到新智能体、检索器和数据集。

Result: 发布了ASQ数据集，这是首个专门捕捉智能体搜索行为的数据集，填补了IR领域在数据驱动评估和优化方面的关键空白。

Conclusion: 信息检索需要适应自动化系统查询的新现实，ASQ数据集为研究智能体搜索行为、优化IR系统性能提供了必要的数据基础，有助于开发同时满足人类和智能体需求的检索模型。

Abstract: With automated systems increasingly issuing search queries alongside humans, Information Retrieval (IR) faces a major shift. Yet IR remains human-centred, with systems, evaluation metrics, user models, and datasets designed around human queries and behaviours. Consequently, IR operates under assumptions that no longer hold in practice, with changes to workload volumes, predictability, and querying behaviours. This misalignment affects system performance and optimisation: caching may lose effectiveness, query pre-processing may add overhead without improving results, and standard metrics may mismeasure satisfaction. Without adaptation, retrieval models risk satisfying neither humans, nor the emerging user segment of agents. However, datasets capturing agent search behaviour are lacking, which is a critical gap given IR's historical reliance on data-driven evaluation and optimisation. We develop a methodology for collecting all the data produced and consumed by agentic retrieval-augmented systems when answering queries, and we release the Agentic Search Queryset (ASQ) dataset. ASQ contains reasoning-induced queries, retrieved documents, and thoughts for queries in HotpotQA, Researchy Questions, and MS MARCO, for 3 diverse agents and 2 retrieval pipelines. The accompanying toolkit enables ASQ to be extended to new agents, retrievers, and datasets.

</details>


### [11] [Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval](https://arxiv.org/abs/2602.17654)
*Jiaqi Xi,Raghav Saboo,Luming Chen,Martin Wang,Sudeep Das*

Main category: cs.IR

TL;DR: 提出两阶段"挖掘与精炼"对比训练框架，用于增强多类别电商搜索的语义文本嵌入，通过策略一致的监督和边界锐化提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 大规模电商搜索需要能够泛化到长尾、噪声查询的嵌入表示，同时需要符合产品策略约束的可扩展监督。实际挑战在于相关性通常是分级的：用户接受替代品或互补品而非精确匹配，生产系统需要清晰的相似度分数分层以实现稳定的混合融合和阈值设置。

Method: 1. 使用轻量级LLM在三级相关性标注下微调，通过参与度驱动的审计减少噪声；2. 第一阶段：用标签感知的监督对比目标训练多语言Siamese双塔检索器，构建鲁棒的全局语义空间；3. 第二阶段：通过ANN挖掘困难样本并用策略对齐的LLM重新标注，引入多类圆形损失的扩展，显式锐化相关性层级间的相似度边界；4. 通过拼写增强和合成查询生成提升鲁棒性。

Result: 广泛的离线评估和生产A/B测试表明，该框架提高了检索相关性，并在参与度和业务影响方面带来了统计显著的提升。

Conclusion: 提出的两阶段"挖掘与精炼"对比训练框架有效解决了电商搜索中分级相关性和策略约束的挑战，通过策略一致的监督和边界锐化技术显著提升了语义嵌入的质量和检索效果。

Abstract: We propose a two-stage "Mine and Refine" contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.

</details>
