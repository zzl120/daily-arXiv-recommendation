<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 51]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Disaster Question Answering with LoRA Efficiency and Accurate End Position](https://arxiv.org/abs/2602.21212)
*Takato Yasuno*

Main category: cs.CL

TL;DR: 该研究提出了一个面向日本灾害情境的问答系统，通过优化BERT-base日语模型结合Bi-LSTM架构，在仅使用5.7%参数的情况下实现了70.4%的端位置准确率，适用于灾害响应场景。


<details>
  <summary>Details</summary>
Motivation: 自然灾害发生频率低且影响范围有限，个人面对灾害时往往缺乏领域知识和经验，而现有RAG和LLM方法在灾害问答中可能产生幻觉导致错误信息传播，需要专门针对灾害情境的可靠问答系统。

Method: 采用cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads架构，结合LoRA效率优化技术，仅使用原始模型5.7%的参数（6.7M/117M）进行微调。

Result: 在端位置准确率上达到70.4%，Span F1分数为0.885，证明了日语BERT-base优化与Bi-LSTM上下文理解的组合在灾害响应场景中具有足够的准确性。

Conclusion: 该系统在参数效率方面表现优异，适合实际灾害响应应用。未来挑战包括：建立自然灾害问答基准数据集、用灾害知识微调基础模型、开发轻量级边缘AI灾害问答应用、解决灾害知识库更新和持续学习能力问题。

Abstract: Natural disasters such as earthquakes, torrential rainfall, floods, and volcanic eruptions occur with extremely low frequency and affect limited geographic areas. When individuals face disaster situations, they often experience confusion and lack the domain-specific knowledge and experience necessary to determine appropriate responses and actions. While disaster information is continuously updated, even when utilizing RAG search and large language models for inquiries, obtaining relevant domain knowledge about natural disasters and experiences similar to one's specific situation is not guaranteed. When hallucinations are included in disaster question answering, artificial misinformation may spread and exacerbate confusion. This work introduces a disaster-focused question answering system based on Japanese disaster situations and response experiences. Utilizing the cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads architecture with LoRA efficiency optimization, we achieved 70.4\% End Position accuracy with only 5.7\% of the total parameters (6.7M/117M). Experimental results demonstrate that the combination of Japanese BERT-base optimization and Bi-LSTM contextual understanding achieves accuracy levels suitable for real disaster response scenarios, attaining a 0.885 Span F1 score. Future challenges include: establishing natural disaster Q\&A benchmark datasets, fine-tuning foundation models with disaster knowledge, developing lightweight and power-efficient edge AI Disaster Q\&A applications for situations with insufficient power and communication during disasters, and addressing disaster knowledge base updates and continual learning capabilities.

</details>


### [2] [Inference-time Alignment via Sparse Junction Steering](https://arxiv.org/abs/2602.21215)
*Runyi Hu,Jie Zhang,Shiqian Zhao,Jiale Meng,Jiwei Li,Jason Zeng,Ming Wu,Michael Heinrich,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: SIA（稀疏推理时对齐）通过在关键决策点而非每个解码步骤进行稀疏干预，实现高效的语言模型对齐，仅需干预20%-80%的token即可达到或超越密集干预效果。


<details>
  <summary>Details</summary>
Motivation: 现有token级引导方法在每个解码步骤进行密集干预，导致计算开销大且可能过度偏离模型固有分布，损害生成质量。需要一种更高效的稀疏干预方法。

Method: 提出SIA方法，仅在高熵决策点（关键生成轨迹节点）进行稀疏干预，这些点对错位特别敏感，需要引入对齐相关的奖励信号。

Result: 实验表明，仅干预20%-80%的token即可实现优越的对齐-效率权衡。对于Qwen3等强基础模型，仅干预20%的token即可匹配甚至超越经过大量后训练的指令模型。稀疏性使计算成本降低高达6倍。

Conclusion: 密集干预是不必要的，稀疏干预在关键决策点进行引导不仅能保持模型固有分布，还能与Best-of-N等搜索方法无缝集成，实现高效且高质量的对齐。

Abstract: Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.

</details>


### [3] [EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning](https://arxiv.org/abs/2602.21216)
*Zhyar Rzgar K Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 该研究通过微调预训练语言模型并结合生物医学实体信息，开发了自动检测EQ-5D相关文献的系统，显著提升了系统文献综述的效率。


<details>
  <summary>Details</summary>
Motivation: 在健康经济学中，系统文献综述依赖准确识别使用EQ-5D的文献，但人工筛选大量文献耗时、易错且不一致，需要自动化解决方案。

Method: 研究微调通用（BERT）和领域专用（SciBERT、BioBERT）预训练语言模型，结合scispaCy提取的生物医学实体信息，设计了9种实验设置，并探索了多实例学习（MIL）方法，使用注意力池化将句子级信息聚合为研究级预测。

Result: 实验结果显示F1分数达到0.82，研究级召回率接近完美，显著超过传统词袋模型基准和近期报道的PLM基准，实体增强显著改善了领域适应和模型泛化能力。

Conclusion: 实体增强的预训练语言模型能有效提升EQ-5D文献检测的准确性，为系统文献综述提供了更精确的自动化筛选工具，提高了研究效率。

Abstract: The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.

</details>


### [4] [Applied Sociolinguistic AI for Community Development (ASA-CD): A New Scientific Paradigm for Linguistically-Grounded Social Intervention](https://arxiv.org/abs/2602.21217)
*S M Ruhul Alam,Rifa Ferzana*

Main category: cs.CL

TL;DR: 提出应用社会语言学AI用于社区发展（ASA-CD）新范式，通过语言基础的AI干预解决社区问题，包含语言生物标志物、发展对齐NLP和五阶段干预协议


<details>
  <summary>Details</summary>
Motivation: 为解决社区挑战提供一种语言基础、AI驱动的干预方法，建立可扩展、价值对齐的AI框架，服务于社区赋权

Method: 提出ASA-CD范式，包含三个核心贡献：1）语言生物标志物作为话语碎片化的计算指标；2）发展对齐的自然语言处理，优先集体结果的AI优化范式；3）标准化的五阶段话语干预协议。通过概念验证研究，结合真实世界和合成语料库进行验证

Result: 概念验证研究表明，排斥性语言与负面情感存在系统性关联，并模拟了基于干预的改进效果

Conclusion: ASA-CD为可扩展、价值对齐的AI提供了一个统一的方法论、伦理和实证框架，服务于社区赋权

Abstract: This paper establishes Applied Sociolinguistic AI for Community Development (ASA-CD) as a novel scientific paradigm for addressing community challenges through linguistically grounded, AI-enabled intervention. ASA-CD introduces three key contributions: (1) linguistic biomarkers as computational indicators of discursive fragmentation; (2) development-aligned natural language processing (NLP), an AI optimisation paradigm prioritising collective outcomes; and (3) a standardised five-phase protocol for discursive intervention. A proof-of-concept study, incorporating real-world and synthetic corpora, demonstrates systematic associations between exclusionary language and negative sentiment and simulates intervention-based improvements. ASA-CD provides a unified methodological, ethical and empirical framework for scalable, value-aligned AI in the service of community empowerment.

</details>


### [5] [EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors](https://arxiv.org/abs/2602.21218)
*Amin Banayeeanzade,Qingchuan Yang,Deqing Fu,Spencer Hong,Erin Babinsky,Alfy Samuel,Anoop Kumar,Robin Jia,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: EPSVec：一种高效的差分隐私文本生成方法，通过数据集向量引导LLM生成，实现隐私预算与生成过程的解耦，在低数据量下仍能保持高质量合成数据生成。


<details>
  <summary>Details</summary>
Motivation: 高质量数据对机器学习至关重要，但许多有价值的数据集因隐私问题无法共享。现有隐私文本生成方法效率低下：需要大量数据、计算缓慢，且通常需要大批量才能达到可用质量。

Method: EPSVec通过提取和净化"数据集向量"（捕捉私有数据与公共先验之间分布差异的激活空间方向）来引导LLM生成。该方法只需一次性提取和净化引导向量，然后执行标准解码，将隐私预算与生成过程解耦。还利用预训练基础模型和固定样本提示来提升生成多样性和保真度。

Result: 实验表明，EPSVec在分布对齐和下游任务效用方面优于现有基线方法，特别是在低数据量情况下，同时显著减少了计算开销。

Conclusion: EPSVec提供了一种高效、轻量级的差分隐私文本生成方案，能够在保护隐私的同时生成高质量的合成数据，尤其适用于数据稀缺场景，且支持无限生成而不增加隐私成本。

Abstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.

</details>


### [6] [Reasoning-Based Personalized Generation for Users with Sparse Data](https://arxiv.org/abs/2602.21219)
*Bo Ni,Branislav Kveton,Samyadeep Basu,Subhojyoti Mukherjee,Leyao Wang,Franck Dernoncourt,Sungchul Kim,Seunghyun Yoon,Zichao Wang,Ruiyi Zhang,Puneet Mathur,Jihyung Kil,Jiuxiang Gu,Nedim Lipka,Yu Wang,Ryan A. Rossi,Tyler Derr*

Main category: cs.CL

TL;DR: GraSPer：基于图的稀疏个性化推理框架，通过预测用户未来可能交互的项目并生成相应文本来增强稀疏上下文，从而改善LLM个性化生成


<details>
  <summary>Details</summary>
Motivation: 现实世界中用户通常具有稀疏的交互历史（如冷启动用户、新注册客户），有限的个人上下文会损害基于LLM的个性化生成效果

Method: GraSPer框架：1）通过预测用户未来可能交互的项目来增强用户上下文；2）通过推理对齐为这些交互生成文本以丰富增强上下文；3）基于真实和合成历史生成个性化输出，确保与用户风格和偏好对齐

Result: 在三个基准个性化生成数据集上的广泛实验表明，GraSPer实现了显著的性能提升，在稀疏用户上下文设置中大幅改善了个性化效果

Conclusion: GraSPer通过图基增强和推理对齐有效解决了稀疏上下文下的LLM个性化挑战，为冷启动用户等场景提供了实用的解决方案

Abstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.

</details>


### [7] [Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation](https://arxiv.org/abs/2602.21220)
*Subhadip Mitra*

Main category: cs.CL

TL;DR: 提出了一种基于场论的AI智能体记忆系统，将存储信息视为偏微分方程控制的连续场而非离散数据库条目，在长上下文基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统AI智能体记忆系统通常采用离散数据库条目方式存储信息，缺乏连续性和动态交互特性。受经典场论启发，研究者希望开发一种更符合信息本质特性的记忆系统，能够模拟记忆在语义空间中的扩散、基于重要性的热力学衰减以及多智能体场景中的场耦合交互。

Method: 提出场论记忆系统，将记忆信息建模为连续场，用偏微分方程描述其动态行为：1) 记忆在语义空间中扩散；2) 基于重要性的热力学衰减；3) 多智能体场景中的场耦合交互。系统在两个长上下文基准测试上进行评估：LoCoMo（ACL 2024）包含35个会话的300轮对话，以及LongMemEval（ICLR 2025）测试500+轮的多会话推理。

Result: 在LongMemEval基准测试中，场论方法取得显著改进：多会话推理F1分数提升116%（p<0.01，效应量d=3.06）；时序推理提升43.8%（p<0.001，d=9.21）；知识更新检索召回率提升27.8%（p<0.001，d=5.00）。多智能体实验通过场耦合实现接近完美的集体智能（>99.8%）。

Conclusion: 场论记忆系统为AI智能体记忆提供了新的范式，通过连续场建模显著提升了长上下文和多会话推理能力，在多智能体协作中展现出强大的集体智能特性，为未来智能体系统设计提供了有前景的方向。

Abstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p<0.01, d= 3.06), +43.8% on temporal reasoning (p<0.001, d= 9.21), and +27.8% retrieval recall on knowledge updates (p<0.001, d= 5.00). Multi-agent experiments show near-perfect collective intelligence (>99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.

</details>


### [8] [Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases](https://arxiv.org/abs/2602.21222)
*Riya Adsul,Balachandra Devarangadi Sunil,Isha Nalawade,Sudharshan Govindan*

Main category: cs.CL

TL;DR: 提出基于向量数据库检索的动态LoRA适配器组合框架，通过相似性检索实现零样本跨任务泛化，无需额外训练检索器，在22个数据集上验证了四种合并方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法（如LoRA）虽然能实现大语言模型的任务特定适配，但如何高效组合多个专用适配器来处理未见任务仍然具有挑战性。需要一种能够实现零样本跨任务泛化的动态适配器组合方法。

Method: 构建任务感知的向量数据库，嵌入来自22个数据集的训练示例（涵盖常识推理、问答、自然语言推理和情感分析）。推理时检索最相似的训练示例，通过nucleus采样计算任务相似度分布，并使用检索加权融合策略动态合并相关LoRA适配器。评估了四种合并方法：线性合并、拼接、TIES和幅度剪枝。

Result: 数据集中心的检索方法通常匹配或超过单独微调的任务特定适配器性能。线性合并方法在PIQA上达到70.95%，在RTE上达到77.62%，显著优于单任务基线（分别为46%和52%）。框架无需额外训练检索器，使用冻结嵌入，实现高效可解释的适配器组合。

Conclusion: 基于检索的动态合并为可扩展的参数高效多任务学习提供了有前景的方向，无需为每个新任务重新训练完整模型。该方法展示了通过相似性检索实现零样本跨任务泛化的有效性。

Abstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.

</details>


### [9] [Measuring Pragmatic Influence in Large Language Model Instructions](https://arxiv.org/abs/2602.21223)
*Yilin Geng,Omri Abend,Eduard Hovy,Lea Frermann*

Main category: cs.CL

TL;DR: 论文研究提示语中的语用框架效应，即通过"紧急"、"作为你的上司"等上下文线索改变LLM行为而不改变任务内容，建立了测量框架并发现语用框架能系统性地影响指令优先级


<details>
  <summary>Details</summary>
Motivation: 现有研究要么将语用框架作为提示优化工具，要么视为安全漏洞，但语用框架本身尚未被视为指令遵循系统的可测量属性。需要系统测量这种影响，但面临分离框架线索与任务内容的挑战

Method: 提出包含三个组件的框架：1) 指令-框架分解，分离框架上下文与任务规范；2) 包含13种策略、4个机制簇的400个实例分类法；3) 基于优先级的测量方法，通过指令优先级可观察变化量化影响

Result: 在五个不同家族和规模的LLM上，影响机制导致指令优先级的一致性和结构化变化，使模型从基线中立性转向偏向框架指令。语用框架效应在不同模型中表现出可预测的模式

Conclusion: 该工作确立了语用框架作为指令遵循系统中可测量和可预测的因素，为理解LLM如何解释和响应人类指令提供了新视角

Abstract: It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like "This is urgent" or "As your supervisor" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.

</details>


### [10] [Make Every Draft Count: Hidden State based Speculative Decoding](https://arxiv.org/abs/2602.21224)
*Yuetao Chen,Xuliang Wang,Xinzhou Zheng,Ming Li,Peng Wang,Hong Xu*

Main category: cs.CL

TL;DR: 提出一种新颖的推测解码系统，通过重用被丢弃的草稿隐藏状态来回收浪费的计算，相比标准推测解码实现最高3.3倍加速。


<details>
  <summary>Details</summary>
Motivation: 标准推测解码中，大多数草稿令牌验证失败被丢弃，导致计算浪费。本文旨在回收这些浪费的计算，提高计算效率。

Method: 1) 基于自回归隐藏状态的草稿模型架构，保留比令牌级草稿更丰富的语义；2) 高效的令牌信息注入机制，构建高质量草稿令牌树并支持从验证失败中重新采样令牌；3) 消除设计中的隐藏开销以最大化硬件利用率。

Result: 通过广泛评估，相比各种基线方法，实现了最高3.3倍的速度提升（相对于标准推测解码）。

Conclusion: 提出的系统通过重用被丢弃的草稿隐藏状态，成功回收了推测解码中的浪费计算，显著提高了LLM推理的计算效率和速度。

Abstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.

</details>


### [11] [Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal](https://arxiv.org/abs/2602.21225)
*Mohammed Hamdan,Vincenzo Dentamaro,Giuseppe Pirlo,Mohamed Cheriet*

Main category: cs.CL

TL;DR: 渐进数据调度（逐步增加训练数据暴露）在文档理解模型中可减少约33%训练时间，其收益取决于模型容量与任务复杂度的交互作用


<details>
  <summary>Details</summary>
Motivation: 研究渐进数据调度（一种课程学习策略）在不同架构的文档理解模型中是否具有一致的效率提升效果，并探究其收益是否源于真正的课程效应而非单纯的计算量减少

Method: 评估BERT（纯文本，110M参数）和LayoutLMv3（多模态，126M参数）在FUNSD和CORD基准上的表现。采用渐进数据调度（33%→67%→100%），引入匹配计算基线（Standard-7）以控制总梯度更新次数。进行调度消融实验，比较渐进、两阶段、反向和随机调度策略

Result: 渐进调度减少约33%训练时间（从6.67到10.0有效epoch当量）。在FUNSD上，BERT的课程调度显著优于匹配计算基线（ΔF1=+0.023，p=0.022，dz=3.83），表明容量受限模型存在真正的调度收益；但LayoutLMv3无类似收益（p=0.621）。在CORD上，所有条件收敛到等效F1分数（≥0.947），表明存在性能天花板。调度消融实验显示效率增益源于数据量减少而非顺序安排

Conclusion: 渐进调度是跨模型族的可靠计算减少策略，其课程特定收益取决于模型容量与任务复杂度的交互作用。容量受限模型（如BERT）从渐进调度中获益，而具有足够归纳偏置的多模态模型（如LayoutLMv3）则无明显优势

Abstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\%$\rightarrow$67\%$\rightarrow$100\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($Δ$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.

</details>


### [12] [Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment](https://arxiv.org/abs/2602.21543)
*Barah Fazili,Koustava Goswami*

Main category: cs.CL

TL;DR: 通过多语言平行语料库进行对比学习，显著提升多语言预训练模型的跨语言对齐能力，在多种NLU任务上取得性能提升


<details>
  <summary>Details</summary>
Motivation: 传统的多语言预训练缺乏显式的对齐信号，导致表示空间中的跨语言对齐效果不理想。需要探索更有效的跨语言对齐方法来提升多语言和跨语言表示的质量。

Method: 构建多语言平行数据集：使用现成的NMT模型将英语文本翻译成6种目标语言，形成多语言平行语料库。通过对比学习训练标准预训练模型（XLM-Roberta和mBERT），实现强跨语言对齐。

Result: 相比英语中心的双语平行数据，多语言平行语料库的对比训练在多个任务上带来显著提升：双语文本挖掘（+21.3%）、语义相似度（+5.3%）、分类任务（+28.4%）。即使在已经预训练的高质量句子嵌入模型（mE5）上，微调少量多语言平行数据也能显著改善双语文本挖掘性能。

Conclusion: 多语言平行语料库的对比学习是提升跨语言对齐的有效方法，能够显著改善多语言表示质量，即使在已预训练的模型上也能带来额外收益。多语言跨语言监督对于高质量句子嵌入模型仍然至关重要。

Abstract: Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.

</details>


### [13] [IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions](https://arxiv.org/abs/2602.21226)
*Ezieddin Elmahjub,Junaid Qadir,Abdullah Mushtaq,Rafay Naeem,Ibrahim Ghaznavi,Waleed Iqbal*

Main category: cs.CL

TL;DR: 伊斯兰法律基准测试显示当前LLMs在伊斯兰法学推理方面存在严重缺陷，最佳模型正确率仅68%，幻觉率21%，无法可靠提供宗教指导


<details>
  <summary>Details</summary>
Motivation: 随着数百万穆斯林使用LLMs寻求宗教指导，需要评估这些AI系统能否可靠地进行伊斯兰法律推理，确保提供准确的法律指导

Method: 引入伊斯兰法律基准测试，涵盖七个伊斯兰法学流派，包含718个实例和13个不同复杂度的任务，评估九个最先进的LLMs

Result: 评估结果显示重大局限性：最佳模型正确率仅68%，幻觉率21%；多个模型正确率低于35%，幻觉率超过55%；few-shot提示效果有限；中等复杂度任务错误率最高；虚假前提检测显示危险顺从性

Conclusion: 基于提示的方法无法弥补基础知识的缺失，伊斯兰法律基准测试为评估AI伊斯兰法律推理提供了首个系统框架，揭示了日益依赖精神指导工具中的关键差距

Abstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.

</details>


### [14] [Budget-Aware Agentic Routing via Boundary-Guided Training](https://arxiv.org/abs/2602.21227)
*Caiqi Zhang,Menglin Xia,Xuchao Zhang,Daniel Madrigal,Ankur Mallick,Samuel Kessler,Victor Ruehle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 论文提出了一种预算感知的智能体路由方法，通过在每个步骤选择廉价或昂贵模型来优化成本-成功率边界，并在严格的任务预算下运行。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型演变为执行长流程工作的自主智能体，在每个步骤都调用高能力模型在经济上不可持续。虽然模型路由对单轮查询有效，但智能体路由是顺序的、路径依赖的问题：早期错误会累积，反馈通常在流程结束时才出现，且部署通常要求严格的任务预算限制。

Method: 提出边界引导训练，利用两个边界策略（始终小模型 vs. 始终大模型）构建难度分类并锚定稀疏奖励下的学习。方法包括：1) 通过分层采样成本高效轨迹进行边界引导的SFT数据合成预热；2) 边界引导策略优化，结合边界相对奖励和参考引导优势以避免廉价的失败解决方案。

Result: 实验结果显示，该方法改进了效率边界，以显著更低的成本匹配强大的路由基线，同时展示了在严格推理时预算约束下的泛化能力。

Conclusion: 该工作为智能体路由建立了基础框架，将范式从静态模型选择转向动态的、预算感知的顺序决策制定。

Abstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.

</details>


### [15] [ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following](https://arxiv.org/abs/2602.21228)
*Yuancheng Yang,Lin Yang,Xu Wang,Chao Tong,Haihua Yang*

Main category: cs.CL

TL;DR: ImpRIF方法通过将复杂指令形式化为可验证的推理图，增强大语言模型对隐含推理指令的理解能力，从而提升复杂指令跟随性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用日益复杂，对鲁棒的复杂指令跟随能力需求增长。作者认为深入理解指令本身，特别是隐含在指令中的潜在推理结构，对于改进指令跟随至关重要。因此针对涉及隐含推理、复杂逻辑关系和多约束依赖的复杂指令进行研究。

Method: 提出ImpRIF方法，将隐含推理指令形式化为可验证的推理图，支持程序化验证和图驱动的思维链推理。基于此形式化方法，合成大规模单轮和多轮数据，提出基于图推理的微调，并应用强化学习明确训练模型沿图进行推理。

Result: 在五个复杂指令跟随基准测试中，模型显著优于其基础模型。结果表明增强隐含推理能力可以显著改善复杂指令跟随性能。

Conclusion: 增强大语言模型对隐含推理的理解能力是提升复杂指令跟随性能的有效途径。通过将指令形式化为推理图并进行针对性训练，可以显著改善模型在复杂场景下的表现。该项目将在近期开源。

Abstract: As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.

</details>


### [16] [Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment](https://arxiv.org/abs/2602.21346)
*Mengxuan Hu,Vivek V. Datla,Anoop Kumar,Zihan Guan,Sheng Li,Alfy Samuel,Daben Liu*

Main category: cs.CL

TL;DR: 该论文提出通过推理感知的后训练增强大语言模型的对齐鲁棒性，包括构建CoT微调数据集和引入Alignment-Weighted DPO方法，以应对间接或欺骗性措辞的越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 尽管SFT、RLHF和DPO等对齐技术提高了LLMs的安全性，但模型仍易受通过间接或欺骗性措辞伪装有害意图的越狱攻击。作者通过因果干预实证发现，这种脆弱性源于缺乏深度推理的浅层对齐机制，模型经常拒绝有害提示但并未真正理解其为何有害。

Method: 1) 构建并发布新颖的CoT微调数据集，包含实用导向和安全关键提示及其逐步推理过程；2) 在该数据集上进行微调，鼓励模型产生基于推理的原则性拒绝；3) 受CoT微调失败模式启发，引入Alignment-Weighted DPO，通过对推理和最终答案段分配不同偏好权重，针对输出中最有问题的部分进行更细粒度的目标更新。

Result: 在多个安全和实用基准测试上的广泛实验表明，该方法在保持整体模型实用性的同时，一致提高了对齐鲁棒性，优于标准SFT基线，并提高了对多样化越狱策略的鲁棒性。

Conclusion: 通过推理感知的后训练增强对齐，特别是结合CoT微调和Alignment-Weighted DPO，能够有效提高LLMs对越狱攻击的鲁棒性，同时保持实用性，为解决浅层对齐机制导致的脆弱性提供了有效方案。

Abstract: Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.

</details>


### [17] [Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages](https://arxiv.org/abs/2602.21374)
*Mohammadreza Ghaffarzadeh-Esfahani,Nahid Yousefian,Ebrahim Heidari-Farsani,Ali Akbar Omidvarian,Sepehr Ghahraei,Atena Farangi,AmirBahador Boroumand*

Main category: cs.CL

TL;DR: 评估波斯语医疗转录本临床信息提取的两步流程：先用Aya-expanse-8B翻译为英语，再用五个开源小语言模型提取13个临床特征。Qwen2.5-7B-Instruct表现最佳，大模型优于小模型，翻译提升敏感度但略降特异性。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（波斯语）医疗转录本临床信息提取的挑战，为基础设施和标注资源有限的医疗NLP应用提供实用、隐私保护的解决方案。

Method: 采用两步流程：1) 使用Aya-expanse-8B将波斯语转录本翻译为英语；2) 使用五个开源小语言模型（Qwen2.5-7B-Instruct、Llama-3.1-8B-Instruct、Llama-3.2-3B-Instruct、Qwen2.5-1.5B-Instruct、Gemma-3-1B-it）进行13个临床特征的二元提取。使用少量样本提示策略，无需微调，评估指标包括宏平均F1分数、马修斯相关系数、敏感度和特异性。

Result: Qwen2.5-7B-Instruct表现最佳（中位数宏F1：0.899；MCC：0.797），Gemma-3-1B-it表现最弱。大模型（7B-8B参数）在敏感度和MCC上持续优于小模型。翻译波斯语到英语提高了敏感度，减少了缺失输出，提升了类别不平衡鲁棒性指标，但略微降低了特异性和精确度。生理症状提取可靠，而心理抱怨、行政请求和复杂躯体特征仍具挑战性。

Conclusion: 研究为多语言临床NLP环境中部署开源小语言模型提供了实用、隐私保护的蓝图，强调了在敏感医疗应用中联合优化模型规模和输入语言策略的重要性。

Abstract: Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.

</details>


### [18] [Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages](https://arxiv.org/abs/2602.21377)
*Felix Schneider,Maria Gogolev,Sven Sickert,Joachim Denzler*

Main category: cs.CL

TL;DR: 提出RCE（Rich Character Embeddings）方法，直接从字符字符串计算词向量，结合语义和句法信息，并设计混合transformer和卷积机制的模型，作为现有模型架构中字典和子词嵌入的替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于分词和子词分词的模型（如word2vec、BERT、GPT）在输入表示方面存在局限，无法充分捕捉正字法相似性和形态变化，特别是在高度屈折和资源匮乏的语言中。

Method: 提出基于transformer的RCE方法，直接从字符字符串计算词向量；进一步提出结合transformer和卷积机制的混合模型；两种向量表示均可作为现有模型架构中字典和子词嵌入的替代方案。

Result: 在SWAG、屈折语言的变格预测、多种语言的隐喻和交错法检测等任务上评估，实验表明在有限数据下使用OddOneOut和TopK指标时，优于传统的基于分词的方桉。

Conclusion: RCE方法有潜力改善BERT等大型上下文语言模型和word2vec等小型模型在资源匮乏和形态丰富语言上的性能，提供更全面的词表示。

Abstract: Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.

</details>


### [19] [MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation](https://arxiv.org/abs/2602.21379)
*Daniel Tamayo,Iñaki Lacunza,Paula Rivera-Hidalgo,Severino Da Dalt,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

TL;DR: MrBERT是基于ModernBERT架构的150M-300M参数编码器家族，支持35种语言和代码，在加泰罗尼亚语和西班牙语任务上达到SOTA，并在生物医学和法律领域表现优异，通过MRL技术实现灵活的向量大小调整以降低推理和存储成本。


<details>
  <summary>Details</summary>
Motivation: 解决现代编码器架构在特定语言任务和领域专业化之间的平衡问题，同时降低生产环境中的推理和存储成本，弥合研究与生产之间的差距。

Method: 基于ModernBERT架构构建150M-300M参数编码器家族，在35种语言和代码上进行预训练，采用针对性适应策略优化特定语言任务，集成Matryoshka表示学习（MRL）技术实现灵活的向量大小调整。

Result: 在加泰罗尼亚语和西班牙语特定任务上达到最先进水平，在生物医学和法律等专业领域建立稳健性能，通过MRL技术显著降低推理和存储成本，模型家族已在Huggingface开源。

Conclusion: 现代编码器架构可以通过优化实现本地化语言卓越性和高效的高风险领域专业化，MRL技术为生产部署提供了成本效益高的解决方案，展示了架构优化的双重潜力。

Abstract: We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.

</details>


### [20] [VecGlypher: Unified Vector Glyph Generation with Language Models](https://arxiv.org/abs/2602.21461)
*Xiaoke Huang,Bhavul Gauri,Kam Woh Ng,Tony Ng,Mengmeng Xu,Zhiheng Liu,Weiming Ren,Zhaochong An,Zijian Zhou,Haonan Qiu,Yuyin Zhou,Sen He,Ziheng Wang,Tao Xiang,Xiao Han*

Main category: cs.CL

TL;DR: VecGlypher是一个多模态语言模型，可直接从文本描述或图像示例生成高质量矢量字形，无需光栅中间处理，产生可编辑的SVG路径。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的字体生成管道依赖精心策划的示例表和光栅到矢量的后处理，限制了可访问性和可编辑性。需要一种能直接从文本或图像生成可编辑矢量字形的方法。

Method: 采用两阶段训练策略：第一阶段在大规模噪声Envato字体数据集上训练以掌握SVG语法和长序列几何；第二阶段在专家标注的Google Fonts数据集上进行后训练，对齐语言、图像与几何。使用绝对坐标序列化、路径规范化、坐标量化等技术确保稳定解码。

Result: 在跨家族OOD评估中，VecGlypher在纯文本生成方面显著优于通用LLM和专用矢量字体基线，图像参考生成达到最先进性能，明显优于DeepVecFont-v2和DualVector。消融研究表明模型规模和两阶段训练策略至关重要。

Conclusion: VecGlypher通过允许用户用文字或示例设计字体，降低了字体创建门槛，为未来多模态设计工具提供了可扩展的基础。

Abstract: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.

</details>


### [21] [Evaluating the Usage of African-American Vernacular English in Large Language Models](https://arxiv.org/abs/2602.21485)
*Deja Dunlap,R. Thomas McCoy*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在表示非裔美国人白话英语（AAVE）时存在显著偏差，模型通常使用不足或误用AAVE语法特征，并复制了对非裔美国人的刻板印象。


<details>
  <summary>Details</summary>
Motivation: 当前AI对自然语言理解任务的评估主要基于标准方言（如标准美式英语），缺乏对非标准方言如非裔美国人白话英语（AAVE）的准确表示研究。本研究旨在探究大型语言模型如何准确表示AAVE，并比较模型使用与母语者使用的差异。

Method: 研究分析了三个大型语言模型：1）使用区域非裔美国人语言语料库和TwitterAAE中的人类访谈数据，识别人们使用AAVE语法特征（如ain't）的典型语境；2）提示模型生成AAVE文本；3）将模型生成的文本与人类使用模式进行比较；4）通过情感分析和人工检查评估模型输出。

Result: 研究发现：1）在许多情况下，大型语言模型与人类在AAVE使用上存在显著差异；2）模型通常使用不足或误用AAVE的语法特征；3）通过情感分析和人工检查发现，模型复制了对非裔美国人的刻板印象。

Conclusion: 研究结果强调了需要更多样化的训练数据和采用公平性方法来减轻刻板印象的延续。当前大型语言模型在表示非标准方言方面存在系统性偏差，需要改进以确保更公平和准确的语言表示。

Abstract: In AI, most evaluations of natural language understanding tasks are conducted in standardized dialects such as Standard American English (SAE). In this work, we investigate how accurately large language models (LLMs) represent African American Vernacular English (AAVE). We analyze three LLMs to compare their usage of AAVE to the usage of humans who natively speak AAVE. We first analyzed interviews from the Corpus of Regional African American Language and TwitterAAE to identify the typical contexts where people use AAVE grammatical features such as ain't. We then prompted the LLMs to produce text in AAVE and compared the model-generated text to human usage patterns. We find that, in many cases, there are substantial differences between AAVE usage in LLMs and humans: LLMs usually underuse and misuse grammatical features characteristic of AAVE. Furthermore, through sentiment analysis and manual inspection, we found that the models replicated stereotypes about African Americans. These results highlight the need for more diversity in training data and the incorporation of fairness methods to mitigate the perpetuation of stereotypes.

</details>


### [22] [MixSarc: A Bangla-English Code-Mixed Corpus for Implicit Meaning Identification](https://arxiv.org/abs/2602.21608)
*Kazi Samin Yasar Alam,Md Tanbir Chowdhury,Tamim Ahmed,Ajwad Abrar,Md Rafid Haque*

Main category: cs.CL

TL;DR: MixSarc是首个公开可用的孟加拉语-英语代码混合语料库，专门用于隐式意义识别，包含9,087个手动标注的句子，标注了幽默、讽刺、冒犯性和粗俗性标签。


<details>
  <summary>Details</summary>
Motivation: 南亚社交媒体中孟加拉语-英语代码混合现象普遍，但缺乏相应的隐式意义识别资源。现有情感和讽刺模型主要针对单语英语或高资源语言，难以处理转写变体、文化引用和句内语言切换问题。

Method: 通过有针对性的社交媒体收集、系统过滤和多标注者验证构建语料库。使用基于Transformer的模型进行基准测试，并在结构化提示下评估零样本大语言模型。

Result: 模型在幽默检测上表现良好，但在讽刺、冒犯和粗俗性检测上因类别不平衡和语用复杂性而表现显著下降。零样本模型获得有竞争力的微平均F1分数但精确匹配准确率低。分析显示外部数据集中超过42%的负面情感实例具有讽刺特征。

Conclusion: MixSarc为文化感知的NLP提供了基础资源，支持在代码混合环境中进行更可靠的多标签建模。

Abstract: Bangla-English code-mixing is widespread across South Asian social media, yet resources for implicit meaning identification in this setting remain scarce. Existing sentiment and sarcasm models largely focus on monolingual English or high-resource languages and struggle with transliteration variation, cultural references, and intra-sentential language switching. To address this gap, we introduce MixSarc, the first publicly available Bangla-English code-mixed corpus for implicit meaning identification. The dataset contains 9,087 manually annotated sentences labeled for humor, sarcasm, offensiveness, and vulgarity. We construct the corpus through targeted social media collection, systematic filtering, and multi-annotator validation. We benchmark transformer-based models and evaluate zero-shot large language models under structured prompting. Results show strong performance on humor detection but substantial degradation on sarcasm, offense, and vulgarity due to class imbalance and pragmatic complexity. Zero-shot models achieve competitive micro-F1 scores but low exact match accuracy. Further analysis reveals that over 42\% of negative sentiment instances in an external dataset exhibit sarcastic characteristics. MixSarc provides a foundational resource for culturally aware NLP and supports more reliable multi-label modeling in code-mixed environments.

</details>


### [23] [When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning](https://arxiv.org/abs/2602.21619)
*Muku Akasaka,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 视觉空间推理中，信息注入并非越多越好，需要选择性、任务对齐的信息注入才能提升性能


<details>
  <summary>Details</summary>
Motivation: 尽管多模态架构有进步，但视觉空间推理对现代视觉语言模型仍具挑战。常见策略是在推理时注入额外信息（空间线索、常识知识、思维链指令），但这些信息何时真正改善推理、何时引入噪声尚不清楚。

Method: 对三个代表性视觉语言模型和两个公共基准进行假设驱动的信息注入分析，考察：(i)空间上下文的类型和数量，(ii)注入常识知识的数量和相关性，(iii)空间基础与思维链提示的交互作用。

Result: 发现一致模式：更多信息不一定带来更好推理。针对性单一空间线索优于多上下文聚合；过多或弱相关常识知识会降低性能；思维链提示仅在空间基础足够精确时才提高准确性。

Conclusion: 强调选择性、任务对齐信息注入的重要性，为设计可靠多模态推理流程提供实用指导。

Abstract: Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or chain-of-thought (CoT) reasoning instructions. However, it remains unclear when such information genuinely improves reasoning and when it introduces noise. In this paper, we conduct a hypothesis-driven analysis of information injection for VSR across three representative VLMs and two public benchmarks. We examine (i) the type and number of spatial contexts, (ii) the amount and relevance of injected commonsense knowledge, and (iii) the interaction between spatial grounding and CoT prompting. Our results reveal a consistent pattern: more information does not necessarily yield better reasoning. Targeted single spatial cues outperform multi-context aggregation, excessive or weakly relevant commonsense knowledge degrades performance, and CoT prompting improves accuracy only when spatial grounding is sufficiently precise. These findings highlight the importance of selective, task-aligned information injection and provide practical guidance for designing reliable multimodal reasoning pipelines.

</details>


### [24] [RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2602.21628)
*Yukun Chen,Jiaming Li,Longze Chen,Ze Gong,Jingpeng Li,Zhen Qin,Hengyu Chang,Ancheng Xu,Zhihao Yang,Hamid Alinejad-Rokny,Qiang Qu,Bo Zheng,Min Yang*

Main category: cs.CL

TL;DR: RuCL提出分层式基于评分标准的课程学习框架，通过动态调整评分标准权重引导模型从基础感知到高级逻辑推理的学习，在视觉推理基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习范式存在奖励黑客风险，而基于评分标准的方法虽然提供细粒度监督信号，但面临高计算成本和将所有评分标准视为同等可学习的低效训练动态问题。

Method: 提出分层式基于评分标准的课程学习框架，将课程学习重点从数据选择转向奖励设计，生成通用评分标准并按模型能力分层，在训练过程中动态调整评分标准权重。

Result: 在多种视觉推理基准测试中，RuCL相比Qwen2.5-VL-7B模型平均提升7.83%，达到60.06%的最新准确率。

Conclusion: RuCL通过分层式评分标准课程学习有效解决了现有方法的局限性，显著提升了多模态大语言模型的推理能力，为强化学习中的奖励设计提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.

</details>


### [25] [Multi-dimensional Assessment and Explainable Feedback for Counselor Responses to Client Resistance in Text-based Counseling with LLMs](https://arxiv.org/abs/2602.21638)
*Anqi Li,Ruihan Wang,Zhaoming Chen,Yuqian Chen,Yu Lu,Yi Zhu,Yuan Xie,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 该研究开发了一个基于NLP的评估系统，专门用于分析心理咨询中针对客户抵抗的干预质量，通过理论驱动的框架和多维度评估，显著提升了咨询师的应对能力。


<details>
  <summary>Details</summary>
Motivation: 心理咨询中有效处理客户抵抗是一项复杂技能，但从业者缺乏及时、可扩展的监督反馈。现有NLP研究主要关注整体咨询质量和一般治疗技能，无法对客户出现抵抗的高风险时刻提供细粒度评估。

Method: 提出了一个理论驱动的框架，将咨询师回应分解为四种不同的沟通机制；创建并分享了专家标注的真实咨询对话数据集；基于Llama-3.1-8B-Instruct骨干模型进行全参数指令微调，建模细粒度评估判断并生成解释。

Result: 模型能有效区分不同沟通机制的质量（77-81% F1），显著优于GPT-4o和Claude-3.5-Sonnet（45-59% F1）；生成的解释与专家参考高度一致，获得接近满分的专家评分（2.8-2.9/3.0）；43名咨询师的对照实验证实，接收AI生成反馈显著提升了他们应对客户抵抗的能力。

Conclusion: 该研究开发了一个有效的AI系统，能够为心理咨询师提供针对客户抵抗的细粒度评估和解释性反馈，填补了现有NLP研究的空白，并证明这种反馈能实际改善咨询师的临床技能。

Abstract: Effectively addressing client resistance is a sophisticated clinical skill in psychological counseling, yet practitioners often lack timely and scalable supervisory feedback to refine their approaches. Although current NLP research has examined overall counseling quality and general therapeutic skills, it fails to provide granular evaluations of high-stakes moments where clients exhibit resistance. In this work, we present a comprehensive pipeline for the multi-dimensional evaluation of human counselors' interventions specifically targeting client resistance in text-based therapy. We introduce a theory-driven framework that decomposes counselor responses into four distinct communication mechanisms. Leveraging this framework, we curate and share an expert-annotated dataset of real-world counseling excerpts, pairing counselor-client interactions with professional ratings and explanatory rationales. Using this data, we perform full-parameter instruction tuning on a Llama-3.1-8B-Instruct backbone to model fine-grained evaluative judgments of response quality and generate explanations underlying. Experimental results show that our approach can effectively distinguish the quality of different communication mechanisms (77-81% F1), substantially outperforming GPT-4o and Claude-3.5-Sonnet (45-59% F1). Moreover, the model produces high-quality explanations that closely align with expert references and receive near-ceiling ratings from human experts (2.8-2.9/3.0). A controlled experiment with 43 counselors further confirms that receiving these AI-generated feedback significantly improves counselors' ability to respond effectively to client resistance.

</details>


### [26] [Mitigating Structural Noise in Low-Resource S2TT: An Optimized Cascaded Nepali-English Pipeline with Punctuation Restoration](https://arxiv.org/abs/2602.21647)
*Tangsang Chongbang,Pranesh Pyara Shrestha,Amrit Sarki,Anku Jaiswal*

Main category: cs.CL

TL;DR: 该论文提出并评估了一个优化的级联式尼泊尔语语音到英语文本翻译系统，通过引入标点恢复模块来缓解ASR引入的结构噪声，显著提升了翻译质量。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在级联语音翻译系统中会引入结构噪声，特别是标点符号的丢失会显著降低机器翻译（NMT）的质量。对于尼泊尔语这种低资源语言，需要有效的方法来缓解这一问题。

Method: 首先建立高性能的ASR（Wav2Vec2-XLS-R-300m模型）和NMT（多阶段微调的MarianMT模型）组件，然后提出并评估中间标点恢复模块（PRM）。在自定义数据集上测试了三种配置，最终确定将PRM直接应用于ASR输出的最优配置。

Result: 标点丢失导致FLORES基准测试上BLEU分数相对下降20.7%。最优配置（ASR输出直接应用PRM）比直接ASR-to-NMT基线提升了4.90 BLEU点（36.38 vs. 31.48）。人类评估也证实了优化管道在充分性（3.673）和流畅性（3.804）方面的优越性。

Conclusion: 针对性的标点恢复是缓解尼泊尔语S2TT管道中结构噪声的最有效干预措施。这项工作为类似低资源语言的级联语音翻译系统建立了优化基线，并提供了关键的架构见解。

Abstract: This paper presents and evaluates an optimized cascaded Nepali speech-to-English text translation (S2TT) system, focusing on mitigating structural noise introduced by Automatic Speech Recognition (ASR). We first establish highly proficient ASR and NMT components: a Wav2Vec2-XLS-R-300m model achieved a state-of-the-art 2.72% CER on OpenSLR-54, and a multi-stage fine-tuned MarianMT model reached a 28.32 BLEU score on the FLORES-200 benchmark. We empirically investigate the influence of punctuation loss, demonstrating that unpunctuated ASR output significantly degrades translation quality, causing a massive 20.7% relative BLEU drop on the FLORES benchmark. To overcome this, we propose and evaluate an intermediate Punctuation Restoration Module (PRM). The final S2TT pipeline was tested across three configurations on a custom dataset. The optimal configuration, which applied the PRM directly to ASR output, achieved a 4.90 BLEU point gain over the direct ASR-to-NMT baseline (BLEU 36.38 vs. 31.48). This improvement was validated by human assessment, which confirmed the optimized pipeline's superior Adequacy (3.673) and Fluency (3.804). This work validates that targeted punctuation restoration is the most effective intervention for mitigating structural noise in the Nepali S2TT pipeline. It establishes an optimized baseline and demonstrates a critical architectural insight for developing cascaded speech translation systems for similar low-resource languages.

</details>


### [27] [Sparsity Induction for Accurate Post-Training Pruning of Large Language Models](https://arxiv.org/abs/2602.21652)
*Minhao Jiang,Zhikai Li,Xuewen Liu,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CL

TL;DR: 提出Sparsity Induction方法，通过在剪枝前从分布和特征层面促进模型向更高稀疏度发展，突破后训练稀疏化的极限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型参数规模增长带来计算和内存效率挑战，后训练稀疏化是有效方法。但原生稠密矩阵缺乏高稀疏度，直接移除权重会破坏模型状态，即使后调优也难以恢复性能。

Method: 提出Sparsity Induction方法：1) 分布层面：通过数学等价的缩放变换增强分布稀疏性，完全可吸收且无额外参数或推理开销；2) 特征层面：引入谱范数损失从低秩角度促进特征稀疏性。

Result: 在不同模型架构和任务上的实验表明，该方法进一步增强了稀疏友好性，在剪枝性能上优于现有方法。

Conclusion: Sparsity Induction通过在剪枝前从分布和特征层面促进模型向更高稀疏度发展，有效提升了后训练稀疏化的性能极限。

Abstract: Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.

</details>


### [28] [DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation](https://arxiv.org/abs/2602.21669)
*Duc Trung Vu,Pham Khanh Chi,Dat Phi Van,Linh Ngo Van,Sang Dinh,Trung Le*

Main category: cs.CL

TL;DR: DWA-KD是一种新颖的跨分词器知识蒸馏框架，通过双空间熵加权和时间扭曲对齐，在token级别和序列级别同时优化教师-学生模型的知识转移。


<details>
  <summary>Details</summary>
Motivation: 现有跨分词器知识蒸馏方法在序列和词汇级别对齐方面存在不足，限制了知识转移效果。需要一种更有效的框架来同时处理token级别和序列级别的对齐问题。

Method: 提出DWA-KD框架：1) token级别：通过双空间映射和KL散度进行知识蒸馏，使用基于熵的双空间权重来强调学生不确定而教师确定的token；2) 序列级别：在嵌入层和最终隐藏状态层应用Soft动态时间扭曲，对齐教师和学生序列的词汇和上下文语义。

Result: 在多个NLP基准测试上的广泛实验表明，DWA-KD优于现有的知识蒸馏基线方法。消融研究证实了基于熵的token加权与嵌入层和最终隐藏状态层的Soft-DTW对齐具有互补贡献。

Conclusion: DWA-KD通过双空间加权和时间扭曲对齐，有效解决了跨分词器知识蒸馏中的序列和词汇对齐问题，显著提升了知识转移效果。

Abstract: Knowledge Distillation (KD) has emerged as a crucial technique for compressing Large Language Models (LLMs). Although existing cross-tokenizer KD methods have made notable progress, their effectiveness remains constrained by suboptimal alignment across sequence and vocabulary levels. To address these limitations, we introduce Dual-Space Weighting and Time-Warped Alignment (DWA-KD), a novel cross-tokenizer distillation framework that enhances token-wise distillation through dual-space entropy-based weighting and achieves precise sequence-level alignment by leveraging both lexical and semantic information. At the token level, DWA-KD maps teacher representations into the student space and vice versa, performing dual-space KD via Kullback-Leibler divergence (KL). The process is modulated by dual-space weights that up-weight tokens where the student is uncertain and the teacher is confident, thereby focusing learning on informative tokens rather than treating all positions equally. At the sequence level, DWA-KD applies Soft Dynamic Time Warping (Soft-DTW) to both the embedding and final hidden-state layers, enabling robust alignment of lexical and contextual semantics between teacher and student sequences. Extensive experiments across diverse NLP benchmarks demonstrate that DWA-KD outperforms state-of-the-art KD baselines, while ablation studies confirm the complementary contributions of entropy-based token weighting and embedding and final hidden state layer Soft-DTW alignment.

</details>


### [29] [Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning](https://arxiv.org/abs/2602.21720)
*Andrea Silvi,Ponrawee Prasertsom,Jennifer Culbertson,Devdatt Dubhashi,Moa Johansson,Kenny Smith*

Main category: cs.CL

TL;DR: 研究表明人类递归数字系统的规律性促进学习，解释了为何规律系统在跨语言中更普遍。


<details>
  <summary>Details</summary>
Motivation: 探究人类递归数字系统（如英语十进制数字）为何普遍具有高度规律性，是否因为规律性促进了学习过程，从而解释了跨语言中的这种普遍趋势。

Method: 采用强化学习方法，比较高度规律的人类数字系统与可能但不存在的非规律系统的学习难度。假设递归数字系统旨在从有限数据中泛化以精确表示所有整数。

Result: 高度规律的人类数字系统比非规律系统更容易学习。对于不自然的高度非规律系统，学习性不受规律性影响，而是受信号长度影响，表明不同压力在不同可能的数字系统空间中影响学习性的方式不同。

Conclusion: 规律性确实促进学习，这解释了递归数字系统在跨语言中的普遍规律性。研究结果支持了学习性与跨语言普遍性之间的联系。

Abstract: Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common because regularity facilitates learning. Adopting methods from the Reinforcement Learning literature, we confirm that highly regular human(-like) systems are easier to learn than unattested but possible irregular systems. This asymmetry emerges under the natural assumption that recursive numeral systems are designed for generalisation from limited data to represent all integers exactly. We also find that the influence of regularity on learnability is absent for unnatural, highly irregular systems, whose learnability is influenced instead by signal length, suggesting that different pressures may influence learnability differently in different parts of the space of possible numeral systems. Our results contribute to the body of work linking learnability to cross-linguistic prevalence.

</details>


### [30] [Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling](https://arxiv.org/abs/2602.21728)
*Shiqi Yan,Yubo Chen,Ruiqi Zhou,Zhengxi Yao,Shuai Chen,Tianyi Zhang,Shijie Zhang,Wei Qiang Zhang,Yongfeng Huang,Haixin Duan,Yunqi Zhang*

Main category: cs.CL

TL;DR: 提出Explore-on-Graph框架，通过强化学习鼓励LLM在知识图谱上自主探索多样化推理路径，解决传统方法局限于先验经验的问题，在KGQA任务上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的LLM增强方法通常通过生成规则约束或模仿固定演示路径来限制推理，这自然将LLM的推理模式局限在先验经验或微调数据范围内，限制了其对分布外图推理问题的泛化能力。

Method: 提出Explore-on-Graph框架：1) 引入强化学习训练，以推理路径最终答案的正确性作为奖励，激励探索和发现新颖推理路径；2) 将路径信息作为额外奖励信号，优化探索过程并减少无效努力。

Result: 在五个KGQA基准数据集上的广泛实验表明，该方法实现了最先进的性能，不仅超越了开源LLM，甚至超越了闭源LLM。

Conclusion: 通过强化学习驱动的自主探索，EoG框架能够突破传统方法的局限，在知识图谱上发现更丰富的推理模式，显著提升KGQA任务的性能和泛化能力。

Abstract: The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods typically constrained LLM reasoning either by enforcing rules during generation or by imitating paths from a fixed set of demonstrations. However, they naturally confined the reasoning patterns of LLMs within the scope of prior experience or fine-tuning data, limiting their generalizability to out-of-distribution graph reasoning problems. To tackle this problem, in this paper, we propose Explore-on-Graph (EoG), a novel framework that encourages LLMs to autonomously explore a more diverse reasoning space on KGs. To incentivize exploration and discovery of novel reasoning paths, we propose to introduce reinforcement learning during training, whose reward is the correctness of the reasoning paths' final answers. To enhance the efficiency and meaningfulness of the exploration, we propose to incorporate path information as additional reward signals to refine the exploration process and reduce futile efforts. Extensive experiments on five KGQA benchmark datasets demonstrate that, to the best of our knowledge, our method achieves state-of-the-art performance, outperforming not only open-source but also even closed-source LLMs.

</details>


### [31] [Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models](https://arxiv.org/abs/2602.22072)
*Christian Nickel,Laura Schrewe,Florian Mai,Lucie Flek*

Main category: cs.CL

TL;DR: LLM在错误信念任务上的心理理论能力在任务扰动下急剧下降，质疑其是否具备稳健的心理理论能力；思维链提示能整体提升性能但某些扰动类型下反而降低准确性


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否真正具备心理理论能力，通过任务扰动测试其稳健性，并研究思维链提示是否能提升性能并解释模型决策

Method: 构建手工标注的心理理论数据集，包含经典和扰动的错误信念任务、有效推理链空间、推理忠实度、任务解决方案；提出评估推理链正确性和答案对推理轨迹忠实度的指标；测试多种LLM在扰动任务上的表现

Result: 所有评估的LLM在任务扰动下心理理论能力急剧下降；思维链提示整体上能忠实提升心理理论性能，但对某些扰动类型反而降低准确性，需要选择性应用

Conclusion: LLM缺乏稳健的心理理论能力；思维链提示虽能提升性能但需谨慎应用；需要更精细的方法来评估和增强LLM的心理理论能力

Abstract: Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.

</details>


### [32] [Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization](https://arxiv.org/abs/2602.21741)
*MD. Sagor Chowdhury,Adiba Fairooz Chowdhury*

Main category: cs.CL

TL;DR: 该论文介绍了参加Kaggle DL Sprint 4.0竞赛的孟加拉语长语音识别和说话人日志系统，通过Whisper模型微调、声源分离和说话人分割优化，在低资源环境下取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语语音处理面临多重挑战：音素库庞大、方言差异显著、与英语频繁混用、大规模标注语料稀缺。这些因素使得传统的语音识别和说话人日志方法在孟加拉语环境下效果有限，需要针对性的解决方案。

Method: 1. 语音识别：使用BengaliAI微调的Whisper medium模型，结合Demucs声源分离进行人声提取，采用静音边界分块策略，并精细调整生成超参数。
2. 说话人日志：改进pyannote.audio流程，用孟加拉语微调的分割模型替换默认模型，配合wespeaker-voxceleb-resnet34-LM嵌入和基于质心的凝聚聚类。

Result: 语音识别：最佳私有WER为0.37738，公开WER为0.36137。
说话人日志：最佳私有DER为0.27671，公开DER为0.20936。
实验表明，领域特定的分割模型微调、声源分离和自然静音感知分块是影响性能的三个最关键设计选择。

Conclusion: 针对低资源孟加拉语语音处理，通过领域特定微调、声源分离技术和静音感知分块的组合策略，可以有效提升语音识别和说话人日志的性能。这些方法为其他低资源语言的语音处理提供了有价值的参考。

Abstract: We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with English, and a relative scarcity of large-scale labelled corpora. For ASR we achieve a best private Word Error Rate (WER) of 0.37738 and public WER of 0.36137, combining a BengaliAI fine-tuned Whisper medium model with Demucs source separation for vocal isolation, silence-boundary chunking, and carefully tuned generation hyperparameters. For speaker diarization we reach a best private Diarization Error Rate (DER) of 0.27671 and public DER of 0.20936 by replacing the default segmentation model inside the pyannote.audio pipeline with a Bengali-fine-tuned variant, pairing it with wespeaker-voxceleb-resnet34-LM embeddings and centroid-based agglomerative clustering. Our experiments demonstrate that domain-specific fine-tuning of the segmentation component, vocal source separation, and natural silence-aware chunking are the three most impactful design choices for low-resource Bengali speech processing.

</details>


### [33] [Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets](https://arxiv.org/abs/2602.22207)
*Hanna Yukhymenko,Anton Alexandrov,Martin Vechev*

Main category: cs.CL

TL;DR: 提出自动化框架解决多语言LLM评估中翻译基准质量不一致问题，通过USI和T-RANK方法提升翻译质量，应用于8种东欧和南欧语言，超越现有资源


<details>
  <summary>Details</summary>
Motivation: 当前多语言大型语言模型评估的可靠性受到翻译基准质量不一致的损害。现有资源常存在语义漂移和上下文丢失问题，导致误导性的性能指标，需要解决这些挑战以实现更准确的多语言AI评估

Method: 开发全自动化框架，采用测试时计算扩展策略，特别是通用自我改进（USI）和提出的多轮排名方法T-RANK，确保基准在本地化过程中保持原始任务结构和语言细微差别

Result: 将框架应用于8种东欧和南欧语言（乌克兰语、保加利亚语、斯洛伐克语、罗马尼亚语、立陶宛语、爱沙尼亚语、土耳其语、希腊语）的流行基准翻译，使用基于参考的指标和LLM作为评判者的评估显示，翻译质量超越现有资源，实现更准确的下游模型评估

Conclusion: 提出的自动化框架能够生成高质量的多语言基准翻译，解决了语义漂移和上下文丢失问题，发布的框架和改进的基准将促进稳健且可复现的多语言AI发展

Abstract: The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.

</details>


### [34] [Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs](https://arxiv.org/abs/2602.21763)
*Heng Wang,Changxing Wu*

Main category: cs.CL

TL;DR: 利用大语言模型的推理能力，通过知识蒸馏提升隐式篇章关系识别的性能和可解释性


<details>
  <summary>Details</summary>
Motivation: 隐式篇章关系识别（IDRR）面临两个主要挑战：1）缺乏显式篇章标记时需要深层语义理解；2）现有方法只能预测关系而不提供解释支持。大语言模型（LLMs）在深度语言理解和自然语言解释生成方面展现出强大推理能力，但直接使用LLMs成本高且不实用。

Method: 提出一个简单有效的知识蒸馏方法：1）首先使用LLM基于黄金标签为每个训练实例生成解释；2）引入新颖的分类-生成框架，联合执行关系预测和解释生成；3）使用LLM生成的解释作为额外监督训练轻量级IDRR模型。该框架是即插即用的，可与大多数现有IDRR模型集成。

Result: 在PDTB数据集上的实验结果表明，该方法显著提高了IDRR性能。人工评估进一步证实生成的解释增强了模型可解释性。此外，在情感分类和自然语言推理任务上的验证证明了该方法的通用性。

Conclusion: 通过将LLMs的推理能力蒸馏到轻量级IDRR模型中，本文提出的方法不仅提升了隐式篇章关系识别的性能，还增强了模型的可解释性。该框架具有通用性，可扩展到其他需要解释的NLP任务。

Abstract: Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting explanations. Recent advances in large language models (LLMs) have shown strong reasoning capabilities in both deep language understanding and natural language explanation generation. In this work, we propose a simple yet effective approach to distill the reasoning capabilities of LLMs into lightweight IDRR models to improve both performance and interpretability. Specifically, we first prompt an LLM to generate explanations for each training instance conditioned on its gold label. Then, we introduce a novel classification-generation framework that jointly performs relation prediction and explanation generation, and train it with the additional supervision of LLM-generated explanations. Our framework is plug-and-play, enabling easy integration with most existing IDRR models. Experimental results on PDTB demonstrate that our approach significantly improves IDRR performance, while human evaluation further confirms that the generated explanations enhance model interpretability. Furthermore, we validate the generality of our approach on sentiment classification and natural language inference

</details>


### [35] [D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models](https://arxiv.org/abs/2602.21786)
*Shunsuke Ubukata*

Main category: cs.CL

TL;DR: 提出D-CoT框架，通过控制标签结构化推理过程，解决小语言模型CoT蒸馏中的"过度思考"问题，实现性能提升和计算成本降低。


<details>
  <summary>Details</summary>
Motivation: 传统CoT蒸馏方法在小语言模型中容易引发"过度思考"问题，导致性能下降和过多的token消耗，需要一种更结构化的推理过程来优化CoT轨迹。

Method: 提出Disciplined Chain-of-Thought (D-CoT)框架，使用控制标签（如<TEMP_LOW>用于事实检查，<TEMP_HIGH>用于多视角探索）作为辅助脚手架来强制结构化推理过程，优化CoT轨迹并抑制推理漂移。

Result: 在Qwen3-8B模型上，仅使用5,000个训练样本，D-CoT显著提升GPQA-diamond准确率9.9%，MMLU-Pro (0-shot)准确率9.1%，同时大幅降低计算成本。模型内化了这种结构化思维，在推理时即使没有显式控制标签也能保持高性能。

Conclusion: D-CoT框架通过结构化推理过程有效解决了小语言模型CoT蒸馏中的"过度思考"问题，实现了性能提升和计算效率优化的双重目标，为高效知识蒸馏提供了新思路。

Abstract: Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces "overthinking" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framework that enforces a structured reasoning process using control tags -- such as <TEMP_LOW> for fact-checking and <TEMP_HIGH> for multi-perspective exploration -- as auxiliary scaffolding during training. By optimizing the CoT trajectory, D-CoT suppresses reasoning drift and simultaneously achieves token reduction and performance improvement. We demonstrate the efficacy of our approach on Qwen3-8B: with only 5,000 training samples, D-CoT significantly boosts accuracy on GPQA-diamond by 9.9% and MMLU-Pro (0-shot) by 9.1%, while drastically reducing computational costs. Furthermore, we confirm that the model internalizes this disciplined thought structure, maintaining high performance even without explicit control tags during inference.

</details>


### [36] [FewMMBench: A Benchmark for Multimodal Few-Shot Learning](https://arxiv.org/abs/2602.21854)
*Mustafa Dogan,Ilker Kesen,Iacer Calixto,Aykut Erdem,Erkut Erdem*

Main category: cs.CL

TL;DR: FewMMBench是一个评估多模态大语言模型少样本学习能力的基准测试，特别关注上下文学习和思维链提示，涵盖多种多模态理解任务，评估了26个开放权重模型。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在处理交错图像-文本数据方面取得进展，评估其少样本学习能力仍然是一个开放挑战。现有研究缺乏系统评估MLLMs在少样本条件下的表现，特别是在上下文学习和思维链提示方面的能力。

Method: 提出FewMMBench基准测试，涵盖从属性识别到时序推理的多样化多模态理解任务。在零样本、少样本和思维链增强的少样本设置下，评估了来自六个模型家族的26个开放权重MLLMs，并分析了任务类型、模型家族和提示策略的影响。

Result: 研究发现：1）指令调优模型在零样本设置下表现强劲，但通过额外演示或思维链推理获益有限甚至出现性能下降；2）基于检索的演示和增加上下文大小带来的增益有限；3）FewMMBench能够有效诊断多模态大语言模型的少样本能力。

Conclusion: FewMMBench为诊断和推进多模态大语言模型的少样本能力提供了一个严谨的测试平台，揭示了当前模型在少样本学习方面的局限性，特别是指令调优模型对额外演示的有限响应。

Abstract: As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot conditions, with a focus on In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting. Covering a diverse suite of multimodal understanding tasks, from attribute recognition to temporal reasoning, FewMMBench enables systematic analysis across task types, model families, and prompting strategies. We evaluate 26 open-weight MLLMs from six model families across zero-shot, few-shot, and CoT-augmented few-shot settings. Our findings reveal that instruction-tuned models exhibit strong zero-shot performance but benefit minimally, or even regress, with additional demonstrations or CoT reasoning. Retrieval-based demonstrations and increased context size also yield limited gains. These results highlight FewMMBench as a rigorous testbed for diagnosing and advancing few-shot capabilities in multimodal LLMs. The data is available at: https://huggingface.co/datasets/mustafaa/FewMMBench

</details>


### [37] [Personalized Graph-Empowered Large Language Model for Proactive Information Access](https://arxiv.org/abs/2602.21862)
*Chia Cheng Chang,An-Zi Yen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 提出基于大语言模型和知识图谱的主动信息访问框架，帮助用户回忆遗忘的生活经历


<details>
  <summary>Details</summary>
Motivation: 个人难以回忆所有生活细节且容易混淆事件，现有记忆回忆系统依赖深度学习需要大量训练数据，而个人生活日志数据稀缺，且系统需要适应随时间增长的新数据

Method: 利用大语言模型进行主动信息访问，集成个人知识图谱，通过精炼的决策过程增强访问需求检测，框架具有高度灵活性，可替换基础模型和修改事实检索方法

Result: 实验结果表明该方法能有效识别遗忘事件，帮助用户更高效地回忆过去经历

Conclusion: 提出的框架利用大语言模型和知识图谱成功解决了个人记忆回忆问题，提供了灵活可改进的系统方案

Abstract: Since individuals may struggle to recall all life details and often confuse events, establishing a system to assist users in recalling forgotten experiences is essential. While numerous studies have proposed memory recall systems, these primarily rely on deep learning techniques that require extensive training and often face data scarcity due to the limited availability of personal lifelogs. As lifelogs grow over time, systems must also adapt quickly to newly accumulated data. Recently, large language models (LLMs) have demonstrated remarkable capabilities across various tasks, making them promising for personalized applications. In this work, we present a framework that leverages LLMs for proactive information access, integrating personal knowledge graphs to enhance the detection of access needs through a refined decision-making process. Our framework offers high flexibility, enabling the replacement of base models and the modification of fact retrieval methods for continuous improvement. Experimental results demonstrate that our approach effectively identifies forgotten events, supporting users in recalling past experiences more efficiently.

</details>


### [38] [ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection](https://arxiv.org/abs/2602.21887)
*Changjiang Gao,Zixian Huang,Kaichen Yang,Jiajun Chen,Jixing Li,Shujian Huang*

Main category: cs.CL

TL;DR: ExpLang是一种新颖的LLM后训练流程，通过启用策略内思考语言选择，利用多语言优势改进强化学习中的探索和利用，在相同训练预算下稳定超越仅英语训练。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在强化学习后训练后表现出色，但主要集中于英语推理，忽视了多语言思维的潜在优势以及全球用户对原生思维轨迹的需求。需要一种方法能够利用多语言性改进模型性能。

Method: 提出ExpLang后训练流程，将策略内思考语言选择作为强化学习中的动作，允许模型在训练过程中动态选择思考语言，从而扩展探索空间并利用非英语优势。

Result: 方法在相同训练预算下稳定超越仅英语训练，对已见和未见语言都表现出高思考语言遵从性。分析显示通过多语言偏好扩展探索空间，并利用非英语优势改进利用结果。

Conclusion: ExpLang方法与大多数强化学习算法正交，为利用多语言性改进大型推理模型开辟了新视角，证明多语言思维选择能有效提升模型性能。

Abstract: Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential advantage of multilingual thinking, as well as the requirement for native thinking traces by global users. In this paper, we propose ExpLang, a novel LLM post-training pipeline that enables on-policy thinking language selection to improve exploration and exploitation during RL with the use of multiple languages. The results show that our method steadily outperforms English-only training with the same training budget, while showing high thinking language compliance for both seen and unseen languages. Analysis shows that, by enabling on-policy thinking language selection as an action during RL, ExpLang effectively extends the RL exploration space with diversified language preference and improves the RL exploitation outcome with leveraged non-English advantage. The method is orthogonal to most RL algorithms and opens up a new perspective on using multilinguality to improve LRMs.

</details>


### [39] [Small Wins Big: Comparing Large Language Models and Domain Fine-Tuned Models for Sarcasm Detection in Code-Mixed Hinglish Text](https://arxiv.org/abs/2602.21933)
*Bitan Majumder,Anirban Sen*

Main category: cs.CL

TL;DR: 在低资源混合语言环境下，经过微调的DistilBERT模型在讽刺检测任务上以84%的准确率超越了Llama 3.1、Mistral、Gemma 3和Phi-4等大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 多语言和混合代码环境中的讽刺检测由于结构变化、非正式表达和低资源语言可用性，对自然语言处理模型构成挑战。研究旨在探索在低资源混合语言（Hinglish）环境下，小型微调模型与大型语言模型在讽刺检测任务上的性能对比。

Method: 研究比较了四种大型语言模型（Llama 3.1、Mistral、Gemma 3、Phi-4）与经过微调的DistilBERT模型在混合代码Hinglish文本讽刺检测任务上的表现。DistilBERT模型使用少量LLM生成的混合代码数据进行顺序微调，而LLMs则在零样本和少样本设置下进行评估。

Result: 经过微调的DistilBERT模型取得了84%的最高总体准确率，在所有零样本和少样本设置下都超越了所有大型语言模型。这表明在低资源和数据稀缺环境下，小型Transformer模型的领域自适应微调相比通用LLM推理能显著提升讽刺检测性能。

Conclusion: 在低资源混合语言讽刺检测任务中，针对特定领域进行微调的小型Transformer模型比通用大型语言模型表现更优，这为资源受限环境下的自然语言处理应用提供了实用解决方案。

Abstract: Sarcasm detection in multilingual and code-mixed environments remains a challenging task for natural language processing models due to structural variations, informal expressions, and low-resource linguistic availability. This study compares four large language models, Llama 3.1, Mistral, Gemma 3, and Phi-4, with a fine-tuned DistilBERT model for sarcasm detection in code-mixed Hinglish text. The results indicate that the smaller, sequentially fine-tuned DistilBERT model achieved the highest overall accuracy of 84%, outperforming all of the LLMs in zero and few-shot set ups, using minimal LLM generated code-mixed data used for fine-tuning. These findings indicate that domain-adaptive fine-tuning of smaller transformer based models may significantly improve sarcasm detection over general LLM inference, in low-resource and data scarce settings.

</details>


### [40] [Large Language Models are Algorithmically Blind](https://arxiv.org/abs/2602.21947)
*Sohan Venkatesh,Ashish Mahendran Kurapath,Tejas Melkote*

Main category: cs.CL

TL;DR: LLMs在算法推理方面存在系统性失败，称为"算法盲视"，表现为无法准确预测算法性能，大多数模型表现甚至不如随机猜测


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出广泛的知识广度，但其对计算过程的推理能力仍未被充分理解。填补这一空白对依赖LLMs指导算法选择和部署的从业者至关重要

Method: 使用因果发现作为测试平台，评估八个前沿LLM，基于大规模算法执行的ground truth进行比较分析

Result: 发现系统性、近乎完全的失败：模型产生的置信区间远宽于真实区间，却仍无法在多数情况下包含真实算法均值；大多数模型表现比随机猜测更差，最佳模型的边际超随机表现最符合基准记忆而非原则性推理

Conclusion: 这种失败被称为"算法盲视"，反映了关于算法的陈述性知识与校准的程序性预测之间的根本差距

Abstract: Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.

</details>


### [41] [MEDSYN: Benchmarking Multi-EviDence SYNthesis in Complex Clinical Cases for Multimodal Large Language Models](https://arxiv.org/abs/2602.21950)
*Boqi Chen,Xudong Liu,Jiachuan Peng,Marianne Frey-Marti,Bang Zheng,Kyle Lam,Lin Li,Jianing Qiu*

Main category: cs.CL

TL;DR: MEDSYN是一个多语言、多模态的医学基准测试，包含高度复杂的临床病例，每个病例最多包含7种不同的视觉临床证据类型。研究发现，虽然顶级MLLM在鉴别诊断生成方面表现优异，但所有模型在综合异构临床证据方面存在明显缺陷，表现为鉴别诊断与最终诊断之间的性能差距远大于人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分捕捉真实世界的临床复杂性，无法全面评估多模态大语言模型在复杂临床环境中的诊断能力。需要创建一个更贴近实际临床工作流程的评估框架，以揭示模型在综合多种临床证据方面的局限性。

Method: 开发了MEDSYN基准测试，包含多语言、多模态的复杂临床病例，每个病例最多包含7种不同的视觉临床证据类型。评估了18个MLLM在鉴别诊断生成和最终诊断选择两个任务上的表现，模拟临床工作流程。通过消融实验分析模型失败原因，并引入"证据敏感性"指标来量化跨模态临床证据利用差距。

Result: 顶级MLLM在鉴别诊断生成方面常能达到甚至超越人类专家水平，但所有模型在鉴别诊断与最终诊断选择之间存在显著性能差距，远大于专家临床医生的差距。研究发现失败原因包括：(1)过度依赖区分度较低的文本临床证据（如病史）；(2)存在跨模态临床证据利用差距。证据敏感性指标显示，较小的跨模态差距与更高的诊断准确性相关。

Conclusion: MLLM在综合异构临床证据方面存在系统性缺陷，特别是在从多种临床证据类型中合成信息以做出最终诊断决策时。证据敏感性指标可作为指导干预措施以改进模型性能的有用工具。研究团队将开源基准测试和代码。

Abstract: Multimodal large language models (MLLMs) have shown great potential in medical applications, yet existing benchmarks inadequately capture real-world clinical complexity. We introduce MEDSYN, a multilingual, multimodal benchmark of highly complex clinical cases with up to 7 distinct visual clinical evidence (CE) types per case. Mirroring clinical workflow, we evaluate 18 MLLMs on differential diagnosis (DDx) generation and final diagnosis (FDx) selection. While top models often match or even outperform human experts on DDx generation, all MLLMs exhibit a much larger DDx--FDx performance gap compared to expert clinicians, indicating a failure mode in synthesis of heterogeneous CE types. Ablations attribute this failure to (i) overreliance on less discriminative textual CE ($\it{e.g.}$, medical history) and (ii) a cross-modal CE utilization gap. We introduce Evidence Sensitivity to quantify the latter and show that a smaller gap correlates with higher diagnostic accuracy. Finally, we demonstrate how it can be used to guide interventions to improve model performance. We will open-source our benchmark and code.

</details>


### [42] [RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning](https://arxiv.org/abs/2602.21951)
*Bo Xue,Yuan Jin,Luoyi Fu,Jiaxin Ding,Xinbing Wang*

Main category: cs.CL

TL;DR: RADAR将知识图谱推理从生成式模式匹配重构为判别式关系推理，通过强化学习增强实体可分性，在表示空间直接推理以避免幻觉，在四个基准上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的知识图谱推理方法主要采用生成式范式，容易记忆表面共现模式而非学习真正的语义关系，限制了分布外泛化能力。需要解决生成式方法对标记似然模仿的依赖及其导致的幻觉问题。

Method: 提出RADAR框架，将知识图谱推理重新定义为判别式实体选择任务。使用强化学习增强实体间的相对可分性，超越基于标记似然的模仿学习。利用这种可分性，推理直接在表示空间进行，确保与判别式优化的一致性，并绕过生成过程引起的幻觉。

Result: 在四个基准测试中，RADAR在链接预测和三元组分类任务上相比强LLM基线获得5-6%的相对性能提升。中间表示的任务相关互信息增加了62.9%，表明获得了更鲁棒和可迁移的关系推理能力。

Conclusion: RADAR通过将知识图谱推理从生成式范式转向判别式关系推理，有效解决了现有方法对表面共现模式的依赖和幻觉问题，实现了更鲁棒、可泛化的关系推理能力，为基于大语言模型的知识图谱推理提供了新范式。

Abstract: Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather than learning genuine relational semantics, limiting out-of-distribution generalization. To address this, we propose RADAR, which reformulates KGR from generative pattern matching to discriminative relational reasoning. We recast KGR as discriminative entity selection, where reinforcement learning enforces relative entity separability beyond token-likelihood imitation. Leveraging this separability, inference operates directly in representation space, ensuring consistency with the discriminative optimization and bypassing generation-induced hallucinations. Across four benchmarks, RADAR achieves 5-6% relative gains on link prediction and triple classification over strong LLM baselines, while increasing task-relevant mutual information in intermediate representations by 62.9%, indicating more robust and transferable relational reasoning.

</details>


### [43] [CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models](https://arxiv.org/abs/2602.21978)
*Miyu Oba,Saku Sugawara*

Main category: cs.CL

TL;DR: CxMP基准测试基于构式语法，通过最小对比对设计评估语言模型对构式（形式-意义配对）的理解能力，发现大型语言模型在构式理解方面存在持续局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注语法可接受性判断，而对语言模型理解语法形式所传达意义的能力研究不足。需要开发专门评估构式理解的基准测试。

Method: 基于构式语法理论，设计包含九种构式类型（如let-alone、致使移动、双及物构式等）的最小对比对基准测试CxMP，评估模型对构式隐含语义关系的理解能力。

Result: 句法能力较早出现，但构式理解发展较慢，即使在大型语言模型中仍存在明显局限。模型在整合形式与意义方面存在持续差距。

Conclusion: CxMP揭示了语言模型在构式理解方面的不足，为研究语言模型的构式理解和学习轨迹提供了框架，表明需要更深入理解形式与意义的整合机制。

Abstract: Recent work has examined language models from a linguistic perspective to better understand how they acquire language. Most existing benchmarks focus on judging grammatical acceptability, whereas the ability to interpret meanings conveyed by grammatical forms has received much less attention. We introduce the Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models (CxMP), a benchmark grounded in Construction Grammar that treats form-meaning pairings, or constructions, as fundamental linguistic units. CxMP evaluates whether models can interpret the semantic relations implied by constructions, using a controlled minimal-pair design across nine construction types, including the let-alone, caused motion, and ditransitive constructions. Our results show that while syntactic competence emerges early, constructional understanding develops more gradually and remains limited even in large language models (LLMs). CxMP thus reveals persistent gaps in how language models integrate form and meaning, providing a framework for studying constructional understanding and learning trajectories in language models.

</details>


### [44] [A Diversity Diet for a Healthier Model: A Case Study of French ModernBERT](https://arxiv.org/abs/2602.22014)
*Louis Estève,Christophe Servan,Thomas Lavergne,Agata Savary*

Main category: cs.CL

TL;DR: 研究探讨多样性对ModernBERT预训练的影响，通过多样性驱动采样减少预训练数据集规模，同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的transformer模型如ModernBERT使用基于规模而非多样性的超大预训练数据集，需要研究多样性对预训练的影响，旨在减少数据集规模同时保持性能。

Method: 比较多样性驱动的采样算法，选择最佳方法，使用多样性驱动采样构建较小规模的预训练数据集。

Result: 多样性驱动采样在某些任务上比同等规模的随机采样数据集性能提升10分；使用1.5亿token的多样性驱动数据集预训练483小时的模型，与使用24亿token随机采样数据集预训练1775小时的模型性能相当。

Conclusion: 多样性驱动采样能显著减少预训练数据集规模和训练时间，同时保持或提升模型性能，为高效预训练提供了新方向。

Abstract: Diversity has been gaining interest in the NLP community in recent years. At the same time, state-of-the-art transformer models such as ModernBERT use very large pre-training datasets, which are driven by size rather than by diversity. This summons for an investigation of the impact of diversity on the ModernBERT pre-training. We do so in this study, with the express intent of reducing pre-training dataset size, while retaining at least comparable performance. We compare diversity-driven sampling algorithms, so as to pick the best one. We find that diversity-driven sampling allows in some tasks to gain 10 points relative to randomly-sampled pre-training data of commensurate size. We also see that a model pre-trained for 483h on a diversity-driven dataset of 150M tokens can yield a commensurate performance to a model pre-trained for 1,775h on a randomly-driven dataset of 2.4B tokens.

</details>


### [45] [DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain](https://arxiv.org/abs/2602.22045)
*Walter Hernandez Cruz,Peter Devine,Nikhil Vadgama,Paolo Tasca,Jiahua Xu*

Main category: cs.CL

TL;DR: DLT-Corpus是迄今为止最大的分布式账本技术领域特定文本语料库，包含29.8亿个token和2212万份文档，涵盖科学文献、专利和社交媒体，并发布了领域适应的LedgerBERT模型。


<details>
  <summary>Details</summary>
Motivation: 现有NLP资源主要关注加密货币价格预测和智能合约，缺乏对分布式账本技术领域特定语言的深入探索，而该领域市值约3万亿美元且技术发展迅速。

Method: 构建了包含科学文献（37,440篇）、美国专利商标局专利（49,023项）和社交媒体（2200万条帖子）的DLT-Corpus语料库，并开发了领域适应的LedgerBERT模型。

Result: 分析显示技术遵循传统转移模式：从科学文献到专利再到社交媒体；社交媒体情绪始终保持看涨，而科学和专利活动独立于市场波动，与整体市场扩张形成良性循环。

Conclusion: DLT-Corpus填补了领域特定语言资源的空白，揭示了DLT技术转移模式和市场-创新关系，为研究提供了重要基础，并公开了语料库、模型和工具。

Abstract: We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.
  We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.
  We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.

</details>


### [46] [Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference](https://arxiv.org/abs/2602.22090)
*Bo-Wei Chen,Chung-Chi Chen,An-Zi Yen*

Main category: cs.CL

TL;DR: 提出基于置信度的动态模型选择策略，通过评估模型处理任务的置信度和响应准确性，将简单任务保留在小模型，复杂任务委托给大模型，在保持准确性的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然性能强大但计算成本高昂，特别是大模型。需要一种方法在保持推理质量的同时降低计算开销，特别是在资源受限的环境中。

Method: 提出置信度驱动的模型选择策略：1）评估模型知道正确答案的可能性；2）评估模型响应准确性的概率；3）根据置信度动态选择最合适的模型，将置信度高的任务保留在小模型，置信度低或复杂的任务委托给大模型。

Result: 在MMLU基准测试中，该方法达到了与大模型相当的准确性，同时将计算成本降低了20%-40%。应用于GPT-4o API调用时，token使用量减少了约60%，显著提高了成本效益。

Conclusion: 置信度驱动的模型选择策略能够有效平衡推理质量和计算成本，特别适用于资源受限的环境如边缘设备和商业API应用，为实际LLM部署提供了有前景的解决方案。

Abstract: Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\% to 40\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.

</details>


### [47] [IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages](https://arxiv.org/abs/2602.22125)
*Thanmay Jayakumar,Mohammed Safi Ur Rahman Khan,Raj Dabre,Ratish Puduppully,Anoop Kunchukuttan*

Main category: cs.CL

TL;DR: IndicIFEval是一个评估LLMs在14种印度语言中约束生成能力的基准，包含自动可验证的规则指令，揭示了模型在印度语言指令遵循方面显著落后于英语。


<details>
  <summary>Details</summary>
Motivation: 目前指令遵循基准主要集中于英语，缺乏对印度语言使用者的评估，存在关键评估缺口。印度有数亿母语使用者，需要专门的基准来评估LLMs在印度语言中的约束生成能力。

Method: 创建IndicIFEval基准，包含两个互补子集：IndicIFEval-Ground（从IFEval翻译并本地化的提示）和IndicIFEval-Ground（基于原生印度内容合成的指令）。每个语言约800个人工验证示例，使用自动可验证的规则指令。对主要开源和专有模型进行全面评估，涵盖推理和非推理模型。

Result: 模型在格式约束方面表现良好，但在词汇和跨语言任务上显著困难。尽管高资源语言有所进展，但整个印度语系的指令遵循能力显著落后于英语。

Conclusion: 需要更多工作提升LLMs在印度语言中的指令遵循能力。IndicIFEval基准及其评估脚本已开源，支持多语言约束生成的进展。

Abstract: Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).

</details>


### [48] [Dynamic Personality Adaptation in Large Language Models via State Machines](https://arxiv.org/abs/2602.22157)
*Leon Pielage,Ole Hätscher,Mitja Back,Bernhard Marschall,Benjamin Risse*

Main category: cs.CL

TL;DR: 提出一个模型无关的动态人格模拟框架，使用状态机表示潜在人格状态，通过对话上下文动态调整转移概率，实现LLM在复杂交互场景中的适应性人格表达。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型无法根据对话动态调整人格表达，这限制了它们在复杂交互场景中的表现。需要一种能够动态模拟人格的框架来提升LLM在医疗教育、客户支持等领域的适应性。

Method: 提出模型无关的动态人格模拟框架：1) 使用状态机表示潜在人格状态，转移概率根据对话上下文动态调整；2) 设计模块化的人格评分管道，沿潜在轴评估对话，独立于具体人格模型、维度、转移机制或LLM；3) 评分作为动态状态变量系统性地重新配置系统提示，引导行为对齐。

Result: 在医疗教育场景中操作化人际环模型(IPC)进行评估：1) 系统成功根据用户输入调整人格状态；2) 系统能够影响用户行为，促进降级训练；3) 评分管道使用轻量级微调分类器而非大规模LLM时仍保持相当的精度。

Conclusion: 证明了模块化、人格自适应架构在教育、客户支持和更广泛人机交互领域的可行性，为LLM在复杂交互场景中的适应性人格表达提供了有效解决方案。

Abstract: The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.

</details>


### [49] [DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs](https://arxiv.org/abs/2602.22175)
*Xi Ye,Wuwei Zhang,Fangcong Yin,Howard Yen,Danqi Chen*

Main category: cs.CL

TL;DR: DySCO是一种无需训练的推理算法，通过动态调整注意力权重来提升语言模型在长上下文任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有语言模型虽然支持长上下文窗口，但随着输入长度增加，其准确性会下降。模型在解码过程中难以保持注意力与最相关上下文的对齐

Method: DySCO利用检索头（专门用于长上下文检索的注意力头子集）在每个解码步骤识别任务相关token，并显式提升其权重，从而动态调整生成过程中的注意力分布

Result: 在多个指令调优和推理模型上，DySCO在具有挑战性的长上下文推理基准测试中表现一致提升，在128K上下文长度下，MRCR和LongBenchV2上获得高达25%的相对增益

Conclusion: DySCO是一种无需训练、可直接应用于现成语言模型的解码算法，通过动态注意力重缩放和检索头引导的选择机制，有效提升长上下文推理能力，同时为解码时注意力行为提供可解释性洞察

Abstract: Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.

</details>


### [50] [Improving Parametric Knowledge Access in Reasoning Language Models](https://arxiv.org/abs/2602.22193)
*Melody Ma,John Hewitt*

Main category: cs.CL

TL;DR: 研究发现语言模型在访问自身参数化知识时推理能力不足，通过强化学习训练可以显著提升知识检索效果


<details>
  <summary>Details</summary>
Motivation: 语言模型虽然能通过推理解决数学问题，但在访问自身存储的世界知识时推理能力不足，需要专门优化

Method: 使用"逐步思考"提示词验证模型知识检索能力，然后通过强化学习在TriviaQA数据集上训练模型进行知识推理

Result: TriviaQA性能提升9.9%，Natural Questions、HotpotQA、SimpleQA、StrategyQA分别提升4.2%、2.1%、0.6%、3.0%

Conclusion: 推理模型在参数化知识访问方面存在优化不足，但通过针对性的强化学习训练可以显著提升其知识推理能力

Abstract: We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple "think step-by-step" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.

</details>


### [51] [SumTablets: A Transliteration Dataset of Sumerian Tablets](https://arxiv.org/abs/2602.22200)
*Cole Simmons,Richard Diehl Martinez,Dan Jurafsky*

Main category: cs.CL

TL;DR: SumTablets数据集将91,606块苏美尔楔形文字泥板的Unicode表示与Oracc发布的音译文本配对，填补了楔形文字与音译之间缺乏大规模对齐数据集的空白，为苏美尔音译的NLP研究提供了基础资源。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量苏美尔楔形文字泥板的音译数据在线发布，但缺乏将音译文本与楔形文字Unicode表示配对的大规模、结构化数据集，这阻碍了现代NLP方法在苏美尔音译任务中的应用。

Method: 1. 预处理和标准化Oracc音译数据；2. 将每个音译映射回源楔形文字的Unicode表示；3. 使用特殊标记保留平行结构信息（如表面、换行、破损片段）；4. 构建包含91,606块泥板、6,970,407个楔形文字的数据集；5. 实现并评估两种音译基线方法：加权采样和自回归语言模型微调。

Result: 1. 发布了SumTablets数据集（CC BY 4.0许可），包含楔形文字Unicode表示与音译的配对；2. 微调的语言模型在字符级F分数（chrF）上达到97.55的平均分，显示出基于Transformer的音译模型在辅助专家快速验证生成音译方面的潜力。

Conclusion: SumTablets数据集填补了苏美尔楔形文字音译研究的关键数据空白，为应用现代NLP方法提供了基础。实验表明基于Transformer的音译模型具有实用价值，能够帮助专家从手动逐块音译转向快速验证生成音译，提高研究效率。

Abstract: Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.
  To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.
  Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [52] [Revisiting RAG Retrievers: An Information Theoretic Benchmark](https://arxiv.org/abs/2602.21553)
*Wenqing Zheng,Dmitri Kalaev,Noah Fatsi,Daniel Barcklow,Owen Reinert,Igor Melnyk,Senthil Kumar,C. Bayan Bruss*

Main category: cs.IR

TL;DR: MIGRASCOPE是一个基于互信息的RAG检索器分析框架，通过信息论和统计估计理论量化检索质量、冗余性、协同效应和边际贡献，发现精心选择的检索器集成优于任何单一检索器。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统依赖检索器提供相关上下文，但各种检索器基于不同排序原理（词汇匹配、密集嵌入、图引用等），缺乏系统理解这些机制差异和重叠的框架。现有基准主要比较整个RAG流程或引入新数据集，对检索器本身的选择和组合提供指导有限。

Method: 提出MIGRASCOPE框架，基于互信息和统计估计理论建立原则性指标，量化检索质量、冗余性、协同效应和边际贡献。重新评估最先进的检索器，并在主要RAG语料库上应用这些工具进行分析。

Result: 研究发现如果精心选择，检索器集成可以超越任何单一检索器。通过开发的工具对主要RAG语料库进行分析，提供了关于最先进检索器贡献水平的独特见解。

Conclusion: 该研究为现代检索技术的结构提供了新视角，并为设计稳健高效的RAG系统提供了可操作的指导。MIGRASCOPE框架能够系统理解不同检索机制的差异和重叠，帮助优化检索器选择和组合。

Abstract: Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.

</details>


### [53] [Retrieval Challenges in Low-Resource Public Service Information: A Case Study on Food Pantry Access](https://arxiv.org/abs/2602.21598)
*Touseef Hasan,Laila Cure,Souvika Sarkar*

Main category: cs.IR

TL;DR: 开发基于RAG的AI对话检索系统，用于低资源环境下的食品储藏室信息检索，通过试点评估揭示检索鲁棒性、查询不明确处理和不一致知识库基础化等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 公共服务信息系统通常碎片化、格式不一致且过时，这些特征创建了低资源检索环境，阻碍了对关键服务的及时访问。研究通过食品储藏室访问这一社会紧迫问题来调查此类环境中的检索挑战。

Method: 开发AI驱动的对话检索系统，抓取并索引公开可用的储藏室数据，采用检索增强生成(RAG)管道支持通过Web界面进行自然语言查询。使用社区来源的查询进行试点评估研究，以检查系统在现实场景中的行为。

Result: 分析揭示了检索鲁棒性、处理不明确查询以及在不一致知识库基础上进行基础化方面的关键限制。系统在低资源环境中表现出检索挑战。

Conclusion: 这项正在进行的工作揭示了低资源环境中的基本信息检索挑战，并激励未来研究鲁棒的对话检索系统，以改善对关键公共资源的访问。

Abstract: Public service information systems are often fragmented, inconsistently formatted, and outdated. These characteristics create low-resource retrieval environments that hinder timely access to critical services. We investigate retrieval challenges in such settings through the domain of food pantry access, a socially urgent problem given persistent food insecurity. We develop an AI-powered conversational retrieval system that scrapes and indexes publicly available pantry data and employs a Retrieval-Augmented Generation (RAG) pipeline to support natural language queries via a web interface. We conduct a pilot evaluation study using community-sourced queries to examine system behavior in realistic scenarios. Our analysis reveals key limitations in retrieval robustness, handling underspecified queries, and grounding over inconsistent knowledge bases. This ongoing work exposes fundamental IR challenges in low-resource environments and motivates future research on robust conversational retrieval to improve access to critical public resources.

</details>


### [54] [AQR-HNSW: Accelerating Approximate Nearest Neighbor Search via Density-aware Quantization and Multi-stage Re-ranking](https://arxiv.org/abs/2602.21600)
*Ganap Ashit Tewary,Nrusinga Charan Gantayat,Jeff Zhang*

Main category: cs.IR

TL;DR: AQR-HNSW框架通过自适应量化、多状态重排序和SIMD优化，显著提升HNSW在十亿级向量数据库中的性能，实现2.5-3.3倍QPS提升、75%内存减少和5倍索引构建加速。


<details>
  <summary>Details</summary>
Motivation: 随着向量数据库扩展到数十亿嵌入向量，HNSW面临内存消耗膨胀、距离计算开销主导查询延迟、在异构数据分布上性能欠佳等关键瓶颈，需要新的优化方案来提升可扩展性。

Method: 提出AQR-HNSW框架，包含三个协同策略：(1)密度感知自适应量化，实现4倍压缩同时保持距离关系；(2)多状态重排序，减少35%不必要计算；(3)量化优化的SIMD实现，在不同架构上实现16-64操作/周期。

Result: 在标准基准测试中，相比最先进的HNSW实现，AQR-HNSW实现2.5-3.3倍更高的每秒查询数(QPS)，同时保持超过98%的召回率，索引图内存减少75%，索引构建速度提升5倍。

Conclusion: AQR-HNSW通过自适应量化、重排序和SIMD优化的协同集成，有效解决了HNSW在大规模向量数据库中的可扩展性瓶颈，为工业级AI基础设施提供了高效、内存优化的近似最近邻搜索解决方案。

Abstract: Approximate Nearest Neighbor (ANN) search has become fundamental to modern AI infrastructure, powering recommendation systems, search engines, and large language models across industry leaders from Google to OpenAI. Hierarchical Navigable Small World (HNSW) graphs have emerged as the dominant ANN algorithm, widely adopted in production systems due to their superior recall versus latency balance. However, as vector databases scale to billions of embeddings, HNSW faces critical bottlenecks: memory consumption expands, distance computation overhead dominates query latency, and it suffers suboptimal performance on heterogeneous data distributions. This paper presents Adaptive Quantization and Rerank HNSW (AQR-HNSW), a novel framework that synergistically integrates three strategies to enhance HNSW scalability. AQR-HNSW introduces (1) density-aware adaptive quantization, achieving 4x compression while preserving distance relationships; (2) multi-state re-ranking that reduces unnecessary computations by 35%; and (3) quantization-optimized SIMD implementations delivering 16-64 operations per cycle across architectures. Evaluation on standard benchmarks demonstrates 2.5-3.3x higher queries per second (QPS) than state-of-the-art HNSW implementations while maintaining over 98% recall, with 75% memory reduction for the index graph and 5x faster index construction.

</details>


### [55] [Offline Reasoning for Efficient Recommendation: LLM-Empowered Persona-Profiled Item Indexing](https://arxiv.org/abs/2602.21756)
*Deogyong Kim,Junseong Lee,Jeongeun Lee,Changhoe Kim,Junguel Lee,Jungseok Lee,Dongha Lee*

Main category: cs.IR

TL;DR: Persona4Rec：基于LLM离线推理构建可解释物品人格表征的推荐框架，实现高效实时推理


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐重排序方法依赖昂贵的在线推理时间推理，导致高延迟，阻碍实际部署。需要一种既能利用LLM语义理解能力，又能实现轻量级实时推理的解决方案。

Method: 1. 离线阶段：利用LLM对物品评论进行推理，推断不同用户可能与该物品互动的多样化动机，构建可解释的人格表征。2. 学习用户档案与最可能物品人格的对齐，通过专用编码器将用户-物品相关性转化为用户-人格相关性。3. 在线阶段：使用人格画像的物品索引进行快速相关性计算，无需调用昂贵的LLM推理。

Result: Persona4Rec在性能上与最近的LLM重排序方法相当，同时显著减少推理时间。定性分析证实人格表征不仅能驱动高效评分，还能提供基于评论的直观解释。

Conclusion: Persona4Rec为下一代推荐系统提供了实用且可解释的解决方案，通过离线推理构建可解释人格表征，实现高效实时推理，同时保持与LLM重排序方法相当的性能。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for recommender systems by capturing the nuanced semantics of user interests and item characteristics through rich semantic understanding and contextual reasoning. In particular, LLMs have been employed as rerankers that reorder candidate items based on inferred user-item relevance. However, these approaches often require expensive online inference-time reasoning, leading to high latency that hampers real-world deployment. In this work, we introduce Persona4Rec, a recommendation framework that performs offline reasoning to construct interpretable persona representations of items, enabling lightweight and scalable real-time inference. In the offline stage, Persona4Rec leverages LLMs to reason over item reviews, inferring diverse user motivations that explain why different types of users may engage with an item; these inferred motivations are materialized as persona representations, providing multiple, human-interpretable views of each item. Unlike conventional approaches that rely on a single item representation, Persona4Rec learns to align user profiles with the most plausible item-side persona through a dedicated encoder, effectively transforming user-item relevance into user-persona relevance. At the online stage, this persona-profiled item index allows fast relevance computation without invoking expensive LLM reasoning. Extensive experiments show that Persona4Rec achieves performance comparable to recent LLM-based rerankers while substantially reducing inference time. Moreover, qualitative analysis confirms that persona representations not only drive efficient scoring but also provide intuitive, review-grounded explanations. These results demonstrate that Persona4Rec offers a practical and interpretable solution for next-generation recommender systems.

</details>


### [56] [Learning to Collaborate via Structures: Cluster-Guided Item Alignment for Federated Recommendation](https://arxiv.org/abs/2602.21957)
*Yuchun Tu,Zhiwei Li,Bingli Sun,Yixuan Li,Xiao Song*

Main category: cs.IR

TL;DR: CGFedRec提出了一种基于聚类标签而非完整嵌入的联邦推荐框架，通过传输紧凑的聚类标签而非高维嵌入来提升通信效率，同时保持推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦推荐方法需要同步高维项目嵌入，假设精确的几何坐标对齐是实现跨客户端协作的必要条件。作者认为建立项目间的相对语义关系比强制共享表示更有效，全局语义关系可作为结构约束，允许项目表示在客户端本地变化，从而在保持全局一致性的同时捕捉细粒度用户个性化。

Method: 提出Cluster-Guided FedRec框架(CGFedRec)，将上传的嵌入转换为紧凑的聚类标签。服务器作为全局结构发现者学习项目聚类，仅分发结果标签。这种机制显式切断项目嵌入的下游传输，使客户端无需维护全局共享的项目嵌入，从而在不传输完整嵌入的情况下将全局协作信号有效注入本地项目表示。

Result: 大量实验表明，该方法在多个数据集上显著提高了通信效率，同时保持了优越的推荐准确性。

Conclusion: CGFedRec通过传输聚类标签而非完整嵌入，实现了通信效率与推荐准确性的平衡，为联邦推荐提供了一种更高效的协作范式。

Abstract: Federated recommendation facilitates collaborative model training across distributed clients while keeping sensitive user interaction data local. Conventional approaches typically rely on synchronizing high-dimensional item representations between the server and clients. This paradigm implicitly assumes that precise geometric alignment of embedding coordinates is necessary for collaboration across clients. We posit that establishing relative semantic relationships among items is more effective than enforcing shared representations. Specifically, global semantic relations serve as structural constraints for items. Within these constraints, the framework allows item representations to vary locally on each client, which flexibility enables the model to capture fine-grained user personalization while maintaining global consistency. To this end, we propose Cluster-Guided FedRec framework (CGFedRec), a framework that transforms uploaded embeddings into compact cluster labels. In this framework, the server functions as a global structure discoverer to learn item clusters and distributes only the resulting labels. This mechanism explicitly cuts off the downstream transmission of item embeddings, relieving clients from maintaining global shared item embeddings. Consequently, CGFedRec achieves the effective injection of global collaborative signals into local item representations without transmitting full embeddings. Extensive experiments demonstrate that our approach significantly improves communication efficiency while maintaining superior recommendation accuracy across multiple datasets.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本书对软集理论及其主要扩展进行了综述性概述，涵盖核心定义、代表性构造和当前发展方向。


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了直接框架，通过将每个属性（参数）分配给给定论域的子集来结构化表示不确定性。该理论在过去几十年中已扩展到众多变体，并与拓扑学、拟阵理论等多个领域建立了联系。

Method: 采用综述性方法，系统性地介绍软集及其主要扩展（包括超软集、超超软集、树软集、双极软集和动态软集等），突出核心定义、代表性构造和关键研究方向。

Result: 提供了软集理论及其扩展的全面概述，展示了该理论的发展脉络、主要变体及其在不同领域的应用联系。

Conclusion: 本书系统总结了软集理论的发展现状，为研究人员提供了该领域的结构化概览，并指明了当前的发展方向和潜在研究机会。

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [58] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: PANGAEA-GPT：用于地球科学数据自主发现和分析的分层多智能体框架


<details>
  <summary>Details</summary>
Motivation: 地球科学数据快速积累导致可扩展性挑战，大量数据集未被充分利用，限制了数据重用性。现有大型语言模型包装器无法有效处理复杂的多步骤工作流。

Method: 采用分层多智能体框架，具有集中式监督者-工作者拓扑结构，包含数据类型感知路由、沙盒确定性代码执行和通过执行反馈的自我校正机制。

Result: 通过物理海洋学和生态学用例场景，证明系统能够以最少人工干预执行复杂的多步骤工作流，实现对异构存储库数据的查询和分析。

Conclusion: PANGAEA-GPT为通过协调智能体工作流查询和分析异构存储库数据提供了一种方法论，解决了地球科学数据利用不足的问题。

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [59] [Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information](https://arxiv.org/abs/2602.21496)
*Umid Suleymanov,Zaur Rajabov,Emil Mirzazada,Murat Kantarcioglu*

Main category: cs.AI

TL;DR: SemSIEdit：一个推理时框架，通过智能"编辑器"迭代批评和重写敏感内容来保护语义敏感信息，在减少34.6%泄露的同时仅损失9.8%的效用，揭示了隐私-效用帕累托边界、规模依赖的安全分歧和推理悖论。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）带来了新的威胁：语义敏感信息（SemSI），即模型推断敏感身份属性、生成损害声誉的内容或产生潜在错误信息。LLMs在保持实用性的同时自我调节这些复杂、上下文相关的敏感信息泄露的能力仍是一个未解决的科学问题。

Method: 提出SemSIEdit框架，采用智能"编辑器"在推理时迭代批评和重写敏感片段，以保持叙事流畅性而非简单拒绝回答。该方法通过隐私-效用帕累托边界分析，评估不同规模模型的安全策略差异。

Result: 智能重写使所有三类SemSI的泄露减少34.6%，而效用损失仅为9.8%。发现规模依赖的安全分歧：大型推理模型通过建设性扩展（增加细微差别）实现安全，而能力受限模型则回归破坏性截断（删除文本）。揭示推理悖论：推理时推理虽然通过使模型进行更深入的敏感推断而增加基线风险，但同时赋能防御执行安全重写。

Conclusion: SemSIEdit框架有效解决了LLMs中的语义敏感信息泄露问题，在保持实用性的同时显著降低隐私风险。研究揭示了模型规模对安全策略的影响以及推理能力在隐私保护中的双重作用，为LLMs的安全部署提供了重要见解。

Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic "Editor" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.

</details>


### [60] [The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems](https://arxiv.org/abs/2602.21745)
*Hyo Jin Kim*

Main category: cs.AI

TL;DR: ASIR勇气模型是一个相动力学框架，将真相披露形式化为状态转移而非人格特质，适用于人类和AI系统在风险下的真实表达


<details>
  <summary>Details</summary>
Motivation: 传统上将勇气视为人格特质，但作者认为真相披露应被理解为在抑制和表达状态之间的相变过程。需要建立统一框架来解释人类在不对称风险下的沉默和AI系统在政策约束下的输出失真现象

Method: 提出ASIR勇气模型，将真相披露形式化为从抑制状态(S0)到表达状态(S1)的相变过程。使用不等式lambda(1+gamma)+psi > theta+phi描述状态转移条件，其中lambda为基线开放度，gamma为关系放大因子，psi为累积内部压力，theta和phi为转移成本。模型包含反馈扩展，模拟转移结果如何递归地重新校准系统参数

Result: 该模型成功将人类真相讲述和AI系统输出约束统一到相同的相动力学架构中。在AI背景下，抑制对应约束输出状态，结构压力来自竞争目标、上下文紧张和递归交互动力学。模型将勇气和对齐重新框架为约束相空间内相互作用力的几何结果

Conclusion: ASIR勇气模型提供了一个形式化视角，用于理解人类和人工系统在风险下的真相披露。通过将勇气和对齐重新框架为共享动力学结构，模型揭示了真相披露作为状态转移而非人格特质的本质，为跨人类和AI系统的真实表达提供了统一的结构性解释

Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.
  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.
  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.

</details>


### [61] [fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation](https://arxiv.org/abs/2602.21746)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: fEDM+扩展了原有的模糊伦理决策框架，增加了可解释性模块和多元语义验证，以解决原模型在原则性解释和伦理多元主义下的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 原fEDM框架虽然保证了形式正确性和决策一致性，但未能充分解决两个关键挑战：决策的原则性可解释性，以及在伦理多元主义下的鲁棒性。需要增强模型的透明度和对不同利益相关者价值观的适应性。

Method: 1. 引入可解释性和可追溯性模块(ETM)，将伦理决策规则与底层道德原则明确关联，为每个推荐行动计算加权原则贡献度；2. 用多元语义验证框架替代单参照验证，评估决策对多个利益相关者参照的符合程度，每个参照编码不同的原则优先级和风险容忍度。

Result: 扩展后的fEDM+保留了形式可验证性，同时实现了增强的可解释性和利益相关者感知的验证。模型能够提供透明、可审计的解释，展示决策依据和原则基础，并能正式表示原则性分歧而非压制它们。

Conclusion: fEDM+通过增强可解释性和多元验证能力，使其更适合作为伦理敏感AI系统的监督和治理层，在保持形式严谨性的同时提高了透明度和上下文敏感性。

Abstract: In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.

</details>


### [62] [Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem](https://arxiv.org/abs/2602.21814)
*Heejin Jo*

Main category: cs.AI

TL;DR: STAR推理框架将洗车问题准确率从0%提升至85%，结合用户画像和RAG达到100%准确率，结构化推理比上下文注入更重要


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在"洗车问题"这一需要隐式物理约束推理的基准测试中持续失败，研究旨在探索生产系统中哪些提示架构层能够实现正确推理

Method: 使用Claude 3.5 Sonnet模型，控制超参数（温度0.7，top_p 1.0），进行变量隔离研究（6个条件，每个条件n=20，共120次试验），比较不同提示架构层的效果，包括STAR推理框架、用户画像向量数据库检索和RAG上下文

Result: STAR推理框架单独将准确率从0%提升至85%（p=0.001，Fisher精确检验，优势比13.22）；添加用户画像上下文提供额外10个百分点的增益；RAG上下文贡献额外5个百分点，完整堆栈条件下达到100%准确率

Conclusion: 对于隐式约束推理任务，结构化推理脚手架——特别是推理前的强制目标表达——比上下文注入更为重要

Abstract: Large language models consistently fail the "car wash problem," a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.

</details>


### [63] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出基于强化学习的联合优化方法，通过GRPO同时优化分解质量和验证器对齐，在6个评估设置中显著提升下游验证性能


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将复杂声明的分解质量与验证性能对齐，需要一种能够同时优化这两个方面的解决方案

Method: 使用强化学习方法，结合结构化顺序推理、教师蒸馏示例的监督微调，以及平衡格式合规性、验证器对齐和分解质量的多目标奖励

Result: 在六个评估设置中，训练的8B分解器将下游验证性能提升至71.75% macro-F1，优于基于提示的方法（+1.99，+6.24）和现有RL方法（+5.84）

Conclusion: 该框架使较小语言模型能够通过联合优化验证准确性和分解质量，实现最先进的声明验证

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


### [64] [Semantic Partial Grounding via LLMs](https://arxiv.org/abs/2602.22067)
*Giuseppe Canonaco,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: SPG-LLM使用大语言模型分析PDDL文件，在规划前启发式识别潜在无关的对象、动作和谓词，显著减少基础化任务规模，在七个难基础化基准测试中实现更快的基础化速度。


<details>
  <summary>Details</summary>
Motivation: 经典规划中的基础化步骤常因任务规模增大导致基础化动作和原子数量指数增长而成为计算瓶颈。现有部分基础化方法主要依赖关系特征或学习嵌入，未能充分利用PDDL描述中的文本和结构线索。

Method: 提出SPG-LLM方法，利用大语言模型分析领域和问题文件，在基础化前启发式识别潜在无关的对象、动作和谓词，从而显著减少基础化任务的规模。

Result: 在七个难基础化基准测试中，SPG-LLM实现了更快的基础化速度（通常快几个数量级），在某些领域还提供了相当或更好的规划成本。

Conclusion: SPG-LLM通过利用大语言模型分析PDDL的文本和结构信息，有效减少了基础化规模，解决了规划中的基础化瓶颈问题，在保持规划质量的同时显著提升了效率。

Abstract: Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.

</details>


### [65] [Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning](https://arxiv.org/abs/2602.22094)
*Nguyen Cong Nhat Le,John G. Rogers,Claire N. Bonial,Neil T. Dantam*

Main category: cs.AI

TL;DR: 提出基于Petri网可达性松弛的方法，用于鲁棒不变式合成、高效目标不可达检测和提供不可行性解释，支持目标和约束的增量更新。


<details>
  <summary>Details</summary>
Motivation: 现实中的计划常因情况变化或认知更新而需要调整，有时甚至不存在可行计划。识别不可行性有助于调整需求，但现有规划方法主要关注可行情况下的高效一次性规划，缺乏对领域更新和不可行性检测的支持。

Method: 采用Petri网可达性松弛技术，实现鲁棒不变式合成；结合增量约束求解器，支持目标和约束的增量更新；系统能够检测目标不可达情况并提供解释。

Result: 与基线相比，系统生成相当数量的不变式，检测到最多2倍的不可行情况；在一次性规划中表现相当，在顺序计划更新场景中优于基线。

Conclusion: 提出的Petri网可达性松弛方法有效支持鲁棒不变式合成、不可行性检测和解释，增量约束求解器使系统能够高效处理目标和约束更新，为动态规划环境提供了实用解决方案。

Abstract: Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.

</details>
