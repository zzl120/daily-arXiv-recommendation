<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Decoder-based Sense Knowledge Distillation](https://arxiv.org/abs/2602.22351)
*Qitong Wang,Mohammed J. Zaki,Georgios Kollias,Vasileios Kalantzis*

Main category: cs.CL

TL;DR: DSKD框架将词典资源整合到解码器式LLM训练中，无需推理时查字典，显著提升解码器的知识蒸馏性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型学习丰富的语义上下文嵌入，但往往忽略结构化词汇知识（如词义和关系）。先前工作表明词典能改进编码器模型的知识蒸馏，但将其应用于解码器生成模型仍具挑战

Method: 提出Decoder-based Sense Knowledge Distillation (DSKD)框架，在解码器式LLM训练中整合词典资源，无需推理时进行词典查找

Result: 在多样化基准测试上的广泛实验表明，DSKD显著提升解码器的知识蒸馏性能，使生成模型能继承结构化语义同时保持高效训练

Conclusion: DSKD成功将词典资源整合到解码器LLM训练中，解决了生成模型继承结构化词汇知识的挑战，实现了高效的知识蒸馏

Abstract: Large language models (LLMs) learn contextual embeddings that capture rich semantic information, yet they often overlook structured lexical knowledge such as word senses and relationships. Prior work has shown that incorporating sense dictionaries can improve knowledge distillation for encoder models, but their application to decoder as generative models remains challenging. In this paper, we introduce Decoder-based Sense Knowledge Distillation (DSKD), a framework that integrates lexical resources into the training of decoder-style LLMs without requiring dictionary lookup at inference time. Extensive experiments on diverse benchmarks demonstrate that DSKD significantly enhances knowledge distillation performance for decoders, enabling generative models to inherit structured semantics while maintaining efficient training.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Graph Your Way to Inspiration: Integrating Co-Author Graphs with Retrieval-Augmented Generation for Large Language Model Based Scientific Idea Generation](https://arxiv.org/abs/2602.22215)
*Pengzhen Xie,Huizhi Liang*

Main category: cs.AI

TL;DR: GYWI系统通过结合作者知识图谱与检索增强生成，为LLMs提供可控的学术上下文和可追溯的灵感路径，显著提升科学想法生成的质量。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在科学想法生成方面存在两个主要问题：1) 生成结果缺乏可控的学术上下文；2) 灵感路径不可追溯。需要一种能够提供可控背景和可追溯灵感路径的系统来提升科学想法生成的质量。

Method: 1) 提出作者中心的知识图谱构建方法和灵感源采样算法构建外部知识库；2) 设计混合检索机制（RAG+GraphRAG）获取深度和广度知识形成混合上下文；3) 提出基于强化学习原理的Prompt优化策略自动引导LLMs优化生成结果。

Result: 基于arXiv（2018-2023）构建评估数据集，从新颖性、可行性、清晰度、相关性和重要性五个维度评估。在GPT-4o、DeepSeek-V3、Qwen3-8B和Gemini 2.5等LLMs上的实验表明，GYWI在多个指标（如新颖性、可靠性和相关性）上显著优于主流LLMs。

Conclusion: GYWI系统通过结合知识图谱和检索增强生成，有效解决了LLMs在科学想法生成中缺乏可控上下文和可追溯灵感路径的问题，显著提升了生成想法的质量，为科学创新提供了新的工具支持。

Abstract: Large Language Models (LLMs) demonstrate potential in the field of scientific idea generation. However, the generated results often lack controllable academic context and traceable inspiration pathways. To bridge this gap, this paper proposes a scientific idea generation system called GYWI, which combines author knowledge graphs with retrieval-augmented generation (RAG) to form an external knowledge base to provide controllable context and trace of inspiration path for LLMs to generate new scientific ideas. We first propose an author-centered knowledge graph construction method and inspiration source sampling algorithms to construct external knowledge base. Then, we propose a hybrid retrieval mechanism that is composed of both RAG and GraphRAG to retrieve content with both depth and breadth knowledge. It forms a hybrid context. Thirdly, we propose a Prompt optimization strategy incorporating reinforcement learning principles to automatically guide LLMs optimizing the results based on the hybrid context. To evaluate the proposed approaches, we constructed an evaluation dataset based on arXiv (2018-2023). This paper also develops a comprehensive evaluation method including empirical automatic assessment in multiple-choice question task, LLM-based scoring, human evaluation, and semantic space visualization analysis. The generated ideas are evaluated from the following five dimensions: novelty, feasibility, clarity, relevance, and significance. We conducted experiments on different LLMs including GPT-4o, DeepSeek-V3, Qwen3-8B, and Gemini 2.5. Experimental results show that GYWI significantly outperforms mainstream LLMs in multiple metrics such as novelty, reliability, and relevance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [3] [Enriching Taxonomies Using Large Language Models](https://arxiv.org/abs/2602.22213)
*Zeinab Ghamlouch,Mehwish Alam*

Main category: cs.IR

TL;DR: Taxoria：基于LLM的自动化分类法增强管道，通过提示LLM生成候选节点并验证后整合，解决现有分类法覆盖不足和节点过时问题


<details>
  <summary>Details</summary>
Motivation: 现有分类法存在覆盖范围有限、节点过时或模糊等问题，降低了知识检索的有效性，需要一种自动化方法来增强和更新分类法

Method: 提出Taxoria分类法增强管道：1) 以现有分类法为种子；2) 提示LLM生成候选节点；3) 验证候选节点以减少幻觉并确保语义相关性；4) 整合验证后的节点；5) 提供来源追踪和最终合并分类法的可视化

Result: 开发了Taxoria系统，能够生成增强的分类法，包含来源追踪功能，并提供最终合并分类法的可视化分析工具

Conclusion: Taxoria提供了一种新颖的基于LLM的分类法增强方法，相比直接提取LLM内部分类法的方法，能够更好地利用现有分类法作为基础，通过验证机制确保增强质量

Abstract: Taxonomies play a vital role in structuring and categorizing information across domains. However, many existing taxonomies suffer from limited coverage and outdated or ambiguous nodes, reducing their effectiveness in knowledge retrieval. To address this, we present Taxoria, a novel taxonomy enrichment pipeline that leverages Large Language Models (LLMs) to enhance a given taxonomy. Unlike approaches that extract internal LLM taxonomies, Taxoria uses an existing taxonomy as a seed and prompts an LLM to propose candidate nodes for enrichment. These candidates are then validated to mitigate hallucinations and ensure semantic relevance before integration. The final output includes an enriched taxonomy with provenance tracking and visualization of the final merged taxonomy for analysis.

</details>
