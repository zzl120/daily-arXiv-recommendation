{"id": "2602.16034", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16034", "abs": "https://arxiv.org/abs/2602.16034", "authors": ["Xinrui He", "Ting-Wei Li", "Tianxin Wei", "Xuying Ning", "Xinyu He", "Wenxuan Bao", "Hanghang Tong", "Jingrui He"], "title": "FeDecider: An LLM-Based Framework for Federated Cross-Domain Recommendation", "comment": "Accepted to The Web Conference (WWW) 2026", "summary": "Federated cross-domain recommendation (Federated CDR) aims to collaboratively learn personalized recommendation models across heterogeneous domains while preserving data privacy. Recently, large language model (LLM)-based recommendation models have demonstrated impressive performance by leveraging LLMs' strong reasoning capabilities and broad knowledge. However, adopting LLM-based recommendation models in Federated CDR scenarios introduces new challenges. First, there exists a risk of overfitting with domain-specific local adapters. The magnitudes of locally optimized parameter updates often vary across domains, causing biased aggregation and overfitting toward domain-specific distributions. Second, unlike traditional recommendation models (e.g., collaborative filtering, bipartite graph-based methods) that learn explicit and comparable user/item representations, LLMs encode knowledge implicitly through autoregressive text generation training. This poses additional challenges for effectively measuring the cross-domain similarities under heterogeneity. To address these challenges, we propose an LLM-based framework for federated cross-domain recommendation, FeDecider. Specifically, FeDecider tackles the challenge of scale-specific noise by disentangling each client's low-rank updates and sharing only their directional components. To handle the need for flexible and effective integration, each client further learns personalized weights that achieve the data-aware integration of updates from other domains. Extensive experiments across diverse datasets validate the effectiveness of our proposed FeDecider.", "AI": {"tldr": "FeDecider\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8054\u90a6\u8de8\u57df\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u4f4e\u79e9\u66f4\u65b0\u548c\u5171\u4eab\u65b9\u5411\u5206\u91cf\u89e3\u51b3\u57df\u7279\u5b9a\u9002\u914d\u5668\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5e76\u5b66\u4e60\u4e2a\u6027\u5316\u6743\u91cd\u5b9e\u73b0\u6570\u636e\u611f\u77e5\u7684\u8de8\u57df\u66f4\u65b0\u96c6\u6210\u3002", "motivation": "\u5728\u8054\u90a6\u8de8\u57df\u63a8\u8350\u4e2d\u91c7\u7528LLM\u6a21\u578b\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) \u57df\u7279\u5b9a\u672c\u5730\u9002\u914d\u5668\u5b58\u5728\u8fc7\u62df\u5408\u98ce\u9669\uff0c\u672c\u5730\u4f18\u5316\u53c2\u6570\u66f4\u65b0\u7684\u5e45\u5ea6\u5728\u4e0d\u540c\u57df\u95f4\u5dee\u5f02\u5bfc\u81f4\u805a\u5408\u504f\u5dee\u548c\u57df\u7279\u5b9a\u5206\u5e03\u8fc7\u62df\u5408\uff1b2) LLM\u901a\u8fc7\u81ea\u56de\u5f52\u6587\u672c\u751f\u6210\u9690\u5f0f\u7f16\u7801\u77e5\u8bc6\uff0c\u4e0e\u4f20\u7edf\u63a8\u8350\u6a21\u578b\u5b66\u4e60\u663e\u5f0f\u53ef\u6bd4\u8f83\u8868\u793a\u4e0d\u540c\uff0c\u8fd9\u7ed9\u5f02\u6784\u73af\u5883\u4e0b\u6709\u6548\u6d4b\u91cf\u8de8\u57df\u76f8\u4f3c\u6027\u5e26\u6765\u989d\u5916\u6311\u6218\u3002", "method": "\u63d0\u51faFeDecider\u6846\u67b6\uff1a1) \u901a\u8fc7\u89e3\u8026\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u4f4e\u79e9\u66f4\u65b0\u5e76\u4ec5\u5171\u4eab\u5176\u65b9\u5411\u5206\u91cf\u6765\u5904\u7406\u5c3a\u5ea6\u7279\u5b9a\u566a\u58f0\u95ee\u9898\uff1b2) \u6bcf\u4e2a\u5ba2\u6237\u7aef\u8fdb\u4e00\u6b65\u5b66\u4e60\u4e2a\u6027\u5316\u6743\u91cd\uff0c\u5b9e\u73b0\u6570\u636e\u611f\u77e5\u7684\u8de8\u57df\u66f4\u65b0\u96c6\u6210\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86FeDecider\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "FeDecider\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u8054\u90a6\u8de8\u57df\u63a8\u8350\u4e2d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u89e3\u8026\u4f4e\u79e9\u66f4\u65b0\u548c\u5171\u4eab\u65b9\u5411\u5206\u91cf\u7f13\u89e3\u8fc7\u62df\u5408\uff0c\u5e76\u901a\u8fc7\u4e2a\u6027\u5316\u6743\u91cd\u5b66\u4e60\u5b9e\u73b0\u6709\u6548\u7684\u8de8\u57df\u96c6\u6210\u3002"}}
{"id": "2602.16124", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16124", "abs": "https://arxiv.org/abs/2602.16124", "authors": ["Jiang Zhang", "Yubo Wang", "Wei Chang", "Lu Han", "Xingying Cheng", "Feng Zhang", "Min Li", "Songhao Jiang", "Wei Zheng", "Harry Tran", "Zhen Wang", "Lei Chen", "Yueming Wang", "Benyu Zhang", "Xiangjun Fan", "Bi Xue", "Qifan Wang"], "title": "Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System", "comment": null, "summary": "Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\\%, cold-content delivery by up to 57.29\\%, and semantic relevance by 13.5\\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency.", "AI": {"tldr": "MFLI\u662f\u4e00\u79cd\u7edf\u4e00\u5b66\u4e60\u5d4c\u5165\u548c\u7d22\u5f15\u7684\u5b9e\u65f6\u68c0\u7d22\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u9762\u5206\u5c42\u7801\u672c\u6d88\u9664ANN\u641c\u7d22\uff0c\u63d0\u5347\u53ec\u56de\u7387\u548c\u670d\u52a1\u6548\u7387", "motivation": "\u4f20\u7edfANN\u68c0\u7d22\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1\uff09\u5d4c\u5165\u5b66\u4e60\u548c\u7d22\u5f15\u6784\u5efa\u5206\u79bb\uff0c\u5bfc\u81f4\u6b21\u4f18\u68c0\u7d22\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5bf9\u65b0\u5185\u5bb9\uff1b2\uff09\u867d\u7136\u67e5\u8be2\u65f6\u95f4\u4e9a\u7ebf\u6027\uff0c\u4f46\u6bcf\u4e2a\u8bf7\u6c42\u4ecd\u9700\u8fd0\u884cANN\uff0c\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u573a\u666f\u4e0b\u8ba1\u7b97\u6210\u672c\u9ad8", "method": "\u63d0\u51fa\u591a\u9762\u53ef\u5b66\u4e60\u7d22\u5f15\uff08MFLI\uff09\uff1a\u901a\u8fc7\u6b8b\u5dee\u91cf\u5316\u6784\u5efa\u591a\u9762\u5206\u5c42\u7801\u672c\uff0c\u4e0e\u5d4c\u5165\u5171\u540c\u8bad\u7ec3\uff1b\u8bbe\u8ba1\u652f\u6301\u5b9e\u65f6\u66f4\u65b0\u7684\u9ad8\u6548\u591a\u9762\u7d22\u5f15\u7ed3\u6784\uff1b\u5728\u670d\u52a1\u65f6\u76f4\u63a5\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u5206\u5c42\u7d22\u5f15\u8bc6\u522b\u76f8\u5173\u9879\u76ee\uff0c\u5b8c\u5168\u907f\u514dANN\u641c\u7d22", "result": "\u5728\u6570\u5341\u4ebf\u7528\u6237\u7684\u771f\u5b9e\u6570\u636e\u4e0a\uff0cMFLI\u76f8\u6bd4SOTA\u65b9\u6cd5\uff1a\u53c2\u4e0e\u5ea6\u4efb\u52a1\u53ec\u56de\u7387\u63d0\u534711.8%\uff0c\u51b7\u5185\u5bb9\u5206\u53d1\u63d0\u534757.29%\uff0c\u8bed\u4e49\u76f8\u5173\u6027\u63d0\u534713.5%\uff1b\u5728\u7ebf\u90e8\u7f72\u663e\u793a\u53c2\u4e0e\u5ea6\u63d0\u9ad8\u3001\u6d41\u884c\u5ea6\u504f\u5dee\u51cf\u5c11\u3001\u670d\u52a1\u6548\u7387\u66f4\u9ad8", "conclusion": "MFLI\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u68c0\u7d22\u8303\u5f0f\uff0c\u7edf\u4e00\u5b66\u4e60\u5d4c\u5165\u548c\u7d22\u5f15\uff0c\u6d88\u9664\u4e86ANN\u641c\u7d22\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u53ec\u56de\u8d28\u91cf\u3001\u51b7\u5185\u5bb9\u5904\u7406\u548c\u8bed\u4e49\u76f8\u5173\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2602.16299", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16299", "abs": "https://arxiv.org/abs/2602.16299", "authors": ["Mathias Vast", "Victor Morand", "Basile van Cooten", "Laure Soulier", "Josiane Mothe", "Benjamin Piwowarski"], "title": "MICE: Minimal Interaction Cross-Encoders for efficient Re-ranking", "comment": "9 pages, 5 figures", "summary": "Cross-encoders deliver state-of-the-art ranking effectiveness in information retrieval, but have a high inference cost. This prevents them from being used as first-stage rankers, but also incurs a cost when re-ranking documents. Prior work has addressed this bottleneck from two largely separate directions: accelerating cross-encoder inference by sparsifying the attention process or improving first-stage retrieval effectiveness using more complex models, e.g. late-interaction ones. In this work, we propose to bridge these two approaches, based on an in-depth understanding of the internal mechanisms of cross-encoders. Starting from cross-encoders, we show that it is possible to derive a new late-interaction-like architecture by carefully removing detrimental or unnecessary interactions. We name this architecture MICE (Minimal Interaction Cross-Encoders). We extensively evaluate MICE across both in-domain (ID) and out-of-domain (OOD) datasets. MICE decreases fourfold the inference latency compared to standard cross-encoders, matching late-interaction models like ColBERT while retaining most of cross-encoder ID effectiveness and demonstrating superior generalization abilities in OOD.", "AI": {"tldr": "MICE\u662f\u4e00\u79cd\u901a\u8fc7\u51cf\u5c11\u4ea4\u53c9\u7f16\u7801\u5668\u5185\u90e8\u4e0d\u5fc5\u8981\u4ea4\u4e92\u6765\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u7684\u65b0\u578b\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u4ea4\u53c9\u7f16\u7801\u5668\u6392\u5e8f\u6548\u679c\u7684\u540c\u65f6\u5b9e\u73b0\u4e0eColBERT\u76f8\u5f53\u7684\u63a8\u7406\u901f\u5ea6", "motivation": "\u4ea4\u53c9\u7f16\u7801\u5668\u5728\u4fe1\u606f\u68c0\u7d22\u4e2d\u5177\u6709\u6700\u5148\u8fdb\u7684\u6392\u5e8f\u6548\u679c\uff0c\u4f46\u63a8\u7406\u6210\u672c\u9ad8\u6602\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u4f5c\u4e3a\u7b2c\u4e00\u9636\u6bb5\u6392\u5e8f\u5668\u7684\u5e94\u7528\uff0c\u5e76\u5728\u91cd\u6392\u5e8f\u65f6\u4ea7\u751f\u9ad8\u6210\u672c\u3002\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u4ece\u4e24\u4e2a\u65b9\u5411\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\uff1a\u901a\u8fc7\u7a00\u758f\u5316\u6ce8\u610f\u529b\u8fc7\u7a0b\u52a0\u901f\u4ea4\u53c9\u7f16\u7801\u5668\u63a8\u7406\uff0c\u6216\u4f7f\u7528\u66f4\u590d\u6742\u7684\u6a21\u578b\uff08\u5982\u5ef6\u8fdf\u4ea4\u4e92\u6a21\u578b\uff09\u63d0\u9ad8\u7b2c\u4e00\u9636\u6bb5\u68c0\u7d22\u6548\u679c\u3002\u672c\u7814\u7a76\u65e8\u5728\u6865\u63a5\u8fd9\u4e24\u79cd\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5bf9\u4ea4\u53c9\u7f16\u7801\u5668\u5185\u90e8\u673a\u5236\u7684\u6df1\u5165\u7406\u89e3\uff0c\u4ece\u4ea4\u53c9\u7f16\u7801\u5668\u51fa\u53d1\uff0c\u901a\u8fc7\u4ed4\u7ec6\u79fb\u9664\u6709\u5bb3\u6216\u4e0d\u5fc5\u8981\u7684\u4ea4\u4e92\uff0c\u63a8\u5bfc\u51fa\u4e00\u79cd\u65b0\u7684\u7c7b\u4f3c\u5ef6\u8fdf\u4ea4\u4e92\u7684\u67b6\u6784\uff0c\u547d\u540d\u4e3aMICE\uff08\u6700\u5c0f\u4ea4\u4e92\u4ea4\u53c9\u7f16\u7801\u5668\uff09\u3002", "result": "MICE\u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u81f3\u6807\u51c6\u4ea4\u53c9\u7f16\u7801\u5668\u7684\u56db\u5206\u4e4b\u4e00\uff0c\u4e0eColBERT\u7b49\u5ef6\u8fdf\u4ea4\u4e92\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u4ea4\u53c9\u7f16\u7801\u5668\u5728\u57df\u5185\u7684\u5927\u90e8\u5206\u6392\u5e8f\u6548\u679c\uff0c\u5e76\u5728\u57df\u5916\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u66f4\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MICE\u6210\u529f\u6865\u63a5\u4e86\u4ea4\u53c9\u7f16\u7801\u5668\u52a0\u901f\u548c\u5ef6\u8fdf\u4ea4\u4e92\u6a21\u578b\u4e24\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4e0d\u5fc5\u8981\u7684\u4ea4\u4e92\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u6709\u6548\u7684\u68c0\u7d22\u67b6\u6784\uff0c\u5728\u63a8\u7406\u901f\u5ea6\u548c\u6392\u5e8f\u6548\u679c\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.16315", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16315", "abs": "https://arxiv.org/abs/2602.16315", "authors": ["Gabriele Barlacchi", "Margherita Lalli", "Emanuele Ferragina", "Fosca Giannotti", "Dino Pedreschi", "Luca Pappalardo"], "title": "The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems", "comment": null, "summary": "Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems.", "AI": {"tldr": "\u63a8\u8350\u7cfb\u7edf\u53cd\u9988\u5faa\u73af\u6a21\u578b\u7814\u7a76\uff1a\u7528\u6237\u884c\u4e3a\u4e0e\u7b97\u6cd5\u63a8\u8350\u534f\u540c\u6f14\u5316\uff0c\u53d1\u73b0\u4e2a\u4f53\u6d88\u8d39\u591a\u6837\u5316\u4f46\u96c6\u4f53\u9700\u6c42\u96c6\u4e2d\u5316\uff0c\u9759\u6001\u8bc4\u4f30\u7684\u591a\u6837\u6027\u589e\u957f\u662f\u5047\u8c61", "motivation": "\u63a8\u8350\u7cfb\u7edf\u901a\u8fc7\u53cd\u9988\u5faa\u73af\u5851\u9020\u4e2a\u4f53\u9009\u62e9\uff0c\u4f46\u73b0\u6709\u6a21\u62df\u7814\u7a76\u5b58\u5728\u4e0d\u73b0\u5b9e\u5047\u8bbe\uff0c\u53cd\u9988\u5faa\u73af\u7684\u7cfb\u7edf\u6027\u6548\u5e94\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u9700\u8981\u5efa\u7acb\u66f4\u771f\u5b9e\u7684\u6a21\u578b\u6765\u7406\u89e3\u7528\u6237\u884c\u4e3a\u4e0e\u7b97\u6cd5\u63a8\u8350\u5982\u4f55\u968f\u65f6\u95f4\u534f\u540c\u6f14\u5316\u3002", "method": "\u63d0\u51fa\u53cd\u9988\u5faa\u73af\u6a21\u578b\uff0c\u5305\u542b\u9690\u5f0f\u53cd\u9988\u3001\u5468\u671f\u6027\u91cd\u65b0\u8bad\u7ec3\u3001\u63a8\u8350\u91c7\u7eb3\u6982\u7387\u548c\u5f02\u6784\u63a8\u8350\u7cfb\u7edf\u3002\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u5728\u7ebf\u96f6\u552e\u548c\u97f3\u4e50\u6d41\u5a92\u4f53\u6570\u636e\uff0c\u5206\u6790\u53cd\u9988\u5faa\u73af\u7684\u7cfb\u7edf\u6027\u6548\u5e94\u3002", "result": "\u589e\u52a0\u63a8\u8350\u91c7\u7eb3\u53ef\u80fd\u5bfc\u81f4\u4e2a\u4f53\u6d88\u8d39\u9010\u6e10\u591a\u6837\u5316\uff0c\u4f46\u96c6\u4f53\u9700\u6c42\u4ee5\u6a21\u578b\u548c\u9886\u57df\u4f9d\u8d56\u7684\u65b9\u5f0f\u91cd\u65b0\u5206\u914d\uff0c\u901a\u5e38\u653e\u5927\u6d41\u884c\u5ea6\u96c6\u4e2d\u3002\u65f6\u95f4\u5206\u6790\u8fdb\u4e00\u6b65\u63ed\u793a\uff1a\u9759\u6001\u8bc4\u4f30\u4e2d\u89c2\u5bdf\u5230\u7684\u4e2a\u4f53\u591a\u6837\u6027\u589e\u52a0\u662f\u5047\u8c61\u2014\u2014\u5f53\u91c7\u7eb3\u56fa\u5b9a\u4e14\u65f6\u95f4\u5c55\u5f00\u65f6\uff0c\u6240\u6709\u6a21\u578b\u4e2d\u4e2a\u4f53\u591a\u6837\u6027\u6301\u7eed\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u9700\u8981\u8d85\u8d8a\u9759\u6001\u8bc4\u4f30\uff0c\u5728\u8bbe\u8ba1\u63a8\u8350\u7cfb\u7edf\u65f6\u660e\u786e\u8003\u8651\u53cd\u9988\u5faa\u73af\u52a8\u6001\u3002\u53cd\u9988\u5faa\u73af\u5bf9\u4e2a\u4f53\u548c\u96c6\u4f53\u6d88\u8d39\u6a21\u5f0f\u6709\u590d\u6742\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u52a8\u6001\u7684\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2602.16541", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16541", "abs": "https://arxiv.org/abs/2602.16541", "authors": ["Santiago de Leon-Martinez", "Robert Moro", "Branislav Kveton", "Maria Bielikova"], "title": "From Latent to Observable Position-Based Click Models in Carousel Interfaces", "comment": null, "summary": "Click models are a central component of learning and evaluation in recommender systems, yet most existing models are designed for single ranked-list interfaces. In contrast, modern recommender platforms increasingly use complex interfaces such as carousels, which consist of multiple swipeable lists that enable complex user browsing behaviors.\n  In this paper, we study position-based click models in carousel interfaces and examine optimization methods, model structure, and alignment with user behavior. We propose three novel position-based models tailored to carousels, including the first position-based model without latent variables that incorporates observed examination signals derived from eye tracking data, called the Observed Examination Position-Based Model (OEPBM). We develop a general implementation of these carousel click models, supporting multiple optimization techniques and conduct experiments comparing gradient-based methods with classical approaches, namely expectation-maximization and maximum likelihood estimation.\n  Our results show that gradient-based optimization consistently achieve better click likelihoods. Among the evaluated models, the OEPBM achieves the strongest performance in click prediction and produces examination patterns that most closely align to user behavior. However, we also demonstrate that strong click fit does not imply realistic modeling of user examination and browsing patterns. This reveals a fundamental limitation of click-only models in complex interfaces and the need for incorporating additional behavioral signals when designing click models for carousel-based recommender systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8f6e\u64ad\u754c\u9762\u4e2d\u7684\u70b9\u51fb\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u7684\u57fa\u4e8e\u4f4d\u7f6e\u7684\u8f6e\u64ad\u70b9\u51fb\u6a21\u578b\uff0c\u5305\u62ec\u9996\u4e2a\u65e0\u9700\u9690\u53d8\u91cf\u4e14\u7ed3\u5408\u773c\u52a8\u8ffd\u8e2a\u6570\u636e\u7684\u89c2\u6d4b\u68c0\u67e5\u6a21\u578b(OEPBM)\uff0c\u53d1\u73b0\u68af\u5ea6\u4f18\u5316\u6548\u679c\u6700\u597d\uff0c\u4f46\u70b9\u51fb\u62df\u5408\u597d\u4e0d\u4ee3\u8868\u7528\u6237\u68c0\u67e5\u884c\u4e3a\u5efa\u6a21\u51c6\u786e\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u5e73\u53f0\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u8f6e\u64ad\u7b49\u590d\u6742\u754c\u9762\uff0c\u800c\u73b0\u6709\u70b9\u51fb\u6a21\u578b\u4e3b\u8981\u9488\u5bf9\u5355\u4e00\u6392\u540d\u5217\u8868\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u6709\u6548\u5efa\u6a21\u8f6e\u64ad\u754c\u9762\u4e2d\u7684\u590d\u6742\u7528\u6237\u6d4f\u89c8\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u4e13\u95e8\u9488\u5bf9\u8f6e\u64ad\u754c\u9762\u7684\u57fa\u4e8e\u4f4d\u7f6e\u70b9\u51fb\u6a21\u578b\uff0c\u5305\u62ec\u89c2\u6d4b\u68c0\u67e5\u4f4d\u7f6e\u6a21\u578b(OEPBM)\uff0c\u8fd9\u662f\u9996\u4e2a\u65e0\u9700\u9690\u53d8\u91cf\u4e14\u7ed3\u5408\u773c\u52a8\u8ffd\u8e2a\u89c2\u6d4b\u68c0\u67e5\u4fe1\u53f7\u7684\u6a21\u578b\u3002\u5f00\u53d1\u4e86\u901a\u7528\u7684\u8f6e\u64ad\u70b9\u51fb\u6a21\u578b\u5b9e\u73b0\uff0c\u652f\u6301\u591a\u79cd\u4f18\u5316\u6280\u672f\uff0c\u6bd4\u8f83\u4e86\u68af\u5ea6\u65b9\u6cd5\u4e0e\u7ecf\u5178\u65b9\u6cd5\uff08\u671f\u671b\u6700\u5927\u5316\u3001\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff09\u3002", "result": "\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u5728\u70b9\u51fb\u4f3c\u7136\u5ea6\u4e0a\u8868\u73b0\u6700\u597d\u3002OEPBM\u5728\u70b9\u51fb\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u6700\u5f3a\uff0c\u4ea7\u751f\u7684\u68c0\u67e5\u6a21\u5f0f\u4e0e\u7528\u6237\u884c\u4e3a\u6700\u63a5\u8fd1\u3002\u4f46\u7814\u7a76\u53d1\u73b0\u70b9\u51fb\u62df\u5408\u597d\u5e76\u4e0d\u4ee3\u8868\u7528\u6237\u68c0\u67e5\u548c\u6d4f\u89c8\u6a21\u5f0f\u5efa\u6a21\u51c6\u786e\u3002", "conclusion": "\u4ec5\u57fa\u4e8e\u70b9\u51fb\u7684\u6a21\u578b\u5728\u590d\u6742\u754c\u9762\u4e2d\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u8bbe\u8ba1\u8f6e\u64ad\u63a8\u8350\u7cfb\u7edf\u7684\u70b9\u51fb\u6a21\u578b\u65f6\u9700\u8981\u7ed3\u5408\u989d\u5916\u7684\u884c\u4e3a\u4fe1\u53f7\u3002"}}
{"id": "2602.16587", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16587", "abs": "https://arxiv.org/abs/2602.16587", "authors": ["Luankang Zhang", "Yonghao Huang", "Hang Lv", "Mingjia Yin", "Liangyue Li", "Zulong Chen", "Hao Wang", "Enhong Chen"], "title": "Why Thinking Hurts? Diagnosing and Rectifying the Reasoning Shift in Foundation Recommender Models", "comment": null, "summary": "Integrating Chain-of-Thought (CoT) reasoning into Semantic ID-based recommendation foundation models (such as OpenOneRec) often paradoxically degrades recommendation performance. We identify the root cause as textual inertia from the General Subspace, where verbose reasoning dominates inference and causes the model to neglect critical Semantic ID. To address this, we propose a training-free Inference-Time Subspace Alignment framework. By compressing reasoning chains and applying bias-subtracted contrastive decoding, our approach mitigates ungrounded textual drift. Experiments show this effectively calibrates inference, allowing foundation models to leverage reasoning without sacrificing ID-grounded accuracy.", "AI": {"tldr": "\u63d0\u51fa\u63a8\u7406\u65f6\u5b50\u7a7a\u95f4\u5bf9\u9f50\u6846\u67b6\uff0c\u89e3\u51b3CoT\u63a8\u7406\u5728\u8bed\u4e49ID\u63a8\u8350\u57fa\u7840\u6a21\u578b\u4e2d\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898", "motivation": "\u5728\u8bed\u4e49ID\u63a8\u8350\u57fa\u7840\u6a21\u578b\uff08\u5982OpenOneRec\uff09\u4e2d\u96c6\u6210CoT\u63a8\u7406\u4f1a\u964d\u4f4e\u63a8\u8350\u6027\u80fd\uff0c\u539f\u56e0\u662f\u901a\u7528\u5b50\u7a7a\u95f4\u7684\u6587\u672c\u60ef\u6027\u5bfc\u81f4\u5197\u957f\u63a8\u7406\u4e3b\u5bfc\u63a8\u65ad\u8fc7\u7a0b\uff0c\u5ffd\u7565\u4e86\u5173\u952e\u7684\u8bed\u4e49ID", "method": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684\u63a8\u7406\u65f6\u5b50\u7a7a\u95f4\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u538b\u7f29\u63a8\u7406\u94fe\u548c\u5e94\u7528\u504f\u7f6e\u51cf\u9664\u5bf9\u6bd4\u89e3\u7801\uff0c\u7f13\u89e3\u672a\u63a5\u5730\u7684\u6587\u672c\u6f02\u79fb", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6821\u51c6\u63a8\u7406\uff0c\u4f7f\u57fa\u7840\u6a21\u578b\u80fd\u591f\u5229\u7528\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u727a\u7272\u57fa\u4e8eID\u7684\u51c6\u786e\u6027", "conclusion": "\u63a8\u7406\u65f6\u5b50\u7a7a\u95f4\u5bf9\u9f50\u6846\u67b6\u89e3\u51b3\u4e86CoT\u63a8\u7406\u4e0e\u8bed\u4e49ID\u63a8\u8350\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u4e0eID\u63a5\u5730\u51c6\u786e\u6027\u7684\u5e73\u8861"}}
