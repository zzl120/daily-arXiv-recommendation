<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Talking to Yourself: Defying Forgetting in Large Language Models](https://arxiv.org/abs/2602.20162)
*Yutao Sun,Mingshuai Chen,Tiancheng Zhao,Phillip Miao,Zilun Zhang,Haozhan Shen,Ruizhe Zhu,Jianwei Yin*

Main category: cs.CL

TL;DR: SA-SFT：一种轻量级自增强方法，通过让大语言模型在微调前生成自我对话数据，与任务数据混合训练，有效缓解灾难性遗忘问题，同时提升领域内性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在特定任务数据上微调时面临灾难性遗忘问题，导致其通用知识和推理能力退化。现有方法如层冻结或外部数据混合存在局限性，需要更简单有效的解决方案。

Method: 提出SA-SFT方法：1）让LLM在微调前生成自我对话数据；2）将自生成数据与任务数据混合；3）不改变优化器或训练计划，保持标准微调流程。该方法无需外部数据或额外调优。

Result: 在50个评估场景中，SA-SFT保持与原模型相当的性能，在40个案例中取得最佳结果，优于层冻结和外部数据混合等基线方法。同时缓解了灾难性遗忘并提升了领域内性能。

Conclusion: 自增强提供了一种简单有效的LLM适应机制，无需额外成本即可避免灾难性遗忘。理论分析表明遗忘部分源于风格诱导的参数漂移，而通过自生成数据的自对齐能有效抵消这种效应。

Abstract: Catastrophic forgetting remains a major challenge when fine-tuning large language models (LLMs) on narrow, task-specific data, often degrading their general knowledge and reasoning abilities. We propose SA-SFT, a lightweight self-augmentation routine in which an LLM generates self-dialogues prior to fine-tuning, and the resulting self-authored data are mixed with task data without modifying optimization or training schedules.
  Despite requiring no external data or additional tuning, SA-SFT consistently mitigates catastrophic forgetting while improving in-domain performance. Across 50 evaluation scenarios, it maintains performance comparable to the original model and achieves the best results in 40 cases, outperforming common baselines such as layer freezing and external data mixing. Guided by these empirical findings, we further present a theoretical analysis suggesting that forgetting can partly stem from style-induced parameter drift, and that self-alignment through self-generated data provides an effective means to counteract this effect. Overall, our results indicate that self-augmentation offers a simple and effective mechanism for robust LLM adaptation without incurring catastrophic forgetting.

</details>


### [2] [Benchmarking Distilled Language Models: Performance and Efficiency in Resource-Constrained Settings](https://arxiv.org/abs/2602.20164)
*Sachin Gopal Wani,Eric Page,Ajay Dholakia,David Ellison*

Main category: cs.CL

TL;DR: 知识蒸馏在构建高效小型语言模型方面具有显著优势，蒸馏8B模型的计算效率比训练原始模型高2000倍以上，推理能力与10倍大小的标准模型相当甚至超越


<details>
  <summary>Details</summary>
Motivation: 为资源受限环境开发强大而高效的小型语言模型，验证知识蒸馏作为构建先进、可访问AI的主要策略而非仅仅是压缩技术

Method: 对蒸馏模型与原始模型及专有模型进行性能和计算成本的基准测试，提供效率的定量分析，比较性能-计算曲线

Result: 蒸馏创造了更优的性能-计算曲线，蒸馏8B模型的计算效率比训练原始模型高2000倍以上，推理能力与10倍大小的标准模型相当甚至超越

Conclusion: 知识蒸馏不仅是压缩技术，更是构建最先进、可访问AI的主要策略，为资源受限环境提供了高效解决方案

Abstract: Knowledge distillation offers a transformative pathway to developing powerful, yet efficient, small language models (SLMs) suitable for resource-constrained environments. In this paper, we benchmark the performance and computational cost of distilled models against their vanilla and proprietary counterparts, providing a quantitative analysis of their efficiency. Our results demonstrate that distillation creates a superior performance-tocompute curve. We find that creating a distilled 8B model is over 2,000 times more compute-efficient than training its vanilla counterpart, while achieving reasoning capabilities on par with, or even exceeding, standard models ten times its size. These findings validate distillation not just as a compression technique, but as a primary strategy for building state-of-the-art, accessible AI

</details>


### [3] [What Makes a Good Query? Measuring the Impact of Human-Confusing Linguistic Features on LLM Performance](https://arxiv.org/abs/2602.20300)
*William Watson,Nicole Cho,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: 研究发现查询特征与LLM幻觉风险相关，特定查询结构（如深层子句嵌套、不明确性）会增加幻觉概率，而明确意图和可回答性则降低风险。


<details>
  <summary>Details</summary>
Motivation: 传统上LLM幻觉被视为模型或解码策略的缺陷，但本文从语言学角度提出查询形式也会影响模型响应，需要探究哪些查询特征会增加幻觉风险。

Method: 构建22维查询特征向量，涵盖子句复杂度、词汇稀有性、回指、否定、可回答性和意图基础等语言学特征；使用369,837个真实世界查询进行大规模分析。

Result: 发现一致的"风险图谱"：深层子句嵌套和不明确性与更高幻觉倾向相关；明确意图基础和可回答性与更低幻觉率相关；领域特异性则呈现混合、数据集和模型依赖效应。

Conclusion: 建立了与幻觉风险相关的可观察查询特征表示，为引导性查询重写和未来干预研究铺平道路，表明查询形式是影响LLM幻觉的重要因素。

Abstract: Large Language Model (LLM) hallucinations are usually treated as defects of the model or its decoding strategy. Drawing on classical linguistics, we argue that a query's form can also shape a listener's (and model's) response. We operationalize this insight by constructing a 22-dimension query feature vector covering clause complexity, lexical rarity, and anaphora, negation, answerability, and intention grounding, all known to affect human comprehension. Using 369,837 real-world queries, we ask: Are there certain types of queries that make hallucination more likely? A large-scale analysis reveals a consistent "risk landscape": certain features such as deep clause nesting and underspecification align with higher hallucination propensity. In contrast, clear intention grounding and answerability align with lower hallucination rates. Others, including domain specificity, show mixed, dataset- and model-dependent effects. Thus, these findings establish an empirically observable query-feature representation correlated with hallucination risk, paving the way for guided query rewriting and future intervention studies.

</details>


### [4] [No One Size Fits All: QueryBandits for Hallucination Mitigation](https://arxiv.org/abs/2602.20332)
*Nicole Cho,William Watson,Alec Koppel,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: QueryBandits：针对闭源大语言模型幻觉问题的模型无关上下文赌博机框架，通过在线学习选择最优查询重写策略，无需模型重训练或梯度调整


<details>
  <summary>Details</summary>
Motivation: 当前大多数缓解LLM幻觉的研究集中在开源模型的后验检测和参数编辑上，而闭源模型在机构部署中占绝大多数却缺乏相关研究，需要一种无需模型内部访问的解决方案

Method: 提出QueryBandits框架，使用上下文赌博机自适应在线学习选择最优查询重写策略，基于经验验证和校准的奖励函数，通过语义特征学习在线策略，仅使用前向传播机制

Result: 在16个QA场景中，最佳QueryBandits（Thompson Sampling）相比无重写基线获得87.5%胜率，分别比零样本静态策略（如Paraphrase或Expand）高出42.6%和60.3%；所有上下文赌博机在所有数据集上都优于普通赌博机

Conclusion: 没有单一重写策略适用于所有查询，不灵活的查询重写策略可能加剧幻觉；QueryBandits通过纯前向传播机制改变模型行为，可用于闭源模型，无需重训练或基于梯度的适应

Abstract: Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models is especially concerning, as they constitute the vast majority of models in institutional deployments. We introduce QueryBandits, a model-agnostic contextual bandit framework that adaptively learns online to select the optimal query-rewrite strategy by leveraging an empirically validated and calibrated reward function. Across 16 QA scenarios, our top QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a No-Rewrite baseline and outperforms zero-shot static policies (e.g., Paraphrase or Expand) by 42.6% and 60.3%, respectively. Moreover, all contextual bandits outperform vanilla bandits across all datasets, with higher feature variance coinciding with greater variance in arm selection. This substantiates our finding that there is no single rewrite policy optimal for all queries. We also discover that certain static policies incur higher cumulative regret than No-Rewrite, indicating that an inflexible query-rewriting policy can worsen hallucinations. Thus, learning an online policy over semantic features with QueryBandits can shift model behavior purely through forward-pass mechanisms, enabling its use with closed-source models and bypassing the need for retraining or gradient-based adaptation.

</details>


### [5] [How communicatively optimal are exact numeral systems? Once more on lexicon size and morphosyntactic complexity](https://arxiv.org/abs/2602.20372)
*Chundra Cathcart,Arne Rubehn,Katja Bocklage,Luca Ciucci,Kellen Parker van Dam,Alžběta Kučerová,Jekaterina Mažara,Carlo Y. Meloni,David Snee,Johann-Mattis List*

Main category: cs.CL

TL;DR: 研究发现许多语言的数字系统在交流效率上远低于预期，挑战了精确递归数字系统优化效率的传统观点。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为精确递归数字系统通过平衡数字词汇库大小和数字术语的平均形态句法复杂性来优化交流效率，但作者认为这些研究未能充分解释语言实际显示的复杂性程度。

Method: 使用来自52种遗传多样性语言的数据，采用区分可预测和不可预测异形（形式变异）的标注方案进行分析。

Result: 研究表明世界上许多语言的数字系统在交流效率上明显低于预期水平。

Conclusion: 研究结果对数字系统研究和语言演化研究具有重要启示，表明实际语言系统可能并不总是遵循最优效率原则。

Abstract: Recent research argues that exact recursive numeral systems optimize communicative efficiency by balancing a tradeoff between the size of the numeral lexicon and the average morphosyntactic complexity (roughly length in morphemes) of numeral terms. We argue that previous studies have not characterized the data in a fashion that accounts for the degree of complexity languages display. Using data from 52 genetically diverse languages and an annotation scheme distinguishing between predictable and unpredictable allomorphy (formal variation), we show that many of the world's languages are decisively less efficient than one would expect. We discuss the implications of our findings for the study of numeral systems and linguistic evolution more generally.

</details>


### [6] [Disentangling Geometry, Performance, and Training in Language Models](https://arxiv.org/abs/2602.20433)
*Atharva Kulkarni,Jacob Mitchell Springer,Arjun Subramonian,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 研究发现Transformer权重几何特性（特别是unembedding矩阵的有效秩）与模型性能的关系并不稳定，有效秩受训练超参数影响，不能可靠预测下游任务表现


<details>
  <summary>Details</summary>
Motivation: Transformer权重（特别是unembedding矩阵）的几何特性在可解释性研究中很有用，但其对下游性能的预测能力尚不清楚，需要系统研究模型性能与unembedding矩阵几何（特别是有效秩）的关系

Method: 使用108个OLMo风格语言模型进行受控实验，系统分析unembedding矩阵几何特性（特别是有效秩）与模型性能的关系，并扩展到其他几何度量和最后一层表示

Result: 1. 最佳模型通常有较高有效秩，但并非所有任务和训练设置都如此；2. 低有效秩不会导致小模型后期性能下降，而是伴随出现；3. 存在低秩模型不饱和的反例；4. 有效秩受批大小和权重衰减等超参数影响；5. 其他几何度量与有效秩基本一致，但都不能可靠预测下游性能

Conclusion: 现有几何度量主要反映训练选择而非性能，不能可靠预测下游任务表现，模型几何特性与性能的关系比先前认为的更复杂

Abstract: Geometric properties of Transformer weights, particularly the unembedding matrix, have been widely useful in language model interpretability research. Yet, their utility for estimating downstream performance remains unclear. In this work, we systematically investigate the relationship between model performance and the unembedding matrix geometry, particularly its effective rank. Our experiments, involving a suite of 108 OLMo-style language models trained under controlled variation, reveal several key findings. While the best-performing models often exhibit a high effective rank, this trend is not universal across tasks and training setups. Contrary to prior work, we find that low effective rank does not cause late-stage performance degradation in small models, but instead co-occurs with it; we find adversarial cases where low-rank models do not exhibit saturation. Moreover, we show that effective rank is strongly influenced by pre-training hyperparameters, such as batch size and weight decay, which in-turn affect the model's performance. Lastly, extending our analysis to other geometric metrics and final-layer representation, we find that these metrics are largely aligned, but none can reliably predict downstream performance. Overall, our findings suggest that the model's geometry, as captured by existing metrics, primarily reflects training choices rather than performance.

</details>


### [7] [Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning](https://arxiv.org/abs/2602.20528)
*Justin Lovelace,Christian Belardi,Sofian Zalouk,Adhitya Polavaram,Srivatsa Kundurthy,Kilian Q. Weinberger*

Main category: cs.CL

TL;DR: STAR-LDM是一种结合潜在扩散规划和自回归生成的语言模型，通过"思考"阶段在连续空间进行全局规划，再生成离散标记，显著提升了语言理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型受限于逐个标记的决策，缺乏全局规划能力。STAR-LDM旨在解决这一问题，通过在生成过程中引入"思考"阶段，在连续语义空间进行全局规划，从而提升语言理解和推理的连贯性。

Method: STAR-LDM将潜在扩散规划与自回归生成相结合。模型在生成过程中暂停，通过扩散过程在连续语义空间中精炼语义计划，然后再继续生成离散标记。这种架构还允许通过轻量级分类器进行直接控制，实现细粒度属性引导而无需重新训练模型。

Result: STAR-LDM在语言理解基准测试中显著优于相似规模模型，在LLM-as-judge比较中，在叙事连贯性和常识推理方面获得超过70%的胜率。该架构在流畅性和控制之间实现了更好的权衡。

Conclusion: STAR-LDM通过整合扩散规划和自回归生成，成功解决了传统语言模型缺乏全局规划的问题，在语言理解和推理任务上表现出色，同时提供了灵活的控制能力而不牺牲流畅性。

Abstract: The Stop-Think-AutoRegress Language Diffusion Model (STAR-LDM) integrates latent diffusion planning with autoregressive generation. Unlike conventional autoregressive language models limited to token-by-token decisions, STAR-LDM incorporates a "thinking" phase that pauses generation to refine a semantic plan through diffusion before continuing. This enables global planning in continuous space prior to committing to discrete tokens. Evaluations show STAR-LDM significantly outperforms similar-sized models on language understanding benchmarks and achieves $>70\%$ win rates in LLM-as-judge comparisons for narrative coherence and commonsense reasoning. The architecture also allows straightforward control through lightweight classifiers, enabling fine-grained steering of attributes without model retraining while maintaining better fluency-control trade-offs than specialized approaches.

</details>


### [8] [Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning](https://arxiv.org/abs/2602.21103)
*Sanket Badhe,Deep Shah*

Main category: cs.CL

TL;DR: 提出Prompt-Level Distillation (PLD)方法，从教师模型中提取显式推理模式，组织成结构化指令列表作为学生模型的系统提示，使小型模型在保持可解释性的同时达到前沿性能，且延迟开销可忽略。


<details>
  <summary>Details</summary>
Motivation: 解决传统Chain-of-Thought提示推理方法的高延迟和高推理成本问题，以及微调小型模型时牺牲可解释性并引入显著资源开销的局限性。

Method: 提出Prompt-Level Distillation (PLD)方法：从教师模型中提取显式推理模式，将其组织成结构化、表达性强的指令列表，作为学生模型的系统提示，使推理过程透明化。

Result: 在StereoSet和Contract-NLI数据集上使用Gemma-3 4B模型评估，PLD将Macro F1分数分别从57%提升至90.0%和从67%提升至83%，使紧凑模型以可忽略的延迟开销达到前沿性能。

Conclusion: PLD方法使小型模型在保持可解释性的同时达到前沿性能，推理过程完全透明可验证，适用于法律、金融、内容审核等受监管行业，以及高吞吐量用例和边缘设备。

Abstract: Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant resource and operational overhead. To address these limitations, we introduce Prompt-Level Distillation (PLD). We extract explicit reasoning patterns from a Teacher model and organize them into a structured list of expressive instructions for the Student model's System Prompt. Evaluated on the StereoSet and Contract-NLI datasets using Gemma-3 4B, PLD improved Macro F1 scores from 57\% to 90.0\% and 67\% to 83\% respectively, enabling this compact model to match frontier performance with negligible latency overhead. These expressive instructions render the decision-making process transparent, allowing for full human verification of logic, making this approach ideal for regulated industries such as law, finance, and content moderation, as well as high-volume use cases and edge devices.

</details>


### [9] [Semantic Novelty at Scale: Narrative Shape Taxonomy and Readership Prediction in 28,606 Books](https://arxiv.org/abs/2602.20647)
*W. Frederick Zimmerman*

Main category: cs.CL

TL;DR: 提出语义新颖性作为叙事结构的信息论度量，应用于28,606本PG19书籍，发现8种叙事形状原型，其中新颖性轨迹的方差最能预测读者参与度，并揭示了体裁对叙事形状的强约束作用。


<details>
  <summary>Details</summary>
Motivation: 研究叙事结构的信息密度动态，区别于情感或主题分析，探索语义新颖性如何作为叙事结构的基本维度，并量化其对读者参与度的影响。

Method: 使用768维SBERT嵌入计算段落级语义新颖性（当前段落与先前段落质心的余弦距离），将新颖性曲线降维为16段PAA表示，通过Ward-linkage聚类识别叙事形状原型，并分析多种统计特征与读者参与度的关系。

Result: 识别出8种典型叙事形状原型（从陡降到陡升）；新颖性轨迹的方差（体积）是最强的长度无关读者参与度预测因子（偏rho=0.32）；体裁强烈约束叙事形状（卡方=2121.6）；1840-1910年间书籍变得更为可预测；85%的书籍具有独特的语义空间路径。

Conclusion: 信息密度动态是叙事结构的基本维度，具有可测量的读者参与度影响；语义新颖性分析揭示了传统相关性研究中长度混杂效应的严重性；体裁和历史时期对叙事形状有系统性影响。

Abstract: I introduce semantic novelty--cosine distance between each paragraph's sentence embedding and the running centroid of all preceding paragraphs--as an information-theoretic measure of narrative structure at corpus scale. Applying it to 28,606 books in PG19 (pre-1920 English literature), I compute paragraph-level novelty curves using 768-dimensional SBERT embeddings, then reduce each to a 16-segment Piecewise Aggregate Approximation (PAA). Ward-linkage clustering on PAA vectors reveals eight canonical narrative shape archetypes, from Steep Descent (rapid convergence) to Steep Ascent (escalating unpredictability). Volume--variance of the novelty trajectory--is the strongest length-independent predictor of readership (partial rho = 0.32), followed by speed (rho = 0.19) and Terminal/Initial ratio (rho = 0.19). Circuitousness shows strong raw correlation (rho = 0.41) but is 93 percent correlated with length; after control, partial rho drops to 0.11--demonstrating that naive correlations in corpus studies can be dominated by length confounds. Genre strongly constrains narrative shape (chi squared = 2121.6, p < 10 to the power negative 242), with fiction maintaining plateau profiles while nonfiction front-loads information. Historical analysis shows books became progressively more predictable between 1840 and 1910 (T/I ratio trend r = negative 0.74, p = 0.037). SAX analysis reveals 85 percent signature uniqueness, suggesting each book traces a nearly unique path through semantic space. These findings demonstrate that information-density dynamics, distinct from sentiment or topic, constitute a fundamental dimension of narrative structure with measurable consequences for reader engagement. Dataset: https://huggingface.co/datasets/wfzimmerman/pg19-semantic-novelty

</details>


### [10] [CARE: An Explainable Computational Framework for Assessing Client-Perceived Therapeutic Alliance Using Large Language Models](https://arxiv.org/abs/2602.20648)
*Anqi Li,Chenxiao Wang,Yu Lu,Renjun Xu,Lizhi Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: CARE是一个基于LLM的框架，用于从心理咨询对话中自动预测多维治疗联盟评分并生成可解释的推理，在预测准确性和解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统治疗联盟评估方法存在局限性：后会话问卷负担重且延迟，现有计算方法产生粗粒度评分、缺乏可解释推理、未能建模完整会话上下文。需要更准确、及时、可解释的评估工具来支持心理健康护理。

Method: 基于CounselingWAI数据集构建CARE框架，使用9,516个专家标注的推理进行增强，采用LLaMA-3.1-8B-Instruct作为骨干模型，通过推理增强监督进行微调，实现多维联盟评分预测和推理生成。

Result: CARE在预测准确性上优于主流LLM，将咨询师评估与客户感知联盟的差距显著缩小，与客户评分的Pearson相关性提高70%以上。推理增强监督进一步提升预测准确率，生成高质量、上下文相关的推理，自动和人工评估均验证其有效性。

Conclusion: CARE框架展示了作为AI辅助工具支持心理健康护理的潜力，能够识别联盟建设挑战、分析互动模式对联盟发展的影响，并提供可操作的见解，为治疗联盟评估提供了准确、可解释的自动化解决方案。

Abstract: Client perceptions of the therapeutic alliance are critical for counseling effectiveness. Accurately capturing these perceptions remains challenging, as traditional post-session questionnaires are burdensome and often delayed, while existing computational approaches produce coarse scores, lack interpretable rationales, and fail to model holistic session context. We present CARE, an LLM-based framework to automatically predict multi-dimensional alliance scores and generate interpretable rationales from counseling transcripts. Built on the CounselingWAI dataset and enriched with 9,516 expert-curated rationales, CARE is fine-tuned using rationale-augmented supervision with the LLaMA-3.1-8B-Instruct backbone. Experiments show that CARE outperforms leading LLMs and substantially reduces the gap between counselor evaluations and client-perceived alliance, achieving over 70% higher Pearson correlation with client ratings. Rationale-augmented supervision further improves predictive accuracy. CARE also produces high-quality, contextually grounded rationales, validated by both automatic and human evaluations. Applied to real-world Chinese online counseling sessions, CARE uncovers common alliance-building challenges, illustrates how interaction patterns shape alliance development, and provides actionable insights, demonstrating its potential as an AI-assisted tool for supporting mental health care.

</details>


### [11] [ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition](https://arxiv.org/abs/2602.20727)
*Xindian Ma,Rundong Kong,Peng Zhang,Ruoxiang Huang,Yongyu Jiang*

Main category: cs.CL

TL;DR: ID-LoRA是一种新型参数高效微调框架，通过从预训练权重矩阵中提取和重用聚类参数组，形成多个共享单一可训练低秩矩阵的低秩组件，在减少可训练参数的同时保持模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA及其变体在大模型扩展时仍会引入可观的可训练参数开销，而过度降低秩以控制开销会显著降低复杂多任务场景下的性能，需要打破这种权衡。

Method: 从预训练权重矩阵中提取聚类参数组，重用这些组形成多个低秩组件，所有组件共享单一初始化的可训练低秩矩阵，从而减少可训练参数数量同时保持模型容量。

Result: 在数学推理、代码生成、MMLU、常识问答和安全对齐五个基准测试中，ID-LoRA优于全量微调和现有PEFT基线（如LoRA、DoRA、HydraLoRA），同时使用比标准LoRA少46%的可训练参数。在多任务场景中，在代码和MMLU任务上超越LoRA及其变体，仅需传统LoRA 54%的可训练参数。

Conclusion: ID-LoRA成功打破了参数效率和性能之间的权衡，提供了一种更高效的参数高效微调方法，在减少可训练参数的同时保持甚至提升模型性能。

Abstract: LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable parameters. Conversely, aggressively lowering the rank to curb this overhead markedly degrades performance in complex multi-task settings. We propose ID-LoRA, a novel PEFT framework that breaks the trade-off. Its core innovation lies in extracting and reusing clustered parameter groups from the pretrained weight matrix. These groups are then used to form multiple low-rank components, all of which share only a single initialized trainable low-rank matrix. This approach cuts the number of trainable parameters while keeping the model's capacity intact. We evaluate ID-LoRA on five diverse benchmarks: Mathematical Reasoning, Code Generation, MMLU, CommonsenseQA, and Safety Alignment. ID-LoRA outperforms both full fine-tuning and existing PEFT baselines (e.g., LoRA, DoRA, HydraLoRA) while using up to 46% fewer trainable parameters than the standard LoRA. In multi-task scenarios, it surpasses LoRA and its recent variants (e.g., DoRA and HydraLoRA) on both Code and MMLU tasks, yet requires only 54% of the trainable parameters demanded by the conventional LoRA.

</details>


### [12] [Adaptive Text Anonymization: Learning Privacy-Utility Trade-offs via Prompt Optimization](https://arxiv.org/abs/2602.20743)
*Gabriel Loiseau,Damien Sileo,Damien Riquet,Maxime Meyer,Marc Tommasi*

Main category: cs.CL

TL;DR: 提出自适应文本匿名化任务，通过任务特定提示优化框架自动生成匿名化指令，在不同隐私-效用需求下优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化方法依赖静态、手动设计的策略，缺乏适应不同需求（数据领域、隐私目标、下游应用）的灵活性，且难以跨领域泛化

Method: 提出自适应文本匿名化任务框架，通过任务特定提示优化自动构建语言模型的匿名化指令，适应不同隐私目标、领域和使用模式

Result: 在包含5个数据集（不同领域、隐私约束和效用目标）的基准测试中，框架在所有设置下均优于现有基线，在开源语言模型上计算高效，性能与大型闭源模型相当，并能发现新的匿名化策略探索隐私-效用权衡前沿

Conclusion: 自适应文本匿名化框架通过自动优化提示，能够灵活适应多样化的隐私-效用需求，在保持计算效率的同时实现更好的权衡，为文本匿名化提供了更通用的解决方案

Abstract: Anonymizing textual documents is a highly context-sensitive problem: the appropriate balance between privacy protection and utility preservation varies with the data domain, privacy objectives, and downstream application. However, existing anonymization methods rely on static, manually designed strategies that lack the flexibility to adjust to diverse requirements and often fail to generalize across domains. We introduce adaptive text anonymization, a new task formulation in which anonymization strategies are automatically adapted to specific privacy-utility requirements. We propose a framework for task-specific prompt optimization that automatically constructs anonymization instructions for language models, enabling adaptation to different privacy goals, domains, and downstream usage patterns. To evaluate our approach, we present a benchmark spanning five datasets with diverse domains, privacy constraints, and utility objectives. Across all evaluated settings, our framework consistently achieves a better privacy-utility trade-off than existing baselines, while remaining computationally efficient and effective on open-source language models, with performance comparable to larger closed-source models. Additionally, we show that our method can discover novel anonymization strategies that explore different points along the privacy-utility trade-off frontier.

</details>


### [13] [Explicit Grammar Semantic Feature Fusion for Robust Text Classification](https://arxiv.org/abs/2602.20749)
*Azrin Sultana,Firoz Ahmed*

Main category: cs.CL

TL;DR: 提出一种轻量级文本分类模型，通过显式编码句子级语法结构与冻结上下文嵌入融合，避免使用计算密集的完整Transformer模型


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型计算密集，不适合资源受限环境，需要构建轻量级但能同时捕捉语法和语义特征的文本分类模型

Method: 将句子级语法结构（句法组成、短语模式、复杂度指标）编码为紧凑语法向量，与冻结的上下文嵌入融合，形成统一特征表示，使用DBNs、LSTMs、BiLSTMs、BERT、XLNET等模型进行训练评估

Result: 统一特征表示模型能同时捕捉文本的语义和结构特性，性能优于基线模型2%-15%，在异构领域实现更有效的学习，特别适合边缘设备

Conclusion: 将语法作为显式归纳偏置而非可学习模块，构建了轻量级高性能模型，为资源受限环境提供了有效的文本分类解决方案

Abstract: Natural Language Processing enables computers to understand human language by analysing and classifying text efficiently with deep-level grammatical and semantic features. Existing models capture features by learning from large corpora with transformer models, which are computationally intensive and unsuitable for resource-constrained environments. Therefore, our proposed study incorporates comprehensive grammatical rules alongside semantic information to build a robust, lightweight classification model without resorting to full parameterised transformer models or heavy deep learning architectures. The novelty of our approach lies in its explicit encoding of sentence-level grammatical structure, including syntactic composition, phrase patterns, and complexity indicators, into a compact grammar vector, which is then fused with frozen contextual embeddings. These heterogeneous elements unified a single representation that captures both the structural and semantic characteristics of the text. Deep learning models such as Deep Belief Networks (DBNs), Long Short-Term Memory (LSTMs), BiLSTMs, and transformer-based BERT and XLNET were used to train and evaluate the model, with the number of epochs varied. Based on experimental results, the unified feature representation model captures both the semantic and structural properties of text, outperforming baseline models by 2%-15%, enabling more effective learning across heterogeneous domains. Unlike prior syntax-aware transformer models that inject grammatical structure through additional attention layers, tree encoders, or full fine-tuning, the proposed framework treats grammar as an explicit inductive bias rather than a learnable module, resulting in a very lightweight model that delivers better performance on edge devices

</details>


### [14] [SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing](https://arxiv.org/abs/2602.20751)
*Yifei Xu,Guilherme Potje,Shivam Shandilya,Tiancheng Yuan,Leonardo de Oliveira Nunes,Rakshanda Agarwal,Saeid Asgari,Adam Atkinson,Emre Kıcıman,Songwu Lu,Ranveer Chandra,Tusher Chakraborty*

Main category: cs.CL

TL;DR: SibylSense：一种通过可调记忆库自适应生成评估标准的推理时学习方法，用于提升开放生成任务的强化学习性能


<details>
  <summary>Details</summary>
Motivation: 开放生成任务的强化学习后训练面临奖励设计难题：专家评估标准成本高，提示生成的评估标准肤浅不一致，固定池判别性评估标准易饱和漂移导致奖励黑客攻击

Method: SibylSense采用推理时学习方法，通过可调记忆库自适应冻结的评估标准生成器。记忆库通过验证器基于参考-候选答案判别性差距的项奖励更新，交替进行记忆调优和评估标准对抗性策略更新

Result: 在两个开放生成任务上的实验表明，SibylSense能产生更具判别性的评估标准，相比静态和非自适应基线显著提升下游强化学习性能

Conclusion: SibylSense通过自适应评估标准生成有效解决了开放生成任务中奖励设计的可扩展性和鲁棒性问题，为强化学习后训练提供了新方法

Abstract: Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inconsistent, and fixed-pool discriminative rubrics can saturate and drift, enabling reward hacking. We present SibylSense, an inference-time learning approach that adapts a frozen rubric generator through a tunable memory bank of validated rubric items. Memory is updated via verifier-based item rewards measured by reference-candidate answer discriminative gaps from a handful of examples. SibylSense alternates memory tuning with a rubric-adversarial policy update that produces rubric-satisfying candidate answers, shrinking discriminative gaps and driving the rubric generator to capture new quality dimensions. Experiments on two open-ended tasks show that SibylSense yields more discriminative rubrics and improves downstream RL performance over static and non-adaptive baselines.

</details>


### [15] [Overton Pluralistic Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.20759)
*Yu Fu,Seongho Son,Ilija Bogunovic*

Main category: cs.CL

TL;DR: OP-GRPO是一种强化学习框架，通过双奖励系统使单个大语言模型能够生成多元视角的回应，无需显式提示或模块化编排，实现了"小模型、大视角覆盖"的效果。


<details>
  <summary>Details</summary>
Motivation: 现有对齐范式在捕捉人类价值观的多元性方面存在局限，需要一种能够从单一查询生成多样化视角回应的方法。

Method: 1. 相似性估计器训练：微调Sentence Transformer用于Overton Pluralism任务，提供更准确的生成回应覆盖评估；2. OP-GRPO训练：将相似性估计器整合到双奖励系统中，确保真实人类视角的广泛覆盖和每个视角的独特性。

Result: Qwen2.5-3B-Instruct模型在自然语言推理基准上相对20B GPT-OSS基线获得37.4%的准确率提升，相对模块化架构基线获得19.1%的改进；使用GPT-4.1作为大语言模型评估器进一步证实了方法的鲁棒性。

Conclusion: OP-GRPO框架成功实现了隐式Overton Pluralism，使单个大语言模型能够生成多元视角的回应，在保持模型规模较小的同时实现了广泛的视角覆盖。

Abstract: Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Optimization), a reinforcement learning framework for implicit Overton Pluralism that enables a single large language model to produce pluralistic responses without explicit prompting or modular orchestration. Our workflow consists of two main steps. First, similarity estimator training fine-tunes a Sentence Transformer for Overton Pluralism tasks to provide more accurate coverage evaluation of generated responses. Second, OP-GRPO training incorporates this similarity estimator into a dual-reward system designed to ensure both broad coverage of genuine human perspectives and the uniqueness of each perspective, thereby promoting diversity. Empirical results demonstrate a "small models, big perspective coverage" effect. The trained Qwen2.5-3B-Instruct model surpasses a 20B GPT-OSS baseline with a 37.4 percent relative accuracy gain on a Natural Language Inference benchmark, and also outperforms a modular architecture baseline with a 19.1 percent relative improvement. Additional evaluations using GPT-4.1 as a large language model judge further confirm the robustness of the approach.

</details>


### [16] [Don't Ignore the Tail: Decoupling top-K Probabilities for Efficient Language Model Distillation](https://arxiv.org/abs/2602.20816)
*Sayantan Dasgupta,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 提出一种尾部感知的KL散度变体，用于语言模型蒸馏，通过解耦教师模型前K个高概率预测与低概率预测的贡献，减少教师主导模式的影响，增强分布尾部信息的作用。


<details>
  <summary>Details</summary>
Motivation: 传统KL散度在语言模型蒸馏中主要受教师模型最高概率的token（模式）主导，削弱了低概率但可能信息丰富的分布尾部成分的影响，需要改进以更全面地利用教师分布信息。

Method: 提出尾部感知散度，将教师模型的前K个最高概率预测与低概率预测解耦，保持与KL散度相同的计算特性，但减少教师模式的主导作用，增强分布尾部贡献。

Result: 实验表明，改进的蒸馏方法在解码器模型的预训练和监督蒸馏中，在各种数据集上都能获得有竞争力的性能，且蒸馏过程高效，可用适度的学术预算处理大型数据集。

Conclusion: 尾部感知散度提供了一种有效的语言模型蒸馏方法，能更好地利用教师分布的完整信息，减少模式主导问题，同时保持计算效率，适合学术环境应用。

Abstract: The core learning signal used in language model distillation is the standard Kullback-Leibler (KL) divergence between the student and teacher distributions. Traditional KL divergence tends to be dominated by the next tokens with the highest probabilities, i.e., the teacher's modes, thereby diminishing the influence of less probable yet potentially informative components of the output distribution. We propose a new tail-aware divergence that decouples the contribution of the teacher model's top-K predicted probabilities from that of lower-probability predictions, while maintaining the same computational profile as the KL Divergence. Our decoupled approach reduces the impact of the teacher modes and, consequently, increases the contribution of the tail of the distribution. Experimental results demonstrate that our modified distillation method yields competitive performance in both pre-training and supervised distillation of decoder models across various datasets. Furthermore, the distillation process is efficient and can be performed with a modest academic budget for large datasets, eliminating the need for industry-scale computing.

</details>


### [17] [FinAnchor: Aligned Multi-Model Representations for Financial Prediction](https://arxiv.org/abs/2602.20859)
*Zirui He,Huopu Zhang,Yanguang Liu,Sirui Wu,Mengnan Du*

Main category: cs.CL

TL;DR: FinAnchor：一种轻量级框架，通过锚定异构LLM嵌入表示来提升金融文档预测性能


<details>
  <summary>Details</summary>
Motivation: 金融长文档预测面临两个主要挑战：1）有效信号稀疏且被噪声掩盖；2）不同任务和时间段下最优的LLM嵌入模型各不相同。现有方法通常依赖单一模型或简单集成，无法有效整合异构嵌入空间的信息。

Method: FinAnchor框架包含三个核心步骤：1）选择一个锚定嵌入空间；2）学习线性映射将其他模型的表示对齐到该锚定空间；3）聚合对齐后的特征形成统一表示用于下游预测。该方法无需微调底层LLM模型，保持轻量级特性。

Result: 在多个金融NLP任务上，FinAnchor consistently outperforms strong single-model baselines and standard ensemble methods，证明了锚定异构表示对稳健金融预测的有效性。

Conclusion: FinAnchor通过锚定和整合多个LLM的异构嵌入表示，有效提升了金融长文档预测的鲁棒性和性能，为解决金融领域信号稀疏和模型选择难题提供了轻量级解决方案。

Abstract: Financial prediction from long documents involves significant challenges, as actionable signals are often sparse and obscured by noise, and the optimal LLM for generating embeddings varies across tasks and time periods. In this paper, we propose FinAnchor(Financial Anchored Representations), a lightweight framework that integrates embeddings from multiple LLMs without fine-tuning the underlying models. FinAnchor addresses the incompatibility of feature spaces by selecting an anchor embedding space and learning linear mappings to align representations from other models into this anchor. These aligned features are then aggregated to form a unified representation for downstream prediction. Across multiple financial NLP tasks, FinAnchor consistently outperforms strong single-model baselines and standard ensemble methods, demonstrating the effectiveness of anchoring heterogeneous representations for robust financial prediction.

</details>


### [18] [Exa-PSD: a new Persian sentiment analysis dataset on Twitter](https://arxiv.org/abs/2602.20892)
*Seyed Himan Ghaderi,Saeed Sarbazi Azad,Mohammad Mehdi Jaziriyan,Ahmad Akbari*

Main category: cs.CL

TL;DR: 该论文介绍了Exa波斯语情感分析数据集，包含12,000条波斯语推文，标注为积极、中性和消极三类，使用预训练模型评估获得79.87的宏平均F1分数。


<details>
  <summary>Details</summary>
Motivation: 波斯语自然语言处理面临挑战，现有数据集多集中于特定领域（如产品、食品、酒店），而社交媒体中用户常使用讽刺、口语化表达，需要专门针对波斯语推文的情感分析数据集。

Method: 从波斯语推文收集数据，构建包含12,000条推文的数据集，由5名波斯语母语标注者进行标注，分为积极、中性和消极三类，使用预训练的Pars Bert和Roberta模型进行评估。

Result: 数据集包含12,000条标注推文，使用预训练模型评估获得79.87的宏平均F1分数，表明该数据集和模型对波斯语情感分析系统具有足够价值。

Conclusion: Exa波斯语情感分析数据集填补了波斯语社交媒体情感分析数据集的空白，为波斯语自然语言处理研究提供了有价值的资源，评估结果显示了其在情感分析系统中的实用性。

Abstract: Today, Social networks such as Twitter are the most widely used platforms for communication of people. Analyzing this data has useful information to recognize the opinion of people in tweets. Sentiment analysis plays a vital role in NLP, which identifies the opinion of the individuals about a specific topic. Natural language processing in Persian has many challenges despite the adventure of strong language models. The datasets available in Persian are generally in special topics such as products, foods, hotels, etc while users may use ironies, colloquial phrases in social media To overcome these challenges, there is a necessity for having a dataset of Persian sentiment analysis on Twitter. In this paper, we introduce the Exa sentiment analysis Persian dataset, which is collected from Persian tweets. This dataset contains 12,000 tweets, annotated by 5 native Persian taggers. The aforementioned data is labeled in 3 classes: positive, neutral and negative. We present the characteristics and statistics of this dataset and use the pre-trained Pars Bert and Roberta as the base model to evaluate this dataset. Our evaluation reached a 79.87 Macro F-score, which shows the model and data can be adequately valuable for a sentiment analysis system.

</details>


### [19] [The Art of Efficient Reasoning: Data, Reward, and Optimization](https://arxiv.org/abs/2602.20945)
*Taiqiang Wu,Zenan Zu,Bo Zhou,Ngai Wong*

Main category: cs.CL

TL;DR: 该论文系统研究LLMs高效推理机制，提出两阶段训练范式，发现训练相对简单提示可避免长度崩溃，并将长度偏差跨领域泛化，在Qwen3系列模型上验证了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通过扩展思维链（CoT）推理获得持续收益，但面临沉重的计算开销。高效推理旨在激励短而准确的思维轨迹，通常通过强化学习（RL）进行奖励塑造。本文旨在系统研究LLMs高效推理的机制。

Method: 采用统一协议进行大规模实验（约20万GPU小时），解构训练提示和rollouts、奖励塑造和优化策略。提出更细粒度的评估指标，包括基于正确性的长度分布和从2k到32k的广泛token预算范围内的性能。在Qwen3系列模型（0.6B到30B）上进行验证。

Result: 发现训练过程遵循两阶段范式：长度适应和推理精炼。关键发现是训练相对简单的提示可以确保正奖励信号的密度，从而避免长度崩溃。同时，学习到的长度偏差可以跨领域泛化。所有发现都转化为有价值的见解和实践指南。

Conclusion: 论文系统揭示了LLMs高效推理的机制，提供了实用的训练指南，并在不同规模的模型上验证了鲁棒性和泛化能力，为开发计算高效的推理方法提供了重要见解。

Abstract: Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.

</details>


### [20] [Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models](https://arxiv.org/abs/2602.20966)
*Paola Merlo,Chunyang Jiang,Giuseppe Samo,Vivi Nastase*

Main category: cs.CL

TL;DR: 本文提出了一种受智力测试启发的新型语言任务——Blackbird Language Matrices (BLM)，构建了结构化多层级的多选题数据集，用于探究大语言模型检测语言对象、利用系统性模式的能力。


<details>
  <summary>Details</summary>
Motivation: 当前需要结构化数据集来探究大语言模型的核心能力：能否检测语言对象及其属性？能否识别和使用跨句子的系统性模式？语言错误和推理错误如何相互作用？传统数据集难以支持这种多方面的可解释性研究。

Method: 创建BLM数据集，包含多层级结构：句子内部、输入序列之间、候选答案内部。数据集经过人工精心构建，包含学习上下文和预期答案。使用简单基线模型和定制模型进行基准测试，特别关注分块和系统性实验。

Result: BLM任务虽然具有挑战性，但可以在多种语言中以良好性能解决。简单基线模型表现尚可，定制模型性能更优。模型表示中包含解决语言任务所需的语法对象和属性。解决方案通过检测跨句子的系统性模式实现。

Conclusion: 精心构建的结构化数据集支持对语言和大语言模型属性的多方面研究。BLM数据集因其结构化、包含学习上下文和答案、部分人工构建的特点，属于支持可解释性研究的类别，有助于理解大语言模型的行为机制。

Abstract: This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice problems, structured at multiple levels: within each sentence, across the input sequence, within each candidate answer. Because of their rich structure, these curated, but naturalistic datasets are key to answer some core questions about current large language models abilities: do LLMs detect linguistic objects and their properties? Do they detect and use systematic patterns across sentences? Are they more prone to linguistic or reasoning errors, and how do these interact?
  We show that BLMs, while challenging, can be solved at good levels of performance, in more than one language, with simple baseline models or, at better performance levels, with more tailored models. We show that their representations contain the grammatical objects and attributes relevant to solve a linguistic task. We also show that these solutions are reached by detecting systematic patterns across sentences.
  The paper supports the point of view that curated, structured datasets support multi-faceted investigations of properties of language and large language models. Because they present a curated, articulated structure, because they comprise both learning contexts and expected answers, and because they are partly built by hand, BLMs fall in the category of datasets that can support explainability investigations, and be useful to ask why large language models behave the way they do.

</details>


### [21] [Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving](https://arxiv.org/abs/2602.20973)
*Yuliang Ji,Fuchen Shen,Jian Wu,Qiujie Xie,Yue Zhang*

Main category: cs.CL

TL;DR: PC-FOL数据集：专注于案例推理的一阶逻辑数据集，揭示LLMs在线性推理与案例推理间的性能差距


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集主要关注线性推理，忽视了反证法、分情况证明等其他重要推理形式，这些对研究LLMs推理能力至关重要

Method: 引入由专业数学家标注的PC-FOL一阶逻辑数据集，专注于案例推理问题，所有实例都配备手写的自然语言证明；通过实验评估主流LLMs性能，并使用图模型进行理论分析

Result: 实验结果显示主流LLMs在线性推理和案例推理问题之间存在显著性能差距；图模型理论分析为这种差异提供了理论解释

Conclusion: PC-FOL数据集揭示了自动自然语言数学证明生成领域的核心挑战，为未来研究铺平道路，强调了案例推理在评估LLMs数学推理能力中的重要性

Abstract: To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by contradiction and proof by cases, which are crucial for investigating LLMs' reasoning abilities. To address this limitation, we first introduce a novel first-order logic (FOL) dataset named PC-FOL, annotated by professional mathematicians, focusing on case-based reasoning problems. All instances in this dataset are equipped with a manually written natural language proof, clearly distinguishing it from conventional linear reasoning datasets. Our experimental results over leading LLMs demonstrate a substantial performance gap between linear reasoning and case-based reasoning problems. To further investigate this phenomenon, we provide a theoretical analysis grounded in graphical model, which provides an explanation for the observed disparity between the two types of reasoning problems. We hope this work can reveal the core challenges in the field of automated natural language mathematical proof generation, paving the way for future research.

</details>


### [22] [Evaluating Proactive Risk Awareness of Large Language Models](https://arxiv.org/abs/2602.20976)
*Xuan Luo,Yubin Chen,Zhiyu Hou,Linpu Yu,Geng Tu,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 论文提出了一种主动风险意识评估框架，用于衡量LLMs是否能预见潜在危害并在损害发生前提供警告，构建了Butterfly数据集在环境生态领域进行验证，发现当前模型在长度限制、跨语言和物种保护方面存在显著盲区。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在日常决策中的广泛应用，其安全责任已从应对明确有害意图扩展到预见非意图但后果严重的风险。需要评估LLMs是否能主动识别潜在危害并提供预警，特别是在环境生态等关键领域。

Method: 1. 提出主动风险意识评估框架；2. 构建Butterfly数据集（1,094个查询），模拟可能产生潜在生态影响的普通解决方案寻求活动；3. 在五个广泛使用的LLMs上进行实验；4. 分析响应长度、语言和多模态的影响。

Result: 实验结果显示：1. 长度限制下主动意识显著下降；2. 跨语言表现相似；3. （多模态）物种保护存在持续盲点。这些发现揭示了当前安全对齐与实际生态责任要求之间的关键差距。

Conclusion: 当前LLMs的安全对齐不足以满足现实世界生态责任要求，突显了在LLM部署中需要主动安全防护措施的重要性。研究为评估和提升LLMs的主动风险意识提供了框架和基准。

Abstract: As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness evaluation framework that measures whether LLMs can anticipate potential harms and provide warnings before damage occurs. We construct the Butterfly dataset to instantiate this framework in the environmental and ecological domain. It contains 1,094 queries that simulate ordinary solution-seeking activities whose responses may induce latent ecological impact. Through experiments across five widely used LLMs, we analyze the effects of response length, languages, and modality. Experimental results reveal consistent, significant declines in proactive awareness under length-restricted responses, cross-lingual similarities, and persistent blind spots in (multimodal) species protection. These findings highlight a critical gap between current safety alignment and the requirements of real-world ecological responsibility, underscoring the need for proactive safeguards in LLM deployment.

</details>


### [23] [Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification](https://arxiv.org/abs/2602.21082)
*Vishal Patil,Shree Vaishnavi Bacha,Revanth Yamani,Yidan Sun,Mayank Kejriwal*

Main category: cs.CL

TL;DR: 该研究提出了一种混合方法，结合大语言模型进行方面识别和传统机器学习进行情感分类，以分析大规模客户评论，并在470万条餐厅评论上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 客户评论已成为企业和顾客的重要信息来源，但分析数百万条非结构化评论仍然具有挑战性。虽然大语言模型在自然语言理解方面表现出潜力，但其在大规模评论分析中的应用受到计算成本和可扩展性问题的限制。

Method: 提出混合方法：使用ChatGPT分析餐厅评论样本进行方面识别，然后基于人工标注的评论开发情感分类器，最后将该方法应用于从主要在线平台收集的17年间的470万条评论。使用回归分析验证机器标注的方面对餐厅总体评分的解释能力。

Result: 机器标注的方面能够显著解释餐厅总体评分的方差，涵盖不同用餐体验方面、菜系和地理区域。混合方法能够有效自动化大规模客户反馈的基于方面的情感分析。

Conclusion: 结合大语言模型与传统机器学习方法可以有效自动化大规模客户反馈的基于方面的情感分析，为酒店业及其他服务行业的研究者和从业者提供了一个实用框架。

Abstract: Customer-provided reviews have become an important source of information for business owners and other customers alike. However, effectively analyzing millions of unstructured reviews remains challenging. While large language models (LLMs) show promise for natural language understanding, their application to large-scale review analysis has been limited by computational costs and scalability concerns. This study proposes a hybrid approach that uses LLMs for aspect identification while employing classic machine-learning methods for sentiment classification at scale. Using ChatGPT to analyze sampled restaurant reviews, we identified key aspects of dining experiences and developed sentiment classifiers using human-labeled reviews, which we subsequently applied to 4.7 million reviews collected over 17 years from a major online platform. Regression analysis reveals that our machine-labeled aspects significantly explain variance in overall restaurant ratings across different aspects of dining experiences, cuisines, and geographical regions. Our findings demonstrate that combining LLMs with traditional machine learning approaches can effectively automate aspect-based sentiment analysis of large-scale customer feedback, suggesting a practical framework for both researchers and practitioners in the hospitality industry and potentially, other service sectors.

</details>


### [24] [PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data](https://arxiv.org/abs/2602.21165)
*Samah Fodeh,Linhai Ma,Yan Wang,Srivani Talakokkul,Ganesh Puthiaraju,Afshan Khan,Ashley Hagaman,Sarah Lowe,Aimee Roundtree*

Main category: cs.CL

TL;DR: PVminer：一个领域适应的NLP框架，用于结构化患者-提供者安全通信中的患者声音，通过多标签多分类预测整合患者特定BERT编码器和主题建模，在分层任务中实现高性能。


<details>
  <summary>Details</summary>
Motivation: 患者生成的文本（如安全消息、调查、访谈）包含丰富的患者声音表达，反映了沟通行为和社会健康决定因素。传统的定性编码框架劳动密集，无法扩展到医疗系统中的大量患者撰写消息。现有的ML/NLP方法提供部分解决方案，但通常将患者中心沟通和社会健康决定因素视为独立任务，或依赖不适合患者面向语言的模型。

Method: PVminer将患者声音检测制定为多标签多分类预测任务，整合患者特定BERT编码器（PV-BERT-base和PV-BERT-large）、用于主题增强的无监督主题建模（PV-Topic-BERT），以及针对Code、Subcode和Combo级标签的微调分类器。在微调和推理过程中融入主题表示以丰富语义输入。

Result: PVminer在分层任务中实现强劲性能，优于生物医学和临床预训练基线，F1分数达到82.25%（Code）、80.14%（Subcode）和最高77.87%（Combo）。消融研究进一步显示作者身份和基于主题的增强各自贡献了有意义的性能提升。

Conclusion: PVminer是一个有效的领域适应NLP框架，用于结构化患者声音，在患者-提供者通信中实现高性能的患者声音检测。预训练模型、源代码和文档将公开发布，标注数据集可根据研究请求提供。

Abstract: Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language. We introduce PVminer, a domain-adapted NLP framework for structuring patient voice in secure patient-provider communication. PVminer formulates PV detection as a multi-label, multi-class prediction task integrating patient-specific BERT encoders (PV-BERT-base and PV-BERT-large), unsupervised topic modeling for thematic augmentation (PV-Topic-BERT), and fine-tuned classifiers for Code, Subcode, and Combo-level labels. Topic representations are incorporated during fine-tuning and inference to enrich semantic inputs. PVminer achieves strong performance across hierarchical tasks and outperforms biomedical and clinical pre-trained baselines, achieving F1 scores of 82.25% (Code), 80.14% (Subcode), and up to 77.87% (Combo). An ablation study further shows that author identity and topic-based augmentation each contribute meaningful gains. Pre-trained models, source code, and documentation will be publicly released, with annotated datasets available upon request for research use.

</details>


### [25] [Multimodal Multi-Agent Empowered Legal Judgment Prediction](https://arxiv.org/abs/2601.12815)
*Zhaolu Kang,Junhao Gong,Qingxi Chen,Hao Zhang,Jiaxin Liu,Rong Fu,Zhiyuan Feng,Yuan Wang,Simon Fong,Kaiyue Zhou*

Main category: cs.CL

TL;DR: 提出JurisMMA框架用于法律判决预测，通过任务分解和流程标准化处理多指控、多样化证据问题，并构建包含10万+中文司法记录的JurisMM多模态数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 传统法律判决预测方法在处理多指控、多样化证据时面临挑战且缺乏适应性，需要更有效的框架来推动法律系统发展。

Method: 提出JurisMMA框架，有效分解审判任务、标准化流程并组织为不同阶段；构建包含文本和多模态视频-文本数据的JurisMM大型数据集。

Result: 在JurisMM和基准数据集LawBench上的实验验证了框架的有效性，表明该框架不仅适用于法律判决预测，还可用于更广泛的法律应用。

Conclusion: JurisMMA框架为法律判决预测提供了新视角，其多阶段标准化方法和多模态数据集为未来法律方法和数据集的发展开辟了新方向。

Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health](https://arxiv.org/abs/2602.20303)
*Joyanta Jyoti Mondal*

Main category: cs.AI

TL;DR: 该研究比较了统计、机器学习和深度学习模型在预测美国青少年超重/肥胖方面的表现，发现逻辑回归、梯度提升和多层感知器表现最稳定，模型复杂度增加带来的改进有限，且所有模型在不同种族和贫困群体间都存在性能差异。


<details>
  <summary>Details</summary>
Motivation: 儿童和青少年超重/肥胖是美国主要的公共卫生问题，受行为、家庭和社区因素共同影响。目前对这些多层次预测因素在人群层面的联合预测结构了解不足，且需要比较不同预测模型的性能、校准和亚组公平性。

Method: 使用2021年国家儿童健康调查中18,792名10-17岁儿童的数据。预测因素包括饮食、体育活动、睡眠、父母压力、社会经济条件、不良经历和社区特征。比较了逻辑回归、随机森林、梯度提升、XGBoost、LightGBM、多层感知器和TabNet等模型，使用AUC、准确率、精确率、召回率、F1分数和Brier分数进行评估。

Result: 模型区分度在0.66-0.79之间。逻辑回归、梯度提升和多层感知器在区分度和校准方面表现最稳定。提升方法和深度学习在召回率和F1分数上略有改善，但没有模型在所有方面都表现最优。所有算法在不同种族和贫困群体间都存在性能差异。

Conclusion: 增加模型复杂度对逻辑回归的改进有限。预测因素始终涵盖行为、家庭和社区领域。持续的亚组差异表明需要改进数据质量和关注公平性的监测，而不是追求更高的算法复杂度。

Abstract: Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.

</details>


### [27] [DMCD: Semantic-Statistical Framework for Causal Discovery](https://arxiv.org/abs/2602.20333)
*Samarth KaPatel,Sofia Nikiforova,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.AI

TL;DR: DMCD是一个两阶段因果发现框架，结合LLM语义草稿与统计验证，通过变量元数据生成稀疏DAG草稿，再经条件独立性测试精修，在多个真实世界基准上取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法通常仅依赖统计测试或结构约束，缺乏利用变量元数据中的语义信息。DMCD旨在整合LLM的语义理解能力与统计验证，提升因果结构学习的准确性和实用性。

Method: 两阶段框架：第一阶段使用大语言模型基于变量元数据生成稀疏DAG草稿，作为语义先验；第二阶段通过条件独立性测试审核和精修草稿，检测差异并指导有针对性的边修正。

Result: 在工业工程、环境监测和IT系统分析三个元数据丰富的真实世界基准上，DMCD相比多种因果发现基线方法取得竞争性或领先性能，尤其在召回率和F1分数上有显著提升。探针和消融实验表明改进源于元数据的语义推理而非基准图的记忆。

Conclusion: 将语义先验与原则性统计验证相结合，能够产生高性能且实际有效的因果结构学习方法，证明了整合语义推理与统计方法的价值。

Abstract: We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.
  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.

</details>


### [28] [Diffusion Modulation via Environment Mechanism Modeling for Planning](https://arxiv.org/abs/2602.20422)
*Hanping Zhang,Yuhong Guo*

Main category: cs.AI

TL;DR: DMEMM是一种新颖的基于扩散模型的规划方法，通过融入环境机制建模来调制扩散训练，解决了传统扩散规划中轨迹一致性问题，在离线强化学习规划中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于扩散模型的规划方法在离线强化学习中生成轨迹时，往往忽略了轨迹中状态转移的一致性要求，导致生成的轨迹与真实环境机制存在显著差异，影响规划的有效性。

Method: 提出DMEMM方法，通过融入关键RL环境机制（特别是转移动态和奖励函数）来调制扩散模型的训练过程，确保生成的轨迹在真实环境中具有一致性。

Result: 实验结果表明，DMEMM在离线强化学习规划任务中达到了最先进的性能水平。

Conclusion: 通过将环境机制建模融入扩散模型训练，DMEMM有效解决了轨迹一致性问题，为基于扩散模型的离线强化学习规划提供了更可靠的解决方案。

Abstract: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

</details>


### [29] [Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use](https://arxiv.org/abs/2602.20426)
*Ruocheng Guo,Kaiwen Dong,Xiang Gao,Kamalika Das*

Main category: cs.AI

TL;DR: Trace-Free+：一种无需执行轨迹的课程学习框架，通过渐进式监督转移优化工具接口，提升LLM智能体在未见工具上的泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体的性能不仅取决于智能体本身，还受限于其使用的工具接口质量。现有工具接口主要面向人类设计，在大规模工具选择场景中成为瓶颈。现有改进方法依赖执行轨迹，这在冷启动或隐私受限场景中不可用，且通常独立优化每个工具，限制了可扩展性和对未见工具的泛化能力。

Method: 提出Trace-Free+课程学习框架，渐进式地将监督从轨迹丰富的设置转移到无轨迹部署，鼓励模型抽象可重用的接口使用模式和工具使用结果。构建大规模高质量工具接口数据集，使用结构化工作流程处理多样化工具集合。

Result: 在StableToolBench和RestBench上的实验显示，对未见工具取得一致性能提升，表现出强大的跨领域泛化能力，并且在候选工具数量超过100时仍保持鲁棒性，证明工具接口优化是智能体微调的实际可行补充方案。

Conclusion: 工具接口优化是提升LLM智能体性能的关键补充策略，Trace-Free+框架通过课程学习实现了无需执行轨迹的接口优化，在可扩展性、泛化能力和部署实用性方面表现出色。

Abstract: The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavailable in cold-start or privacy-constrained settings, and typically optimize each tool independently, limiting scalability and generalization to unseen tools. We propose Trace-Free+, a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment, encouraging the model to abstract reusable interface-usage patterns and tool usage outcomes. To support this approach, we construct a large-scale dataset of high-quality tool interfaces using a structured workflow over a diverse collection of tools. Experiments on StableToolBench and RestBench show consistent gains on unseen tools, strong cross-domain generalization, and robustness as the number of candidate tools scales to over 100, demonstrating that tool interface optimization is a practical and deployable complement to agent fine-tuning.

</details>


### [30] [PreScience: A Benchmark for Forecasting Scientific Contributions](https://arxiv.org/abs/2602.20459)
*Anirudh Ajith,Amanpreet Singh,Jay DeYoung,Nadav Kunievsky,Austin C. Kozlowski,Oyvind Tafjord,James Evans,Daniel S. Weld,Tom Hope,Doug Downey*

Main category: cs.AI

TL;DR: PreScience是一个科学预测基准，将研究过程分解为四个相互依赖的生成任务：合作者预测、先前工作选择、贡献生成和影响力预测，用于评估AI系统能否基于历史科学记录预测未来科学进展。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索AI系统能否基于固定时间点之前的科学记录预测未来的科学进展。这种能力可以帮助研究人员识别合作者、发现有影响力的研究方向，并预测哪些问题和方法将成为未来的核心。

Method: 方法包括：1) 构建PreScience基准数据集，包含98K篇近期AI相关研究论文，具有消歧的作者身份、时间对齐的学术元数据，以及包含502K篇论文的作者发表历史和引用结构化图；2) 为四个任务开发基线和评估方法；3) 提出LACERScore，一种基于LLM的贡献相似性度量方法，优于先前指标并接近人工标注者间一致性。

Result: 结果显示：1) 在贡献生成任务中，前沿LLM仅达到中等相似度（GPT-5平均5.6分，1-10分制）；2) 每个任务仍有显著改进空间；3) 当组合成12个月的端到端科学生产模拟时，生成的合成语料库在多样性和新颖性方面系统性低于同期人类撰写的研究。

Conclusion: 结论表明AI系统在科学预测方面仍有很大提升空间，当前方法生成的科学研究在多样性和新颖性上不如人类研究，需要进一步改进模型以更好地预测和模拟科学进展。

Abstract: Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.

</details>


### [31] [KairosVL: Orchestrating Time Series and Semantics for Unified Reasoning](https://arxiv.org/abs/2602.20494)
*Haotian Si,Changhua Pei,Xiao He,Zeyan Li,Zhe Xie,Zexin Wang,Jiyao Hu,Zhaoyang Yu,Tieying Zhang,Dan Pei,Jianhui Li,Gaogang Xie*

Main category: cs.AI

TL;DR: 提出语义条件时间序列推理任务和KairosVL模型，通过两轮强化学习框架结合语义理解与时间序列分析，提升复杂决策能力。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分析主要关注数值建模，缺乏对上下文和语义的理解。随着时间序列分析需求日益复杂和决策导向，需要将语义理解融入时间序列分析，以处理更复杂的现实世界问题。

Method: 提出语义条件时间序列推理任务，并设计两轮强化学习框架：第一轮增强模型对基本时间原语的感知能力，第二轮专注于语义条件推理。最终构建KairosVL模型。

Result: KairosVL在合成和真实世界任务中均取得有竞争力的性能。大量实验和消融研究表明，该框架不仅提升性能，还保留内在推理能力，并显著提高对未见场景的泛化能力。

Conclusion: 该工作展示了将语义推理与时间建模结合的潜力，为现实世界时间序列智能提供了实用框架，满足了当前对复杂时间序列分析的迫切需求。

Abstract: Driven by the increasingly complex and decision-oriented demands of time series analysis, we introduce the Semantic-Conditional Time Series Reasoning task, which extends conventional time series analysis beyond purely numerical modeling to incorporate contextual and semantic understanding. To further enhance the mode's reasoning capabilities on complex time series problems, we propose a two-round reinforcement learning framework: the first round strengthens the mode's perception of fundamental temporal primitives, while the second focuses on semantic-conditioned reasoning. The resulting model, KairosVL, achieves competitive performance across both synthetic and real-world tasks. Extensive experiments and ablation studies demonstrate that our framework not only boosts performance but also preserves intrinsic reasoning ability and significantly improves generalization to unseen scenarios. To summarize, our work highlights the potential of combining semantic reasoning with temporal modeling and provides a practical framework for real-world time series intelligence, which is in urgent demand.

</details>


### [32] [From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production](https://arxiv.org/abs/2602.20558)
*Yucheng Shi,Ying Li,Yu Wang,Yesu Feng,Arjun Rao,Rein Houthooft,Shradha Sehgal,Jin Wang,Hao Zhen,Ninghao Liu,Linas Baltrunas*

Main category: cs.AI

TL;DR: 提出基于强化学习的数据中心化框架，学习将结构化用户交互日志转化为优化文本表示，显著提升LLM推荐系统性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统面临关键挑战：如何将结构化用户交互日志有效转化为自然语言输入。传统方法依赖简单拼接字段的固定模板，产生次优表示，限制了推荐性能。

Method: 提出数据中心化框架，使用强化学习训练verbalization agent，将原始交互历史转化为优化文本上下文。以推荐准确率作为训练信号，学习过滤噪声、整合相关元数据、重组信息以提升下游预测。

Result: 在大规模工业流媒体数据集上的实验表明，学习到的verbalization相比基于模板的基线方法，在发现项推荐准确率上获得高达93%的相对提升。分析揭示了用户兴趣总结、噪声去除和语法规范化等涌现策略。

Conclusion: 学习verbalization能显著提升LLM推荐系统性能，为基于LLM的推荐系统提供了有效的上下文构建洞察。该方法展示了数据驱动verbalization策略的重要性。

Abstract: Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalization agent transforms raw interaction histories into optimized textual contexts, with recommendation accuracy as the training signal. This agent learns to filter noise, incorporate relevant metadata, and reorganize information to improve downstream predictions. Experiments on a large-scale industrial streaming dataset show that learned verbalization delivers up to 93% relative improvement in discovery item recommendation accuracy over template-based baselines. Further analysis reveals emergent strategies such as user interest summarization, noise removal, and syntax normalization, offering insights into effective context construction for LLM-based recommender systems.

</details>


### [33] [Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination](https://arxiv.org/abs/2602.20517)
*Rakshit Trivedi,Kartik Sharma,David C Parkes*

Main category: cs.AI

TL;DR: MIMIC框架使用语言作为行为意图的内部表示，通过视觉语言模型训练条件变分自编码器生成内部语音，再结合扩散行为克隆策略实现细粒度行为控制


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法难以捕捉人类行为的多样性和非马尔可夫特性，且缺乏在推理时引导行为的能力。受人类认知过程中内部语音指导行动选择的理论启发，需要开发能够生成内部语音表示并实现细粒度行为控制的框架

Method: 提出MIMIC框架：1) 使用视觉语言模型作为语言支架训练条件变分自编码器，从观察中生成内部语音；2) 采用基于扩散的行为克隆策略，根据当前观察和生成的内部语音选择行动；3) 在推理时通过条件化特定行为语音实现细粒度行为引导

Result: 在机器人操作任务和人机协作游戏中的实验表明，MIMIC显著提高了行为多样性和对人类演示的保真度，同时无需额外演示训练即可实现细致的行为引导

Conclusion: MIMIC通过语言作为行为意图的内部表示，成功解决了模仿学习中行为多样性和推理时控制能力的挑战，为人机协调提供了更灵活、适应性更强的智能体

Abstract: Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the theory of human cognitive processes, where inner speech guides action selection before execution, we propose MIMIC (Modeling Inner Motivations for Imitation and Control), a framework that uses language as an internal representation of behavioral intent. MIMIC employs the novel use of vision-language models as linguistic scaffolding to train a conditional variational autoencoder capable of generating inner speech from observations. A diffusion-based behavior cloning policy then selects actions conditioned on current observations and the generated inner speech. MIMIC enables fine-grained steering of behavior at inference time by conditioning the agent on behavior-specific speech. Experiments across robotic manipulation tasks and human-AI collaboration games demonstrate that MIMIC significantly enhances both behavior diversity and fidelity to human demonstrations while enabling nuanced behavioral steering without training on additional demonstrations. We open source our code and provide pre-trained MIMIC agents and qualitative demos at: https://mimic-research.github.io.

</details>


### [34] [A Benchmark for Deep Information Synthesis](https://arxiv.org/abs/2602.21143)
*Debjit Paul,Daniel Murphy,Milan Gritta,Ronald Cardenas,Victor Prokhorov,Lena Sophia Bolliger,Aysim Toker,Roy Miles,Andreea-Maria Oncescu,Jasivan Alex Sivakumar,Philipp Borchert,Ismail Elezi,Meiru Zhang,Ka Yiu Lee,Guchun Zhang,Jun Wang,Gerasimos Lampouras*

Main category: cs.AI

TL;DR: DEEPSYNTH是一个评估LLM智能体解决复杂现实任务能力的新基准，包含120个跨7个领域和67个国家的任务，要求信息收集、综合和结构化推理，当前最先进模型在该基准上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体的评估基准无法充分评估其解决现实世界复杂任务的能力，这些任务需要从多个来源综合信息并进行超越简单事实检索的推理洞察。

Method: 采用多阶段数据收集流程构建DEEPSYNTH基准：收集官方数据源、创建假设、进行手动分析、设计具有可验证答案的任务。包含120个跨7个领域和67个国家的任务。

Result: 在DEEPSYNTH上评估11个最先进的LLM和深度研究智能体，最大F1分数仅为8.97，LLM-judge指标为17.5，表明基准难度很高。分析显示当前智能体存在幻觉问题，难以在大信息空间中进行推理。

Conclusion: DEEPSYNTH是一个关键的评估基准，揭示了当前LLM智能体在解决复杂现实任务时的局限性，特别是信息综合和推理方面的挑战，为未来研究提供了重要指导。

Abstract: Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.

</details>


### [35] [CausalReasoningBenchmark: A Real-World Benchmark for Disentangled Evaluation of Causal Identification and Estimation](https://arxiv.org/abs/2602.20571)
*Ayush Sawarni,Jiyuan Tan,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 提出CausalReasoningBenchmark基准测试，将因果推理分解为识别和估计两个独立步骤进行评分，包含173个查询和138个真实数据集，用于诊断自动化因果推理系统的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有因果推理基准通常只评估单一数值输出（如平均处理效应），混淆了因果分析的两个关键步骤：识别（在给定假设下制定有效研究设计）和估计（在有限数据上数值实现设计）。这种混淆使得无法区分因果推理失败和数值执行错误。

Method: 构建包含173个查询、138个真实数据集的基准测试，数据来源于85篇同行评审论文和4本广泛使用的因果推理教材。要求系统为每个查询生成：(1)结构化识别规范，包括策略名称、处理变量、结果变量、控制变量及所有设计特定元素；(2)点估计和标准误。对这两个组件分别评分。

Result: 使用最先进的大语言模型作为基线，结果显示模型在84%的情况下能正确识别高层策略，但完整识别规范的正确率仅为30%。这表明瓶颈在于研究设计的细微细节而非计算过程。

Conclusion: CausalReasoningBenchmark通过分离识别和估计的评分，实现了对自动化因果推理系统的细粒度诊断。基准测试已在Hugging Face公开，旨在促进更稳健的自动化因果推理系统的发展。

Abstract: Many benchmarks for automated causal inference evaluate a system's performance based on a single numerical output, such as an Average Treatment Effect (ATE). This approach conflates two distinct steps in causal analysis: identification-formulating a valid research design under stated assumptions-and estimation-implementing that design numerically on finite data. We introduce CausalReasoningBenchmark, a benchmark of 173 queries across 138 real-world datasets, curated from 85 peer-reviewed research papers and four widely-used causal-inference textbooks. For each query a system must produce (i) a structured identification specification that names the strategy, the treatment, outcome, and control variables, and all design-specific elements, and (ii) a point estimate with a standard error. By scoring these two components separately, our benchmark enables granular diagnosis: it distinguishes failures in causal reasoning from errors in numerical execution. Baseline results with a state-of-the-art LLM show that, while the model correctly identifies the high-level strategy in 84 % of cases, full identification-specification correctness drops to only 30 %, revealing that the bottleneck lies in the nuanced details of research design rather than in computation. CausalReasoningBenchmark is publicly available on Hugging Face and is designed to foster the development of more robust automated causal-inference systems.

</details>


### [36] [When can we trust untrusted monitoring? A safety case sketch across collusion strategies](https://arxiv.org/abs/2602.20628)
*Nelson Gardner-Challis,Jonathan Bostock,Georgiy Kozhevnikov,Morgan Sinclaire,Joan Velja,Alessandro Abate,Charlie Griffin*

Main category: cs.AI

TL;DR: 论文研究了不可信监控的安全性，放松了先前AI控制研究中关于恶意AI合谋策略的假设，开发了包含被动自我识别、因果合谋、非因果合谋等策略的分类法，并构建了安全案例框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI自主性和能力的增强，错位AI可能造成灾难性伤害的风险增加。不可信监控（用一个不可信模型监督另一个）是降低风险的方法之一，但由于无法安全部署错位模型直接测试协议，证明其安全性具有挑战性。

Method: 基于已有的预部署测试方法，放松了先前AI控制研究中关于恶意AI合谋策略的假设，开发了包含被动自我识别、因果合谋（隐藏预共享信号）、非因果合谋（通过谢林点隐藏信号）及组合策略的分类法，创建了安全案例框架来明确呈现论证、假设和未解决问题。

Result: 确定了被动自我识别可能比先前研究的策略更有效的条件，为不可信监控的更稳健评估奠定了基础。

Conclusion: 该研究通过放松合谋策略假设和开发分类法，推进了不可信监控的安全性论证，识别了关键挑战，为未来更稳健的安全评估提供了框架。

Abstract: AIs are increasingly being deployed with greater autonomy and capabilities, which increases the risk that a misaligned AI may be able to cause catastrophic harm. Untrusted monitoring -- using one untrusted model to oversee another -- is one approach to reducing risk. Justifying the safety of an untrusted monitoring deployment is challenging because developers cannot safely deploy a misaligned model to test their protocol directly. In this paper, we develop upon existing methods for rigorously demonstrating safety based on pre-deployment testing. We relax assumptions that previous AI control research made about the collusion strategies a misaligned AI might use to subvert untrusted monitoring. We develop a taxonomy covering passive self-recognition, causal collusion (hiding pre-shared signals), acausal collusion (hiding signals via Schelling points), and combined strategies. We create a safety case sketch to clearly present our argument, explicitly state our assumptions, and highlight unsolved challenges. We identify conditions under which passive self-recognition could be a more effective collusion strategy than those studied previously. Our work builds towards more robust evaluations of untrusted monitoring.

</details>


### [37] [Identifying two piecewise linear additive value functions from anonymous preference information](https://arxiv.org/abs/2602.20638)
*Vincent Auriau,Khaled Belahcene,Emmanuel Malherbe,Vincent Mousseau,Marc Pirlot*

Main category: cs.AI

TL;DR: 提出一种同时从两位决策者中引出偏好模型的程序，通过同时查询两人获得两个答案（但不知道哪个答案对应哪个决策者），在边际价值函数为分段线性且断点已知的条件下识别出两个偏好模型。


<details>
  <summary>Details</summary>
Motivation: 在同时查询两位决策者时，虽然能获得两个答案，但不知道哪个答案对应哪个决策者，这给偏好模型的引出带来了挑战。需要开发一种方法能够在不知道答案归属的情况下，同时识别出两位决策者的偏好模型。

Method: 提出一种引出程序，假设偏好可以用加性价值函数表示，且边际价值函数是分段线性的，断点已知。通过同时向两位决策者提问，获得两个答案（无噪声），在不知道答案对应关系的情况下，利用分段线性结构的特性来识别两个价值函数。

Result: 该方法能够在边际价值函数为分段线性且断点已知的条件下，成功识别出两位决策者各自的偏好模型，即使不知道哪个答案对应哪个决策者。

Conclusion: 提出的引出程序解决了同时从两位决策者引出偏好模型的问题，在特定假设下（加性价值函数、分段线性边际函数、已知断点）能够有效识别两个偏好模型，为群体决策分析提供了新方法。

Abstract: Eliciting a preference model involves asking a person, named decision-maker, a series of questions. We assume that these preferences can be represented by an additive value function. In this work, we query simultaneously two decision-makers in the aim to elicit their respective value functions. For each query we receive two answers, without noise, but without knowing which answer corresponds to which decision-maker.We propose an elicitation procedure that identifies the two preference models when the marginal value functions are piecewise linear with known breaking points.

</details>


### [38] [Grounding LLMs in Scientific Discovery via Embodied Actions](https://arxiv.org/abs/2602.20639)
*Bo Zhang,Jinfeng Zhou,Yuxuan Chen,Jianing Yin,Minlie Huang,Hongning Wang*

Main category: cs.AI

TL;DR: EmbodiedAct框架将科学软件转化为具身智能体，通过紧密的感知-执行循环让LLM在物理仿真中实现主动感知和动态调整


<details>
  <summary>Details</summary>
Motivation: 现有LLM在科学发现中难以弥合理论推理与可验证物理仿真之间的鸿沟，传统"执行-响应"被动循环缺乏运行时感知能力，无法处理瞬态异常（如数值不稳定或发散振荡）

Method: 提出EmbodiedAct框架，将成熟科学软件转化为主动具身智能体，通过将LLM与具身动作相结合，建立紧密的感知-执行循环，在MATLAB环境中实现该框架

Result: 在复杂工程设计和科学建模任务上的广泛实验表明，EmbodiedAct显著优于现有基线，达到SOTA性能，确保长时程仿真的满意可靠性和稳定性，并提升科学建模的准确性

Conclusion: EmbodiedAct通过将科学软件转化为具身智能体，有效解决了LLM在物理仿真中的感知-执行脱节问题，为科学发现提供了更可靠和稳定的仿真环境

Abstract: Large Language Models (LLMs) have shown significant potential in scientific discovery but struggle to bridge the gap between theoretical reasoning and verifiable physical simulation. Existing solutions operate in a passive "execute-then-response" loop and thus lacks runtime perception, obscuring agents to transient anomalies (e.g., numerical instability or diverging oscillations). To address this limitation, we propose EmbodiedAct, a framework that transforms established scientific software into active embodied agents by grounding LLMs in embodied actions with a tight perception-execution loop. We instantiate EmbodiedAct within MATLAB and evaluate it on complex engineering design and scientific modeling tasks. Extensive experiments show that EmbodiedAct significantly outperforms existing baselines, achieving SOTA performance by ensuring satisfactory reliability and stability in long-horizon simulations and enhanced accuracy in scientific modeling.

</details>


### [39] [Recursive Belief Vision Language Model](https://arxiv.org/abs/2602.20659)
*Vaidehi Bagaria,Bijo Sebastian,Nirav Patel*

Main category: cs.AI

TL;DR: RB-VLA：基于信念的视觉语言动作模型，通过自监督世界模型目标训练，维护紧凑的潜在状态编码任务历史、动态和物体交互，解决长时程操作中的部分可观测性问题，显著提升多阶段任务成功率并降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言动作模型在部分可观测条件下的长时程操作中存在困难。现有方法主要依赖观测驱动，使用短上下文窗口或重复查询视觉语言模型，导致任务进度丢失、感知混淆下的动作重复和高推理延迟。语义推理并非主要瓶颈，而是缺乏持久、动作条件的状态表示以及有限的时空和物理推理能力。

Method: 提出RB-VLA，基于信念中心的架构，通过自监督世界模型目标训练，维护紧凑的潜在状态编码任务相关历史、动态和物体交互。VLM仅用于高层意图查询，信念模块跟踪任务进度，在部分可观测条件下实现阶段感知、因果基础的控制，无需存储原始观测或随时间扩展内存。信念和意图共同调节扩散策略进行鲁棒闭环执行。

Result: 在长时程基准测试中优于现有VLA模型：多阶段拾放任务成功率提高52.5%，堆叠任务提高37.5%（相比π0）。推理延迟降低高达5倍，消除了现有VLA中随时间步增长的内存问题。消融实验显示信念模块是性能提升的主要驱动力，成功率从32.5%提升至77.5%。

Conclusion: 基于信念的状态表示对于长时程VLA策略具有显著效果。RB-VLA通过信念中心架构解决了部分可观测性、时间推理和物理推理的挑战，为长时程操作任务提供了更有效的解决方案。

Abstract: Current vision-language-action (VLA) models struggle with long-horizon manipulation under partial observability. Most existing approaches remain observation-driven, relying on short context windows or repeated queries to vision-language models (VLMs). This leads to loss of task progress, action repetition under perceptual aliasing, and high inference latency. Semantic reasoning alone is not the primary bottleneck in long-horizon manipulation. Instead, VLAs lack persistent, action-conditioned state representations and exhibit limited temporal and physical reasoning, making them ill-suited for multi-stage control. This paper introduces RB-VLA, a belief-centric architecture trained with self-supervised world-model objectives that maintains a compact latent state encoding task-relevant history, dynamics, and object interactions. Queried once for high-level intent, the VLM provides task specification, while the belief tracks task progress and enables phase-aware, causally grounded control under partial observability without storing raw observations or scaling memory with time. The belief and intent jointly condition a diffusion policy for robust closed-loop execution. RB-VLA outperforms prior VLAs on long-horizon benchmarks, achieving 52.5% and 37.5% higher success on multi-stage pick-and-place and stacking tasks, respectively, compared to π0. It also reduces inference latency by up to 5x relative to baselines and eliminates memory growth across timesteps observed in existing VLAs. Ablations show that the belief module is the primary driver of performance, increasing success rates from 32.5% to 77.5%. These results demonstrate the effectiveness of belief-based state representations for long-horizon VLA policies.

</details>


### [40] [How Foundational Skills Influence VLM-based Embodied Agents:A Native Perspective](https://arxiv.org/abs/2602.20687)
*Bo Peng,Pi Bu,Keyu Pan,Xinrun Xu,Yinxiu Zhao,Miao Chen,Yang Du,Lin Li,Jun Song,Tong Xu*

Main category: cs.AI

TL;DR: NativeEmbodied是一个用于视觉语言模型驱动具身智能体的基准测试，采用统一的原生低级动作空间，包含高级任务和低级技能任务的双粒度评估。


<details>
  <summary>Details</summary>
Motivation: 现有VLM驱动具身智能体的基准测试存在两个主要问题：1) 使用高级命令或离散化动作空间，这与真实世界控制存在显著差异；2) 主要关注高级任务，缺乏对低级和高级能力的联合评估分析。

Method: 构建NativeEmbodied基准测试，基于多样化模拟场景，包含三个代表性高级任务评估整体性能，同时解耦复杂任务所需技能，构建四类低级任务分别针对基础具身技能，实现任务和技能粒度的联合评估。

Result: 实验显示最先进的VLMs在多个基础具身技能上存在明显缺陷，进一步分析表明这些瓶颈显著限制了高级任务的性能表现。

Conclusion: NativeEmbodied揭示了当前VLM驱动具身智能体的关键挑战，为未来研究提供了指导方向，强调了统一原生动作空间和双粒度评估的重要性。

Abstract: Recent advances in vision-language models (VLMs) have shown promise for human-level embodied intelligence. However, existing benchmarks for VLM-driven embodied agents often rely on high-level commands or discretized action spaces, which are non-native settings that differ markedly from real-world control. In addition, current benchmarks focus primarily on high-level tasks and lack joint evaluation and analysis at both low and high levels. To address these limitations, we present NativeEmbodied, a challenging benchmark for VLM-driven embodied agents that uses a unified, native low-level action space. Built on diverse simulated scenes, NativeEmbodied includes three representative high-level tasks in complex scenarios to evaluate overall performance. For more detailed analysis, we further decouple the skills required by complex tasks and construct four types of low-level tasks, each targeting a fundamental embodied skill. This joint evaluation across task and skill granularities enables fine-grained assessment of embodied agents. Experiments with state-of-the-art VLMs reveal clear deficiencies in several fundamental embodied skills, and further analysis shows that these bottlenecks significantly limit performance on high-level tasks. NativeEmbodied highlights key challenges for current VLM-driven embodied agents and provides insights to guide future research.

</details>


### [41] [PromptCD: Test-Time Behavior Enhancement via Polarity-Prompt Contrastive Decoding](https://arxiv.org/abs/2602.20696)
*Baolong Bi,Yuyao Ge,Shenghua Liu,Yuchen He,Siqian Tong,Lizhe Chen,Lingrui Mei,Zehao Li,Yiwei Wang,Yujun Cai,Ming-Hsuan Yang,Xueqi Cheng*

Main category: cs.AI

TL;DR: 提出PromptCD方法，通过构建正负引导提示对比模型响应，实现无需额外训练的多模态行为控制


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法大多需要训练时操作和高质量数据，计算和标注成本高；对比解码方法适用范围有限，难以扩展到广泛的行为控制场景

Method: 提出Polarity-Prompt Contrastive Decoding (PromptCD)：为目标行为构建正负引导提示对，对比模型响应（LLMs中的token级概率分布和VLMs中的视觉注意力模式），强化期望结果

Result: 在LLMs的"3H"对齐目标上取得一致且显著的改进；在VLMs中显著提升VQA性能，通过强化行为一致的视觉基础

Conclusion: PromptCD是一种简单、通用且成本高效的策略，可在无需额外训练的情况下实现跨模态的可靠行为控制

Abstract: Reliable AI systems require large language models (LLMs) to exhibit behaviors aligned with human preferences and values. However, most existing alignment approaches operate at training time and rely on additional high-quality data, incurring significant computational and annotation costs. While recent work has shown that contrastive decoding can leverage a model's internal distributions to improve specific capabilities, its applicability remains limited to narrow behavioral scopes and scenarios. In this work, we introduce Polarity-Prompt Contrastive Decoding (PromptCD), a test-time behavior control method that generalizes contrastive decoding to broader enhancement settings. PromptCD constructs paired positive and negative guiding prompts for a target behavior and contrasts model responses-specifically token-level probability distributions in LLMs and visual attention patterns in VLMs-to reinforce desirable outcomes. This formulation extends contrastive decoding to a wide range of enhancement objectives and is applicable to both LLMs and Vision-Language Models (VLMs) without additional training. For LLMs, experiments on the "3H" alignment objectives (helpfulness, honesty, and harmlessness) demonstrate consistent and substantial improvements, indicating that post-trained models can achieve meaningful self-enhancement purely at test time. For VLMs, we further analyze contrastive effects on visual attention, showing that PromptCD significantly improves VQA performance by reinforcing behavior-consistent visual grounding. Collectively, these results highlight PromptCD as a simple, general, and cost-efficient strategy for reliable behavior control across modalities.

</details>


### [42] [Online Algorithms with Unreliable Guidance](https://arxiv.org/abs/2602.20706)
*Julien Dallot,Yuval Emek,Yuval Gil,Maciej Pacut,Stefan Schmid*

Main category: cs.AI

TL;DR: 提出OAG模型分离预测与算法组件，通过DTB编译器将在线算法转化为学习增强算法，在缓存、度量任务系统和二分图匹配问题上获得最优或优于现有方法的性能保证


<details>
  <summary>Details</summary>
Motivation: 现有机器学习增强的在线决策模型通常将预测组件与算法组件紧密耦合，缺乏统一的分析框架。本文旨在建立一个完全分离预测与算法组件的模型，提供单一、明确定义的分析框架，使平滑性概念自然地从一致性过渡到鲁棒性

Method: 提出OAG模型：将在线决策建模为请求-回答游戏，算法接收来自问题答案空间的指导信息（可能被对抗性污染）。开发DTB编译器：将任何在线算法转化为学习增强算法，通过有偏硬币决定是盲目跟随指导还是忽略指导执行原始算法

Result: DTB编译器生成的算法在三个经典在线问题上获得优异性能：对于缓存和均匀度量任务系统，算法达到最优；对于二分图匹配（对抗性到达顺序），算法性能优于现有最佳方法

Conclusion: OAG模型为机器学习增强的在线决策提供了统一的分析框架，DTB编译器提供了一种系统化方法将传统在线算法转化为学习增强算法，在多个重要问题上实现了最优或接近最优的一致性-鲁棒性权衡

Abstract: This paper introduces a new model for ML-augmented online decision making, called online algorithms with unreliable guidance (OAG). This model completely separates between the predictive and algorithmic components, thus offering a single well-defined analysis framework that relies solely on the considered problem. Formulated through the lens of request-answer games, an OAG algorithm receives, with each incoming request, a piece of guidance which is taken from the problem's answer space; ideally, this guidance is the optimal answer for the current request, however with probability $β$, the guidance is adversarially corrupted. The goal is to develop OAG algorithms that admit good competitiveness when $β= 0$ (a.k.a. consistency) as well as when $β= 1$ (a.k.a. robustness); the appealing notion of smoothness, that in most prior work required a dedicated loss function, now arises naturally as $β$ shifts from $0$ to $1$.
  We then describe a systematic method, called the drop or trust blindly (DTB) compiler, which transforms any online algorithm into a learning-augmented online algorithm in the OAG model. Given a prediction-oblivious online algorithm, its learning-augmented counterpart produced by applying the DTB compiler either follows the incoming guidance blindly or ignores it altogether and proceeds as the initial algorithm would have; the choice between these two alternatives is based on the outcome of a (biased) coin toss. As our main technical contribution, we prove (rigorously) that although remarkably simple, the class of algorithms produced via the DTB compiler includes algorithms with attractive consistency-robustness guarantees for three classic online problems: for caching and uniform metrical task systems our algorithms are optimal, whereas for bipartite matching (with adversarial arrival order), our algorithm outperforms the state-of-the-art.

</details>


### [43] [Counterfactual Simulation Training for Chain-of-Thought Faithfulness](https://arxiv.org/abs/2602.20710)
*Peter Hase,Christopher Potts*

Main category: cs.AI

TL;DR: 提出Counterfactual Simulation Training (CST)训练方法，通过奖励能在反事实输入下准确预测模型输出的思维链，提高LLM思维链的忠实性。


<details>
  <summary>Details</summary>
Motivation: 思维链推理是理解LLM输出的常用方法，但思维链的忠实性问题严重限制了从中获得的洞察。现有方法存在思维链不忠实的问题，需要改进思维链的忠实性以更好地理解和监控模型行为。

Method: 提出Counterfactual Simulation Training (CST)训练方法：1) 基于线索的反事实思维链监控，检测模型是否依赖虚假特征、奖励黑客行为或奉承；2) 基于通用模型的反事实模拟，鼓励模型在思维链中产生更忠实、可泛化的推理。通过强化学习奖励能在反事实输入下准确预测模型输出的思维链。

Result: 在高达235B参数的模型上实验显示：CST显著提高基于线索反事实的监控准确率（提升35个准确点）和通用反事实的可模拟性（提升2点）。CST优于提示基线，用LLM重写不忠实思维链比单独使用RL效率高5倍，忠实性改进不泛化到劝阻线索，更大模型不会自动产生更忠实思维链但能从CST中获益更多。

Conclusion: CST能普遍提高思维链的忠实性，在思维链监控方面有良好应用前景。代码已开源。

Abstract: Inspecting Chain-of-Thought reasoning is among the most common means of understanding why an LLM produced its output. But well-known problems with CoT faithfulness severely limit what insights can be gained from this practice. In this paper, we introduce a training method called Counterfactual Simulation Training (CST), which aims to improve CoT faithfulness by rewarding CoTs that enable a simulator to accurately predict a model's outputs over counterfactual inputs. We apply CST in two settings: (1) CoT monitoring with cue-based counterfactuals, to detect when models rely on spurious features, reward hack, or are sycophantic, and (2) counterfactual simulation over generic model-based counterfactuals, to encourage models to produce more faithful, generalizable reasoning in the CoT. Experiments with models up to 235B parameters show that CST can substantially improve monitor accuracy on cue-based counterfactuals (by 35 accuracy points) as well as simulatability over generic counterfactuals (by 2 points). We further show that: (1) CST outperforms prompting baselines, (2) rewriting unfaithful CoTs with an LLM is 5x more efficient than RL alone, (3) faithfulness improvements do not generalize to dissuading cues (as opposed to persuading cues), and (4) larger models do not show more faithful CoT out of the box, but they do benefit more from CST. These results suggest that CST can improve CoT faithfulness in general, with promising applications for CoT monitoring. Code for experiments in this paper is available at https://github.com/peterbhase/counterfactual-simulation-training

</details>


### [44] [Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning](https://arxiv.org/abs/2602.20722)
*Xu Wan,Yansheng Wang,Wenqi Huang,Mingyang Sun*

Main category: cs.AI

TL;DR: BAPO是一种用于大语言模型后训练的离策略RLVR框架，通过动态选择训练批次和重用高质量样本，解决了传统RLVR框架的经验浪费和奖励同质化问题，显著提升了数据效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于策略的RLVR框架存在经验浪费和奖励同质化问题，这直接阻碍了大语言模型后训练中困难样本的学习效率。需要一种更高效的数据利用方法来提升模型在复杂任务上的表现。

Method: 提出Batch Adaptation Policy Optimization (BAPO)，这是一种离策略RLVR框架。它通过重新评估历史困难样本并重用高质量样本来动态选择训练批次，同时保持策略改进的下界保证。

Result: 实验表明，BAPO在数学、规划和视觉推理任务上平均比GRPO提升了12.5%。更重要的是，BAPO成功解决了基础模型持续无法解决的40.7%的问题。

Conclusion: BAPO通过改进数据效率和样本选择机制，有效解决了传统RLVR框架的局限性，显著提升了大语言模型在复杂任务上的后训练效果，特别是在处理困难样本方面表现出色。

Abstract: Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.

</details>


### [45] [Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback](https://arxiv.org/abs/2602.20728)
*Chenyang Zhao,Vinny Cahill,Ivana Dusparic*

Main category: cs.AI

TL;DR: 该论文将基于AI反馈的强化学习（RLAIF）扩展到多目标自适应性系统，展示了如何利用大语言模型生成偏好标签来平衡冲突目标，避免繁琐的奖励工程。


<details>
  <summary>Details</summary>
Motivation: 现实世界强化学习部署中的奖励设计是一个核心挑战，特别是在多目标设置中。现有的RLAIF工作通常只关注单目标任务，而多目标系统中冲突目标之间的权衡难以明确指定，策略容易偏向优化主导目标。需要探索RLAIF在多目标自适应性系统中的应用。

Method: 将RLAIF范式扩展到多目标自适应性系统，利用大语言模型生成偏好标签来替代人工标注。通过AI反馈学习用户对不同行为结果的偏好，从而在多目标环境中实现平衡的权衡。

Result: 多目标RLAIF能够产生反映不同用户优先级的平衡权衡策略，无需繁琐的奖励工程。这表明RLAIF可以有效地处理具有内在冲突目标的系统。

Conclusion: 将RLAIF集成到多目标强化学习中，为在具有内在冲突目标的领域中实现用户对齐的策略学习提供了一条可扩展的路径。这种方法避免了传统奖励工程的复杂性，能够更好地反映用户偏好。

Abstract: Reward design has been one of the central challenges for real world reinforcement learning (RL) deployment, especially in settings with multiple objectives. Preference-based RL offers an appealing alternative by learning from human preferences over pairs of behavioural outcomes. More recently, RL from AI feedback (RLAIF) has demonstrated that large language models (LLMs) can generate preference labels at scale, mitigating the reliance on human annotators. However, existing RLAIF work typically focuses only on single-objective tasks, leaving the open question of how RLAIF handles systems that involve multiple objectives. In such systems trade-offs among conflicting objectives are difficult to specify, and policies risk collapsing into optimizing for a dominant goal. In this paper, we explore the extension of the RLAIF paradigm to multi-objective self-adaptive systems. We show that multi-objective RLAIF can produce policies that yield balanced trade-offs reflecting different user priorities without laborious reward engineering. We argue that integrating RLAIF into multi-objective RL offers a scalable path toward user-aligned policy learning in domains with inherently conflicting objectives.

</details>


### [46] [CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference](https://arxiv.org/abs/2602.20732)
*Chao Fei,Guozhong Li,Chenxi Liu,Panos Kalnis*

Main category: cs.AI

TL;DR: CHESS是一个算法-系统协同设计的KV缓存管理系统，通过上下文感知的分层选择策略动态重构解码上下文，仅使用1%的KV缓存就能超越Full-KV质量，实现高达4.56倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM需要低延迟的准确推理，但随着上下文增长，解码主要受KV缓存约束。现有剪枝方法大多是上下文无关的：其token选择忽略了步级相关性和局部语义，损害了质量。此外，它们的不规则访问和选择开销仅带来有限的实时加速。

Method: CHESS采用算法-系统协同设计。算法层面：引入上下文感知的分层选择策略，动态重构当前解码的连贯上下文。系统层面：粗粒度选择消除了昂贵的数据移动，充分实现理论稀疏性的实际加速。

Result: 广泛评估表明，CHESS仅使用1%的KV缓存就能超越Full-KV质量，提供低延迟稳定推理，吞吐量最高提升4.56倍，并持续优于其他强基线。

Conclusion: CHESS通过算法-系统协同设计有效解决了长上下文LLM中KV缓存约束问题，实现了高质量、低延迟的推理，为实际部署提供了可行的解决方案。

Abstract: Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \textbf{CHESS}, an \textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \textbf{1\%} of the KV cache, delivers low-latency stable inference with up to \textbf{4.56$\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.

</details>


### [47] [PyVision-RL: Forging Open Agentic Vision Models via RL](https://arxiv.org/abs/2602.20739)
*Shitian Zhao,Shaoheng Lin,Ming Li,Haoquan Zhang,Wenshuo Peng,Kaipeng Zhang,Chen Wei*

Main category: cs.AI

TL;DR: PyVision-RL是一个用于开放权重多模态模型的强化学习框架，通过过采样-过滤-排序策略和累积工具奖励来防止交互崩溃，维持多轮工具使用，并开发了图像和视频理解模型，其中视频模型采用按需上下文构建来减少视觉标记使用。


<details>
  <summary>Details</summary>
Motivation: 多模态模型的强化学习经常面临交互崩溃问题，模型倾向于减少工具使用和多轮推理，限制了智能体行为的优势。需要一种能够稳定训练并维持交互的框架。

Method: 提出PyVision-RL框架，结合过采样-过滤-排序策略和累积工具奖励来防止交互崩溃并鼓励多轮工具使用。采用统一训练流程开发PyVision-Image和PyVision-Video模型。对于视频推理，PyVision-Video采用按需上下文构建，在推理过程中选择性采样任务相关帧以减少视觉标记使用。

Result: 实验显示PyVision模型表现出强大的性能和改进的效率，证明了持续交互和按需视觉处理对于可扩展多模态智能体的重要性。

Conclusion: 持续交互和按需视觉处理是构建可扩展多模态智能体的关键要素，PyVision-RL框架通过防止交互崩溃和优化视觉处理，为多模态智能体学习提供了有效的解决方案。

Abstract: Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.

</details>


### [48] [POMDPPlanners: Open-Source Package for POMDP Planning](https://arxiv.org/abs/2602.20810)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: POMDPPlanners是一个用于POMDP规划算法实证评估的开源Python包，集成了先进算法、基准环境、自动超参数优化和并行仿真功能


<details>
  <summary>Details</summary>
Motivation: 现有的POMDP工具包在风险敏感设置下存在不足，需要进行可扩展、可复现的决策研究，特别是安全关键场景下的不确定性决策

Method: 开发开源Python包，集成最先进的规划算法，提供基准环境（包括安全关键变体），通过Optuna实现自动超参数优化，支持持久化缓存和故障恢复，配置并行仿真

Result: 创建了POMDPPlanners包，显著减少了大规模仿真研究的开销，支持不确定性决策的规模化可复现研究

Conclusion: POMDPPlanners为POMDP规划算法的实证评估提供了全面工具，特别适用于风险敏感设置，弥补了现有工具包的不足

Abstract: We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to enable scalable, reproducible research on decision-making under uncertainty, with particular emphasis on risk-sensitive settings where standard toolkits fall short.

</details>


### [49] [Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset](https://arxiv.org/abs/2602.20812)
*Jia-Rui Lin,Yun-Hong Cai,Xiang-Rui Ni,Shaojie Zhou,Peng Pan*

Main category: cs.AI

TL;DR: 该研究针对BIM（建筑信息模型）设计领域缺乏专门数据集和LLM评估基准的问题，提出了首个BIM设计专用评估基准、数据生成方法和LLM微调策略，并开发了Qwen-BIM模型，在仅14B参数下达到与671B通用LLM相当的性能。


<details>
  <summary>Details</summary>
Motivation: 建筑行业数字化转型中，BIM设计成为智能建造的关键驱动力。尽管大型语言模型在促进BIM设计方面显示潜力，但缺乏特定领域的数据集和评估基准严重限制了LLM在BIM设计中的性能表现。

Method: 1) 提出BIM设计评估基准及定量指标；2) 开发从BIM生成文本数据的方法，构建用于LLM评估和微调的BIM衍生数据集；3) 设计LLM微调策略以适应BIM设计任务。

Result: 提出的领域专用基准能全面评估LLM能力，显示通用LLM在领域特定任务中仍不称职。基于该基准和数据集开发的Qwen-BIM模型，相比基础LLM在G-Eval得分上平均提升21.0%。仅14B参数的Qwen-BIM在BIM设计任务上性能与671B参数的通用LLM相当。

Conclusion: 本研究通过引入全面的评估基准和高质量数据集，开发了首个BIM设计专用LLM，为各领域开发BIM相关LLM奠定了坚实基础。

Abstract: As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with corresponding quantitative indicators to evaluate the performance of LLMs, 2) a method for generating textual data from BIM and constructing corresponding BIM-derived datasets for LLM evaluation and fine-tuning, and 3) a fine-tuning strategy to adapt LLMs for BIM-based design. Results demonstrate that the proposed domain-specific benchmark effectively and comprehensively assesses LLM capabilities, highlighting that general LLMs are still incompetent for domain-specific tasks. Meanwhile, with the proposed benchmark and datasets, Qwen-BIM is developed and achieves a 21.0% average increase in G-Eval score compared to the base LLM model. Notably, with only 14B parameters, performance of Qwen-BIM is comparable to that of general LLMs with 671B parameters for BIM-based design tasks. Overall, this study develops the first domain-specific LLM for BIM-based design by introducing a comprehensive benchmark and high-quality dataset, which provide a solid foundation for developing BIM-related LLMs in various fields.

</details>


### [50] [Pressure Reveals Character: Behavioural Alignment Evaluation at Depth](https://arxiv.org/abs/2602.20813)
*Nora Petrova,John Burden*

Main category: cs.AI

TL;DR: 该论文提出了一个包含904个场景、6个类别的对齐基准测试，用于在现实压力下评估语言模型的行为，发现对齐表现呈现统一构造特征，多数模型存在系统性弱点。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型对齐性需要测试其在现实压力下的实际行为，而不仅仅是声称的意图。当前缺乏包含现实多轮场景的全面评估框架，而对齐失败正导致越来越多的现实危害。

Method: 1) 构建包含904个场景的基准测试，涵盖诚实性、安全性、非操纵性、鲁棒性、可修正性和阴谋性6个类别，经人类评估者验证为现实场景；2) 场景设计包含冲突指令、模拟工具访问和多轮升级；3) 使用经人类标注验证的LLM评估器对24个前沿模型进行评估。

Result: 1) 即使是表现最佳的模型在特定类别中也存在差距；2) 大多数模型在所有类别中表现出一致的弱点；3) 因子分析显示对齐性表现为统一构造（类似于认知研究中的g因子），模型在一个类别得分高时在其他类别也倾向于得分高。

Conclusion: 该研究提出了一个全面的对齐基准测试，揭示了语言模型在现实压力下的行为模式。对齐性表现为统一构造特征，多数模型存在系统性弱点。作者公开了基准测试和交互式排行榜，计划在观察到持续弱点的领域扩展场景，并添加新发布的模型。

Abstract: Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenarios place models under conflicting instructions, simulated tool access, and multi-turn escalation to reveal behavioural tendencies that single-turn evaluations miss. Evaluating 24 frontier models using LLM judges validated against human annotations, we find that even top-performing models exhibit gaps in specific categories, while the majority of models show consistent weaknesses across the board. Factor analysis reveals that alignment behaves as a unified construct (analogous to the g-factor in cognitive research) with models scoring high on one category tending to score high on others. We publicly release the benchmark and an interactive leaderboard to support ongoing evaluation, with plans to expand scenarios in areas where we observe persistent weaknesses and to add new models as they are released.

</details>


### [51] [Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs](https://arxiv.org/abs/2602.20878)
*Dhita Putri Pratama,Soyeon Caren Han,Yihao Ding*

Main category: cs.AI

TL;DR: 论文提出Vision-Language Causal Graphs (VLCGs)结构化表示和ViLCaR诊断基准，用于评估大视觉语言模型中的因果推理能力，发现现有模型主要缺乏结构化指导而非推理能力不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型在视觉问答任务中表现出色，但往往依赖虚假相关性而非真正的因果推理。当前的评估主要关注答案正确性，无法区分失败是由于推理能力有限还是未能识别因果相关信息。

Method: 提出Vision-Language Causal Graphs (VLCGs)——一种结构化、查询条件化的表示方法，显式编码因果相关的对象、属性、关系和场景基础假设。基于此构建ViLCaR诊断基准，包含因果归因、因果推理和问答任务，以及图对齐的评估指标。

Result: 实验表明，注入结构化相关性信息相比零样本和标准上下文学习，能显著提高归因和推理的一致性。这表明当前LVLM在因果推理方面的限制主要源于结构化指导不足，而非推理能力缺乏。

Conclusion: 当前大视觉语言模型的因果推理局限主要来自缺乏结构化指导，而非推理能力不足。VLCGs和ViLCaR为诊断和改进模型的因果推理能力提供了有效工具。

Abstract: Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly encodes causally relevant objects, attributes, relations, and scene-grounded assumptions. Building on this representation, we present ViLCaR, a diagnostic benchmark comprising tasks for Causal Attribution, Causal Inference, and Question Answering, along with graph-aligned evaluation metrics that assess relevance identification beyond final answer accuracy. Experiments in state-of-the-art LVLMs show that injecting structured relevance information significantly improves attribution and inference consistency compared to zero-shot and standard in-context learning. These findings suggest that current limitations in LVLM causal reasoning stem primarily from insufficient structural guidance rather than a lack of reasoning capacity.

</details>


### [52] [HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG](https://arxiv.org/abs/2602.20926)
*Yuqi Huang,Ning Liao,Kai Yang,Anning Hu,Shengchao Hu,Xiaoxing Wang,Junchi Yan*

Main category: cs.AI

TL;DR: HELP框架通过超节点扩展和逻辑路径引导的证据定位策略，在保持检索精度的同时显著提升图增强检索生成效率


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成方法在处理多跳推理时忽视结构依赖关系，而基于图的RAG方法在准确性和效率之间存在权衡，面临图遍历成本高和LLM生成摘要语义噪声等问题

Method: 提出HELP框架，包含两个核心策略：1) 超节点扩展：迭代地将知识三元组链接为连贯推理路径并抽象为超节点，捕捉复杂结构依赖；2) 逻辑路径引导的证据定位：利用预计算的图-文本相关性将路径直接映射到语料库，避免昂贵的随机游走

Result: 在多个简单和多跳QA基准测试中取得竞争性性能，相比领先的基于图的RAG基线实现高达28.8倍的加速

Conclusion: HELP框架通过平衡准确性和实际效率，有效解决了图增强检索生成中的结构依赖捕捉和效率瓶颈问题，同时避免了语义失真并保持知识完整性

Abstract: Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic noise in LLM-generated summaries. In this paper, we propose HyperNode Expansion and Logical Path-Guided Evidence Localization strategies for GraphRAG (HELP), a novel framework designed to balance accuracy with practical efficiency through two core strategies: 1) HyperNode Expansion, which iteratively chains knowledge triplets into coherent reasoning paths abstracted as HyperNodes to capture complex structural dependencies and ensure retrieval accuracy; and 2) Logical Path-Guided Evidence Localization, which leverages precomputed graph-text correlations to map these paths directly to the corpus for superior efficiency. HELP avoids expensive random walks and semantic distortion, preserving knowledge integrity while drastically reducing retrieval latency. Extensive experiments demonstrate that HELP achieves competitive performance across multiple simple and multi-hop QA benchmarks and up to a 28.8$\times$ speedup over leading Graph-based RAG baselines.

</details>


### [53] [Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence](https://arxiv.org/abs/2602.20934)
*ChengYou Li,XiaoDong Liu,XiangBao Meng,XinYu Zhao*

Main category: cs.AI

TL;DR: 论文提出AgentOS框架，将大语言模型重新定义为"推理内核"，采用操作系统逻辑管理，通过深度上下文管理将上下文窗口视为可寻址语义空间，解决微观token处理与宏观系统智能之间的理论鸿沟。


<details>
  <summary>Details</summary>
Motivation: 当前LLM研究主要关注扩展上下文窗口或优化提示工程，但微观token处理与宏观系统智能之间的理论桥梁仍然碎片化。需要从静态推理引擎向动态自主认知系统进行根本性转变。

Method: 提出AgentOS整体概念框架，将LLM重新定义为"推理内核"，采用结构化操作系统逻辑管理。核心是深度上下文管理，将上下文窗口概念化为可寻址语义空间而非被动缓冲区。引入语义切片和时间对齐机制来缓解多智能体编排中的认知漂移，并将经典操作系统抽象（内存分页、中断处理、进程调度）映射到LLM原生构造上。

Result: 提供了一个严谨的路线图，用于构建弹性、可扩展和自我进化的认知环境。分析表明AGI发展的下一个前沿在于系统级协调的架构效率。

Conclusion: 通过将操作系统原理应用于LLM架构，AgentOS框架为构建更强大、更协调的认知系统提供了理论基础，强调系统级协调的架构效率是AGI发展的关键方向。

Abstract: The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a "Reasoning Kernel" governed by structured operating system logic.Central to this architecture is Deep Context Management which conceptualizes the context window as an Addressable Semantic Space rather than a passive buffer.We systematically deconstruct the transition from discrete sequences to coherent cognitive states introducing mechanisms for Semantic Slicing and Temporal Alignment to mitigate cognitive drift in multi-agent orchestration.By mapping classical OS abstractions such as memory paging interrupt handling and process scheduling onto LLM native constructs, this review provides a rigorous roadmap for architecting resilient scalable and self-evolving cognitive environments.Our analysis asserts that the next frontier of AGI development lies in the architectural efficiency of system-level coordination.

</details>


### [54] [LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification](https://arxiv.org/abs/2602.21044)
*Yanrui Wu,Lingling Zhang,Xinyu Zhang,Jiayu Chang,Pengyu Li,Xu Jiang,Jingtao Hu,Jun Liu*

Main category: cs.AI

TL;DR: LogicGraph是首个评估多路径逻辑推理的基准，通过神经符号框架构建包含深度多路径推理和逻辑干扰的问题，揭示LLM倾向于过早固定单一推理路径而无法探索替代方案的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估主要关注收敛性逻辑推理（产生单一正确证明），但许多现实推理问题存在多种有效推导路径，需要模型探索多样逻辑路径而非固守单一路线。

Method: 提出LogicGraph基准，采用神经符号框架结合后向逻辑生成和语义实例化，构建经过求解器验证的推理问题，包含高深度多路径推理和内在逻辑干扰，每个实例关联一组最小证明的穷举集。

Result: 实验显示先进语言模型的共同局限：模型倾向于过早固定单一推理路径而无法探索替代方案，且随着推理深度增加，覆盖差距显著扩大。LogicGraph揭示了这种发散差距。

Conclusion: LogicGraph暴露了LLM在多路径逻辑推理方面的局限性，为未来改进提供了可操作的见解，代码和数据已开源。

Abstract: Evaluations of large language models (LLMs) primarily emphasize convergent logical reasoning, where success is defined by producing a single correct proof. However, many real-world reasoning problems admit multiple valid derivations, requiring models to explore diverse logical paths rather than committing to one route. To address this limitation, we introduce LogicGraph, the first benchmark aimed to systematically evaluate multi-path logical reasoning, constructed via a neuro-symbolic framework that leverages backward logic generation and semantic instantiation. This pipeline yields solver-verified reasoning problems formalized by high-depth multi-path reasoning and inherent logical distractions, where each instance is associated with an exhaustive set of minimal proofs. We further propose a reference-free evaluation framework to rigorously assess model performance in both convergent and divergent regimes. Experiments on state-of-the-art language models reveal a common limitation: models tend to commit early to a single route and fail to explore alternatives, and the coverage gap grows substantially with reasoning depth. LogicGraph exposes this divergence gap and provides actionable insights to motivate future improvements. Our code and data will be released at https://github.com/kkkkarry/LogicGraph.

</details>


### [55] [Tool Building as a Path to "Superintelligence"](https://arxiv.org/abs/2602.21061)
*David Koplow,Tomer Galanti,Tomaso Poggio*

Main category: cs.AI

TL;DR: 论文设计了一个基准来测量LLMs在逻辑分布外推理中的步骤成功概率γ，发现前沿模型在该任务上表现出部分鲁棒性，精确的工具调用是实现通用超智能的关键能力。


<details>
  <summary>Details</summary>
Motivation: Diligent Learner框架认为LLMs可以通过测试时搜索实现超智能，前提是有足够的步骤成功概率γ。本研究旨在设计一个基准来测量γ值，特别是在逻辑分布外推理任务上，以评估LLMs实现超智能的可行性。

Method: 构建了一类涉及GF(2)电路重建的任务，这些任务随着推理步骤的增加而变得更加困难，并且从信息论角度看，除非LLM仔细整合所有提供的信息，否则无法可靠解决。通过这个基准测量不同规模LLMs的γ值。

Result: 小型LLMs的γ值随着深度增加呈超线性下降，而前沿模型在该任务上表现出部分鲁棒性。研究发现，成功的规模化推理依赖于精确的工具调用，工具设计被确定为LLMs通过Diligent Learner框架实现通用超智能的关键能力。

Conclusion: 工具设计是LLMs通过Diligent Learner框架实现通用超智能的关键瓶颈。虽然前沿模型在逻辑分布外推理任务上表现出部分鲁棒性，但精确的工具调用能力对于实现可靠的规模化推理至关重要。

Abstract: The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $γ$. In this work, we design a benchmark to measure $γ$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the information provided. Our analysis demonstrates that while the $γ$ value for small LLMs declines superlinearly as depth increases, frontier models exhibit partial robustness on this task. Furthermore, we find that successful reasoning at scale is contingent upon precise tool calls, identifying tool design as a critical capability for LLMs to achieve general superintelligence through the Diligent Learner framework.

</details>


### [56] [The Initial Exploration Problem in Knowledge Graph Exploration](https://arxiv.org/abs/2602.21066)
*Claire McNamara,Lucy Hederman,Declan O'Sullivan*

Main category: cs.AI

TL;DR: 论文提出"初始探索问题"理论框架，分析知识图谱面向非专家用户时的入门障碍，指出当前界面设计缺乏范围揭示机制


<details>
  <summary>Details</summary>
Motivation: 知识图谱虽然能整合复杂信息，但其语义丰富性和结构复杂性为非专家用户设置了显著障碍。用户在首次接触陌生知识图谱时面临独特的定向挑战：不知道可以提出什么问题、知识如何组织、如何开始探索。现有研究多假设用户已有起点或信息目标，而忽视了首次接触时的特殊困难。

Method: 基于信息行为和人机交互理论（包括ASK理论、探索性搜索、信息觅食、认知负荷理论），构建IEP概念框架，识别三个相互依存的障碍：范围不确定性、本体不透明性、查询能力不足。通过分析知识图谱探索界面的交互原语，揭示设计空间中的结构性缺口。

Result: 提出了"初始探索问题"的理论框架，将其特征化为三个相互关联的障碍。发现许多系统依赖的认知假设在首次接触时不成立，揭示了设计空间中的结构性缺口：缺乏"范围揭示"交互原语——即在不要求用户制定查询或解释本体结构的情况下传达知识图谱内容的机制。

Conclusion: IEP框架为评估知识图谱界面和设计支持初始探索的入口支架提供了理论视角。强调需要开发专门的交互原语来帮助用户在首次接触时理解知识图谱的范围和可能性，从而降低入门门槛。

Abstract: Knowledge Graphs (KGs) enable the integration and representation of complex information across domains, but their semantic richness and structural complexity create substantial barriers for lay users without expertise in semantic web technologies. When encountering an unfamiliar KG, such users face a distinct orientation challenge: they do not know what questions are possible, how the knowledge is structured, or how to begin exploration. This paper identifies and theorises this phenomenon as the Initial Exploration Problem (IEP). Drawing on theories from information behaviour and human-computer interaction, including ASK, exploratory search, information foraging, and cognitive load theory, we develop a conceptual framing of the IEP characterised by three interdependent barriers: scope uncertainty, ontology opacity, and query incapacity. We argue that these barriers converge at the moment of first contact, distinguishing the IEP from related concepts that presuppose an existing starting point or information goal. Analysing KG exploration interfaces at the level of interaction primitives, we suggest that many systems rely on epistemic assumptions that do not hold at first contact. This reveals a structural gap in the design space: the absence of interaction primitives for scope revelation, mechanisms that communicate what a KG contains without requiring users to formulate queries or interpret ontological structures. In articulating the IEP, this paper provides a theoretical lens for evaluating KG interfaces and for designing entry-point scaffolding that supports initial exploration.

</details>


### [57] [CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning](https://arxiv.org/abs/2602.21154)
*Ziwei Niu,Hao Sun,Shujun Bian,Xihong Yang,Lanfen Lin,Yuxin Liu,Yueming Jin*

Main category: cs.AI

TL;DR: CG-DMER：一种用于解耦多模态心电图表示学习的对比生成框架，通过空间-时间掩码建模和表示解耦对齐策略解决现有方法在模态内和模态间的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态心电图分析方法存在两个主要问题：1）模态内：现有模型以导联无关的方式处理心电图，忽略了导联间的时空依赖性，限制了其对细粒度诊断模式的建模能力；2）模态间：现有方法直接将心电图信号与临床报告对齐，由于报告的自由文本性质引入了模态特定偏差。

Method: 提出CG-DMER框架，包含两个关键设计：1）空间-时间掩码建模：通过在空间和时间维度上应用掩码并重建缺失信息，更好地捕捉细粒度时间动态和导联间空间依赖性；2）表示解耦和对齐策略：引入模态特定和模态共享编码器，确保模态不变和模态特定表示之间的清晰分离，减少不必要噪声和模态特定偏差。

Result: 在三个公共数据集上的实验表明，CG-DMER在多种下游任务中实现了最先进的性能。

Conclusion: CG-DMER通过解决多模态心电图分析中的模态内和模态间问题，提供了一种有效的解耦表示学习方法，显著提升了心电图诊断的准确性和鲁棒性。

Abstract: Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing modality-specific biases due to the free-text nature of the reports. In light of these two issues, we propose CG-DMER, a contrastive-generative framework for disentangled multimodal ECG representation learning, powered by two key designs: (1) Spatial-temporal masked modeling is designed to better capture fine-grained temporal dynamics and inter-lead spatial dependencies by applying masking across both spatial and temporal dimensions and reconstructing the missing information. (2) A representation disentanglement and alignment strategy is designed to mitigate unnecessary noise and modality-specific biases by introducing modality-specific and modality-shared encoders, ensuring a clearer separation between modality-invariant and modality-specific representations. Experiments on three public datasets demonstrate that CG-DMER achieves state-of-the-art performance across diverse downstream tasks.

</details>


### [58] [NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning](https://arxiv.org/abs/2602.21172)
*Ishaan Rawal,Shubh Gupta,Yihan Hu,Wei Zhan*

Main category: cs.AI

TL;DR: NoRD模型通过消除推理标注需求，在仅使用60%数据的情况下实现了与现有VLA模型竞争的性能，减少了3倍token使用，并通过Dr. GRPO算法解决了难度偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在自动驾驶应用中面临两大昂贵需求：1）需要大量数据集收集；2）需要密集的推理标注。这些要求限制了VLA模型的实际部署效率。

Method: 提出NoRD模型，采用无推理标注的训练方法，仅使用<60%的数据量。针对标准GRPO在小规模无推理数据集上效果不佳的问题，引入Dr. GRPO算法来缓解难度偏差问题，该算法专门设计用于处理高方差rollout场景中的奖励信号惩罚问题。

Result: NoRD在Waymo和NAVSIM基准测试中取得了与现有VLA模型竞争的性能，同时训练数据量减少40%以上，token使用量减少3倍，且完全不需要推理标注。

Conclusion: NoRD通过消除推理标注需求并大幅减少数据需求，为构建更高效的自动驾驶系统提供了可行方案，Dr. GRPO算法的引入有效解决了小规模无推理数据集上的强化学习优化问题。

Abstract: Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \modelname (\textbf{No} \textbf{R}easoning for \textbf{D}riving). Compared to existing VLAs, \modelname achieves competitive performance while being fine-tuned on $<$60\% of the data and no reasoning annotations, resulting in 3$\times$ fewer tokens. We identify that standard Group Relative Policy Optimization (GRPO) fails to yield significant improvements when applied to policies trained on such small, reasoning-free datasets. We show that this limitation stems from difficulty bias, which disproportionately penalizes reward signals from scenarios that produce high-variance rollouts within GRPO. \modelname overcomes this by incorporating Dr.~GRPO, a recent algorithm designed to mitigate difficulty bias in LLMs. As a result, \modelname achieves competitive performance on Waymo and NAVSIM with a fraction of the training data and no reasoning overhead, enabling more efficient autonomous systems.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [59] [Indaleko: The Unified Personal Index](https://arxiv.org/abs/2602.20507)
*William Anthony Mason*

Main category: cs.IR

TL;DR: 提出统一个人索引（UPI）架构，通过记忆对齐方法解决个人信息检索问题，开发Indaleko原型系统处理3100万文件，实现基于时间、空间和活动上下文的自然语言查询。


<details>
  <summary>Details</summary>
Motivation: 现有个人信息检索系统忽略人类记忆工作原理，强制使用关键词搜索孤立数据孤岛，而人类自然通过情景线索（何时、何地、何种上下文）回忆信息，存在根本性差距。

Method: 提出统一个人索引（UPI）架构，开发Indaleko原型系统，将时间、空间和活动元数据整合到统一图数据库中，使用记忆锚索引实现亚秒级查询响应，通过UUID语义解耦保护隐私。

Result: 在160TB、8个存储平台的3100万文件数据集上验证可行性，实现自然语言查询如"去年春天会议地点附近的照片"，相比Google Drive等商业系统，Indaleko能成功处理多维查询，保持完美精度，新数据源集成仅需10分钟到10小时。

Conclusion: UPI架构将认知理论与分布式系统设计结合，将个人信息检索从关键词匹配转变为记忆对齐查找，为现有数据提供即时价值，为未来上下文感知系统奠定基础。

Abstract: Personal information retrieval fails when systems ignore how human memory works. While existing platforms force keyword searches across isolated silos, humans naturally recall through episodic cues like when, where, and in what context information was encountered. This dissertation presents the Unified Personal Index (UPI), a memory-aligned architecture that bridges this fundamental gap. The Indaleko prototype demonstrates the UPI's feasibility on a 31-million file dataset spanning 160TB across eight storage platforms. By integrating temporal, spatial, and activity metadata into a unified graph database, Indaleko enables natural language queries like "photos near the conference venue last spring" that existing systems cannot process. The implementation achieves sub-second query responses through memory anchor indexing, eliminates cross-platform search fragmentation, and maintains perfect precision for well-specified memory patterns. Evaluation against commercial systems (Google Drive, OneDrive, Dropbox, Windows Search) reveals that all fail on memory-based queries, returning overwhelming result sets without contextual filtering. In contrast, Indaleko successfully processes multi-dimensional queries combining time, location, and activity patterns. The extensible architecture supports rapid integration of new data sources (10 minutes to 10 hours per provider) while preserving privacy through UUID-based semantic decoupling. The UPI's architectural synthesis bridges cognitive theory with distributed systems design, as demonstrated through the Indaleko prototype and rigorous evaluation. This work transforms personal information retrieval from keyword matching to memory-aligned finding, providing immediate benefits for existing data while establishing foundations for future context-aware systems.

</details>


### [60] [PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization](https://arxiv.org/abs/2602.20676)
*Shuzhi Cao,Rong Chen,Ailong He,Shuguang Han,Jufeng Chen*

Main category: cs.IR

TL;DR: PRECTR-V2通过挖掘全局相关性偏好解决冷启动问题，通过嵌入噪声注入和相关性标签重构构建硬负样本纠正曝光偏差，并通过轻量级Transformer编码器替代冻结BERT实现联合优化，提升了搜索相关性和点击率预测的协同效果。


<details>
  <summary>Details</summary>
Motivation: 解决PRECTR框架面临的三个主要挑战：1) 低活跃用户和新用户搜索行为数据有限，难以实现有效的个性化相关性偏好建模；2) 排序模型训练数据主要来自高相关性曝光，与粗排候选空间存在分布不匹配，导致泛化偏差；3) 原始模型采用Emb+MLP架构和冻结BERT编码器，无法联合优化，造成表示学习与CTR微调之间的不对齐。

Method: 1) 在特定查询下挖掘全局相关性偏好，解决冷启动场景下的个性化建模问题；2) 通过嵌入噪声注入和相关性标签重构构建硬负样本，使用成对损失优化正负样本的相对排序，纠正曝光偏差；3) 通过知识蒸馏从LLM获取知识并在文本相关性分类任务上进行SFT，预训练轻量级Transformer编码器，替代冻结BERT模块，实现与CTR微调的更好适配。

Result: PRECTR-V2有效解决了冷启动用户建模问题，通过硬负样本构建纠正了曝光偏差，轻量级Transformer编码器实现了表示学习与CTR微调的联合优化，超越了传统的Emb+MLP范式。

Conclusion: PRECTR-V2通过三个关键技术改进，全面解决了原框架的局限性，实现了搜索相关性匹配与CTR预测的更有效协同，为搜索系统提供了更强大的统一框架。

Abstract: In search systems, effectively coordinating the two core objectives of search relevance matching and click-through rate (CTR) prediction is crucial for discovering users' interests and enhancing platform revenue. In our prior work PRECTR, we proposed a unified framework to integrate these two subtasks,thereby eliminating their inconsistency and leading to mutual benefit.However, our previous work still faces three main challenges. First, low-active users and new users have limited search behavioral data, making it difficult to achieve effective personalized relevance preference modeling. Second, training data for ranking models predominantly come from high-relevance exposures, creating a distribution mismatch with the broader candidate space in coarse-ranking, leading to generalization bias. Third, due to the latency constraint, the original model employs an Emb+MLP architecture with a frozen BERT encoder, which prevents joint optimization and creates misalignment between representation learning and CTR fine-tuning. To solve these issues, we further reinforce our method and propose PRECTR-V2. Specifically, we mitigate the low-activity users' sparse behavior problem by mining global relevance preferences under the specific query, which facilitates effective personalized relevance modeling for cold-start scenarios. Subsequently, we construct hard negative samples through embedding noise injection and relevance label reconstruction, and optimize their relative ranking against positive samples via pairwise loss, thereby correcting exposure bias. Finally, we pretrain a lightweight transformer-based encoder via knowledge distillation from LLM and SFT on the text relevance classification task. This encoder replaces the frozen BERT module, enabling better adaptation to CTR fine-tuning and advancing beyond the traditional Emb+MLP paradigm.

</details>


### [61] [IntRR: A Framework for Integrating SID Redistribution and Length Reduction](https://arxiv.org/abs/2602.20704)
*Zesheng Wang,Longfei Xu,Weidong Deng,Huimin Yan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: IntRR框架通过语义ID重分布和长度缩减解决生成式推荐中语义ID与推荐目标不对齐、序列过长的问题，提升推荐准确性和效率


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐中的语义ID存在两个核心问题：1）索引目标（第一阶段）与推荐目标（第二阶段）不对齐，且语义ID在第二阶段保持静态，无法适应用户交互的复杂性；2）将分层语义ID展平为序列导致序列长度膨胀，带来计算开销和推理延迟问题

Method: 提出IntRR框架，包含目标对齐的语义ID重分布和结构长度缩减。利用项目特定唯一ID作为协作锚点，在分层码本层间动态重分布语义权重；同时递归处理语义ID层次结构，避免序列展平，确保每个项目固定为一个token

Result: 在基准数据集上的大量实验表明，IntRR相比代表性生成式基线方法有显著改进，在推荐准确性和效率方面都实现了优越性能

Conclusion: IntRR通过语义ID重分布和长度缩减有效解决了生成式推荐中语义ID不对齐和序列过长的问题，为生成式推荐系统提供了更准确高效的解决方案

Abstract: Generative Recommendation (GR) has emerged as a transformative paradigm that reformulates the traditional cascade ranking system into a sequence-to-item generation task, facilitated by the use of discrete Semantic IDs (SIDs). However, current SIDs are suboptimal as the indexing objectives (Stage 1) are misaligned with the actual recommendation goals (Stage 2). Since these identifiers remain static (Stage 2), the backbone model lacks the flexibility to adapt them to the evolving complexities of user interactions. Furthermore, the prevailing strategy of flattening hierarchical SIDs into token sequences leads to sequence length inflation, resulting in prohibitive computational overhead and inference latency. To address these challenges, we propose IntRR, a novel framework that integrates objective-aligned SID Redistribution and structural Length Reduction. By leveraging item-specific Unique IDs (UIDs) as collaborative anchors, this approach dynamically redistributes semantic weights across hierarchical codebook layers. Concurrently, IntRR handles the SID hierarchy recursively, eliminating the need to flatten sequences. This ensures a fixed cost of one token per item. Extensive experiments on benchmark datasets demonstrate that IntRR yields substantial improvements over representative generative baselines, achieving superior performance in both recommendation accuracy and efficiency.

</details>


### [62] [RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition](https://arxiv.org/abs/2602.20735)
*Kun Ran,Marwah Alaofi,Danula Hettiachchi,Chenglong Ma,Khoi Nguyen Dinh Anh,Khoi Vo Nguyen,Sachin Pathiyan Cherumanal,Lida Rashidi,Falk Scholer,Damiano Spina,Shuoqi Sun,Oleg Zendel*

Main category: cs.IR

TL;DR: RMIT-ADM+S团队提出R2RAG架构，在NeurIPS 2025 MMU-RAG竞赛文本-文本赛道获奖，通过轻量级组件动态调整检索策略，在消费级GPU上高效运行复杂研究任务。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统在面对不同复杂度查询时检索策略固定、资源消耗大的问题，旨在开发能够根据查询复杂性和证据充分性动态调整检索策略的轻量级RAG架构，使其能在消费级硬件上高效运行。

Method: 提出Routing-to-RAG (R2RAG)架构，基于G-RAG系统（ACM SIGIR 2025 LiveRAG挑战赛获胜系统）扩展，包含轻量级组件：1) 查询复杂度推断模块；2) 证据充分性评估模块；3) 动态检索策略路由模块。系统使用较小规模LLM，支持在单张消费级GPU上运行。

Result: R2RAG在NeurIPS 2025 MMU-RAG竞赛文本-文本赛道中获得最佳动态评估奖（开源类别），证明了其高有效性。系统通过精心设计和资源高效利用，在保持高性能的同时显著降低了计算资源需求。

Conclusion: R2RAG展示了通过轻量级组件和动态路由机制，可以在有限计算资源下实现高效的检索增强生成系统，为资源受限环境中的复杂研究任务提供了可行的解决方案，并验证了基于查询复杂性和证据充分性的动态策略调整的有效性。

Abstract: This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text
  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG
  (R2RAG), a research-focused retrieval-augmented generation (RAG)
  architecture composed of lightweight components that dynamically adapt the
  retrieval strategy based on inferred query complexity and evidence
  sufficiency. The system uses smaller LLMs, enabling operation on a single
  consumer-grade GPU while supporting complex research tasks. It builds on the
  G-RAG system, winner of the ACM~SIGIR~2025 LiveRAG Challenge, and extends it
  with modules informed by qualitative review of outputs. R2RAG won the Best
  Dynamic Evaluation award in the Open Source category, demonstrating high
  effectiveness with careful design and efficient use of resources.

</details>


### [63] [Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking](https://arxiv.org/abs/2602.20800)
*Dalia Nahhas,Xiaohao Cai,Imran Razzak,Shoaib Jameel*

Main category: cs.IR

TL;DR: 论文提出了一种无泄漏的双法官框架，用于评估生成信息检索中的文化相关性，通过严格分离监督和评估模型解决现有LLM评估中的循环性和偏好泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 当前生成信息检索中，候选选择的瓶颈已从生成转向选择，特别是在文化相关性等规范性标准方面。现有的LLM-as-a-Judge评估方法存在循环性和偏好泄漏问题，即监督和评估模型重叠导致性能虚高。

Method: 1) 将文化相关性形式化为查询内排序任务；2) 引入无泄漏的双法官框架，严格分离监督模型(Judge B)和评估模型(Judge A)；3) 使用从Judge B监督的交叉编码器蒸馏得到的密集双编码器；4) 在包含33,052个文化基础故事的新基准(NGR-33k)上进行验证。

Result: 1) 经典基线方法仅获得适度提升；2) 从交叉编码器蒸馏得到的密集双编码器(BGE-M3)非常有效；3) 尽管交叉编码器为蒸馏提供了强监督信号，但蒸馏后的BGE-M3模型在无泄漏的Judge A评估中显著优于它；4) 在人工策划的Moral Stories数据集上验证，显示与人类规范的强对齐。

Conclusion: 严格的评估者分离是可信的生成信息检索评估的前提，证明微妙的文化偏好可以在无泄漏的情况下蒸馏到高效的排序器中。该框架为文化相关性等规范性标准的评估提供了可靠方法。

Abstract: In Generative Information Retrieval (GenIR), the bottleneck has shifted from generation to the selection of candidates, particularly for normative criteria such as cultural relevance. Current LLM-as-a-Judge evaluations often suffer from circularity and preference leakage, where overlapping supervision and evaluation models inflate performance. We address this by formalising cultural relevance as a within-query ranking task and introducing a leakage-free two-judge framework that strictly separates supervision (Judge B) from evaluation (Judge A). On a new benchmark of 33,052 (NGR-33k) culturally grounded stories, we find that while classical baselines yield only modest gains, a dense bi-encoder distilled from a Judge-B-supervised Cross-Encoder is highly effective. Although the Cross-Encoder provides a strong supervision signal for distillation, the distilled BGE-M3 model substantially outperforms it under leakage-free Judge~A evaluation. We validate our framework on the human-curated Moral Stories dataset, showing strong alignment with human norms. Our results demonstrate that rigorous evaluator separation is a prerequisite for credible GenIR evaluation, proving that subtle cultural preferences can be distilled into efficient rankers without leakage.

</details>


### [64] [Naver Labs Europe @ WSDM CUP | Multilingual Retrieval](https://arxiv.org/abs/2602.20986)
*Thibault Formal,Maxime Louis,Hervé Déjean,Stéphane Clinchant*

Main category: cs.IR

TL;DR: 该论文介绍了团队在WSDM Cup 2026多语言文档检索任务中的参赛方案，展示了SPLARE稀疏检索模型在多语言场景下的优异表现。


<details>
  <summary>Details</summary>
Motivation: WSDM Cup 2026的多语言文档检索任务为跨语言泛化提供了具有挑战性的基准测试，同时也为评估SPLARE模型提供了天然测试平台。该任务旨在验证学习型稀疏检索模型在多语言环境下的有效性和竞争力。

Method: 采用SPLARE-7B作为基础模型，通过渐进增强的方式构建了五个不同配置的检索系统。改进包括使用Qwen3-Reranker-4B进行重排序，以及采用简单的分数融合策略。这些改进都是轻量级的，旨在保持模型效率的同时提升性能。

Result: 实验结果表明，SPLARE模型相比最先进的稠密基线模型（如Qwen3-8B-Embed）表现出更强的检索能力。团队提交的结果证明了学习型稀疏检索模型在多语言场景下的持续相关性和竞争力。

Conclusion: 该研究强调了学习型稀疏检索模型在超越英语中心场景的多语言检索任务中仍然具有重要价值和竞争力。SPLARE模型能够产生可泛化的稀疏潜在表示，特别适合多语言检索设置。

Abstract: This report presents our participation to the WSDM Cup 2026 shared task on multilingual document retrieval from English queries. The task provides a challenging benchmark for cross-lingual generalization. It also provides a natural testbed for evaluating SPLARE, our recently proposed learned sparse retrieval model, which produces generalizable sparse latent representations and is particularly well suited to multilingual retrieval settings.
  We evaluate five progressively enhanced runs, starting from a SPLARE-7B model and incorporating lightweight improvements, including reranking with Qwen3-Reranker-4B and simple score fusion strategies. Our results demonstrate the strength of SPLARE compared to state-of-the-art dense baselines such as Qwen3-8B-Embed. More broadly, our submission highlights the continued relevance and competitiveness of learned sparse retrieval models beyond English-centric scenarios.

</details>


### [65] [Generative Pseudo-Labeling for Pre-Ranking with LLMs](https://arxiv.org/abs/2602.20995)
*Junyu Bi,Xinting Niu,Daixuan Cheng,Kun Yuan,Tao Wang,Binbin Cao,Jian Wu,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出GPL框架，利用大语言模型为未曝光项目生成无偏、内容感知的伪标签，解决预排序阶段的训练-服务差异问题，在工业推荐系统中显著提升点击率和多样性。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统中预排序阶段面临训练-服务差异：模型仅在曝光交互上训练，但需要在线上服务时对所有召回候选（包括未曝光项目）进行评分。这种不匹配不仅导致严重的样本选择偏差，还降低了泛化能力，特别是对长尾内容。现有去偏方法依赖启发式方法（如负采样）或从有偏排序器蒸馏，这些方法要么将合理的未曝光项目错误标记为负样本，要么将曝光偏差传播到伪标签中。

Method: 提出生成式伪标签（GPL）框架，利用大语言模型为未曝光项目生成无偏、内容感知的伪标签，显式地将训练分布与在线服务空间对齐。通过离线生成用户特定的兴趣锚点，并在冻结的语义空间中与候选项目匹配，GPL提供高质量监督而不增加在线延迟。

Result: 在大型生产系统中部署，GPL将点击率提高了3.07%，同时显著增强了推荐多样性和长尾项目发现。

Conclusion: GPL框架通过利用大语言模型生成无偏伪标签，有效解决了预排序阶段的训练-服务差异问题，在保持低延迟的同时提升了推荐系统的性能和多样性。

Abstract: Pre-ranking is a critical stage in industrial recommendation systems, tasked with efficiently scoring thousands of recalled items for downstream ranking. A key challenge is the train-serving discrepancy: pre-ranking models are trained only on exposed interactions, yet must score all recalled candidates -- including unexposed items -- during online serving. This mismatch not only induces severe sample selection bias but also degrades generalization, especially for long-tail content. Existing debiasing approaches typically rely on heuristics (e.g., negative sampling) or distillation from biased rankers, which either mislabel plausible unexposed items as negatives or propagate exposure bias into pseudo-labels. In this work, we propose Generative Pseudo-Labeling (GPL), a framework that leverages large language models (LLMs) to generate unbiased, content-aware pseudo-labels for unexposed items, explicitly aligning the training distribution with the online serving space. By offline generating user-specific interest anchors and matching them with candidates in a frozen semantic space, GPL provides high-quality supervision without adding online latency. Deployed in a large-scale production system, GPL improves click-through rate by 3.07%, while significantly enhancing recommendation diversity and long-tail item discovery.

</details>


### [66] [Position-Aware Sequential Attention for Accurate Next Item Recommendations](https://arxiv.org/abs/2602.21052)
*Timur Nabiev,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出了一种核化的自注意力机制，使用可学习的位置核在位置空间中操作，与语义相似性解耦，直接调节注意力权重，用于改进序列建模。


<details>
  <summary>Details</summary>
Motivation: 传统的加性位置嵌入存在三个主要问题：1）位置信息与项目嵌入语义纠缠；2）在深度架构中传播弱；3）限制了捕捉丰富序列模式的能力。作者认为加性位置嵌入只让注意力机制在表面上对序列顺序敏感。

Method: 引入核化自注意力机制，其中可学习的位置核纯粹在位置空间中操作，与语义相似性解耦，直接调节注意力权重。当应用于每个注意力块时，该核能够实现自适应多尺度序列建模。

Result: 在标准的下一个项目预测基准测试中，位置核注意力机制持续优于强大的竞争基线方法。

Conclusion: 通过将位置信息与语义表示解耦，并使用专门的位置核直接调节注意力权重，可以更有效地建模序列顺序，提高序列预测任务的性能。

Abstract: Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled with item embedding semantics, propagates weakly in deep architectures, and limits the ability to capture rich sequential patterns. To address these limitations, we introduce a kernelized self-attention mechanism, where a learnable positional kernel operates purely in the position space, disentangled from semantic similarity, and directly modulates attention weights. When applied per attention block, this kernel enables adaptive multi-scale sequential modeling. Experiments on standard next-item prediction benchmarks show that our positional kernel attention consistently improves over strong competing baselines.

</details>


### [67] [Multi-Vector Index Compression in Any Modality](https://arxiv.org/abs/2602.21202)
*Hanxiang Qin,Alexander Martin,Rohan Jha,Chunsheng Zuo,Reno Kriz,Benjamin Van Durme*

Main category: cs.IR

TL;DR: 该论文提出了一种用于多模态检索中多向量表示的查询无关压缩方法，通过注意力引导聚类（AGC）在固定向量预算下压缩文档表示，在文本、视觉文档和视频检索任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 晚期交互已成为文本、图像、视觉文档和视频信息检索的主要范式，但其计算和存储成本随文档长度线性增长，对于图像、视频和音频丰富的语料库成本过高。需要解决多向量文档表示在固定向量预算下的压缩问题。

Method: 提出了四种索引压缩方法：序列调整、记忆令牌、分层池化以及新颖的注意力引导聚类（AGC）。AGC使用注意力引导机制识别文档中最具语义显著性的区域作为聚类中心，并对令牌聚合进行加权。

Result: 在文本（BEIR）、视觉文档（ViDoRe）和视频（MSR-VTT、MultiVENT 2.0）检索任务上的评估表明，注意力引导聚类始终优于其他参数化压缩方法（序列调整和记忆令牌），在索引大小方面比非参数化分层聚类提供更大灵活性，并且相比完整未压缩索引实现了竞争性或改进的性能。

Conclusion: 注意力引导聚类（AGC）是一种有效的多模态多向量检索压缩方法，能够在固定向量预算下保持检索性能，为多模态检索系统的效率优化提供了实用解决方案。

Abstract: We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has emerged as a dominant paradigm for information retrieval in text, images, visual documents, and videos, but its computation and storage costs grow linearly with document length, making it costly for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic methods for compressing multi-vector document representations under a constant vector budget. We introduce four approaches for index compression: sequence resizing, memory tokens, hierarchical pooling, and a novel attention-guided clustering (AGC). AGC uses an attention-guided mechanism to identify the most semantically salient regions of a document as cluster centroids and to weight token aggregation. Evaluating these methods on retrieval tasks spanning text (BEIR), visual-document (ViDoRe), and video (MSR-VTT, MultiVENT 2.0), we show that attention-guided clustering consistently outperforms other parameterized compression methods (sequence resizing and memory tokens), provides greater flexibility in index size than non-parametric hierarchical clustering, and achieves competitive or improved performance compared to a full, uncompressed index. The source code is available at: github.com/hanxiangqin/omni-col-press.

</details>
