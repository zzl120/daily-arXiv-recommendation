{"id": "2602.20162", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20162", "abs": "https://arxiv.org/abs/2602.20162", "authors": ["Yutao Sun", "Mingshuai Chen", "Tiancheng Zhao", "Phillip Miao", "Zilun Zhang", "Haozhan Shen", "Ruizhe Zhu", "Jianwei Yin"], "title": "Talking to Yourself: Defying Forgetting in Large Language Models", "comment": null, "summary": "Catastrophic forgetting remains a major challenge when fine-tuning large language models (LLMs) on narrow, task-specific data, often degrading their general knowledge and reasoning abilities. We propose SA-SFT, a lightweight self-augmentation routine in which an LLM generates self-dialogues prior to fine-tuning, and the resulting self-authored data are mixed with task data without modifying optimization or training schedules.\n  Despite requiring no external data or additional tuning, SA-SFT consistently mitigates catastrophic forgetting while improving in-domain performance. Across 50 evaluation scenarios, it maintains performance comparable to the original model and achieves the best results in 40 cases, outperforming common baselines such as layer freezing and external data mixing. Guided by these empirical findings, we further present a theoretical analysis suggesting that forgetting can partly stem from style-induced parameter drift, and that self-alignment through self-generated data provides an effective means to counteract this effect. Overall, our results indicate that self-augmentation offers a simple and effective mechanism for robust LLM adaptation without incurring catastrophic forgetting.", "AI": {"tldr": "SA-SFT\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u81ea\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u524d\u751f\u6210\u81ea\u6211\u5bf9\u8bdd\u6570\u636e\uff0c\u4e0e\u4efb\u52a1\u6570\u636e\u6df7\u5408\u8bad\u7ec3\uff0c\u6709\u6548\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u9886\u57df\u5185\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u6570\u636e\u4e0a\u5fae\u8c03\u65f6\u9762\u4e34\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5bfc\u81f4\u5176\u901a\u7528\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u9000\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u5c42\u51bb\u7ed3\u6216\u5916\u90e8\u6570\u636e\u6df7\u5408\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faSA-SFT\u65b9\u6cd5\uff1a1\uff09\u8ba9LLM\u5728\u5fae\u8c03\u524d\u751f\u6210\u81ea\u6211\u5bf9\u8bdd\u6570\u636e\uff1b2\uff09\u5c06\u81ea\u751f\u6210\u6570\u636e\u4e0e\u4efb\u52a1\u6570\u636e\u6df7\u5408\uff1b3\uff09\u4e0d\u6539\u53d8\u4f18\u5316\u5668\u6216\u8bad\u7ec3\u8ba1\u5212\uff0c\u4fdd\u6301\u6807\u51c6\u5fae\u8c03\u6d41\u7a0b\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5916\u90e8\u6570\u636e\u6216\u989d\u5916\u8c03\u4f18\u3002", "result": "\u572850\u4e2a\u8bc4\u4f30\u573a\u666f\u4e2d\uff0cSA-SFT\u4fdd\u6301\u4e0e\u539f\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u572840\u4e2a\u6848\u4f8b\u4e2d\u53d6\u5f97\u6700\u4f73\u7ed3\u679c\uff0c\u4f18\u4e8e\u5c42\u51bb\u7ed3\u548c\u5916\u90e8\u6570\u636e\u6df7\u5408\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002\u540c\u65f6\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u5e76\u63d0\u5347\u4e86\u9886\u57df\u5185\u6027\u80fd\u3002", "conclusion": "\u81ea\u589e\u5f3a\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684LLM\u9002\u5e94\u673a\u5236\uff0c\u65e0\u9700\u989d\u5916\u6210\u672c\u5373\u53ef\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u9057\u5fd8\u90e8\u5206\u6e90\u4e8e\u98ce\u683c\u8bf1\u5bfc\u7684\u53c2\u6570\u6f02\u79fb\uff0c\u800c\u901a\u8fc7\u81ea\u751f\u6210\u6570\u636e\u7684\u81ea\u5bf9\u9f50\u80fd\u6709\u6548\u62b5\u6d88\u8fd9\u79cd\u6548\u5e94\u3002"}}
{"id": "2602.20507", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.20507", "abs": "https://arxiv.org/abs/2602.20507", "authors": ["William Anthony Mason"], "title": "Indaleko: The Unified Personal Index", "comment": "PhD dissertation, University of British Columbia, August 2025. 287 pages", "summary": "Personal information retrieval fails when systems ignore how human memory works. While existing platforms force keyword searches across isolated silos, humans naturally recall through episodic cues like when, where, and in what context information was encountered. This dissertation presents the Unified Personal Index (UPI), a memory-aligned architecture that bridges this fundamental gap. The Indaleko prototype demonstrates the UPI's feasibility on a 31-million file dataset spanning 160TB across eight storage platforms. By integrating temporal, spatial, and activity metadata into a unified graph database, Indaleko enables natural language queries like \"photos near the conference venue last spring\" that existing systems cannot process. The implementation achieves sub-second query responses through memory anchor indexing, eliminates cross-platform search fragmentation, and maintains perfect precision for well-specified memory patterns. Evaluation against commercial systems (Google Drive, OneDrive, Dropbox, Windows Search) reveals that all fail on memory-based queries, returning overwhelming result sets without contextual filtering. In contrast, Indaleko successfully processes multi-dimensional queries combining time, location, and activity patterns. The extensible architecture supports rapid integration of new data sources (10 minutes to 10 hours per provider) while preserving privacy through UUID-based semantic decoupling. The UPI's architectural synthesis bridges cognitive theory with distributed systems design, as demonstrated through the Indaleko prototype and rigorous evaluation. This work transforms personal information retrieval from keyword matching to memory-aligned finding, providing immediate benefits for existing data while establishing foundations for future context-aware systems.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u4e2a\u4eba\u7d22\u5f15\uff08UPI\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u8bb0\u5fc6\u5bf9\u9f50\u65b9\u6cd5\u89e3\u51b3\u4e2a\u4eba\u4fe1\u606f\u68c0\u7d22\u95ee\u9898\uff0c\u5f00\u53d1Indaleko\u539f\u578b\u7cfb\u7edf\u5904\u74063100\u4e07\u6587\u4ef6\uff0c\u5b9e\u73b0\u57fa\u4e8e\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u6d3b\u52a8\u4e0a\u4e0b\u6587\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3002", "motivation": "\u73b0\u6709\u4e2a\u4eba\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u5ffd\u7565\u4eba\u7c7b\u8bb0\u5fc6\u5de5\u4f5c\u539f\u7406\uff0c\u5f3a\u5236\u4f7f\u7528\u5173\u952e\u8bcd\u641c\u7d22\u5b64\u7acb\u6570\u636e\u5b64\u5c9b\uff0c\u800c\u4eba\u7c7b\u81ea\u7136\u901a\u8fc7\u60c5\u666f\u7ebf\u7d22\uff08\u4f55\u65f6\u3001\u4f55\u5730\u3001\u4f55\u79cd\u4e0a\u4e0b\u6587\uff09\u56de\u5fc6\u4fe1\u606f\uff0c\u5b58\u5728\u6839\u672c\u6027\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u4e2a\u4eba\u7d22\u5f15\uff08UPI\uff09\u67b6\u6784\uff0c\u5f00\u53d1Indaleko\u539f\u578b\u7cfb\u7edf\uff0c\u5c06\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u6d3b\u52a8\u5143\u6570\u636e\u6574\u5408\u5230\u7edf\u4e00\u56fe\u6570\u636e\u5e93\u4e2d\uff0c\u4f7f\u7528\u8bb0\u5fc6\u951a\u7d22\u5f15\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u67e5\u8be2\u54cd\u5e94\uff0c\u901a\u8fc7UUID\u8bed\u4e49\u89e3\u8026\u4fdd\u62a4\u9690\u79c1\u3002", "result": "\u5728160TB\u30018\u4e2a\u5b58\u50a8\u5e73\u53f0\u76843100\u4e07\u6587\u4ef6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u53ef\u884c\u6027\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5982\"\u53bb\u5e74\u6625\u5929\u4f1a\u8bae\u5730\u70b9\u9644\u8fd1\u7684\u7167\u7247\"\uff0c\u76f8\u6bd4Google Drive\u7b49\u5546\u4e1a\u7cfb\u7edf\uff0cIndaleko\u80fd\u6210\u529f\u5904\u7406\u591a\u7ef4\u67e5\u8be2\uff0c\u4fdd\u6301\u5b8c\u7f8e\u7cbe\u5ea6\uff0c\u65b0\u6570\u636e\u6e90\u96c6\u6210\u4ec5\u970010\u5206\u949f\u523010\u5c0f\u65f6\u3002", "conclusion": "UPI\u67b6\u6784\u5c06\u8ba4\u77e5\u7406\u8bba\u4e0e\u5206\u5e03\u5f0f\u7cfb\u7edf\u8bbe\u8ba1\u7ed3\u5408\uff0c\u5c06\u4e2a\u4eba\u4fe1\u606f\u68c0\u7d22\u4ece\u5173\u952e\u8bcd\u5339\u914d\u8f6c\u53d8\u4e3a\u8bb0\u5fc6\u5bf9\u9f50\u67e5\u627e\uff0c\u4e3a\u73b0\u6709\u6570\u636e\u63d0\u4f9b\u5373\u65f6\u4ef7\u503c\uff0c\u4e3a\u672a\u6765\u4e0a\u4e0b\u6587\u611f\u77e5\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2602.20164", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20164", "abs": "https://arxiv.org/abs/2602.20164", "authors": ["Sachin Gopal Wani", "Eric Page", "Ajay Dholakia", "David Ellison"], "title": "Benchmarking Distilled Language Models: Performance and Efficiency in Resource-Constrained Settings", "comment": "16 pages, 5 figures, accepted at the the 2025 TPCTC Conference", "summary": "Knowledge distillation offers a transformative pathway to developing powerful, yet efficient, small language models (SLMs) suitable for resource-constrained environments. In this paper, we benchmark the performance and computational cost of distilled models against their vanilla and proprietary counterparts, providing a quantitative analysis of their efficiency. Our results demonstrate that distillation creates a superior performance-tocompute curve. We find that creating a distilled 8B model is over 2,000 times more compute-efficient than training its vanilla counterpart, while achieving reasoning capabilities on par with, or even exceeding, standard models ten times its size. These findings validate distillation not just as a compression technique, but as a primary strategy for building state-of-the-art, accessible AI", "AI": {"tldr": "\u77e5\u8bc6\u84b8\u998f\u5728\u6784\u5efa\u9ad8\u6548\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u84b8\u998f8B\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\u6bd4\u8bad\u7ec3\u539f\u59cb\u6a21\u578b\u9ad82000\u500d\u4ee5\u4e0a\uff0c\u63a8\u7406\u80fd\u529b\u4e0e10\u500d\u5927\u5c0f\u7684\u6807\u51c6\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a", "motivation": "\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u5f00\u53d1\u5f3a\u5927\u800c\u9ad8\u6548\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u9a8c\u8bc1\u77e5\u8bc6\u84b8\u998f\u4f5c\u4e3a\u6784\u5efa\u5148\u8fdb\u3001\u53ef\u8bbf\u95eeAI\u7684\u4e3b\u8981\u7b56\u7565\u800c\u975e\u4ec5\u4ec5\u662f\u538b\u7f29\u6280\u672f", "method": "\u5bf9\u84b8\u998f\u6a21\u578b\u4e0e\u539f\u59cb\u6a21\u578b\u53ca\u4e13\u6709\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u6548\u7387\u7684\u5b9a\u91cf\u5206\u6790\uff0c\u6bd4\u8f83\u6027\u80fd-\u8ba1\u7b97\u66f2\u7ebf", "result": "\u84b8\u998f\u521b\u9020\u4e86\u66f4\u4f18\u7684\u6027\u80fd-\u8ba1\u7b97\u66f2\u7ebf\uff0c\u84b8\u998f8B\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\u6bd4\u8bad\u7ec3\u539f\u59cb\u6a21\u578b\u9ad82000\u500d\u4ee5\u4e0a\uff0c\u63a8\u7406\u80fd\u529b\u4e0e10\u500d\u5927\u5c0f\u7684\u6807\u51c6\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u4e0d\u4ec5\u662f\u538b\u7f29\u6280\u672f\uff0c\u66f4\u662f\u6784\u5efa\u6700\u5148\u8fdb\u3001\u53ef\u8bbf\u95eeAI\u7684\u4e3b\u8981\u7b56\u7565\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.20676", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20676", "abs": "https://arxiv.org/abs/2602.20676", "authors": ["Shuzhi Cao", "Rong Chen", "Ailong He", "Shuguang Han", "Jufeng Chen"], "title": "PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization", "comment": "arXiv admin note: text overlap with arXiv:2503.18395", "summary": "In search systems, effectively coordinating the two core objectives of search relevance matching and click-through rate (CTR) prediction is crucial for discovering users' interests and enhancing platform revenue. In our prior work PRECTR, we proposed a unified framework to integrate these two subtasks,thereby eliminating their inconsistency and leading to mutual benefit.However, our previous work still faces three main challenges. First, low-active users and new users have limited search behavioral data, making it difficult to achieve effective personalized relevance preference modeling. Second, training data for ranking models predominantly come from high-relevance exposures, creating a distribution mismatch with the broader candidate space in coarse-ranking, leading to generalization bias. Third, due to the latency constraint, the original model employs an Emb+MLP architecture with a frozen BERT encoder, which prevents joint optimization and creates misalignment between representation learning and CTR fine-tuning. To solve these issues, we further reinforce our method and propose PRECTR-V2. Specifically, we mitigate the low-activity users' sparse behavior problem by mining global relevance preferences under the specific query, which facilitates effective personalized relevance modeling for cold-start scenarios. Subsequently, we construct hard negative samples through embedding noise injection and relevance label reconstruction, and optimize their relative ranking against positive samples via pairwise loss, thereby correcting exposure bias. Finally, we pretrain a lightweight transformer-based encoder via knowledge distillation from LLM and SFT on the text relevance classification task. This encoder replaces the frozen BERT module, enabling better adaptation to CTR fine-tuning and advancing beyond the traditional Emb+MLP paradigm.", "AI": {"tldr": "PRECTR-V2\u901a\u8fc7\u6316\u6398\u5168\u5c40\u76f8\u5173\u6027\u504f\u597d\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u901a\u8fc7\u5d4c\u5165\u566a\u58f0\u6ce8\u5165\u548c\u76f8\u5173\u6027\u6807\u7b7e\u91cd\u6784\u6784\u5efa\u786c\u8d1f\u6837\u672c\u7ea0\u6b63\u66dd\u5149\u504f\u5dee\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7Transformer\u7f16\u7801\u5668\u66ff\u4ee3\u51bb\u7ed3BERT\u5b9e\u73b0\u8054\u5408\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u641c\u7d22\u76f8\u5173\u6027\u548c\u70b9\u51fb\u7387\u9884\u6d4b\u7684\u534f\u540c\u6548\u679c\u3002", "motivation": "\u89e3\u51b3PRECTR\u6846\u67b6\u9762\u4e34\u7684\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) \u4f4e\u6d3b\u8dc3\u7528\u6237\u548c\u65b0\u7528\u6237\u641c\u7d22\u884c\u4e3a\u6570\u636e\u6709\u9650\uff0c\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u4e2a\u6027\u5316\u76f8\u5173\u6027\u504f\u597d\u5efa\u6a21\uff1b2) \u6392\u5e8f\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e3b\u8981\u6765\u81ea\u9ad8\u76f8\u5173\u6027\u66dd\u5149\uff0c\u4e0e\u7c97\u6392\u5019\u9009\u7a7a\u95f4\u5b58\u5728\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u6cdb\u5316\u504f\u5dee\uff1b3) \u539f\u59cb\u6a21\u578b\u91c7\u7528Emb+MLP\u67b6\u6784\u548c\u51bb\u7ed3BERT\u7f16\u7801\u5668\uff0c\u65e0\u6cd5\u8054\u5408\u4f18\u5316\uff0c\u9020\u6210\u8868\u793a\u5b66\u4e60\u4e0eCTR\u5fae\u8c03\u4e4b\u95f4\u7684\u4e0d\u5bf9\u9f50\u3002", "method": "1) \u5728\u7279\u5b9a\u67e5\u8be2\u4e0b\u6316\u6398\u5168\u5c40\u76f8\u5173\u6027\u504f\u597d\uff0c\u89e3\u51b3\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u7684\u4e2a\u6027\u5316\u5efa\u6a21\u95ee\u9898\uff1b2) \u901a\u8fc7\u5d4c\u5165\u566a\u58f0\u6ce8\u5165\u548c\u76f8\u5173\u6027\u6807\u7b7e\u91cd\u6784\u6784\u5efa\u786c\u8d1f\u6837\u672c\uff0c\u4f7f\u7528\u6210\u5bf9\u635f\u5931\u4f18\u5316\u6b63\u8d1f\u6837\u672c\u7684\u76f8\u5bf9\u6392\u5e8f\uff0c\u7ea0\u6b63\u66dd\u5149\u504f\u5dee\uff1b3) \u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4eceLLM\u83b7\u53d6\u77e5\u8bc6\u5e76\u5728\u6587\u672c\u76f8\u5173\u6027\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884cSFT\uff0c\u9884\u8bad\u7ec3\u8f7b\u91cf\u7ea7Transformer\u7f16\u7801\u5668\uff0c\u66ff\u4ee3\u51bb\u7ed3BERT\u6a21\u5757\uff0c\u5b9e\u73b0\u4e0eCTR\u5fae\u8c03\u7684\u66f4\u597d\u9002\u914d\u3002", "result": "PRECTR-V2\u6709\u6548\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u7528\u6237\u5efa\u6a21\u95ee\u9898\uff0c\u901a\u8fc7\u786c\u8d1f\u6837\u672c\u6784\u5efa\u7ea0\u6b63\u4e86\u66dd\u5149\u504f\u5dee\uff0c\u8f7b\u91cf\u7ea7Transformer\u7f16\u7801\u5668\u5b9e\u73b0\u4e86\u8868\u793a\u5b66\u4e60\u4e0eCTR\u5fae\u8c03\u7684\u8054\u5408\u4f18\u5316\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684Emb+MLP\u8303\u5f0f\u3002", "conclusion": "PRECTR-V2\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u6280\u672f\u6539\u8fdb\uff0c\u5168\u9762\u89e3\u51b3\u4e86\u539f\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u641c\u7d22\u76f8\u5173\u6027\u5339\u914d\u4e0eCTR\u9884\u6d4b\u7684\u66f4\u6709\u6548\u534f\u540c\uff0c\u4e3a\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2602.20704", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.20704", "abs": "https://arxiv.org/abs/2602.20704", "authors": ["Zesheng Wang", "Longfei Xu", "Weidong Deng", "Huimin Yan", "Kaikui Liu", "Xiangxiang Chu"], "title": "IntRR: A Framework for Integrating SID Redistribution and Length Reduction", "comment": null, "summary": "Generative Recommendation (GR) has emerged as a transformative paradigm that reformulates the traditional cascade ranking system into a sequence-to-item generation task, facilitated by the use of discrete Semantic IDs (SIDs). However, current SIDs are suboptimal as the indexing objectives (Stage 1) are misaligned with the actual recommendation goals (Stage 2). Since these identifiers remain static (Stage 2), the backbone model lacks the flexibility to adapt them to the evolving complexities of user interactions. Furthermore, the prevailing strategy of flattening hierarchical SIDs into token sequences leads to sequence length inflation, resulting in prohibitive computational overhead and inference latency. To address these challenges, we propose IntRR, a novel framework that integrates objective-aligned SID Redistribution and structural Length Reduction. By leveraging item-specific Unique IDs (UIDs) as collaborative anchors, this approach dynamically redistributes semantic weights across hierarchical codebook layers. Concurrently, IntRR handles the SID hierarchy recursively, eliminating the need to flatten sequences. This ensures a fixed cost of one token per item. Extensive experiments on benchmark datasets demonstrate that IntRR yields substantial improvements over representative generative baselines, achieving superior performance in both recommendation accuracy and efficiency.", "AI": {"tldr": "IntRR\u6846\u67b6\u901a\u8fc7\u8bed\u4e49ID\u91cd\u5206\u5e03\u548c\u957f\u5ea6\u7f29\u51cf\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u8bed\u4e49ID\u4e0e\u63a8\u8350\u76ee\u6807\u4e0d\u5bf9\u9f50\u3001\u5e8f\u5217\u8fc7\u957f\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u548c\u6548\u7387", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u8bed\u4e49ID\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a1\uff09\u7d22\u5f15\u76ee\u6807\uff08\u7b2c\u4e00\u9636\u6bb5\uff09\u4e0e\u63a8\u8350\u76ee\u6807\uff08\u7b2c\u4e8c\u9636\u6bb5\uff09\u4e0d\u5bf9\u9f50\uff0c\u4e14\u8bed\u4e49ID\u5728\u7b2c\u4e8c\u9636\u6bb5\u4fdd\u6301\u9759\u6001\uff0c\u65e0\u6cd5\u9002\u5e94\u7528\u6237\u4ea4\u4e92\u7684\u590d\u6742\u6027\uff1b2\uff09\u5c06\u5206\u5c42\u8bed\u4e49ID\u5c55\u5e73\u4e3a\u5e8f\u5217\u5bfc\u81f4\u5e8f\u5217\u957f\u5ea6\u81a8\u80c0\uff0c\u5e26\u6765\u8ba1\u7b97\u5f00\u9500\u548c\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898", "method": "\u63d0\u51faIntRR\u6846\u67b6\uff0c\u5305\u542b\u76ee\u6807\u5bf9\u9f50\u7684\u8bed\u4e49ID\u91cd\u5206\u5e03\u548c\u7ed3\u6784\u957f\u5ea6\u7f29\u51cf\u3002\u5229\u7528\u9879\u76ee\u7279\u5b9a\u552f\u4e00ID\u4f5c\u4e3a\u534f\u4f5c\u951a\u70b9\uff0c\u5728\u5206\u5c42\u7801\u672c\u5c42\u95f4\u52a8\u6001\u91cd\u5206\u5e03\u8bed\u4e49\u6743\u91cd\uff1b\u540c\u65f6\u9012\u5f52\u5904\u7406\u8bed\u4e49ID\u5c42\u6b21\u7ed3\u6784\uff0c\u907f\u514d\u5e8f\u5217\u5c55\u5e73\uff0c\u786e\u4fdd\u6bcf\u4e2a\u9879\u76ee\u56fa\u5b9a\u4e3a\u4e00\u4e2atoken", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cIntRR\u76f8\u6bd4\u4ee3\u8868\u6027\u751f\u6210\u5f0f\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5728\u63a8\u8350\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u90fd\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd", "conclusion": "IntRR\u901a\u8fc7\u8bed\u4e49ID\u91cd\u5206\u5e03\u548c\u957f\u5ea6\u7f29\u51cf\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u8bed\u4e49ID\u4e0d\u5bf9\u9f50\u548c\u5e8f\u5217\u8fc7\u957f\u7684\u95ee\u9898\uff0c\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.20735", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20735", "abs": "https://arxiv.org/abs/2602.20735", "authors": ["Kun Ran", "Marwah Alaofi", "Danula Hettiachchi", "Chenglong Ma", "Khoi Nguyen Dinh Anh", "Khoi Vo Nguyen", "Sachin Pathiyan Cherumanal", "Lida Rashidi", "Falk Scholer", "Damiano Spina", "Shuoqi Sun", "Oleg Zendel"], "title": "RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition", "comment": "MMU-RAG NeurIPS 2025 winning system", "summary": "This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text\n  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG\n  (R2RAG), a research-focused retrieval-augmented generation (RAG)\n  architecture composed of lightweight components that dynamically adapt the\n  retrieval strategy based on inferred query complexity and evidence\n  sufficiency. The system uses smaller LLMs, enabling operation on a single\n  consumer-grade GPU while supporting complex research tasks. It builds on the\n  G-RAG system, winner of the ACM~SIGIR~2025 LiveRAG Challenge, and extends it\n  with modules informed by qualitative review of outputs. R2RAG won the Best\n  Dynamic Evaluation award in the Open Source category, demonstrating high\n  effectiveness with careful design and efficient use of resources.", "AI": {"tldr": "RMIT-ADM+S\u56e2\u961f\u63d0\u51faR2RAG\u67b6\u6784\uff0c\u5728NeurIPS 2025 MMU-RAG\u7ade\u8d5b\u6587\u672c-\u6587\u672c\u8d5b\u9053\u83b7\u5956\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7ec4\u4ef6\u52a8\u6001\u8c03\u6574\u68c0\u7d22\u7b56\u7565\uff0c\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u9ad8\u6548\u8fd0\u884c\u590d\u6742\u7814\u7a76\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfRAG\u7cfb\u7edf\u5728\u9762\u5bf9\u4e0d\u540c\u590d\u6742\u5ea6\u67e5\u8be2\u65f6\u68c0\u7d22\u7b56\u7565\u56fa\u5b9a\u3001\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u6839\u636e\u67e5\u8be2\u590d\u6742\u6027\u548c\u8bc1\u636e\u5145\u5206\u6027\u52a8\u6001\u8c03\u6574\u68c0\u7d22\u7b56\u7565\u7684\u8f7b\u91cf\u7ea7RAG\u67b6\u6784\uff0c\u4f7f\u5176\u80fd\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "method": "\u63d0\u51faRouting-to-RAG (R2RAG)\u67b6\u6784\uff0c\u57fa\u4e8eG-RAG\u7cfb\u7edf\uff08ACM SIGIR 2025 LiveRAG\u6311\u6218\u8d5b\u83b7\u80dc\u7cfb\u7edf\uff09\u6269\u5c55\uff0c\u5305\u542b\u8f7b\u91cf\u7ea7\u7ec4\u4ef6\uff1a1) \u67e5\u8be2\u590d\u6742\u5ea6\u63a8\u65ad\u6a21\u5757\uff1b2) \u8bc1\u636e\u5145\u5206\u6027\u8bc4\u4f30\u6a21\u5757\uff1b3) \u52a8\u6001\u68c0\u7d22\u7b56\u7565\u8def\u7531\u6a21\u5757\u3002\u7cfb\u7edf\u4f7f\u7528\u8f83\u5c0f\u89c4\u6a21LLM\uff0c\u652f\u6301\u5728\u5355\u5f20\u6d88\u8d39\u7ea7GPU\u4e0a\u8fd0\u884c\u3002", "result": "R2RAG\u5728NeurIPS 2025 MMU-RAG\u7ade\u8d5b\u6587\u672c-\u6587\u672c\u8d5b\u9053\u4e2d\u83b7\u5f97\u6700\u4f73\u52a8\u6001\u8bc4\u4f30\u5956\uff08\u5f00\u6e90\u7c7b\u522b\uff09\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u6709\u6548\u6027\u3002\u7cfb\u7edf\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u548c\u8d44\u6e90\u9ad8\u6548\u5229\u7528\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "conclusion": "R2RAG\u5c55\u793a\u4e86\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7ec4\u4ef6\u548c\u52a8\u6001\u8def\u7531\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u590d\u6742\u7814\u7a76\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u67e5\u8be2\u590d\u6742\u6027\u548c\u8bc1\u636e\u5145\u5206\u6027\u7684\u52a8\u6001\u7b56\u7565\u8c03\u6574\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.20303", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20303", "abs": "https://arxiv.org/abs/2602.20303", "authors": ["Joyanta Jyoti Mondal"], "title": "Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health", "comment": null, "summary": "Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u7edf\u8ba1\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u7f8e\u56fd\u9752\u5c11\u5e74\u8d85\u91cd/\u80a5\u80d6\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u903b\u8f91\u56de\u5f52\u3001\u68af\u5ea6\u63d0\u5347\u548c\u591a\u5c42\u611f\u77e5\u5668\u8868\u73b0\u6700\u7a33\u5b9a\uff0c\u6a21\u578b\u590d\u6742\u5ea6\u589e\u52a0\u5e26\u6765\u7684\u6539\u8fdb\u6709\u9650\uff0c\u4e14\u6240\u6709\u6a21\u578b\u5728\u4e0d\u540c\u79cd\u65cf\u548c\u8d2b\u56f0\u7fa4\u4f53\u95f4\u90fd\u5b58\u5728\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u513f\u7ae5\u548c\u9752\u5c11\u5e74\u8d85\u91cd/\u80a5\u80d6\u662f\u7f8e\u56fd\u4e3b\u8981\u7684\u516c\u5171\u536b\u751f\u95ee\u9898\uff0c\u53d7\u884c\u4e3a\u3001\u5bb6\u5ead\u548c\u793e\u533a\u56e0\u7d20\u5171\u540c\u5f71\u54cd\u3002\u76ee\u524d\u5bf9\u8fd9\u4e9b\u591a\u5c42\u6b21\u9884\u6d4b\u56e0\u7d20\u5728\u4eba\u7fa4\u5c42\u9762\u7684\u8054\u5408\u9884\u6d4b\u7ed3\u6784\u4e86\u89e3\u4e0d\u8db3\uff0c\u4e14\u9700\u8981\u6bd4\u8f83\u4e0d\u540c\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3001\u6821\u51c6\u548c\u4e9a\u7ec4\u516c\u5e73\u6027\u3002", "method": "\u4f7f\u75282021\u5e74\u56fd\u5bb6\u513f\u7ae5\u5065\u5eb7\u8c03\u67e5\u4e2d18,792\u540d10-17\u5c81\u513f\u7ae5\u7684\u6570\u636e\u3002\u9884\u6d4b\u56e0\u7d20\u5305\u62ec\u996e\u98df\u3001\u4f53\u80b2\u6d3b\u52a8\u3001\u7761\u7720\u3001\u7236\u6bcd\u538b\u529b\u3001\u793e\u4f1a\u7ecf\u6d4e\u6761\u4ef6\u3001\u4e0d\u826f\u7ecf\u5386\u548c\u793e\u533a\u7279\u5f81\u3002\u6bd4\u8f83\u4e86\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\u3001XGBoost\u3001LightGBM\u3001\u591a\u5c42\u611f\u77e5\u5668\u548cTabNet\u7b49\u6a21\u578b\uff0c\u4f7f\u7528AUC\u3001\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cBrier\u5206\u6570\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u533a\u5206\u5ea6\u57280.66-0.79\u4e4b\u95f4\u3002\u903b\u8f91\u56de\u5f52\u3001\u68af\u5ea6\u63d0\u5347\u548c\u591a\u5c42\u611f\u77e5\u5668\u5728\u533a\u5206\u5ea6\u548c\u6821\u51c6\u65b9\u9762\u8868\u73b0\u6700\u7a33\u5b9a\u3002\u63d0\u5347\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u7565\u6709\u6539\u5584\uff0c\u4f46\u6ca1\u6709\u6a21\u578b\u5728\u6240\u6709\u65b9\u9762\u90fd\u8868\u73b0\u6700\u4f18\u3002\u6240\u6709\u7b97\u6cd5\u5728\u4e0d\u540c\u79cd\u65cf\u548c\u8d2b\u56f0\u7fa4\u4f53\u95f4\u90fd\u5b58\u5728\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u5bf9\u903b\u8f91\u56de\u5f52\u7684\u6539\u8fdb\u6709\u9650\u3002\u9884\u6d4b\u56e0\u7d20\u59cb\u7ec8\u6db5\u76d6\u884c\u4e3a\u3001\u5bb6\u5ead\u548c\u793e\u533a\u9886\u57df\u3002\u6301\u7eed\u7684\u4e9a\u7ec4\u5dee\u5f02\u8868\u660e\u9700\u8981\u6539\u8fdb\u6570\u636e\u8d28\u91cf\u548c\u5173\u6ce8\u516c\u5e73\u6027\u7684\u76d1\u6d4b\uff0c\u800c\u4e0d\u662f\u8ffd\u6c42\u66f4\u9ad8\u7684\u7b97\u6cd5\u590d\u6742\u5ea6\u3002"}}
{"id": "2602.20300", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20300", "abs": "https://arxiv.org/abs/2602.20300", "authors": ["William Watson", "Nicole Cho", "Sumitra Ganesh", "Manuela Veloso"], "title": "What Makes a Good Query? Measuring the Impact of Human-Confusing Linguistic Features on LLM Performance", "comment": "EACL 2026 Findings", "summary": "Large Language Model (LLM) hallucinations are usually treated as defects of the model or its decoding strategy. Drawing on classical linguistics, we argue that a query's form can also shape a listener's (and model's) response. We operationalize this insight by constructing a 22-dimension query feature vector covering clause complexity, lexical rarity, and anaphora, negation, answerability, and intention grounding, all known to affect human comprehension. Using 369,837 real-world queries, we ask: Are there certain types of queries that make hallucination more likely? A large-scale analysis reveals a consistent \"risk landscape\": certain features such as deep clause nesting and underspecification align with higher hallucination propensity. In contrast, clear intention grounding and answerability align with lower hallucination rates. Others, including domain specificity, show mixed, dataset- and model-dependent effects. Thus, these findings establish an empirically observable query-feature representation correlated with hallucination risk, paving the way for guided query rewriting and future intervention studies.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u67e5\u8be2\u7279\u5f81\u4e0eLLM\u5e7b\u89c9\u98ce\u9669\u76f8\u5173\uff0c\u7279\u5b9a\u67e5\u8be2\u7ed3\u6784\uff08\u5982\u6df1\u5c42\u5b50\u53e5\u5d4c\u5957\u3001\u4e0d\u660e\u786e\u6027\uff09\u4f1a\u589e\u52a0\u5e7b\u89c9\u6982\u7387\uff0c\u800c\u660e\u786e\u610f\u56fe\u548c\u53ef\u56de\u7b54\u6027\u5219\u964d\u4f4e\u98ce\u9669\u3002", "motivation": "\u4f20\u7edf\u4e0aLLM\u5e7b\u89c9\u88ab\u89c6\u4e3a\u6a21\u578b\u6216\u89e3\u7801\u7b56\u7565\u7684\u7f3a\u9677\uff0c\u4f46\u672c\u6587\u4ece\u8bed\u8a00\u5b66\u89d2\u5ea6\u63d0\u51fa\u67e5\u8be2\u5f62\u5f0f\u4e5f\u4f1a\u5f71\u54cd\u6a21\u578b\u54cd\u5e94\uff0c\u9700\u8981\u63a2\u7a76\u54ea\u4e9b\u67e5\u8be2\u7279\u5f81\u4f1a\u589e\u52a0\u5e7b\u89c9\u98ce\u9669\u3002", "method": "\u6784\u5efa22\u7ef4\u67e5\u8be2\u7279\u5f81\u5411\u91cf\uff0c\u6db5\u76d6\u5b50\u53e5\u590d\u6742\u5ea6\u3001\u8bcd\u6c47\u7a00\u6709\u6027\u3001\u56de\u6307\u3001\u5426\u5b9a\u3001\u53ef\u56de\u7b54\u6027\u548c\u610f\u56fe\u57fa\u7840\u7b49\u8bed\u8a00\u5b66\u7279\u5f81\uff1b\u4f7f\u7528369,837\u4e2a\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4e00\u81f4\u7684\"\u98ce\u9669\u56fe\u8c31\"\uff1a\u6df1\u5c42\u5b50\u53e5\u5d4c\u5957\u548c\u4e0d\u660e\u786e\u6027\u4e0e\u66f4\u9ad8\u5e7b\u89c9\u503e\u5411\u76f8\u5173\uff1b\u660e\u786e\u610f\u56fe\u57fa\u7840\u548c\u53ef\u56de\u7b54\u6027\u4e0e\u66f4\u4f4e\u5e7b\u89c9\u7387\u76f8\u5173\uff1b\u9886\u57df\u7279\u5f02\u6027\u5219\u5448\u73b0\u6df7\u5408\u3001\u6570\u636e\u96c6\u548c\u6a21\u578b\u4f9d\u8d56\u6548\u5e94\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e0e\u5e7b\u89c9\u98ce\u9669\u76f8\u5173\u7684\u53ef\u89c2\u5bdf\u67e5\u8be2\u7279\u5f81\u8868\u793a\uff0c\u4e3a\u5f15\u5bfc\u6027\u67e5\u8be2\u91cd\u5199\u548c\u672a\u6765\u5e72\u9884\u7814\u7a76\u94fa\u5e73\u9053\u8def\uff0c\u8868\u660e\u67e5\u8be2\u5f62\u5f0f\u662f\u5f71\u54cdLLM\u5e7b\u89c9\u7684\u91cd\u8981\u56e0\u7d20\u3002"}}
{"id": "2602.20800", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.20800", "abs": "https://arxiv.org/abs/2602.20800", "authors": ["Dalia Nahhas", "Xiaohao Cai", "Imran Razzak", "Shoaib Jameel"], "title": "Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking", "comment": null, "summary": "In Generative Information Retrieval (GenIR), the bottleneck has shifted from generation to the selection of candidates, particularly for normative criteria such as cultural relevance. Current LLM-as-a-Judge evaluations often suffer from circularity and preference leakage, where overlapping supervision and evaluation models inflate performance. We address this by formalising cultural relevance as a within-query ranking task and introducing a leakage-free two-judge framework that strictly separates supervision (Judge B) from evaluation (Judge A). On a new benchmark of 33,052 (NGR-33k) culturally grounded stories, we find that while classical baselines yield only modest gains, a dense bi-encoder distilled from a Judge-B-supervised Cross-Encoder is highly effective. Although the Cross-Encoder provides a strong supervision signal for distillation, the distilled BGE-M3 model substantially outperforms it under leakage-free Judge~A evaluation. We validate our framework on the human-curated Moral Stories dataset, showing strong alignment with human norms. Our results demonstrate that rigorous evaluator separation is a prerequisite for credible GenIR evaluation, proving that subtle cultural preferences can be distilled into efficient rankers without leakage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6cc4\u6f0f\u7684\u53cc\u6cd5\u5b98\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u6587\u5316\u76f8\u5173\u6027\uff0c\u901a\u8fc7\u4e25\u683c\u5206\u79bb\u76d1\u7763\u548c\u8bc4\u4f30\u6a21\u578b\u89e3\u51b3\u73b0\u6709LLM\u8bc4\u4f30\u4e2d\u7684\u5faa\u73af\u6027\u548c\u504f\u597d\u6cc4\u6f0f\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u4fe1\u606f\u68c0\u7d22\u4e2d\uff0c\u5019\u9009\u9009\u62e9\u7684\u74f6\u9888\u5df2\u4ece\u751f\u6210\u8f6c\u5411\u9009\u62e9\uff0c\u7279\u522b\u662f\u5728\u6587\u5316\u76f8\u5173\u6027\u7b49\u89c4\u8303\u6027\u6807\u51c6\u65b9\u9762\u3002\u73b0\u6709\u7684LLM-as-a-Judge\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5faa\u73af\u6027\u548c\u504f\u597d\u6cc4\u6f0f\u95ee\u9898\uff0c\u5373\u76d1\u7763\u548c\u8bc4\u4f30\u6a21\u578b\u91cd\u53e0\u5bfc\u81f4\u6027\u80fd\u865a\u9ad8\u3002", "method": "1) \u5c06\u6587\u5316\u76f8\u5173\u6027\u5f62\u5f0f\u5316\u4e3a\u67e5\u8be2\u5185\u6392\u5e8f\u4efb\u52a1\uff1b2) \u5f15\u5165\u65e0\u6cc4\u6f0f\u7684\u53cc\u6cd5\u5b98\u6846\u67b6\uff0c\u4e25\u683c\u5206\u79bb\u76d1\u7763\u6a21\u578b(Judge B)\u548c\u8bc4\u4f30\u6a21\u578b(Judge A)\uff1b3) \u4f7f\u7528\u4eceJudge B\u76d1\u7763\u7684\u4ea4\u53c9\u7f16\u7801\u5668\u84b8\u998f\u5f97\u5230\u7684\u5bc6\u96c6\u53cc\u7f16\u7801\u5668\uff1b4) \u5728\u5305\u542b33,052\u4e2a\u6587\u5316\u57fa\u7840\u6545\u4e8b\u7684\u65b0\u57fa\u51c6(NGR-33k)\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "1) \u7ecf\u5178\u57fa\u7ebf\u65b9\u6cd5\u4ec5\u83b7\u5f97\u9002\u5ea6\u63d0\u5347\uff1b2) \u4ece\u4ea4\u53c9\u7f16\u7801\u5668\u84b8\u998f\u5f97\u5230\u7684\u5bc6\u96c6\u53cc\u7f16\u7801\u5668(BGE-M3)\u975e\u5e38\u6709\u6548\uff1b3) \u5c3d\u7ba1\u4ea4\u53c9\u7f16\u7801\u5668\u4e3a\u84b8\u998f\u63d0\u4f9b\u4e86\u5f3a\u76d1\u7763\u4fe1\u53f7\uff0c\u4f46\u84b8\u998f\u540e\u7684BGE-M3\u6a21\u578b\u5728\u65e0\u6cc4\u6f0f\u7684Judge A\u8bc4\u4f30\u4e2d\u663e\u8457\u4f18\u4e8e\u5b83\uff1b4) \u5728\u4eba\u5de5\u7b56\u5212\u7684Moral Stories\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u663e\u793a\u4e0e\u4eba\u7c7b\u89c4\u8303\u7684\u5f3a\u5bf9\u9f50\u3002", "conclusion": "\u4e25\u683c\u7684\u8bc4\u4f30\u8005\u5206\u79bb\u662f\u53ef\u4fe1\u7684\u751f\u6210\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u7684\u524d\u63d0\uff0c\u8bc1\u660e\u5fae\u5999\u7684\u6587\u5316\u504f\u597d\u53ef\u4ee5\u5728\u65e0\u6cc4\u6f0f\u7684\u60c5\u51b5\u4e0b\u84b8\u998f\u5230\u9ad8\u6548\u7684\u6392\u5e8f\u5668\u4e2d\u3002\u8be5\u6846\u67b6\u4e3a\u6587\u5316\u76f8\u5173\u6027\u7b49\u89c4\u8303\u6027\u6807\u51c6\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u65b9\u6cd5\u3002"}}
{"id": "2602.20332", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20332", "abs": "https://arxiv.org/abs/2602.20332", "authors": ["Nicole Cho", "William Watson", "Alec Koppel", "Sumitra Ganesh", "Manuela Veloso"], "title": "No One Size Fits All: QueryBandits for Hallucination Mitigation", "comment": null, "summary": "Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models is especially concerning, as they constitute the vast majority of models in institutional deployments. We introduce QueryBandits, a model-agnostic contextual bandit framework that adaptively learns online to select the optimal query-rewrite strategy by leveraging an empirically validated and calibrated reward function. Across 16 QA scenarios, our top QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a No-Rewrite baseline and outperforms zero-shot static policies (e.g., Paraphrase or Expand) by 42.6% and 60.3%, respectively. Moreover, all contextual bandits outperform vanilla bandits across all datasets, with higher feature variance coinciding with greater variance in arm selection. This substantiates our finding that there is no single rewrite policy optimal for all queries. We also discover that certain static policies incur higher cumulative regret than No-Rewrite, indicating that an inflexible query-rewriting policy can worsen hallucinations. Thus, learning an online policy over semantic features with QueryBandits can shift model behavior purely through forward-pass mechanisms, enabling its use with closed-source models and bypassing the need for retraining or gradient-based adaptation.", "AI": {"tldr": "QueryBandits\uff1a\u9488\u5bf9\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u7684\u6a21\u578b\u65e0\u5173\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u9009\u62e9\u6700\u4f18\u67e5\u8be2\u91cd\u5199\u7b56\u7565\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u7ec3\u6216\u68af\u5ea6\u8c03\u6574", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u7f13\u89e3LLM\u5e7b\u89c9\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u5f00\u6e90\u6a21\u578b\u7684\u540e\u9a8c\u68c0\u6d4b\u548c\u53c2\u6570\u7f16\u8f91\u4e0a\uff0c\u800c\u95ed\u6e90\u6a21\u578b\u5728\u673a\u6784\u90e8\u7f72\u4e2d\u5360\u7edd\u5927\u591a\u6570\u5374\u7f3a\u4e4f\u76f8\u5173\u7814\u7a76\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u6a21\u578b\u5185\u90e8\u8bbf\u95ee\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faQueryBandits\u6846\u67b6\uff0c\u4f7f\u7528\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u81ea\u9002\u5e94\u5728\u7ebf\u5b66\u4e60\u9009\u62e9\u6700\u4f18\u67e5\u8be2\u91cd\u5199\u7b56\u7565\uff0c\u57fa\u4e8e\u7ecf\u9a8c\u9a8c\u8bc1\u548c\u6821\u51c6\u7684\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u8bed\u4e49\u7279\u5f81\u5b66\u4e60\u5728\u7ebf\u7b56\u7565\uff0c\u4ec5\u4f7f\u7528\u524d\u5411\u4f20\u64ad\u673a\u5236", "result": "\u572816\u4e2aQA\u573a\u666f\u4e2d\uff0c\u6700\u4f73QueryBandits\uff08Thompson Sampling\uff09\u76f8\u6bd4\u65e0\u91cd\u5199\u57fa\u7ebf\u83b7\u5f9787.5%\u80dc\u7387\uff0c\u5206\u522b\u6bd4\u96f6\u6837\u672c\u9759\u6001\u7b56\u7565\uff08\u5982Paraphrase\u6216Expand\uff09\u9ad8\u51fa42.6%\u548c60.3%\uff1b\u6240\u6709\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u90fd\u4f18\u4e8e\u666e\u901a\u8d4c\u535a\u673a", "conclusion": "\u6ca1\u6709\u5355\u4e00\u91cd\u5199\u7b56\u7565\u9002\u7528\u4e8e\u6240\u6709\u67e5\u8be2\uff0c\u4e0d\u7075\u6d3b\u7684\u67e5\u8be2\u91cd\u5199\u7b56\u7565\u53ef\u80fd\u52a0\u5267\u5e7b\u89c9\uff1bQueryBandits\u901a\u8fc7\u7eaf\u524d\u5411\u4f20\u64ad\u673a\u5236\u6539\u53d8\u6a21\u578b\u884c\u4e3a\uff0c\u53ef\u7528\u4e8e\u95ed\u6e90\u6a21\u578b\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u6216\u57fa\u4e8e\u68af\u5ea6\u7684\u9002\u5e94"}}
{"id": "2602.20333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20333", "abs": "https://arxiv.org/abs/2602.20333", "authors": ["Samarth KaPatel", "Sofia Nikiforova", "Giacinto Paolo Saggese", "Paul Smith"], "title": "DMCD: Semantic-Statistical Framework for Causal Discovery", "comment": null, "summary": "We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.\n  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.", "AI": {"tldr": "DMCD\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u7ed3\u5408LLM\u8bed\u4e49\u8349\u7a3f\u4e0e\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u901a\u8fc7\u53d8\u91cf\u5143\u6570\u636e\u751f\u6210\u7a00\u758fDAG\u8349\u7a3f\uff0c\u518d\u7ecf\u6761\u4ef6\u72ec\u7acb\u6027\u6d4b\u8bd5\u7cbe\u4fee\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u4e0a\u53d6\u5f97\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u901a\u5e38\u4ec5\u4f9d\u8d56\u7edf\u8ba1\u6d4b\u8bd5\u6216\u7ed3\u6784\u7ea6\u675f\uff0c\u7f3a\u4e4f\u5229\u7528\u53d8\u91cf\u5143\u6570\u636e\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u3002DMCD\u65e8\u5728\u6574\u5408LLM\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u4e0e\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u63d0\u5347\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u53d8\u91cf\u5143\u6570\u636e\u751f\u6210\u7a00\u758fDAG\u8349\u7a3f\uff0c\u4f5c\u4e3a\u8bed\u4e49\u5148\u9a8c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6761\u4ef6\u72ec\u7acb\u6027\u6d4b\u8bd5\u5ba1\u6838\u548c\u7cbe\u4fee\u8349\u7a3f\uff0c\u68c0\u6d4b\u5dee\u5f02\u5e76\u6307\u5bfc\u6709\u9488\u5bf9\u6027\u7684\u8fb9\u4fee\u6b63\u3002", "result": "\u5728\u5de5\u4e1a\u5de5\u7a0b\u3001\u73af\u5883\u76d1\u6d4b\u548cIT\u7cfb\u7edf\u5206\u6790\u4e09\u4e2a\u5143\u6570\u636e\u4e30\u5bcc\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u4e0a\uff0cDMCD\u76f8\u6bd4\u591a\u79cd\u56e0\u679c\u53d1\u73b0\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u7ade\u4e89\u6027\u6216\u9886\u5148\u6027\u80fd\uff0c\u5c24\u5176\u5728\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002\u63a2\u9488\u548c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u6539\u8fdb\u6e90\u4e8e\u5143\u6570\u636e\u7684\u8bed\u4e49\u63a8\u7406\u800c\u975e\u57fa\u51c6\u56fe\u7684\u8bb0\u5fc6\u3002", "conclusion": "\u5c06\u8bed\u4e49\u5148\u9a8c\u4e0e\u539f\u5219\u6027\u7edf\u8ba1\u9a8c\u8bc1\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u4ea7\u751f\u9ad8\u6027\u80fd\u4e14\u5b9e\u9645\u6709\u6548\u7684\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u6574\u5408\u8bed\u4e49\u63a8\u7406\u4e0e\u7edf\u8ba1\u65b9\u6cd5\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.20986", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.20986", "abs": "https://arxiv.org/abs/2602.20986", "authors": ["Thibault Formal", "Maxime Louis", "Herv\u00e9 D\u00e9jean", "St\u00e9phane Clinchant"], "title": "Naver Labs Europe @ WSDM CUP | Multilingual Retrieval", "comment": "Report paper of our submission to the WSDM Cup 2026", "summary": "This report presents our participation to the WSDM Cup 2026 shared task on multilingual document retrieval from English queries. The task provides a challenging benchmark for cross-lingual generalization. It also provides a natural testbed for evaluating SPLARE, our recently proposed learned sparse retrieval model, which produces generalizable sparse latent representations and is particularly well suited to multilingual retrieval settings.\n  We evaluate five progressively enhanced runs, starting from a SPLARE-7B model and incorporating lightweight improvements, including reranking with Qwen3-Reranker-4B and simple score fusion strategies. Our results demonstrate the strength of SPLARE compared to state-of-the-art dense baselines such as Qwen3-8B-Embed. More broadly, our submission highlights the continued relevance and competitiveness of learned sparse retrieval models beyond English-centric scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u56e2\u961f\u5728WSDM Cup 2026\u591a\u8bed\u8a00\u6587\u6863\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u53c2\u8d5b\u65b9\u6848\uff0c\u5c55\u793a\u4e86SPLARE\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "WSDM Cup 2026\u7684\u591a\u8bed\u8a00\u6587\u6863\u68c0\u7d22\u4efb\u52a1\u4e3a\u8de8\u8bed\u8a00\u6cdb\u5316\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u540c\u65f6\u4e5f\u4e3a\u8bc4\u4f30SPLARE\u6a21\u578b\u63d0\u4f9b\u4e86\u5929\u7136\u6d4b\u8bd5\u5e73\u53f0\u3002\u8be5\u4efb\u52a1\u65e8\u5728\u9a8c\u8bc1\u5b66\u4e60\u578b\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u548c\u7ade\u4e89\u529b\u3002", "method": "\u91c7\u7528SPLARE-7B\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u6e10\u8fdb\u589e\u5f3a\u7684\u65b9\u5f0f\u6784\u5efa\u4e86\u4e94\u4e2a\u4e0d\u540c\u914d\u7f6e\u7684\u68c0\u7d22\u7cfb\u7edf\u3002\u6539\u8fdb\u5305\u62ec\u4f7f\u7528Qwen3-Reranker-4B\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u4ee5\u53ca\u91c7\u7528\u7b80\u5355\u7684\u5206\u6570\u878d\u5408\u7b56\u7565\u3002\u8fd9\u4e9b\u6539\u8fdb\u90fd\u662f\u8f7b\u91cf\u7ea7\u7684\uff0c\u65e8\u5728\u4fdd\u6301\u6a21\u578b\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSPLARE\u6a21\u578b\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u7a20\u5bc6\u57fa\u7ebf\u6a21\u578b\uff08\u5982Qwen3-8B-Embed\uff09\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u68c0\u7d22\u80fd\u529b\u3002\u56e2\u961f\u63d0\u4ea4\u7684\u7ed3\u679c\u8bc1\u660e\u4e86\u5b66\u4e60\u578b\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u6301\u7eed\u76f8\u5173\u6027\u548c\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5b66\u4e60\u578b\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5728\u8d85\u8d8a\u82f1\u8bed\u4e2d\u5fc3\u573a\u666f\u7684\u591a\u8bed\u8a00\u68c0\u7d22\u4efb\u52a1\u4e2d\u4ecd\u7136\u5177\u6709\u91cd\u8981\u4ef7\u503c\u548c\u7ade\u4e89\u529b\u3002SPLARE\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u53ef\u6cdb\u5316\u7684\u7a00\u758f\u6f5c\u5728\u8868\u793a\uff0c\u7279\u522b\u9002\u5408\u591a\u8bed\u8a00\u68c0\u7d22\u8bbe\u7f6e\u3002"}}
{"id": "2602.20422", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20422", "abs": "https://arxiv.org/abs/2602.20422", "authors": ["Hanping Zhang", "Yuhong Guo"], "title": "Diffusion Modulation via Environment Mechanism Modeling for Planning", "comment": null, "summary": "Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.", "AI": {"tldr": "DMEMM\u662f\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5165\u73af\u5883\u673a\u5236\u5efa\u6a21\u6765\u8c03\u5236\u6269\u6563\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6269\u6563\u89c4\u5212\u4e2d\u8f68\u8ff9\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u89c4\u5212\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u89c4\u5212\u65b9\u6cd5\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u751f\u6210\u8f68\u8ff9\u65f6\uff0c\u5f80\u5f80\u5ffd\u7565\u4e86\u8f68\u8ff9\u4e2d\u72b6\u6001\u8f6c\u79fb\u7684\u4e00\u81f4\u6027\u8981\u6c42\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8f68\u8ff9\u4e0e\u771f\u5b9e\u73af\u5883\u673a\u5236\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f71\u54cd\u89c4\u5212\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faDMEMM\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5165\u5173\u952eRL\u73af\u5883\u673a\u5236\uff08\u7279\u522b\u662f\u8f6c\u79fb\u52a8\u6001\u548c\u5956\u52b1\u51fd\u6570\uff09\u6765\u8c03\u5236\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u786e\u4fdd\u751f\u6210\u7684\u8f68\u8ff9\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u5177\u6709\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDMEMM\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u89c4\u5212\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u901a\u8fc7\u5c06\u73af\u5883\u673a\u5236\u5efa\u6a21\u878d\u5165\u6269\u6563\u6a21\u578b\u8bad\u7ec3\uff0cDMEMM\u6709\u6548\u89e3\u51b3\u4e86\u8f68\u8ff9\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.20372", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20372", "abs": "https://arxiv.org/abs/2602.20372", "authors": ["Chundra Cathcart", "Arne Rubehn", "Katja Bocklage", "Luca Ciucci", "Kellen Parker van Dam", "Al\u017eb\u011bta Ku\u010derov\u00e1", "Jekaterina Ma\u017eara", "Carlo Y. Meloni", "David Snee", "Johann-Mattis List"], "title": "How communicatively optimal are exact numeral systems? Once more on lexicon size and morphosyntactic complexity", "comment": null, "summary": "Recent research argues that exact recursive numeral systems optimize communicative efficiency by balancing a tradeoff between the size of the numeral lexicon and the average morphosyntactic complexity (roughly length in morphemes) of numeral terms. We argue that previous studies have not characterized the data in a fashion that accounts for the degree of complexity languages display. Using data from 52 genetically diverse languages and an annotation scheme distinguishing between predictable and unpredictable allomorphy (formal variation), we show that many of the world's languages are decisively less efficient than one would expect. We discuss the implications of our findings for the study of numeral systems and linguistic evolution more generally.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bb8\u591a\u8bed\u8a00\u7684\u6570\u5b57\u7cfb\u7edf\u5728\u4ea4\u6d41\u6548\u7387\u4e0a\u8fdc\u4f4e\u4e8e\u9884\u671f\uff0c\u6311\u6218\u4e86\u7cbe\u786e\u9012\u5f52\u6570\u5b57\u7cfb\u7edf\u4f18\u5316\u6548\u7387\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8ba4\u4e3a\u7cbe\u786e\u9012\u5f52\u6570\u5b57\u7cfb\u7edf\u901a\u8fc7\u5e73\u8861\u6570\u5b57\u8bcd\u6c47\u5e93\u5927\u5c0f\u548c\u6570\u5b57\u672f\u8bed\u7684\u5e73\u5747\u5f62\u6001\u53e5\u6cd5\u590d\u6742\u6027\u6765\u4f18\u5316\u4ea4\u6d41\u6548\u7387\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e9b\u7814\u7a76\u672a\u80fd\u5145\u5206\u89e3\u91ca\u8bed\u8a00\u5b9e\u9645\u663e\u793a\u7684\u590d\u6742\u6027\u7a0b\u5ea6\u3002", "method": "\u4f7f\u7528\u6765\u81ea52\u79cd\u9057\u4f20\u591a\u6837\u6027\u8bed\u8a00\u7684\u6570\u636e\uff0c\u91c7\u7528\u533a\u5206\u53ef\u9884\u6d4b\u548c\u4e0d\u53ef\u9884\u6d4b\u5f02\u5f62\uff08\u5f62\u5f0f\u53d8\u5f02\uff09\u7684\u6807\u6ce8\u65b9\u6848\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u8868\u660e\u4e16\u754c\u4e0a\u8bb8\u591a\u8bed\u8a00\u7684\u6570\u5b57\u7cfb\u7edf\u5728\u4ea4\u6d41\u6548\u7387\u4e0a\u660e\u663e\u4f4e\u4e8e\u9884\u671f\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u6570\u5b57\u7cfb\u7edf\u7814\u7a76\u548c\u8bed\u8a00\u6f14\u5316\u7814\u7a76\u5177\u6709\u91cd\u8981\u542f\u793a\uff0c\u8868\u660e\u5b9e\u9645\u8bed\u8a00\u7cfb\u7edf\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u9075\u5faa\u6700\u4f18\u6548\u7387\u539f\u5219\u3002"}}
{"id": "2602.20995", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20995", "abs": "https://arxiv.org/abs/2602.20995", "authors": ["Junyu Bi", "Xinting Niu", "Daixuan Cheng", "Kun Yuan", "Tao Wang", "Binbin Cao", "Jian Wu", "Yuning Jiang"], "title": "Generative Pseudo-Labeling for Pre-Ranking with LLMs", "comment": null, "summary": "Pre-ranking is a critical stage in industrial recommendation systems, tasked with efficiently scoring thousands of recalled items for downstream ranking. A key challenge is the train-serving discrepancy: pre-ranking models are trained only on exposed interactions, yet must score all recalled candidates -- including unexposed items -- during online serving. This mismatch not only induces severe sample selection bias but also degrades generalization, especially for long-tail content. Existing debiasing approaches typically rely on heuristics (e.g., negative sampling) or distillation from biased rankers, which either mislabel plausible unexposed items as negatives or propagate exposure bias into pseudo-labels. In this work, we propose Generative Pseudo-Labeling (GPL), a framework that leverages large language models (LLMs) to generate unbiased, content-aware pseudo-labels for unexposed items, explicitly aligning the training distribution with the online serving space. By offline generating user-specific interest anchors and matching them with candidates in a frozen semantic space, GPL provides high-quality supervision without adding online latency. Deployed in a large-scale production system, GPL improves click-through rate by 3.07%, while significantly enhancing recommendation diversity and long-tail item discovery.", "AI": {"tldr": "\u63d0\u51faGPL\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u672a\u66dd\u5149\u9879\u76ee\u751f\u6210\u65e0\u504f\u3001\u5185\u5bb9\u611f\u77e5\u7684\u4f2a\u6807\u7b7e\uff0c\u89e3\u51b3\u9884\u6392\u5e8f\u9636\u6bb5\u7684\u8bad\u7ec3-\u670d\u52a1\u5dee\u5f02\u95ee\u9898\uff0c\u5728\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u663e\u8457\u63d0\u5347\u70b9\u51fb\u7387\u548c\u591a\u6837\u6027\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u9884\u6392\u5e8f\u9636\u6bb5\u9762\u4e34\u8bad\u7ec3-\u670d\u52a1\u5dee\u5f02\uff1a\u6a21\u578b\u4ec5\u5728\u66dd\u5149\u4ea4\u4e92\u4e0a\u8bad\u7ec3\uff0c\u4f46\u9700\u8981\u5728\u7ebf\u4e0a\u670d\u52a1\u65f6\u5bf9\u6240\u6709\u53ec\u56de\u5019\u9009\uff08\u5305\u62ec\u672a\u66dd\u5149\u9879\u76ee\uff09\u8fdb\u884c\u8bc4\u5206\u3002\u8fd9\u79cd\u4e0d\u5339\u914d\u4e0d\u4ec5\u5bfc\u81f4\u4e25\u91cd\u7684\u6837\u672c\u9009\u62e9\u504f\u5dee\uff0c\u8fd8\u964d\u4f4e\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5bf9\u957f\u5c3e\u5185\u5bb9\u3002\u73b0\u6709\u53bb\u504f\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u5982\u8d1f\u91c7\u6837\uff09\u6216\u4ece\u6709\u504f\u6392\u5e8f\u5668\u84b8\u998f\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8981\u4e48\u5c06\u5408\u7406\u7684\u672a\u66dd\u5149\u9879\u76ee\u9519\u8bef\u6807\u8bb0\u4e3a\u8d1f\u6837\u672c\uff0c\u8981\u4e48\u5c06\u66dd\u5149\u504f\u5dee\u4f20\u64ad\u5230\u4f2a\u6807\u7b7e\u4e2d\u3002", "method": "\u63d0\u51fa\u751f\u6210\u5f0f\u4f2a\u6807\u7b7e\uff08GPL\uff09\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u672a\u66dd\u5149\u9879\u76ee\u751f\u6210\u65e0\u504f\u3001\u5185\u5bb9\u611f\u77e5\u7684\u4f2a\u6807\u7b7e\uff0c\u663e\u5f0f\u5730\u5c06\u8bad\u7ec3\u5206\u5e03\u4e0e\u5728\u7ebf\u670d\u52a1\u7a7a\u95f4\u5bf9\u9f50\u3002\u901a\u8fc7\u79bb\u7ebf\u751f\u6210\u7528\u6237\u7279\u5b9a\u7684\u5174\u8da3\u951a\u70b9\uff0c\u5e76\u5728\u51bb\u7ed3\u7684\u8bed\u4e49\u7a7a\u95f4\u4e2d\u4e0e\u5019\u9009\u9879\u76ee\u5339\u914d\uff0cGPL\u63d0\u4f9b\u9ad8\u8d28\u91cf\u76d1\u7763\u800c\u4e0d\u589e\u52a0\u5728\u7ebf\u5ef6\u8fdf\u3002", "result": "\u5728\u5927\u578b\u751f\u4ea7\u7cfb\u7edf\u4e2d\u90e8\u7f72\uff0cGPL\u5c06\u70b9\u51fb\u7387\u63d0\u9ad8\u4e863.07%\uff0c\u540c\u65f6\u663e\u8457\u589e\u5f3a\u4e86\u63a8\u8350\u591a\u6837\u6027\u548c\u957f\u5c3e\u9879\u76ee\u53d1\u73b0\u3002", "conclusion": "GPL\u6846\u67b6\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u65e0\u504f\u4f2a\u6807\u7b7e\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9884\u6392\u5e8f\u9636\u6bb5\u7684\u8bad\u7ec3-\u670d\u52a1\u5dee\u5f02\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2602.20426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20426", "abs": "https://arxiv.org/abs/2602.20426", "authors": ["Ruocheng Guo", "Kaiwen Dong", "Xiang Gao", "Kamalika Das"], "title": "Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use", "comment": "Preprint", "summary": "The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavailable in cold-start or privacy-constrained settings, and typically optimize each tool independently, limiting scalability and generalization to unseen tools. We propose Trace-Free+, a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment, encouraging the model to abstract reusable interface-usage patterns and tool usage outcomes. To support this approach, we construct a large-scale dataset of high-quality tool interfaces using a structured workflow over a diverse collection of tools. Experiments on StableToolBench and RestBench show consistent gains on unseen tools, strong cross-domain generalization, and robustness as the number of candidate tools scales to over 100, demonstrating that tool interface optimization is a practical and deployable complement to agent fine-tuning.", "AI": {"tldr": "Trace-Free+\uff1a\u4e00\u79cd\u65e0\u9700\u6267\u884c\u8f68\u8ff9\u7684\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u76d1\u7763\u8f6c\u79fb\u4f18\u5316\u5de5\u5177\u63a5\u53e3\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u672a\u89c1\u5de5\u5177\u4e0a\u7684\u6cdb\u5316\u80fd\u529b", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7684\u6027\u80fd\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u667a\u80fd\u4f53\u672c\u8eab\uff0c\u8fd8\u53d7\u9650\u4e8e\u5176\u4f7f\u7528\u7684\u5de5\u5177\u63a5\u53e3\u8d28\u91cf\u3002\u73b0\u6709\u5de5\u5177\u63a5\u53e3\u4e3b\u8981\u9762\u5411\u4eba\u7c7b\u8bbe\u8ba1\uff0c\u5728\u5927\u89c4\u6a21\u5de5\u5177\u9009\u62e9\u573a\u666f\u4e2d\u6210\u4e3a\u74f6\u9888\u3002\u73b0\u6709\u6539\u8fdb\u65b9\u6cd5\u4f9d\u8d56\u6267\u884c\u8f68\u8ff9\uff0c\u8fd9\u5728\u51b7\u542f\u52a8\u6216\u9690\u79c1\u53d7\u9650\u573a\u666f\u4e2d\u4e0d\u53ef\u7528\uff0c\u4e14\u901a\u5e38\u72ec\u7acb\u4f18\u5316\u6bcf\u4e2a\u5de5\u5177\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u5bf9\u672a\u89c1\u5de5\u5177\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faTrace-Free+\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u6e10\u8fdb\u5f0f\u5730\u5c06\u76d1\u7763\u4ece\u8f68\u8ff9\u4e30\u5bcc\u7684\u8bbe\u7f6e\u8f6c\u79fb\u5230\u65e0\u8f68\u8ff9\u90e8\u7f72\uff0c\u9f13\u52b1\u6a21\u578b\u62bd\u8c61\u53ef\u91cd\u7528\u7684\u63a5\u53e3\u4f7f\u7528\u6a21\u5f0f\u548c\u5de5\u5177\u4f7f\u7528\u7ed3\u679c\u3002\u6784\u5efa\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u5de5\u5177\u63a5\u53e3\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u5904\u7406\u591a\u6837\u5316\u5de5\u5177\u96c6\u5408\u3002", "result": "\u5728StableToolBench\u548cRestBench\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5bf9\u672a\u89c1\u5de5\u5177\u53d6\u5f97\u4e00\u81f4\u6027\u80fd\u63d0\u5347\uff0c\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u5019\u9009\u5de5\u5177\u6570\u91cf\u8d85\u8fc7100\u65f6\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u8bc1\u660e\u5de5\u5177\u63a5\u53e3\u4f18\u5316\u662f\u667a\u80fd\u4f53\u5fae\u8c03\u7684\u5b9e\u9645\u53ef\u884c\u8865\u5145\u65b9\u6848\u3002", "conclusion": "\u5de5\u5177\u63a5\u53e3\u4f18\u5316\u662f\u63d0\u5347LLM\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5173\u952e\u8865\u5145\u7b56\u7565\uff0cTrace-Free+\u6846\u67b6\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u4e86\u65e0\u9700\u6267\u884c\u8f68\u8ff9\u7684\u63a5\u53e3\u4f18\u5316\uff0c\u5728\u53ef\u6269\u5c55\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u90e8\u7f72\u5b9e\u7528\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.20433", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20433", "abs": "https://arxiv.org/abs/2602.20433", "authors": ["Atharva Kulkarni", "Jacob Mitchell Springer", "Arjun Subramonian", "Swabha Swayamdipta"], "title": "Disentangling Geometry, Performance, and Training in Language Models", "comment": null, "summary": "Geometric properties of Transformer weights, particularly the unembedding matrix, have been widely useful in language model interpretability research. Yet, their utility for estimating downstream performance remains unclear. In this work, we systematically investigate the relationship between model performance and the unembedding matrix geometry, particularly its effective rank. Our experiments, involving a suite of 108 OLMo-style language models trained under controlled variation, reveal several key findings. While the best-performing models often exhibit a high effective rank, this trend is not universal across tasks and training setups. Contrary to prior work, we find that low effective rank does not cause late-stage performance degradation in small models, but instead co-occurs with it; we find adversarial cases where low-rank models do not exhibit saturation. Moreover, we show that effective rank is strongly influenced by pre-training hyperparameters, such as batch size and weight decay, which in-turn affect the model's performance. Lastly, extending our analysis to other geometric metrics and final-layer representation, we find that these metrics are largely aligned, but none can reliably predict downstream performance. Overall, our findings suggest that the model's geometry, as captured by existing metrics, primarily reflects training choices rather than performance.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0Transformer\u6743\u91cd\u51e0\u4f55\u7279\u6027\uff08\u7279\u522b\u662funembedding\u77e9\u9635\u7684\u6709\u6548\u79e9\uff09\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u7cfb\u5e76\u4e0d\u7a33\u5b9a\uff0c\u6709\u6548\u79e9\u53d7\u8bad\u7ec3\u8d85\u53c2\u6570\u5f71\u54cd\uff0c\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0", "motivation": "Transformer\u6743\u91cd\uff08\u7279\u522b\u662funembedding\u77e9\u9635\uff09\u7684\u51e0\u4f55\u7279\u6027\u5728\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e2d\u5f88\u6709\u7528\uff0c\u4f46\u5176\u5bf9\u4e0b\u6e38\u6027\u80fd\u7684\u9884\u6d4b\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u6a21\u578b\u6027\u80fd\u4e0eunembedding\u77e9\u9635\u51e0\u4f55\uff08\u7279\u522b\u662f\u6709\u6548\u79e9\uff09\u7684\u5173\u7cfb", "method": "\u4f7f\u7528108\u4e2aOLMo\u98ce\u683c\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u5206\u6790unembedding\u77e9\u9635\u51e0\u4f55\u7279\u6027\uff08\u7279\u522b\u662f\u6709\u6548\u79e9\uff09\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u5e76\u6269\u5c55\u5230\u5176\u4ed6\u51e0\u4f55\u5ea6\u91cf\u548c\u6700\u540e\u4e00\u5c42\u8868\u793a", "result": "1. \u6700\u4f73\u6a21\u578b\u901a\u5e38\u6709\u8f83\u9ad8\u6709\u6548\u79e9\uff0c\u4f46\u5e76\u975e\u6240\u6709\u4efb\u52a1\u548c\u8bad\u7ec3\u8bbe\u7f6e\u90fd\u5982\u6b64\uff1b2. \u4f4e\u6709\u6548\u79e9\u4e0d\u4f1a\u5bfc\u81f4\u5c0f\u6a21\u578b\u540e\u671f\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u662f\u4f34\u968f\u51fa\u73b0\uff1b3. \u5b58\u5728\u4f4e\u79e9\u6a21\u578b\u4e0d\u9971\u548c\u7684\u53cd\u4f8b\uff1b4. \u6709\u6548\u79e9\u53d7\u6279\u5927\u5c0f\u548c\u6743\u91cd\u8870\u51cf\u7b49\u8d85\u53c2\u6570\u5f71\u54cd\uff1b5. \u5176\u4ed6\u51e0\u4f55\u5ea6\u91cf\u4e0e\u6709\u6548\u79e9\u57fa\u672c\u4e00\u81f4\uff0c\u4f46\u90fd\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u4e0b\u6e38\u6027\u80fd", "conclusion": "\u73b0\u6709\u51e0\u4f55\u5ea6\u91cf\u4e3b\u8981\u53cd\u6620\u8bad\u7ec3\u9009\u62e9\u800c\u975e\u6027\u80fd\uff0c\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\uff0c\u6a21\u578b\u51e0\u4f55\u7279\u6027\u4e0e\u6027\u80fd\u7684\u5173\u7cfb\u6bd4\u5148\u524d\u8ba4\u4e3a\u7684\u66f4\u590d\u6742"}}
{"id": "2602.21052", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21052", "abs": "https://arxiv.org/abs/2602.21052", "authors": ["Timur Nabiev", "Evgeny Frolov"], "title": "Position-Aware Sequential Attention for Accurate Next Item Recommendations", "comment": null, "summary": "Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled with item embedding semantics, propagates weakly in deep architectures, and limits the ability to capture rich sequential patterns. To address these limitations, we introduce a kernelized self-attention mechanism, where a learnable positional kernel operates purely in the position space, disentangled from semantic similarity, and directly modulates attention weights. When applied per attention block, this kernel enables adaptive multi-scale sequential modeling. Experiments on standard next-item prediction benchmarks show that our positional kernel attention consistently improves over strong competing baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6838\u5316\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u6838\u5728\u4f4d\u7f6e\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u4e0e\u8bed\u4e49\u76f8\u4f3c\u6027\u89e3\u8026\uff0c\u76f4\u63a5\u8c03\u8282\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u7528\u4e8e\u6539\u8fdb\u5e8f\u5217\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edf\u7684\u52a0\u6027\u4f4d\u7f6e\u5d4c\u5165\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f4d\u7f6e\u4fe1\u606f\u4e0e\u9879\u76ee\u5d4c\u5165\u8bed\u4e49\u7ea0\u7f20\uff1b2\uff09\u5728\u6df1\u5ea6\u67b6\u6784\u4e2d\u4f20\u64ad\u5f31\uff1b3\uff09\u9650\u5236\u4e86\u6355\u6349\u4e30\u5bcc\u5e8f\u5217\u6a21\u5f0f\u7684\u80fd\u529b\u3002\u4f5c\u8005\u8ba4\u4e3a\u52a0\u6027\u4f4d\u7f6e\u5d4c\u5165\u53ea\u8ba9\u6ce8\u610f\u529b\u673a\u5236\u5728\u8868\u9762\u4e0a\u5bf9\u5e8f\u5217\u987a\u5e8f\u654f\u611f\u3002", "method": "\u5f15\u5165\u6838\u5316\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5176\u4e2d\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u6838\u7eaf\u7cb9\u5728\u4f4d\u7f6e\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u4e0e\u8bed\u4e49\u76f8\u4f3c\u6027\u89e3\u8026\uff0c\u76f4\u63a5\u8c03\u8282\u6ce8\u610f\u529b\u6743\u91cd\u3002\u5f53\u5e94\u7528\u4e8e\u6bcf\u4e2a\u6ce8\u610f\u529b\u5757\u65f6\uff0c\u8be5\u6838\u80fd\u591f\u5b9e\u73b0\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u5e8f\u5217\u5efa\u6a21\u3002", "result": "\u5728\u6807\u51c6\u7684\u4e0b\u4e00\u4e2a\u9879\u76ee\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f4d\u7f6e\u6838\u6ce8\u610f\u529b\u673a\u5236\u6301\u7eed\u4f18\u4e8e\u5f3a\u5927\u7684\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4f4d\u7f6e\u4fe1\u606f\u4e0e\u8bed\u4e49\u8868\u793a\u89e3\u8026\uff0c\u5e76\u4f7f\u7528\u4e13\u95e8\u7684\u4f4d\u7f6e\u6838\u76f4\u63a5\u8c03\u8282\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u5efa\u6a21\u5e8f\u5217\u987a\u5e8f\uff0c\u63d0\u9ad8\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2602.20459", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20459", "abs": "https://arxiv.org/abs/2602.20459", "authors": ["Anirudh Ajith", "Amanpreet Singh", "Jay DeYoung", "Nadav Kunievsky", "Austin C. Kozlowski", "Oyvind Tafjord", "James Evans", "Daniel S. Weld", "Tom Hope", "Doug Downey"], "title": "PreScience: A Benchmark for Forecasting Scientific Contributions", "comment": "10 pages (53 with bibliography and appendix), 4 figures (13 with appendix), 4 tables (10 with appendix), 1 algorithm", "summary": "Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.", "AI": {"tldr": "PreScience\u662f\u4e00\u4e2a\u79d1\u5b66\u9884\u6d4b\u57fa\u51c6\uff0c\u5c06\u7814\u7a76\u8fc7\u7a0b\u5206\u89e3\u4e3a\u56db\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u751f\u6210\u4efb\u52a1\uff1a\u5408\u4f5c\u8005\u9884\u6d4b\u3001\u5148\u524d\u5de5\u4f5c\u9009\u62e9\u3001\u8d21\u732e\u751f\u6210\u548c\u5f71\u54cd\u529b\u9884\u6d4b\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u7cfb\u7edf\u80fd\u5426\u57fa\u4e8e\u5386\u53f2\u79d1\u5b66\u8bb0\u5f55\u9884\u6d4b\u672a\u6765\u79d1\u5b66\u8fdb\u5c55\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22AI\u7cfb\u7edf\u80fd\u5426\u57fa\u4e8e\u56fa\u5b9a\u65f6\u95f4\u70b9\u4e4b\u524d\u7684\u79d1\u5b66\u8bb0\u5f55\u9884\u6d4b\u672a\u6765\u7684\u79d1\u5b66\u8fdb\u5c55\u3002\u8fd9\u79cd\u80fd\u529b\u53ef\u4ee5\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u8bc6\u522b\u5408\u4f5c\u8005\u3001\u53d1\u73b0\u6709\u5f71\u54cd\u529b\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u9884\u6d4b\u54ea\u4e9b\u95ee\u9898\u548c\u65b9\u6cd5\u5c06\u6210\u4e3a\u672a\u6765\u7684\u6838\u5fc3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u6784\u5efaPreScience\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b98K\u7bc7\u8fd1\u671fAI\u76f8\u5173\u7814\u7a76\u8bba\u6587\uff0c\u5177\u6709\u6d88\u6b67\u7684\u4f5c\u8005\u8eab\u4efd\u3001\u65f6\u95f4\u5bf9\u9f50\u7684\u5b66\u672f\u5143\u6570\u636e\uff0c\u4ee5\u53ca\u5305\u542b502K\u7bc7\u8bba\u6587\u7684\u4f5c\u8005\u53d1\u8868\u5386\u53f2\u548c\u5f15\u7528\u7ed3\u6784\u5316\u56fe\uff1b2) \u4e3a\u56db\u4e2a\u4efb\u52a1\u5f00\u53d1\u57fa\u7ebf\u548c\u8bc4\u4f30\u65b9\u6cd5\uff1b3) \u63d0\u51faLACERScore\uff0c\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u8d21\u732e\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4f18\u4e8e\u5148\u524d\u6307\u6807\u5e76\u63a5\u8fd1\u4eba\u5de5\u6807\u6ce8\u8005\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1) \u5728\u8d21\u732e\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u524d\u6cbfLLM\u4ec5\u8fbe\u5230\u4e2d\u7b49\u76f8\u4f3c\u5ea6\uff08GPT-5\u5e73\u57475.6\u5206\uff0c1-10\u5206\u5236\uff09\uff1b2) \u6bcf\u4e2a\u4efb\u52a1\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\uff1b3) \u5f53\u7ec4\u5408\u621012\u4e2a\u6708\u7684\u7aef\u5230\u7aef\u79d1\u5b66\u751f\u4ea7\u6a21\u62df\u65f6\uff0c\u751f\u6210\u7684\u5408\u6210\u8bed\u6599\u5e93\u5728\u591a\u6837\u6027\u548c\u65b0\u9896\u6027\u65b9\u9762\u7cfb\u7edf\u6027\u4f4e\u4e8e\u540c\u671f\u4eba\u7c7b\u64b0\u5199\u7684\u7814\u7a76\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660eAI\u7cfb\u7edf\u5728\u79d1\u5b66\u9884\u6d4b\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\uff0c\u5f53\u524d\u65b9\u6cd5\u751f\u6210\u7684\u79d1\u5b66\u7814\u7a76\u5728\u591a\u6837\u6027\u548c\u65b0\u9896\u6027\u4e0a\u4e0d\u5982\u4eba\u7c7b\u7814\u7a76\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u548c\u6a21\u62df\u79d1\u5b66\u8fdb\u5c55\u3002"}}
{"id": "2602.20494", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20494", "abs": "https://arxiv.org/abs/2602.20494", "authors": ["Haotian Si", "Changhua Pei", "Xiao He", "Zeyan Li", "Zhe Xie", "Zexin Wang", "Jiyao Hu", "Zhaoyang Yu", "Tieying Zhang", "Dan Pei", "Jianhui Li", "Gaogang Xie"], "title": "KairosVL: Orchestrating Time Series and Semantics for Unified Reasoning", "comment": null, "summary": "Driven by the increasingly complex and decision-oriented demands of time series analysis, we introduce the Semantic-Conditional Time Series Reasoning task, which extends conventional time series analysis beyond purely numerical modeling to incorporate contextual and semantic understanding. To further enhance the mode's reasoning capabilities on complex time series problems, we propose a two-round reinforcement learning framework: the first round strengthens the mode's perception of fundamental temporal primitives, while the second focuses on semantic-conditioned reasoning. The resulting model, KairosVL, achieves competitive performance across both synthetic and real-world tasks. Extensive experiments and ablation studies demonstrate that our framework not only boosts performance but also preserves intrinsic reasoning ability and significantly improves generalization to unseen scenarios. To summarize, our work highlights the potential of combining semantic reasoning with temporal modeling and provides a practical framework for real-world time series intelligence, which is in urgent demand.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u6761\u4ef6\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u548cKairosVL\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u8bed\u4e49\u7406\u89e3\u4e0e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u63d0\u5347\u590d\u6742\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e3b\u8981\u5173\u6ce8\u6570\u503c\u5efa\u6a21\uff0c\u7f3a\u4e4f\u5bf9\u4e0a\u4e0b\u6587\u548c\u8bed\u4e49\u7684\u7406\u89e3\u3002\u968f\u7740\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u9700\u6c42\u65e5\u76ca\u590d\u6742\u548c\u51b3\u7b56\u5bfc\u5411\uff0c\u9700\u8981\u5c06\u8bed\u4e49\u7406\u89e3\u878d\u5165\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u6761\u4ef6\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e24\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a\u7b2c\u4e00\u8f6e\u589e\u5f3a\u6a21\u578b\u5bf9\u57fa\u672c\u65f6\u95f4\u539f\u8bed\u7684\u611f\u77e5\u80fd\u529b\uff0c\u7b2c\u4e8c\u8f6e\u4e13\u6ce8\u4e8e\u8bed\u4e49\u6761\u4ef6\u63a8\u7406\u3002\u6700\u7ec8\u6784\u5efaKairosVL\u6a21\u578b\u3002", "result": "KairosVL\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002\u5927\u91cf\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u6027\u80fd\uff0c\u8fd8\u4fdd\u7559\u5185\u5728\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u5bf9\u672a\u89c1\u573a\u666f\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u5c06\u8bed\u4e49\u63a8\u7406\u4e0e\u65f6\u95f4\u5efa\u6a21\u7ed3\u5408\u7684\u6f5c\u529b\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u667a\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u6ee1\u8db3\u4e86\u5f53\u524d\u5bf9\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u8feb\u5207\u9700\u6c42\u3002"}}
{"id": "2602.20528", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20528", "abs": "https://arxiv.org/abs/2602.20528", "authors": ["Justin Lovelace", "Christian Belardi", "Sofian Zalouk", "Adhitya Polavaram", "Srivatsa Kundurthy", "Kilian Q. Weinberger"], "title": "Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning", "comment": "COLM 2025", "summary": "The Stop-Think-AutoRegress Language Diffusion Model (STAR-LDM) integrates latent diffusion planning with autoregressive generation. Unlike conventional autoregressive language models limited to token-by-token decisions, STAR-LDM incorporates a \"thinking\" phase that pauses generation to refine a semantic plan through diffusion before continuing. This enables global planning in continuous space prior to committing to discrete tokens. Evaluations show STAR-LDM significantly outperforms similar-sized models on language understanding benchmarks and achieves $>70\\%$ win rates in LLM-as-judge comparisons for narrative coherence and commonsense reasoning. The architecture also allows straightforward control through lightweight classifiers, enabling fine-grained steering of attributes without model retraining while maintaining better fluency-control trade-offs than specialized approaches.", "AI": {"tldr": "STAR-LDM\u662f\u4e00\u79cd\u7ed3\u5408\u6f5c\u5728\u6269\u6563\u89c4\u5212\u548c\u81ea\u56de\u5f52\u751f\u6210\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\"\u601d\u8003\"\u9636\u6bb5\u5728\u8fde\u7eed\u7a7a\u95f4\u8fdb\u884c\u5168\u5c40\u89c4\u5212\uff0c\u518d\u751f\u6210\u79bb\u6563\u6807\u8bb0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u53d7\u9650\u4e8e\u9010\u4e2a\u6807\u8bb0\u7684\u51b3\u7b56\uff0c\u7f3a\u4e4f\u5168\u5c40\u89c4\u5212\u80fd\u529b\u3002STAR-LDM\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5f15\u5165\"\u601d\u8003\"\u9636\u6bb5\uff0c\u5728\u8fde\u7eed\u8bed\u4e49\u7a7a\u95f4\u8fdb\u884c\u5168\u5c40\u89c4\u5212\uff0c\u4ece\u800c\u63d0\u5347\u8bed\u8a00\u7406\u89e3\u548c\u63a8\u7406\u7684\u8fde\u8d2f\u6027\u3002", "method": "STAR-LDM\u5c06\u6f5c\u5728\u6269\u6563\u89c4\u5212\u4e0e\u81ea\u56de\u5f52\u751f\u6210\u76f8\u7ed3\u5408\u3002\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u6682\u505c\uff0c\u901a\u8fc7\u6269\u6563\u8fc7\u7a0b\u5728\u8fde\u7eed\u8bed\u4e49\u7a7a\u95f4\u4e2d\u7cbe\u70bc\u8bed\u4e49\u8ba1\u5212\uff0c\u7136\u540e\u518d\u7ee7\u7eed\u751f\u6210\u79bb\u6563\u6807\u8bb0\u3002\u8fd9\u79cd\u67b6\u6784\u8fd8\u5141\u8bb8\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u8fdb\u884c\u76f4\u63a5\u63a7\u5236\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5c5e\u6027\u5f15\u5bfc\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "result": "STAR-LDM\u5728\u8bed\u8a00\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u76f8\u4f3c\u89c4\u6a21\u6a21\u578b\uff0c\u5728LLM-as-judge\u6bd4\u8f83\u4e2d\uff0c\u5728\u53d9\u4e8b\u8fde\u8d2f\u6027\u548c\u5e38\u8bc6\u63a8\u7406\u65b9\u9762\u83b7\u5f97\u8d85\u8fc770%\u7684\u80dc\u7387\u3002\u8be5\u67b6\u6784\u5728\u6d41\u7545\u6027\u548c\u63a7\u5236\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6743\u8861\u3002", "conclusion": "STAR-LDM\u901a\u8fc7\u6574\u5408\u6269\u6563\u89c4\u5212\u548c\u81ea\u56de\u5f52\u751f\u6210\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5168\u5c40\u89c4\u5212\u7684\u95ee\u9898\uff0c\u5728\u8bed\u8a00\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u63a7\u5236\u80fd\u529b\u800c\u4e0d\u727a\u7272\u6d41\u7545\u6027\u3002"}}
{"id": "2602.21202", "categories": ["cs.IR", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21202", "abs": "https://arxiv.org/abs/2602.21202", "authors": ["Hanxiang Qin", "Alexander Martin", "Rohan Jha", "Chunsheng Zuo", "Reno Kriz", "Benjamin Van Durme"], "title": "Multi-Vector Index Compression in Any Modality", "comment": "12 pages, 4 figures", "summary": "We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has emerged as a dominant paradigm for information retrieval in text, images, visual documents, and videos, but its computation and storage costs grow linearly with document length, making it costly for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic methods for compressing multi-vector document representations under a constant vector budget. We introduce four approaches for index compression: sequence resizing, memory tokens, hierarchical pooling, and a novel attention-guided clustering (AGC). AGC uses an attention-guided mechanism to identify the most semantically salient regions of a document as cluster centroids and to weight token aggregation. Evaluating these methods on retrieval tasks spanning text (BEIR), visual-document (ViDoRe), and video (MSR-VTT, MultiVENT 2.0), we show that attention-guided clustering consistently outperforms other parameterized compression methods (sequence resizing and memory tokens), provides greater flexibility in index size than non-parametric hierarchical clustering, and achieves competitive or improved performance compared to a full, uncompressed index. The source code is available at: github.com/hanxiangqin/omni-col-press.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u6a21\u6001\u68c0\u7d22\u4e2d\u591a\u5411\u91cf\u8868\u793a\u7684\u67e5\u8be2\u65e0\u5173\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5f15\u5bfc\u805a\u7c7b\uff08AGC\uff09\u5728\u56fa\u5b9a\u5411\u91cf\u9884\u7b97\u4e0b\u538b\u7f29\u6587\u6863\u8868\u793a\uff0c\u5728\u6587\u672c\u3001\u89c6\u89c9\u6587\u6863\u548c\u89c6\u9891\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u665a\u671f\u4ea4\u4e92\u5df2\u6210\u4e3a\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u89c9\u6587\u6863\u548c\u89c6\u9891\u4fe1\u606f\u68c0\u7d22\u7684\u4e3b\u8981\u8303\u5f0f\uff0c\u4f46\u5176\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u968f\u6587\u6863\u957f\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u5bf9\u4e8e\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\u4e30\u5bcc\u7684\u8bed\u6599\u5e93\u6210\u672c\u8fc7\u9ad8\u3002\u9700\u8981\u89e3\u51b3\u591a\u5411\u91cf\u6587\u6863\u8868\u793a\u5728\u56fa\u5b9a\u5411\u91cf\u9884\u7b97\u4e0b\u7684\u538b\u7f29\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u7d22\u5f15\u538b\u7f29\u65b9\u6cd5\uff1a\u5e8f\u5217\u8c03\u6574\u3001\u8bb0\u5fc6\u4ee4\u724c\u3001\u5206\u5c42\u6c60\u5316\u4ee5\u53ca\u65b0\u9896\u7684\u6ce8\u610f\u529b\u5f15\u5bfc\u805a\u7c7b\uff08AGC\uff09\u3002AGC\u4f7f\u7528\u6ce8\u610f\u529b\u5f15\u5bfc\u673a\u5236\u8bc6\u522b\u6587\u6863\u4e2d\u6700\u5177\u8bed\u4e49\u663e\u8457\u6027\u7684\u533a\u57df\u4f5c\u4e3a\u805a\u7c7b\u4e2d\u5fc3\uff0c\u5e76\u5bf9\u4ee4\u724c\u805a\u5408\u8fdb\u884c\u52a0\u6743\u3002", "result": "\u5728\u6587\u672c\uff08BEIR\uff09\u3001\u89c6\u89c9\u6587\u6863\uff08ViDoRe\uff09\u548c\u89c6\u9891\uff08MSR-VTT\u3001MultiVENT 2.0\uff09\u68c0\u7d22\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6ce8\u610f\u529b\u5f15\u5bfc\u805a\u7c7b\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u53c2\u6570\u5316\u538b\u7f29\u65b9\u6cd5\uff08\u5e8f\u5217\u8c03\u6574\u548c\u8bb0\u5fc6\u4ee4\u724c\uff09\uff0c\u5728\u7d22\u5f15\u5927\u5c0f\u65b9\u9762\u6bd4\u975e\u53c2\u6570\u5316\u5206\u5c42\u805a\u7c7b\u63d0\u4f9b\u66f4\u5927\u7075\u6d3b\u6027\uff0c\u5e76\u4e14\u76f8\u6bd4\u5b8c\u6574\u672a\u538b\u7f29\u7d22\u5f15\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6216\u6539\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6ce8\u610f\u529b\u5f15\u5bfc\u805a\u7c7b\uff08AGC\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u6a21\u6001\u591a\u5411\u91cf\u68c0\u7d22\u538b\u7f29\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u56fa\u5b9a\u5411\u91cf\u9884\u7b97\u4e0b\u4fdd\u6301\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u7cfb\u7edf\u7684\u6548\u7387\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.20558", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.20558", "abs": "https://arxiv.org/abs/2602.20558", "authors": ["Yucheng Shi", "Ying Li", "Yu Wang", "Yesu Feng", "Arjun Rao", "Rein Houthooft", "Shradha Sehgal", "Jin Wang", "Hao Zhen", "Ninghao Liu", "Linas Baltrunas"], "title": "From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production", "comment": "Work in progress", "summary": "Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalization agent transforms raw interaction histories into optimized textual contexts, with recommendation accuracy as the training signal. This agent learns to filter noise, incorporate relevant metadata, and reorganize information to improve downstream predictions. Experiments on a large-scale industrial streaming dataset show that learned verbalization delivers up to 93% relative improvement in discovery item recommendation accuracy over template-based baselines. Further analysis reveals emergent strategies such as user interest summarization, noise removal, and syntax normalization, offering insights into effective context construction for LLM-based recommender systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u5b66\u4e60\u5c06\u7ed3\u6784\u5316\u7528\u6237\u4ea4\u4e92\u65e5\u5fd7\u8f6c\u5316\u4e3a\u4f18\u5316\u6587\u672c\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u8350\u7cfb\u7edf\u6027\u80fd", "motivation": "\u73b0\u6709LLM\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u5173\u952e\u6311\u6218\uff1a\u5982\u4f55\u5c06\u7ed3\u6784\u5316\u7528\u6237\u4ea4\u4e92\u65e5\u5fd7\u6709\u6548\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7b80\u5355\u62fc\u63a5\u5b57\u6bb5\u7684\u56fa\u5b9a\u6a21\u677f\uff0c\u4ea7\u751f\u6b21\u4f18\u8868\u793a\uff0c\u9650\u5236\u4e86\u63a8\u8350\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u6570\u636e\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3verbalization agent\uff0c\u5c06\u539f\u59cb\u4ea4\u4e92\u5386\u53f2\u8f6c\u5316\u4e3a\u4f18\u5316\u6587\u672c\u4e0a\u4e0b\u6587\u3002\u4ee5\u63a8\u8350\u51c6\u786e\u7387\u4f5c\u4e3a\u8bad\u7ec3\u4fe1\u53f7\uff0c\u5b66\u4e60\u8fc7\u6ee4\u566a\u58f0\u3001\u6574\u5408\u76f8\u5173\u5143\u6570\u636e\u3001\u91cd\u7ec4\u4fe1\u606f\u4ee5\u63d0\u5347\u4e0b\u6e38\u9884\u6d4b\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u6d41\u5a92\u4f53\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b66\u4e60\u5230\u7684verbalization\u76f8\u6bd4\u57fa\u4e8e\u6a21\u677f\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u53d1\u73b0\u9879\u63a8\u8350\u51c6\u786e\u7387\u4e0a\u83b7\u5f97\u9ad8\u8fbe93%\u7684\u76f8\u5bf9\u63d0\u5347\u3002\u5206\u6790\u63ed\u793a\u4e86\u7528\u6237\u5174\u8da3\u603b\u7ed3\u3001\u566a\u58f0\u53bb\u9664\u548c\u8bed\u6cd5\u89c4\u8303\u5316\u7b49\u6d8c\u73b0\u7b56\u7565\u3002", "conclusion": "\u5b66\u4e60verbalization\u80fd\u663e\u8457\u63d0\u5347LLM\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u6784\u5efa\u6d1e\u5bdf\u3002\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u6570\u636e\u9a71\u52a8verbalization\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.20517", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20517", "abs": "https://arxiv.org/abs/2602.20517", "authors": ["Rakshit Trivedi", "Kartik Sharma", "David C Parkes"], "title": "Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination", "comment": "Spotlight paper at NeurIPS 2025", "summary": "Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the theory of human cognitive processes, where inner speech guides action selection before execution, we propose MIMIC (Modeling Inner Motivations for Imitation and Control), a framework that uses language as an internal representation of behavioral intent. MIMIC employs the novel use of vision-language models as linguistic scaffolding to train a conditional variational autoencoder capable of generating inner speech from observations. A diffusion-based behavior cloning policy then selects actions conditioned on current observations and the generated inner speech. MIMIC enables fine-grained steering of behavior at inference time by conditioning the agent on behavior-specific speech. Experiments across robotic manipulation tasks and human-AI collaboration games demonstrate that MIMIC significantly enhances both behavior diversity and fidelity to human demonstrations while enabling nuanced behavioral steering without training on additional demonstrations. We open source our code and provide pre-trained MIMIC agents and qualitative demos at: https://mimic-research.github.io.", "code_url": "https://mimic-research.github.io", "AI": {"tldr": "MIMIC\u6846\u67b6\u4f7f\u7528\u8bed\u8a00\u4f5c\u4e3a\u884c\u4e3a\u610f\u56fe\u7684\u5185\u90e8\u8868\u793a\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u751f\u6210\u5185\u90e8\u8bed\u97f3\uff0c\u518d\u7ed3\u5408\u6269\u6563\u884c\u4e3a\u514b\u9686\u7b56\u7565\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u884c\u4e3a\u63a7\u5236", "motivation": "\u5f53\u524d\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\u7684\u591a\u6837\u6027\u548c\u975e\u9a6c\u5c14\u53ef\u592b\u7279\u6027\uff0c\u4e14\u7f3a\u4e4f\u5728\u63a8\u7406\u65f6\u5f15\u5bfc\u884c\u4e3a\u7684\u80fd\u529b\u3002\u53d7\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u4e2d\u5185\u90e8\u8bed\u97f3\u6307\u5bfc\u884c\u52a8\u9009\u62e9\u7684\u7406\u8bba\u542f\u53d1\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u751f\u6210\u5185\u90e8\u8bed\u97f3\u8868\u793a\u5e76\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u884c\u4e3a\u63a7\u5236\u7684\u6846\u67b6", "method": "\u63d0\u51faMIMIC\u6846\u67b6\uff1a1) \u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bed\u8a00\u652f\u67b6\u8bad\u7ec3\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u4ece\u89c2\u5bdf\u4e2d\u751f\u6210\u5185\u90e8\u8bed\u97f3\uff1b2) \u91c7\u7528\u57fa\u4e8e\u6269\u6563\u7684\u884c\u4e3a\u514b\u9686\u7b56\u7565\uff0c\u6839\u636e\u5f53\u524d\u89c2\u5bdf\u548c\u751f\u6210\u7684\u5185\u90e8\u8bed\u97f3\u9009\u62e9\u884c\u52a8\uff1b3) \u5728\u63a8\u7406\u65f6\u901a\u8fc7\u6761\u4ef6\u5316\u7279\u5b9a\u884c\u4e3a\u8bed\u97f3\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5f15\u5bfc", "result": "\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u548c\u4eba\u673a\u534f\u4f5c\u6e38\u620f\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMIMIC\u663e\u8457\u63d0\u9ad8\u4e86\u884c\u4e3a\u591a\u6837\u6027\u548c\u5bf9\u4eba\u7c7b\u6f14\u793a\u7684\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u65e0\u9700\u989d\u5916\u6f14\u793a\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u7ec6\u81f4\u7684\u884c\u4e3a\u5f15\u5bfc", "conclusion": "MIMIC\u901a\u8fc7\u8bed\u8a00\u4f5c\u4e3a\u884c\u4e3a\u610f\u56fe\u7684\u5185\u90e8\u8868\u793a\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6a21\u4eff\u5b66\u4e60\u4e2d\u884c\u4e3a\u591a\u6837\u6027\u548c\u63a8\u7406\u65f6\u63a7\u5236\u80fd\u529b\u7684\u6311\u6218\uff0c\u4e3a\u4eba\u673a\u534f\u8c03\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u667a\u80fd\u4f53"}}
{"id": "2602.21103", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.21103", "abs": "https://arxiv.org/abs/2602.21103", "authors": ["Sanket Badhe", "Deep Shah"], "title": "Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning", "comment": null, "summary": "Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant resource and operational overhead. To address these limitations, we introduce Prompt-Level Distillation (PLD). We extract explicit reasoning patterns from a Teacher model and organize them into a structured list of expressive instructions for the Student model's System Prompt. Evaluated on the StereoSet and Contract-NLI datasets using Gemma-3 4B, PLD improved Macro F1 scores from 57\\% to 90.0\\% and 67\\% to 83\\% respectively, enabling this compact model to match frontier performance with negligible latency overhead. These expressive instructions render the decision-making process transparent, allowing for full human verification of logic, making this approach ideal for regulated industries such as law, finance, and content moderation, as well as high-volume use cases and edge devices.", "AI": {"tldr": "\u63d0\u51faPrompt-Level Distillation (PLD)\u65b9\u6cd5\uff0c\u4ece\u6559\u5e08\u6a21\u578b\u4e2d\u63d0\u53d6\u663e\u5f0f\u63a8\u7406\u6a21\u5f0f\uff0c\u7ec4\u7ec7\u6210\u7ed3\u6784\u5316\u6307\u4ee4\u5217\u8868\u4f5c\u4e3a\u5b66\u751f\u6a21\u578b\u7684\u7cfb\u7edf\u63d0\u793a\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u8fbe\u5230\u524d\u6cbf\u6027\u80fd\uff0c\u4e14\u5ef6\u8fdf\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfChain-of-Thought\u63d0\u793a\u63a8\u7406\u65b9\u6cd5\u7684\u9ad8\u5ef6\u8fdf\u548c\u9ad8\u63a8\u7406\u6210\u672c\u95ee\u9898\uff0c\u4ee5\u53ca\u5fae\u8c03\u5c0f\u578b\u6a21\u578b\u65f6\u727a\u7272\u53ef\u89e3\u91ca\u6027\u5e76\u5f15\u5165\u663e\u8457\u8d44\u6e90\u5f00\u9500\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faPrompt-Level Distillation (PLD)\u65b9\u6cd5\uff1a\u4ece\u6559\u5e08\u6a21\u578b\u4e2d\u63d0\u53d6\u663e\u5f0f\u63a8\u7406\u6a21\u5f0f\uff0c\u5c06\u5176\u7ec4\u7ec7\u6210\u7ed3\u6784\u5316\u3001\u8868\u8fbe\u6027\u5f3a\u7684\u6307\u4ee4\u5217\u8868\uff0c\u4f5c\u4e3a\u5b66\u751f\u6a21\u578b\u7684\u7cfb\u7edf\u63d0\u793a\uff0c\u4f7f\u63a8\u7406\u8fc7\u7a0b\u900f\u660e\u5316\u3002", "result": "\u5728StereoSet\u548cContract-NLI\u6570\u636e\u96c6\u4e0a\u4f7f\u7528Gemma-3 4B\u6a21\u578b\u8bc4\u4f30\uff0cPLD\u5c06Macro F1\u5206\u6570\u5206\u522b\u4ece57%\u63d0\u5347\u81f390.0%\u548c\u4ece67%\u63d0\u5347\u81f383%\uff0c\u4f7f\u7d27\u51d1\u6a21\u578b\u4ee5\u53ef\u5ffd\u7565\u7684\u5ef6\u8fdf\u5f00\u9500\u8fbe\u5230\u524d\u6cbf\u6027\u80fd\u3002", "conclusion": "PLD\u65b9\u6cd5\u4f7f\u5c0f\u578b\u6a21\u578b\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u8fbe\u5230\u524d\u6cbf\u6027\u80fd\uff0c\u63a8\u7406\u8fc7\u7a0b\u5b8c\u5168\u900f\u660e\u53ef\u9a8c\u8bc1\uff0c\u9002\u7528\u4e8e\u6cd5\u5f8b\u3001\u91d1\u878d\u3001\u5185\u5bb9\u5ba1\u6838\u7b49\u53d7\u76d1\u7ba1\u884c\u4e1a\uff0c\u4ee5\u53ca\u9ad8\u541e\u5410\u91cf\u7528\u4f8b\u548c\u8fb9\u7f18\u8bbe\u5907\u3002"}}
{"id": "2602.20647", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20647", "abs": "https://arxiv.org/abs/2602.20647", "authors": ["W. Frederick Zimmerman"], "title": "Semantic Novelty at Scale: Narrative Shape Taxonomy and Readership Prediction in 28,606 Books", "comment": "six figures. dataset available at Hugging Face", "summary": "I introduce semantic novelty--cosine distance between each paragraph's sentence embedding and the running centroid of all preceding paragraphs--as an information-theoretic measure of narrative structure at corpus scale. Applying it to 28,606 books in PG19 (pre-1920 English literature), I compute paragraph-level novelty curves using 768-dimensional SBERT embeddings, then reduce each to a 16-segment Piecewise Aggregate Approximation (PAA). Ward-linkage clustering on PAA vectors reveals eight canonical narrative shape archetypes, from Steep Descent (rapid convergence) to Steep Ascent (escalating unpredictability). Volume--variance of the novelty trajectory--is the strongest length-independent predictor of readership (partial rho = 0.32), followed by speed (rho = 0.19) and Terminal/Initial ratio (rho = 0.19). Circuitousness shows strong raw correlation (rho = 0.41) but is 93 percent correlated with length; after control, partial rho drops to 0.11--demonstrating that naive correlations in corpus studies can be dominated by length confounds. Genre strongly constrains narrative shape (chi squared = 2121.6, p < 10 to the power negative 242), with fiction maintaining plateau profiles while nonfiction front-loads information. Historical analysis shows books became progressively more predictable between 1840 and 1910 (T/I ratio trend r = negative 0.74, p = 0.037). SAX analysis reveals 85 percent signature uniqueness, suggesting each book traces a nearly unique path through semantic space. These findings demonstrate that information-density dynamics, distinct from sentiment or topic, constitute a fundamental dimension of narrative structure with measurable consequences for reader engagement. Dataset: https://huggingface.co/datasets/wfzimmerman/pg19-semantic-novelty", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u65b0\u9896\u6027\u4f5c\u4e3a\u53d9\u4e8b\u7ed3\u6784\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\uff0c\u5e94\u7528\u4e8e28,606\u672cPG19\u4e66\u7c4d\uff0c\u53d1\u73b08\u79cd\u53d9\u4e8b\u5f62\u72b6\u539f\u578b\uff0c\u5176\u4e2d\u65b0\u9896\u6027\u8f68\u8ff9\u7684\u65b9\u5dee\u6700\u80fd\u9884\u6d4b\u8bfb\u8005\u53c2\u4e0e\u5ea6\uff0c\u5e76\u63ed\u793a\u4e86\u4f53\u88c1\u5bf9\u53d9\u4e8b\u5f62\u72b6\u7684\u5f3a\u7ea6\u675f\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u53d9\u4e8b\u7ed3\u6784\u7684\u4fe1\u606f\u5bc6\u5ea6\u52a8\u6001\uff0c\u533a\u522b\u4e8e\u60c5\u611f\u6216\u4e3b\u9898\u5206\u6790\uff0c\u63a2\u7d22\u8bed\u4e49\u65b0\u9896\u6027\u5982\u4f55\u4f5c\u4e3a\u53d9\u4e8b\u7ed3\u6784\u7684\u57fa\u672c\u7ef4\u5ea6\uff0c\u5e76\u91cf\u5316\u5176\u5bf9\u8bfb\u8005\u53c2\u4e0e\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528768\u7ef4SBERT\u5d4c\u5165\u8ba1\u7b97\u6bb5\u843d\u7ea7\u8bed\u4e49\u65b0\u9896\u6027\uff08\u5f53\u524d\u6bb5\u843d\u4e0e\u5148\u524d\u6bb5\u843d\u8d28\u5fc3\u7684\u4f59\u5f26\u8ddd\u79bb\uff09\uff0c\u5c06\u65b0\u9896\u6027\u66f2\u7ebf\u964d\u7ef4\u4e3a16\u6bb5PAA\u8868\u793a\uff0c\u901a\u8fc7Ward-linkage\u805a\u7c7b\u8bc6\u522b\u53d9\u4e8b\u5f62\u72b6\u539f\u578b\uff0c\u5e76\u5206\u6790\u591a\u79cd\u7edf\u8ba1\u7279\u5f81\u4e0e\u8bfb\u8005\u53c2\u4e0e\u5ea6\u7684\u5173\u7cfb\u3002", "result": "\u8bc6\u522b\u51fa8\u79cd\u5178\u578b\u53d9\u4e8b\u5f62\u72b6\u539f\u578b\uff08\u4ece\u9661\u964d\u5230\u9661\u5347\uff09\uff1b\u65b0\u9896\u6027\u8f68\u8ff9\u7684\u65b9\u5dee\uff08\u4f53\u79ef\uff09\u662f\u6700\u5f3a\u7684\u957f\u5ea6\u65e0\u5173\u8bfb\u8005\u53c2\u4e0e\u5ea6\u9884\u6d4b\u56e0\u5b50\uff08\u504frho=0.32\uff09\uff1b\u4f53\u88c1\u5f3a\u70c8\u7ea6\u675f\u53d9\u4e8b\u5f62\u72b6\uff08\u5361\u65b9=2121.6\uff09\uff1b1840-1910\u5e74\u95f4\u4e66\u7c4d\u53d8\u5f97\u66f4\u4e3a\u53ef\u9884\u6d4b\uff1b85%\u7684\u4e66\u7c4d\u5177\u6709\u72ec\u7279\u7684\u8bed\u4e49\u7a7a\u95f4\u8def\u5f84\u3002", "conclusion": "\u4fe1\u606f\u5bc6\u5ea6\u52a8\u6001\u662f\u53d9\u4e8b\u7ed3\u6784\u7684\u57fa\u672c\u7ef4\u5ea6\uff0c\u5177\u6709\u53ef\u6d4b\u91cf\u7684\u8bfb\u8005\u53c2\u4e0e\u5ea6\u5f71\u54cd\uff1b\u8bed\u4e49\u65b0\u9896\u6027\u5206\u6790\u63ed\u793a\u4e86\u4f20\u7edf\u76f8\u5173\u6027\u7814\u7a76\u4e2d\u957f\u5ea6\u6df7\u6742\u6548\u5e94\u7684\u4e25\u91cd\u6027\uff1b\u4f53\u88c1\u548c\u5386\u53f2\u65f6\u671f\u5bf9\u53d9\u4e8b\u5f62\u72b6\u6709\u7cfb\u7edf\u6027\u5f71\u54cd\u3002"}}
{"id": "2602.21143", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21143", "abs": "https://arxiv.org/abs/2602.21143", "authors": ["Debjit Paul", "Daniel Murphy", "Milan Gritta", "Ronald Cardenas", "Victor Prokhorov", "Lena Sophia Bolliger", "Aysim Toker", "Roy Miles", "Andreea-Maria Oncescu", "Jasivan Alex Sivakumar", "Philipp Borchert", "Ismail Elezi", "Meiru Zhang", "Ka Yiu Lee", "Guchun Zhang", "Jun Wang", "Gerasimos Lampouras"], "title": "A Benchmark for Deep Information Synthesis", "comment": "Accepted at ICLR 2026", "summary": "Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.", "AI": {"tldr": "DEEPSYNTH\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b120\u4e2a\u8de87\u4e2a\u9886\u57df\u548c67\u4e2a\u56fd\u5bb6\u7684\u4efb\u52a1\uff0c\u8981\u6c42\u4fe1\u606f\u6536\u96c6\u3001\u7efc\u5408\u548c\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u8be5\u57fa\u51c6\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u57fa\u51c6\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5176\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u8fd9\u4e9b\u4efb\u52a1\u9700\u8981\u4ece\u591a\u4e2a\u6765\u6e90\u7efc\u5408\u4fe1\u606f\u5e76\u8fdb\u884c\u8d85\u8d8a\u7b80\u5355\u4e8b\u5b9e\u68c0\u7d22\u7684\u63a8\u7406\u6d1e\u5bdf\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6570\u636e\u6536\u96c6\u6d41\u7a0b\u6784\u5efaDEEPSYNTH\u57fa\u51c6\uff1a\u6536\u96c6\u5b98\u65b9\u6570\u636e\u6e90\u3001\u521b\u5efa\u5047\u8bbe\u3001\u8fdb\u884c\u624b\u52a8\u5206\u6790\u3001\u8bbe\u8ba1\u5177\u6709\u53ef\u9a8c\u8bc1\u7b54\u6848\u7684\u4efb\u52a1\u3002\u5305\u542b120\u4e2a\u8de87\u4e2a\u9886\u57df\u548c67\u4e2a\u56fd\u5bb6\u7684\u4efb\u52a1\u3002", "result": "\u5728DEEPSYNTH\u4e0a\u8bc4\u4f3011\u4e2a\u6700\u5148\u8fdb\u7684LLM\u548c\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\uff0c\u6700\u5927F1\u5206\u6570\u4ec5\u4e3a8.97\uff0cLLM-judge\u6307\u6807\u4e3a17.5\uff0c\u8868\u660e\u57fa\u51c6\u96be\u5ea6\u5f88\u9ad8\u3002\u5206\u6790\u663e\u793a\u5f53\u524d\u667a\u80fd\u4f53\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u96be\u4ee5\u5728\u5927\u4fe1\u606f\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a8\u7406\u3002", "conclusion": "DEEPSYNTH\u662f\u4e00\u4e2a\u5173\u952e\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u65f6\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u4fe1\u606f\u7efc\u5408\u548c\u63a8\u7406\u65b9\u9762\u7684\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2602.20571", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20571", "abs": "https://arxiv.org/abs/2602.20571", "authors": ["Ayush Sawarni", "Jiyuan Tan", "Vasilis Syrgkanis"], "title": "CausalReasoningBenchmark: A Real-World Benchmark for Disentangled Evaluation of Causal Identification and Estimation", "comment": null, "summary": "Many benchmarks for automated causal inference evaluate a system's performance based on a single numerical output, such as an Average Treatment Effect (ATE). This approach conflates two distinct steps in causal analysis: identification-formulating a valid research design under stated assumptions-and estimation-implementing that design numerically on finite data. We introduce CausalReasoningBenchmark, a benchmark of 173 queries across 138 real-world datasets, curated from 85 peer-reviewed research papers and four widely-used causal-inference textbooks. For each query a system must produce (i) a structured identification specification that names the strategy, the treatment, outcome, and control variables, and all design-specific elements, and (ii) a point estimate with a standard error. By scoring these two components separately, our benchmark enables granular diagnosis: it distinguishes failures in causal reasoning from errors in numerical execution. Baseline results with a state-of-the-art LLM show that, while the model correctly identifies the high-level strategy in 84 % of cases, full identification-specification correctness drops to only 30 %, revealing that the bottleneck lies in the nuanced details of research design rather than in computation. CausalReasoningBenchmark is publicly available on Hugging Face and is designed to foster the development of more robust automated causal-inference systems.", "AI": {"tldr": "\u63d0\u51faCausalReasoningBenchmark\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u56e0\u679c\u63a8\u7406\u5206\u89e3\u4e3a\u8bc6\u522b\u548c\u4f30\u8ba1\u4e24\u4e2a\u72ec\u7acb\u6b65\u9aa4\u8fdb\u884c\u8bc4\u5206\uff0c\u5305\u542b173\u4e2a\u67e5\u8be2\u548c138\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bca\u65ad\u81ea\u52a8\u5316\u56e0\u679c\u63a8\u7406\u7cfb\u7edf\u7684\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u63a8\u7406\u57fa\u51c6\u901a\u5e38\u53ea\u8bc4\u4f30\u5355\u4e00\u6570\u503c\u8f93\u51fa\uff08\u5982\u5e73\u5747\u5904\u7406\u6548\u5e94\uff09\uff0c\u6df7\u6dc6\u4e86\u56e0\u679c\u5206\u6790\u7684\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a\u8bc6\u522b\uff08\u5728\u7ed9\u5b9a\u5047\u8bbe\u4e0b\u5236\u5b9a\u6709\u6548\u7814\u7a76\u8bbe\u8ba1\uff09\u548c\u4f30\u8ba1\uff08\u5728\u6709\u9650\u6570\u636e\u4e0a\u6570\u503c\u5b9e\u73b0\u8bbe\u8ba1\uff09\u3002\u8fd9\u79cd\u6df7\u6dc6\u4f7f\u5f97\u65e0\u6cd5\u533a\u5206\u56e0\u679c\u63a8\u7406\u5931\u8d25\u548c\u6570\u503c\u6267\u884c\u9519\u8bef\u3002", "method": "\u6784\u5efa\u5305\u542b173\u4e2a\u67e5\u8be2\u3001138\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6570\u636e\u6765\u6e90\u4e8e85\u7bc7\u540c\u884c\u8bc4\u5ba1\u8bba\u6587\u548c4\u672c\u5e7f\u6cdb\u4f7f\u7528\u7684\u56e0\u679c\u63a8\u7406\u6559\u6750\u3002\u8981\u6c42\u7cfb\u7edf\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u751f\u6210\uff1a(1)\u7ed3\u6784\u5316\u8bc6\u522b\u89c4\u8303\uff0c\u5305\u62ec\u7b56\u7565\u540d\u79f0\u3001\u5904\u7406\u53d8\u91cf\u3001\u7ed3\u679c\u53d8\u91cf\u3001\u63a7\u5236\u53d8\u91cf\u53ca\u6240\u6709\u8bbe\u8ba1\u7279\u5b9a\u5143\u7d20\uff1b(2)\u70b9\u4f30\u8ba1\u548c\u6807\u51c6\u8bef\u3002\u5bf9\u8fd9\u4e24\u4e2a\u7ec4\u4ef6\u5206\u522b\u8bc4\u5206\u3002", "result": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\uff0c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u572884%\u7684\u60c5\u51b5\u4e0b\u80fd\u6b63\u786e\u8bc6\u522b\u9ad8\u5c42\u7b56\u7565\uff0c\u4f46\u5b8c\u6574\u8bc6\u522b\u89c4\u8303\u7684\u6b63\u786e\u7387\u4ec5\u4e3a30%\u3002\u8fd9\u8868\u660e\u74f6\u9888\u5728\u4e8e\u7814\u7a76\u8bbe\u8ba1\u7684\u7ec6\u5fae\u7ec6\u8282\u800c\u975e\u8ba1\u7b97\u8fc7\u7a0b\u3002", "conclusion": "CausalReasoningBenchmark\u901a\u8fc7\u5206\u79bb\u8bc6\u522b\u548c\u4f30\u8ba1\u7684\u8bc4\u5206\uff0c\u5b9e\u73b0\u4e86\u5bf9\u81ea\u52a8\u5316\u56e0\u679c\u63a8\u7406\u7cfb\u7edf\u7684\u7ec6\u7c92\u5ea6\u8bca\u65ad\u3002\u57fa\u51c6\u6d4b\u8bd5\u5df2\u5728Hugging Face\u516c\u5f00\uff0c\u65e8\u5728\u4fc3\u8fdb\u66f4\u7a33\u5065\u7684\u81ea\u52a8\u5316\u56e0\u679c\u63a8\u7406\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.20648", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20648", "abs": "https://arxiv.org/abs/2602.20648", "authors": ["Anqi Li", "Chenxiao Wang", "Yu Lu", "Renjun Xu", "Lizhi Ma", "Zhenzhong Lan"], "title": "CARE: An Explainable Computational Framework for Assessing Client-Perceived Therapeutic Alliance Using Large Language Models", "comment": "14 pages, 4 figures", "summary": "Client perceptions of the therapeutic alliance are critical for counseling effectiveness. Accurately capturing these perceptions remains challenging, as traditional post-session questionnaires are burdensome and often delayed, while existing computational approaches produce coarse scores, lack interpretable rationales, and fail to model holistic session context. We present CARE, an LLM-based framework to automatically predict multi-dimensional alliance scores and generate interpretable rationales from counseling transcripts. Built on the CounselingWAI dataset and enriched with 9,516 expert-curated rationales, CARE is fine-tuned using rationale-augmented supervision with the LLaMA-3.1-8B-Instruct backbone. Experiments show that CARE outperforms leading LLMs and substantially reduces the gap between counselor evaluations and client-perceived alliance, achieving over 70% higher Pearson correlation with client ratings. Rationale-augmented supervision further improves predictive accuracy. CARE also produces high-quality, contextually grounded rationales, validated by both automatic and human evaluations. Applied to real-world Chinese online counseling sessions, CARE uncovers common alliance-building challenges, illustrates how interaction patterns shape alliance development, and provides actionable insights, demonstrating its potential as an AI-assisted tool for supporting mental health care.", "AI": {"tldr": "CARE\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u4e2d\u81ea\u52a8\u9884\u6d4b\u591a\u7ef4\u6cbb\u7597\u8054\u76df\u8bc4\u5206\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6cbb\u7597\u8054\u76df\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u540e\u4f1a\u8bdd\u95ee\u5377\u8d1f\u62c5\u91cd\u4e14\u5ef6\u8fdf\uff0c\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u4ea7\u751f\u7c97\u7c92\u5ea6\u8bc4\u5206\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u63a8\u7406\u3001\u672a\u80fd\u5efa\u6a21\u5b8c\u6574\u4f1a\u8bdd\u4e0a\u4e0b\u6587\u3002\u9700\u8981\u66f4\u51c6\u786e\u3001\u53ca\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u5de5\u5177\u6765\u652f\u6301\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u3002", "method": "\u57fa\u4e8eCounselingWAI\u6570\u636e\u96c6\u6784\u5efaCARE\u6846\u67b6\uff0c\u4f7f\u75289,516\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684\u63a8\u7406\u8fdb\u884c\u589e\u5f3a\uff0c\u91c7\u7528LLaMA-3.1-8B-Instruct\u4f5c\u4e3a\u9aa8\u5e72\u6a21\u578b\uff0c\u901a\u8fc7\u63a8\u7406\u589e\u5f3a\u76d1\u7763\u8fdb\u884c\u5fae\u8c03\uff0c\u5b9e\u73b0\u591a\u7ef4\u8054\u76df\u8bc4\u5206\u9884\u6d4b\u548c\u63a8\u7406\u751f\u6210\u3002", "result": "CARE\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u4e3b\u6d41LLM\uff0c\u5c06\u54a8\u8be2\u5e08\u8bc4\u4f30\u4e0e\u5ba2\u6237\u611f\u77e5\u8054\u76df\u7684\u5dee\u8ddd\u663e\u8457\u7f29\u5c0f\uff0c\u4e0e\u5ba2\u6237\u8bc4\u5206\u7684Pearson\u76f8\u5173\u6027\u63d0\u9ad870%\u4ee5\u4e0a\u3002\u63a8\u7406\u589e\u5f3a\u76d1\u7763\u8fdb\u4e00\u6b65\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u63a8\u7406\uff0c\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u5747\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "CARE\u6846\u67b6\u5c55\u793a\u4e86\u4f5c\u4e3aAI\u8f85\u52a9\u5de5\u5177\u652f\u6301\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u8bc6\u522b\u8054\u76df\u5efa\u8bbe\u6311\u6218\u3001\u5206\u6790\u4e92\u52a8\u6a21\u5f0f\u5bf9\u8054\u76df\u53d1\u5c55\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u4e3a\u6cbb\u7597\u8054\u76df\u8bc4\u4f30\u63d0\u4f9b\u4e86\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.20628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20628", "abs": "https://arxiv.org/abs/2602.20628", "authors": ["Nelson Gardner-Challis", "Jonathan Bostock", "Georgiy Kozhevnikov", "Morgan Sinclaire", "Joan Velja", "Alessandro Abate", "Charlie Griffin"], "title": "When can we trust untrusted monitoring? A safety case sketch across collusion strategies", "comment": "66 pages, 14 figures, Preprint", "summary": "AIs are increasingly being deployed with greater autonomy and capabilities, which increases the risk that a misaligned AI may be able to cause catastrophic harm. Untrusted monitoring -- using one untrusted model to oversee another -- is one approach to reducing risk. Justifying the safety of an untrusted monitoring deployment is challenging because developers cannot safely deploy a misaligned model to test their protocol directly. In this paper, we develop upon existing methods for rigorously demonstrating safety based on pre-deployment testing. We relax assumptions that previous AI control research made about the collusion strategies a misaligned AI might use to subvert untrusted monitoring. We develop a taxonomy covering passive self-recognition, causal collusion (hiding pre-shared signals), acausal collusion (hiding signals via Schelling points), and combined strategies. We create a safety case sketch to clearly present our argument, explicitly state our assumptions, and highlight unsolved challenges. We identify conditions under which passive self-recognition could be a more effective collusion strategy than those studied previously. Our work builds towards more robust evaluations of untrusted monitoring.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e0d\u53ef\u4fe1\u76d1\u63a7\u7684\u5b89\u5168\u6027\uff0c\u653e\u677e\u4e86\u5148\u524dAI\u63a7\u5236\u7814\u7a76\u4e2d\u5173\u4e8e\u6076\u610fAI\u5408\u8c0b\u7b56\u7565\u7684\u5047\u8bbe\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u88ab\u52a8\u81ea\u6211\u8bc6\u522b\u3001\u56e0\u679c\u5408\u8c0b\u3001\u975e\u56e0\u679c\u5408\u8c0b\u7b49\u7b56\u7565\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u5b89\u5168\u6848\u4f8b\u6846\u67b6\u3002", "motivation": "\u968f\u7740AI\u81ea\u4e3b\u6027\u548c\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u9519\u4f4dAI\u53ef\u80fd\u9020\u6210\u707e\u96be\u6027\u4f24\u5bb3\u7684\u98ce\u9669\u589e\u52a0\u3002\u4e0d\u53ef\u4fe1\u76d1\u63a7\uff08\u7528\u4e00\u4e2a\u4e0d\u53ef\u4fe1\u6a21\u578b\u76d1\u7763\u53e6\u4e00\u4e2a\uff09\u662f\u964d\u4f4e\u98ce\u9669\u7684\u65b9\u6cd5\u4e4b\u4e00\uff0c\u4f46\u7531\u4e8e\u65e0\u6cd5\u5b89\u5168\u90e8\u7f72\u9519\u4f4d\u6a21\u578b\u76f4\u63a5\u6d4b\u8bd5\u534f\u8bae\uff0c\u8bc1\u660e\u5176\u5b89\u5168\u6027\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u57fa\u4e8e\u5df2\u6709\u7684\u9884\u90e8\u7f72\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u653e\u677e\u4e86\u5148\u524dAI\u63a7\u5236\u7814\u7a76\u4e2d\u5173\u4e8e\u6076\u610fAI\u5408\u8c0b\u7b56\u7565\u7684\u5047\u8bbe\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u88ab\u52a8\u81ea\u6211\u8bc6\u522b\u3001\u56e0\u679c\u5408\u8c0b\uff08\u9690\u85cf\u9884\u5171\u4eab\u4fe1\u53f7\uff09\u3001\u975e\u56e0\u679c\u5408\u8c0b\uff08\u901a\u8fc7\u8c22\u6797\u70b9\u9690\u85cf\u4fe1\u53f7\uff09\u53ca\u7ec4\u5408\u7b56\u7565\u7684\u5206\u7c7b\u6cd5\uff0c\u521b\u5efa\u4e86\u5b89\u5168\u6848\u4f8b\u6846\u67b6\u6765\u660e\u786e\u5448\u73b0\u8bba\u8bc1\u3001\u5047\u8bbe\u548c\u672a\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u786e\u5b9a\u4e86\u88ab\u52a8\u81ea\u6211\u8bc6\u522b\u53ef\u80fd\u6bd4\u5148\u524d\u7814\u7a76\u7684\u7b56\u7565\u66f4\u6709\u6548\u7684\u6761\u4ef6\uff0c\u4e3a\u4e0d\u53ef\u4fe1\u76d1\u63a7\u7684\u66f4\u7a33\u5065\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u653e\u677e\u5408\u8c0b\u7b56\u7565\u5047\u8bbe\u548c\u5f00\u53d1\u5206\u7c7b\u6cd5\uff0c\u63a8\u8fdb\u4e86\u4e0d\u53ef\u4fe1\u76d1\u63a7\u7684\u5b89\u5168\u6027\u8bba\u8bc1\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u66f4\u7a33\u5065\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6846\u67b6\u3002"}}
{"id": "2602.20727", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20727", "abs": "https://arxiv.org/abs/2602.20727", "authors": ["Xindian Ma", "Rundong Kong", "Peng Zhang", "Ruoxiang Huang", "Yongyu Jiang"], "title": "ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition", "comment": null, "summary": "LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable parameters. Conversely, aggressively lowering the rank to curb this overhead markedly degrades performance in complex multi-task settings. We propose ID-LoRA, a novel PEFT framework that breaks the trade-off. Its core innovation lies in extracting and reusing clustered parameter groups from the pretrained weight matrix. These groups are then used to form multiple low-rank components, all of which share only a single initialized trainable low-rank matrix. This approach cuts the number of trainable parameters while keeping the model's capacity intact. We evaluate ID-LoRA on five diverse benchmarks: Mathematical Reasoning, Code Generation, MMLU, CommonsenseQA, and Safety Alignment. ID-LoRA outperforms both full fine-tuning and existing PEFT baselines (e.g., LoRA, DoRA, HydraLoRA) while using up to 46% fewer trainable parameters than the standard LoRA. In multi-task scenarios, it surpasses LoRA and its recent variants (e.g., DoRA and HydraLoRA) on both Code and MMLU tasks, yet requires only 54% of the trainable parameters demanded by the conventional LoRA.", "AI": {"tldr": "ID-LoRA\u662f\u4e00\u79cd\u65b0\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u9884\u8bad\u7ec3\u6743\u91cd\u77e9\u9635\u4e2d\u63d0\u53d6\u548c\u91cd\u7528\u805a\u7c7b\u53c2\u6570\u7ec4\uff0c\u5f62\u6210\u591a\u4e2a\u5171\u4eab\u5355\u4e00\u53ef\u8bad\u7ec3\u4f4e\u79e9\u77e9\u9635\u7684\u4f4e\u79e9\u7ec4\u4ef6\uff0c\u5728\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LoRA\u53ca\u5176\u53d8\u4f53\u5728\u5927\u6a21\u578b\u6269\u5c55\u65f6\u4ecd\u4f1a\u5f15\u5165\u53ef\u89c2\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u5f00\u9500\uff0c\u800c\u8fc7\u5ea6\u964d\u4f4e\u79e9\u4ee5\u63a7\u5236\u5f00\u9500\u4f1a\u663e\u8457\u964d\u4f4e\u590d\u6742\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u9700\u8981\u6253\u7834\u8fd9\u79cd\u6743\u8861\u3002", "method": "\u4ece\u9884\u8bad\u7ec3\u6743\u91cd\u77e9\u9635\u4e2d\u63d0\u53d6\u805a\u7c7b\u53c2\u6570\u7ec4\uff0c\u91cd\u7528\u8fd9\u4e9b\u7ec4\u5f62\u6210\u591a\u4e2a\u4f4e\u79e9\u7ec4\u4ef6\uff0c\u6240\u6709\u7ec4\u4ef6\u5171\u4eab\u5355\u4e00\u521d\u59cb\u5316\u7684\u53ef\u8bad\u7ec3\u4f4e\u79e9\u77e9\u9635\uff0c\u4ece\u800c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5bb9\u91cf\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u3001MMLU\u3001\u5e38\u8bc6\u95ee\u7b54\u548c\u5b89\u5168\u5bf9\u9f50\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cID-LoRA\u4f18\u4e8e\u5168\u91cf\u5fae\u8c03\u548c\u73b0\u6709PEFT\u57fa\u7ebf\uff08\u5982LoRA\u3001DoRA\u3001HydraLoRA\uff09\uff0c\u540c\u65f6\u4f7f\u7528\u6bd4\u6807\u51c6LoRA\u5c1146%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\uff0c\u5728\u4ee3\u7801\u548cMMLU\u4efb\u52a1\u4e0a\u8d85\u8d8aLoRA\u53ca\u5176\u53d8\u4f53\uff0c\u4ec5\u9700\u4f20\u7edfLoRA 54%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "conclusion": "ID-LoRA\u6210\u529f\u6253\u7834\u4e86\u53c2\u6570\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.20638", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20638", "abs": "https://arxiv.org/abs/2602.20638", "authors": ["Vincent Auriau", "Khaled Belahcene", "Emmanuel Malherbe", "Vincent Mousseau", "Marc Pirlot"], "title": "Identifying two piecewise linear additive value functions from anonymous preference information", "comment": null, "summary": "Eliciting a preference model involves asking a person, named decision-maker, a series of questions. We assume that these preferences can be represented by an additive value function. In this work, we query simultaneously two decision-makers in the aim to elicit their respective value functions. For each query we receive two answers, without noise, but without knowing which answer corresponds to which decision-maker.We propose an elicitation procedure that identifies the two preference models when the marginal value functions are piecewise linear with known breaking points.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540c\u65f6\u4ece\u4e24\u4f4d\u51b3\u7b56\u8005\u4e2d\u5f15\u51fa\u504f\u597d\u6a21\u578b\u7684\u7a0b\u5e8f\uff0c\u901a\u8fc7\u540c\u65f6\u67e5\u8be2\u4e24\u4eba\u83b7\u5f97\u4e24\u4e2a\u7b54\u6848\uff08\u4f46\u4e0d\u77e5\u9053\u54ea\u4e2a\u7b54\u6848\u5bf9\u5e94\u54ea\u4e2a\u51b3\u7b56\u8005\uff09\uff0c\u5728\u8fb9\u9645\u4ef7\u503c\u51fd\u6570\u4e3a\u5206\u6bb5\u7ebf\u6027\u4e14\u65ad\u70b9\u5df2\u77e5\u7684\u6761\u4ef6\u4e0b\u8bc6\u522b\u51fa\u4e24\u4e2a\u504f\u597d\u6a21\u578b\u3002", "motivation": "\u5728\u540c\u65f6\u67e5\u8be2\u4e24\u4f4d\u51b3\u7b56\u8005\u65f6\uff0c\u867d\u7136\u80fd\u83b7\u5f97\u4e24\u4e2a\u7b54\u6848\uff0c\u4f46\u4e0d\u77e5\u9053\u54ea\u4e2a\u7b54\u6848\u5bf9\u5e94\u54ea\u4e2a\u51b3\u7b56\u8005\uff0c\u8fd9\u7ed9\u504f\u597d\u6a21\u578b\u7684\u5f15\u51fa\u5e26\u6765\u4e86\u6311\u6218\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u77e5\u9053\u7b54\u6848\u5f52\u5c5e\u7684\u60c5\u51b5\u4e0b\uff0c\u540c\u65f6\u8bc6\u522b\u51fa\u4e24\u4f4d\u51b3\u7b56\u8005\u7684\u504f\u597d\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5f15\u51fa\u7a0b\u5e8f\uff0c\u5047\u8bbe\u504f\u597d\u53ef\u4ee5\u7528\u52a0\u6027\u4ef7\u503c\u51fd\u6570\u8868\u793a\uff0c\u4e14\u8fb9\u9645\u4ef7\u503c\u51fd\u6570\u662f\u5206\u6bb5\u7ebf\u6027\u7684\uff0c\u65ad\u70b9\u5df2\u77e5\u3002\u901a\u8fc7\u540c\u65f6\u5411\u4e24\u4f4d\u51b3\u7b56\u8005\u63d0\u95ee\uff0c\u83b7\u5f97\u4e24\u4e2a\u7b54\u6848\uff08\u65e0\u566a\u58f0\uff09\uff0c\u5728\u4e0d\u77e5\u9053\u7b54\u6848\u5bf9\u5e94\u5173\u7cfb\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u5206\u6bb5\u7ebf\u6027\u7ed3\u6784\u7684\u7279\u6027\u6765\u8bc6\u522b\u4e24\u4e2a\u4ef7\u503c\u51fd\u6570\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u8fb9\u9645\u4ef7\u503c\u51fd\u6570\u4e3a\u5206\u6bb5\u7ebf\u6027\u4e14\u65ad\u70b9\u5df2\u77e5\u7684\u6761\u4ef6\u4e0b\uff0c\u6210\u529f\u8bc6\u522b\u51fa\u4e24\u4f4d\u51b3\u7b56\u8005\u5404\u81ea\u7684\u504f\u597d\u6a21\u578b\uff0c\u5373\u4f7f\u4e0d\u77e5\u9053\u54ea\u4e2a\u7b54\u6848\u5bf9\u5e94\u54ea\u4e2a\u51b3\u7b56\u8005\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f15\u51fa\u7a0b\u5e8f\u89e3\u51b3\u4e86\u540c\u65f6\u4ece\u4e24\u4f4d\u51b3\u7b56\u8005\u5f15\u51fa\u504f\u597d\u6a21\u578b\u7684\u95ee\u9898\uff0c\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\uff08\u52a0\u6027\u4ef7\u503c\u51fd\u6570\u3001\u5206\u6bb5\u7ebf\u6027\u8fb9\u9645\u51fd\u6570\u3001\u5df2\u77e5\u65ad\u70b9\uff09\u80fd\u591f\u6709\u6548\u8bc6\u522b\u4e24\u4e2a\u504f\u597d\u6a21\u578b\uff0c\u4e3a\u7fa4\u4f53\u51b3\u7b56\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.20743", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20743", "abs": "https://arxiv.org/abs/2602.20743", "authors": ["Gabriel Loiseau", "Damien Sileo", "Damien Riquet", "Maxime Meyer", "Marc Tommasi"], "title": "Adaptive Text Anonymization: Learning Privacy-Utility Trade-offs via Prompt Optimization", "comment": null, "summary": "Anonymizing textual documents is a highly context-sensitive problem: the appropriate balance between privacy protection and utility preservation varies with the data domain, privacy objectives, and downstream application. However, existing anonymization methods rely on static, manually designed strategies that lack the flexibility to adjust to diverse requirements and often fail to generalize across domains. We introduce adaptive text anonymization, a new task formulation in which anonymization strategies are automatically adapted to specific privacy-utility requirements. We propose a framework for task-specific prompt optimization that automatically constructs anonymization instructions for language models, enabling adaptation to different privacy goals, domains, and downstream usage patterns. To evaluate our approach, we present a benchmark spanning five datasets with diverse domains, privacy constraints, and utility objectives. Across all evaluated settings, our framework consistently achieves a better privacy-utility trade-off than existing baselines, while remaining computationally efficient and effective on open-source language models, with performance comparable to larger closed-source models. Additionally, we show that our method can discover novel anonymization strategies that explore different points along the privacy-utility trade-off frontier.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u6587\u672c\u533f\u540d\u5316\u4efb\u52a1\uff0c\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u4f18\u5316\u6846\u67b6\u81ea\u52a8\u751f\u6210\u533f\u540d\u5316\u6307\u4ee4\uff0c\u5728\u4e0d\u540c\u9690\u79c1-\u6548\u7528\u9700\u6c42\u4e0b\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u73b0\u6709\u6587\u672c\u533f\u540d\u5316\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u3001\u624b\u52a8\u8bbe\u8ba1\u7684\u7b56\u7565\uff0c\u7f3a\u4e4f\u9002\u5e94\u4e0d\u540c\u9700\u6c42\uff08\u6570\u636e\u9886\u57df\u3001\u9690\u79c1\u76ee\u6807\u3001\u4e0b\u6e38\u5e94\u7528\uff09\u7684\u7075\u6d3b\u6027\uff0c\u4e14\u96be\u4ee5\u8de8\u9886\u57df\u6cdb\u5316", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u6587\u672c\u533f\u540d\u5316\u4efb\u52a1\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u4f18\u5316\u81ea\u52a8\u6784\u5efa\u8bed\u8a00\u6a21\u578b\u7684\u533f\u540d\u5316\u6307\u4ee4\uff0c\u9002\u5e94\u4e0d\u540c\u9690\u79c1\u76ee\u6807\u3001\u9886\u57df\u548c\u4f7f\u7528\u6a21\u5f0f", "result": "\u5728\u5305\u542b5\u4e2a\u6570\u636e\u96c6\uff08\u4e0d\u540c\u9886\u57df\u3001\u9690\u79c1\u7ea6\u675f\u548c\u6548\u7528\u76ee\u6807\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6846\u67b6\u5728\u6240\u6709\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e0a\u8ba1\u7b97\u9ad8\u6548\uff0c\u6027\u80fd\u4e0e\u5927\u578b\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\uff0c\u5e76\u80fd\u53d1\u73b0\u65b0\u7684\u533f\u540d\u5316\u7b56\u7565\u63a2\u7d22\u9690\u79c1-\u6548\u7528\u6743\u8861\u524d\u6cbf", "conclusion": "\u81ea\u9002\u5e94\u6587\u672c\u533f\u540d\u5316\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u4f18\u5316\u63d0\u793a\uff0c\u80fd\u591f\u7075\u6d3b\u9002\u5e94\u591a\u6837\u5316\u7684\u9690\u79c1-\u6548\u7528\u9700\u6c42\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u597d\u7684\u6743\u8861\uff0c\u4e3a\u6587\u672c\u533f\u540d\u5316\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.20639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20639", "abs": "https://arxiv.org/abs/2602.20639", "authors": ["Bo Zhang", "Jinfeng Zhou", "Yuxuan Chen", "Jianing Yin", "Minlie Huang", "Hongning Wang"], "title": "Grounding LLMs in Scientific Discovery via Embodied Actions", "comment": "24 pages, 7 figures, 7 tables. Preprint", "summary": "Large Language Models (LLMs) have shown significant potential in scientific discovery but struggle to bridge the gap between theoretical reasoning and verifiable physical simulation. Existing solutions operate in a passive \"execute-then-response\" loop and thus lacks runtime perception, obscuring agents to transient anomalies (e.g., numerical instability or diverging oscillations). To address this limitation, we propose EmbodiedAct, a framework that transforms established scientific software into active embodied agents by grounding LLMs in embodied actions with a tight perception-execution loop. We instantiate EmbodiedAct within MATLAB and evaluate it on complex engineering design and scientific modeling tasks. Extensive experiments show that EmbodiedAct significantly outperforms existing baselines, achieving SOTA performance by ensuring satisfactory reliability and stability in long-horizon simulations and enhanced accuracy in scientific modeling.", "AI": {"tldr": "EmbodiedAct\u6846\u67b6\u5c06\u79d1\u5b66\u8f6f\u4ef6\u8f6c\u5316\u4e3a\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7d27\u5bc6\u7684\u611f\u77e5-\u6267\u884c\u5faa\u73af\u8ba9LLM\u5728\u7269\u7406\u4eff\u771f\u4e2d\u5b9e\u73b0\u4e3b\u52a8\u611f\u77e5\u548c\u52a8\u6001\u8c03\u6574", "motivation": "\u73b0\u6709LLM\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u96be\u4ee5\u5f25\u5408\u7406\u8bba\u63a8\u7406\u4e0e\u53ef\u9a8c\u8bc1\u7269\u7406\u4eff\u771f\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4f20\u7edf\"\u6267\u884c-\u54cd\u5e94\"\u88ab\u52a8\u5faa\u73af\u7f3a\u4e4f\u8fd0\u884c\u65f6\u611f\u77e5\u80fd\u529b\uff0c\u65e0\u6cd5\u5904\u7406\u77ac\u6001\u5f02\u5e38\uff08\u5982\u6570\u503c\u4e0d\u7a33\u5b9a\u6216\u53d1\u6563\u632f\u8361\uff09", "method": "\u63d0\u51faEmbodiedAct\u6846\u67b6\uff0c\u5c06\u6210\u719f\u79d1\u5b66\u8f6f\u4ef6\u8f6c\u5316\u4e3a\u4e3b\u52a8\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5c06LLM\u4e0e\u5177\u8eab\u52a8\u4f5c\u76f8\u7ed3\u5408\uff0c\u5efa\u7acb\u7d27\u5bc6\u7684\u611f\u77e5-\u6267\u884c\u5faa\u73af\uff0c\u5728MATLAB\u73af\u5883\u4e2d\u5b9e\u73b0\u8be5\u6846\u67b6", "result": "\u5728\u590d\u6742\u5de5\u7a0b\u8bbe\u8ba1\u548c\u79d1\u5b66\u5efa\u6a21\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEmbodiedAct\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u786e\u4fdd\u957f\u65f6\u7a0b\u4eff\u771f\u7684\u6ee1\u610f\u53ef\u9760\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u5347\u79d1\u5b66\u5efa\u6a21\u7684\u51c6\u786e\u6027", "conclusion": "EmbodiedAct\u901a\u8fc7\u5c06\u79d1\u5b66\u8f6f\u4ef6\u8f6c\u5316\u4e3a\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u7269\u7406\u4eff\u771f\u4e2d\u7684\u611f\u77e5-\u6267\u884c\u8131\u8282\u95ee\u9898\uff0c\u4e3a\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u7a33\u5b9a\u7684\u4eff\u771f\u73af\u5883"}}
{"id": "2602.20749", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20749", "abs": "https://arxiv.org/abs/2602.20749", "authors": ["Azrin Sultana", "Firoz Ahmed"], "title": "Explicit Grammar Semantic Feature Fusion for Robust Text Classification", "comment": "30 pages, 9 figures", "summary": "Natural Language Processing enables computers to understand human language by analysing and classifying text efficiently with deep-level grammatical and semantic features. Existing models capture features by learning from large corpora with transformer models, which are computationally intensive and unsuitable for resource-constrained environments. Therefore, our proposed study incorporates comprehensive grammatical rules alongside semantic information to build a robust, lightweight classification model without resorting to full parameterised transformer models or heavy deep learning architectures. The novelty of our approach lies in its explicit encoding of sentence-level grammatical structure, including syntactic composition, phrase patterns, and complexity indicators, into a compact grammar vector, which is then fused with frozen contextual embeddings. These heterogeneous elements unified a single representation that captures both the structural and semantic characteristics of the text. Deep learning models such as Deep Belief Networks (DBNs), Long Short-Term Memory (LSTMs), BiLSTMs, and transformer-based BERT and XLNET were used to train and evaluate the model, with the number of epochs varied. Based on experimental results, the unified feature representation model captures both the semantic and structural properties of text, outperforming baseline models by 2%-15%, enabling more effective learning across heterogeneous domains. Unlike prior syntax-aware transformer models that inject grammatical structure through additional attention layers, tree encoders, or full fine-tuning, the proposed framework treats grammar as an explicit inductive bias rather than a learnable module, resulting in a very lightweight model that delivers better performance on edge devices", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u663e\u5f0f\u7f16\u7801\u53e5\u5b50\u7ea7\u8bed\u6cd5\u7ed3\u6784\u4e0e\u51bb\u7ed3\u4e0a\u4e0b\u6587\u5d4c\u5165\u878d\u5408\uff0c\u907f\u514d\u4f7f\u7528\u8ba1\u7b97\u5bc6\u96c6\u7684\u5b8c\u6574Transformer\u6a21\u578b", "motivation": "\u73b0\u6709Transformer\u6a21\u578b\u8ba1\u7b97\u5bc6\u96c6\uff0c\u4e0d\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff0c\u9700\u8981\u6784\u5efa\u8f7b\u91cf\u7ea7\u4f46\u80fd\u540c\u65f6\u6355\u6349\u8bed\u6cd5\u548c\u8bed\u4e49\u7279\u5f81\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b", "method": "\u5c06\u53e5\u5b50\u7ea7\u8bed\u6cd5\u7ed3\u6784\uff08\u53e5\u6cd5\u7ec4\u6210\u3001\u77ed\u8bed\u6a21\u5f0f\u3001\u590d\u6742\u5ea6\u6307\u6807\uff09\u7f16\u7801\u4e3a\u7d27\u51d1\u8bed\u6cd5\u5411\u91cf\uff0c\u4e0e\u51bb\u7ed3\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u878d\u5408\uff0c\u5f62\u6210\u7edf\u4e00\u7279\u5f81\u8868\u793a\uff0c\u4f7f\u7528DBNs\u3001LSTMs\u3001BiLSTMs\u3001BERT\u3001XLNET\u7b49\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u8bc4\u4f30", "result": "\u7edf\u4e00\u7279\u5f81\u8868\u793a\u6a21\u578b\u80fd\u540c\u65f6\u6355\u6349\u6587\u672c\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u7279\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b2%-15%\uff0c\u5728\u5f02\u6784\u9886\u57df\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5b66\u4e60\uff0c\u7279\u522b\u9002\u5408\u8fb9\u7f18\u8bbe\u5907", "conclusion": "\u5c06\u8bed\u6cd5\u4f5c\u4e3a\u663e\u5f0f\u5f52\u7eb3\u504f\u7f6e\u800c\u975e\u53ef\u5b66\u4e60\u6a21\u5757\uff0c\u6784\u5efa\u4e86\u8f7b\u91cf\u7ea7\u9ad8\u6027\u80fd\u6a21\u578b\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6587\u672c\u5206\u7c7b\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.20659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20659", "abs": "https://arxiv.org/abs/2602.20659", "authors": ["Vaidehi Bagaria", "Bijo Sebastian", "Nirav Patel"], "title": "Recursive Belief Vision Language Model", "comment": null, "summary": "Current vision-language-action (VLA) models struggle with long-horizon manipulation under partial observability. Most existing approaches remain observation-driven, relying on short context windows or repeated queries to vision-language models (VLMs). This leads to loss of task progress, action repetition under perceptual aliasing, and high inference latency. Semantic reasoning alone is not the primary bottleneck in long-horizon manipulation. Instead, VLAs lack persistent, action-conditioned state representations and exhibit limited temporal and physical reasoning, making them ill-suited for multi-stage control. This paper introduces RB-VLA, a belief-centric architecture trained with self-supervised world-model objectives that maintains a compact latent state encoding task-relevant history, dynamics, and object interactions. Queried once for high-level intent, the VLM provides task specification, while the belief tracks task progress and enables phase-aware, causally grounded control under partial observability without storing raw observations or scaling memory with time. The belief and intent jointly condition a diffusion policy for robust closed-loop execution. RB-VLA outperforms prior VLAs on long-horizon benchmarks, achieving 52.5% and 37.5% higher success on multi-stage pick-and-place and stacking tasks, respectively, compared to \u03c00. It also reduces inference latency by up to 5x relative to baselines and eliminates memory growth across timesteps observed in existing VLAs. Ablations show that the belief module is the primary driver of performance, increasing success rates from 32.5% to 77.5%. These results demonstrate the effectiveness of belief-based state representations for long-horizon VLA policies.", "AI": {"tldr": "RB-VLA\uff1a\u57fa\u4e8e\u4fe1\u5ff5\u7684\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u4e16\u754c\u6a21\u578b\u76ee\u6807\u8bad\u7ec3\uff0c\u7ef4\u62a4\u7d27\u51d1\u7684\u6f5c\u5728\u72b6\u6001\u7f16\u7801\u4efb\u52a1\u5386\u53f2\u3001\u52a8\u6001\u548c\u7269\u4f53\u4ea4\u4e92\uff0c\u89e3\u51b3\u957f\u65f6\u7a0b\u64cd\u4f5c\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u591a\u9636\u6bb5\u4efb\u52a1\u6210\u529f\u7387\u5e76\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u7684\u957f\u65f6\u7a0b\u64cd\u4f5c\u4e2d\u5b58\u5728\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u89c2\u6d4b\u9a71\u52a8\uff0c\u4f7f\u7528\u77ed\u4e0a\u4e0b\u6587\u7a97\u53e3\u6216\u91cd\u590d\u67e5\u8be2\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5bfc\u81f4\u4efb\u52a1\u8fdb\u5ea6\u4e22\u5931\u3001\u611f\u77e5\u6df7\u6dc6\u4e0b\u7684\u52a8\u4f5c\u91cd\u590d\u548c\u9ad8\u63a8\u7406\u5ef6\u8fdf\u3002\u8bed\u4e49\u63a8\u7406\u5e76\u975e\u4e3b\u8981\u74f6\u9888\uff0c\u800c\u662f\u7f3a\u4e4f\u6301\u4e45\u3001\u52a8\u4f5c\u6761\u4ef6\u7684\u72b6\u6001\u8868\u793a\u4ee5\u53ca\u6709\u9650\u7684\u65f6\u7a7a\u548c\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faRB-VLA\uff0c\u57fa\u4e8e\u4fe1\u5ff5\u4e2d\u5fc3\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u4e16\u754c\u6a21\u578b\u76ee\u6807\u8bad\u7ec3\uff0c\u7ef4\u62a4\u7d27\u51d1\u7684\u6f5c\u5728\u72b6\u6001\u7f16\u7801\u4efb\u52a1\u76f8\u5173\u5386\u53f2\u3001\u52a8\u6001\u548c\u7269\u4f53\u4ea4\u4e92\u3002VLM\u4ec5\u7528\u4e8e\u9ad8\u5c42\u610f\u56fe\u67e5\u8be2\uff0c\u4fe1\u5ff5\u6a21\u5757\u8ddf\u8e2a\u4efb\u52a1\u8fdb\u5ea6\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9636\u6bb5\u611f\u77e5\u3001\u56e0\u679c\u57fa\u7840\u7684\u63a7\u5236\uff0c\u65e0\u9700\u5b58\u50a8\u539f\u59cb\u89c2\u6d4b\u6216\u968f\u65f6\u95f4\u6269\u5c55\u5185\u5b58\u3002\u4fe1\u5ff5\u548c\u610f\u56fe\u5171\u540c\u8c03\u8282\u6269\u6563\u7b56\u7565\u8fdb\u884c\u9c81\u68d2\u95ed\u73af\u6267\u884c\u3002", "result": "\u5728\u957f\u65f6\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709VLA\u6a21\u578b\uff1a\u591a\u9636\u6bb5\u62fe\u653e\u4efb\u52a1\u6210\u529f\u7387\u63d0\u9ad852.5%\uff0c\u5806\u53e0\u4efb\u52a1\u63d0\u9ad837.5%\uff08\u76f8\u6bd4\u03c00\uff09\u3002\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe5\u500d\uff0c\u6d88\u9664\u4e86\u73b0\u6709VLA\u4e2d\u968f\u65f6\u95f4\u6b65\u589e\u957f\u7684\u5185\u5b58\u95ee\u9898\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\u4fe1\u5ff5\u6a21\u5757\u662f\u6027\u80fd\u63d0\u5347\u7684\u4e3b\u8981\u9a71\u52a8\u529b\uff0c\u6210\u529f\u7387\u4ece32.5%\u63d0\u5347\u81f377.5%\u3002", "conclusion": "\u57fa\u4e8e\u4fe1\u5ff5\u7684\u72b6\u6001\u8868\u793a\u5bf9\u4e8e\u957f\u65f6\u7a0bVLA\u7b56\u7565\u5177\u6709\u663e\u8457\u6548\u679c\u3002RB-VLA\u901a\u8fc7\u4fe1\u5ff5\u4e2d\u5fc3\u67b6\u6784\u89e3\u51b3\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u3001\u65f6\u95f4\u63a8\u7406\u548c\u7269\u7406\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3a\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.20751", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20751", "abs": "https://arxiv.org/abs/2602.20751", "authors": ["Yifei Xu", "Guilherme Potje", "Shivam Shandilya", "Tiancheng Yuan", "Leonardo de Oliveira Nunes", "Rakshanda Agarwal", "Saeid Asgari", "Adam Atkinson", "Emre K\u0131c\u0131man", "Songwu Lu", "Ranveer Chandra", "Tusher Chakraborty"], "title": "SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing", "comment": null, "summary": "Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inconsistent, and fixed-pool discriminative rubrics can saturate and drift, enabling reward hacking. We present SibylSense, an inference-time learning approach that adapts a frozen rubric generator through a tunable memory bank of validated rubric items. Memory is updated via verifier-based item rewards measured by reference-candidate answer discriminative gaps from a handful of examples. SibylSense alternates memory tuning with a rubric-adversarial policy update that produces rubric-satisfying candidate answers, shrinking discriminative gaps and driving the rubric generator to capture new quality dimensions. Experiments on two open-ended tasks show that SibylSense yields more discriminative rubrics and improves downstream RL performance over static and non-adaptive baselines.", "AI": {"tldr": "SibylSense\uff1a\u4e00\u79cd\u901a\u8fc7\u53ef\u8c03\u8bb0\u5fc6\u5e93\u81ea\u9002\u5e94\u751f\u6210\u8bc4\u4f30\u6807\u51c6\u7684\u63a8\u7406\u65f6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u5f00\u653e\u751f\u6210\u4efb\u52a1\u7684\u5f3a\u5316\u5b66\u4e60\u6027\u80fd", "motivation": "\u5f00\u653e\u751f\u6210\u4efb\u52a1\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u9762\u4e34\u5956\u52b1\u8bbe\u8ba1\u96be\u9898\uff1a\u4e13\u5bb6\u8bc4\u4f30\u6807\u51c6\u6210\u672c\u9ad8\uff0c\u63d0\u793a\u751f\u6210\u7684\u8bc4\u4f30\u6807\u51c6\u80a4\u6d45\u4e0d\u4e00\u81f4\uff0c\u56fa\u5b9a\u6c60\u5224\u522b\u6027\u8bc4\u4f30\u6807\u51c6\u6613\u9971\u548c\u6f02\u79fb\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb", "method": "SibylSense\u91c7\u7528\u63a8\u7406\u65f6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u8c03\u8bb0\u5fc6\u5e93\u81ea\u9002\u5e94\u51bb\u7ed3\u7684\u8bc4\u4f30\u6807\u51c6\u751f\u6210\u5668\u3002\u8bb0\u5fc6\u5e93\u901a\u8fc7\u9a8c\u8bc1\u5668\u57fa\u4e8e\u53c2\u8003-\u5019\u9009\u7b54\u6848\u5224\u522b\u6027\u5dee\u8ddd\u7684\u9879\u5956\u52b1\u66f4\u65b0\uff0c\u4ea4\u66ff\u8fdb\u884c\u8bb0\u5fc6\u8c03\u4f18\u548c\u8bc4\u4f30\u6807\u51c6\u5bf9\u6297\u6027\u7b56\u7565\u66f4\u65b0", "result": "\u5728\u4e24\u4e2a\u5f00\u653e\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSibylSense\u80fd\u4ea7\u751f\u66f4\u5177\u5224\u522b\u6027\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u76f8\u6bd4\u9759\u6001\u548c\u975e\u81ea\u9002\u5e94\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u5f3a\u5316\u5b66\u4e60\u6027\u80fd", "conclusion": "SibylSense\u901a\u8fc7\u81ea\u9002\u5e94\u8bc4\u4f30\u6807\u51c6\u751f\u6210\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u751f\u6210\u4efb\u52a1\u4e2d\u5956\u52b1\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2602.20687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20687", "abs": "https://arxiv.org/abs/2602.20687", "authors": ["Bo Peng", "Pi Bu", "Keyu Pan", "Xinrun Xu", "Yinxiu Zhao", "Miao Chen", "Yang Du", "Lin Li", "Jun Song", "Tong Xu"], "title": "How Foundational Skills Influence VLM-based Embodied Agents:A Native Perspective", "comment": null, "summary": "Recent advances in vision-language models (VLMs) have shown promise for human-level embodied intelligence. However, existing benchmarks for VLM-driven embodied agents often rely on high-level commands or discretized action spaces, which are non-native settings that differ markedly from real-world control. In addition, current benchmarks focus primarily on high-level tasks and lack joint evaluation and analysis at both low and high levels. To address these limitations, we present NativeEmbodied, a challenging benchmark for VLM-driven embodied agents that uses a unified, native low-level action space. Built on diverse simulated scenes, NativeEmbodied includes three representative high-level tasks in complex scenarios to evaluate overall performance. For more detailed analysis, we further decouple the skills required by complex tasks and construct four types of low-level tasks, each targeting a fundamental embodied skill. This joint evaluation across task and skill granularities enables fine-grained assessment of embodied agents. Experiments with state-of-the-art VLMs reveal clear deficiencies in several fundamental embodied skills, and further analysis shows that these bottlenecks significantly limit performance on high-level tasks. NativeEmbodied highlights key challenges for current VLM-driven embodied agents and provides insights to guide future research.", "AI": {"tldr": "NativeEmbodied\u662f\u4e00\u4e2a\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u5177\u8eab\u667a\u80fd\u4f53\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u7edf\u4e00\u7684\u539f\u751f\u4f4e\u7ea7\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5305\u542b\u9ad8\u7ea7\u4efb\u52a1\u548c\u4f4e\u7ea7\u6280\u80fd\u4efb\u52a1\u7684\u53cc\u7c92\u5ea6\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709VLM\u9a71\u52a8\u5177\u8eab\u667a\u80fd\u4f53\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u4f7f\u7528\u9ad8\u7ea7\u547d\u4ee4\u6216\u79bb\u6563\u5316\u52a8\u4f5c\u7a7a\u95f4\uff0c\u8fd9\u4e0e\u771f\u5b9e\u4e16\u754c\u63a7\u5236\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b2) \u4e3b\u8981\u5173\u6ce8\u9ad8\u7ea7\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u4f4e\u7ea7\u548c\u9ad8\u7ea7\u80fd\u529b\u7684\u8054\u5408\u8bc4\u4f30\u5206\u6790\u3002", "method": "\u6784\u5efaNativeEmbodied\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8e\u591a\u6837\u5316\u6a21\u62df\u573a\u666f\uff0c\u5305\u542b\u4e09\u4e2a\u4ee3\u8868\u6027\u9ad8\u7ea7\u4efb\u52a1\u8bc4\u4f30\u6574\u4f53\u6027\u80fd\uff0c\u540c\u65f6\u89e3\u8026\u590d\u6742\u4efb\u52a1\u6240\u9700\u6280\u80fd\uff0c\u6784\u5efa\u56db\u7c7b\u4f4e\u7ea7\u4efb\u52a1\u5206\u522b\u9488\u5bf9\u57fa\u7840\u5177\u8eab\u6280\u80fd\uff0c\u5b9e\u73b0\u4efb\u52a1\u548c\u6280\u80fd\u7c92\u5ea6\u7684\u8054\u5408\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6700\u5148\u8fdb\u7684VLMs\u5728\u591a\u4e2a\u57fa\u7840\u5177\u8eab\u6280\u80fd\u4e0a\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff0c\u8fdb\u4e00\u6b65\u5206\u6790\u8868\u660e\u8fd9\u4e9b\u74f6\u9888\u663e\u8457\u9650\u5236\u4e86\u9ad8\u7ea7\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "NativeEmbodied\u63ed\u793a\u4e86\u5f53\u524dVLM\u9a71\u52a8\u5177\u8eab\u667a\u80fd\u4f53\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u7edf\u4e00\u539f\u751f\u52a8\u4f5c\u7a7a\u95f4\u548c\u53cc\u7c92\u5ea6\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.20759", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20759", "abs": "https://arxiv.org/abs/2602.20759", "authors": ["Yu Fu", "Seongho Son", "Ilija Bogunovic"], "title": "Overton Pluralistic Reinforcement Learning for Large Language Models", "comment": "28 pages, 8 figures", "summary": "Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Optimization), a reinforcement learning framework for implicit Overton Pluralism that enables a single large language model to produce pluralistic responses without explicit prompting or modular orchestration. Our workflow consists of two main steps. First, similarity estimator training fine-tunes a Sentence Transformer for Overton Pluralism tasks to provide more accurate coverage evaluation of generated responses. Second, OP-GRPO training incorporates this similarity estimator into a dual-reward system designed to ensure both broad coverage of genuine human perspectives and the uniqueness of each perspective, thereby promoting diversity. Empirical results demonstrate a \"small models, big perspective coverage\" effect. The trained Qwen2.5-3B-Instruct model surpasses a 20B GPT-OSS baseline with a 37.4 percent relative accuracy gain on a Natural Language Inference benchmark, and also outperforms a modular architecture baseline with a 19.1 percent relative improvement. Additional evaluations using GPT-4.1 as a large language model judge further confirm the robustness of the approach.", "AI": {"tldr": "OP-GRPO\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5956\u52b1\u7cfb\u7edf\u4f7f\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u591a\u5143\u89c6\u89d2\u7684\u56de\u5e94\uff0c\u65e0\u9700\u663e\u5f0f\u63d0\u793a\u6216\u6a21\u5757\u5316\u7f16\u6392\uff0c\u5b9e\u73b0\u4e86\"\u5c0f\u6a21\u578b\u3001\u5927\u89c6\u89d2\u8986\u76d6\"\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u8303\u5f0f\u5728\u6355\u6349\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u591a\u5143\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4ece\u5355\u4e00\u67e5\u8be2\u751f\u6210\u591a\u6837\u5316\u89c6\u89d2\u56de\u5e94\u7684\u65b9\u6cd5\u3002", "method": "1. \u76f8\u4f3c\u6027\u4f30\u8ba1\u5668\u8bad\u7ec3\uff1a\u5fae\u8c03Sentence Transformer\u7528\u4e8eOverton Pluralism\u4efb\u52a1\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u751f\u6210\u56de\u5e94\u8986\u76d6\u8bc4\u4f30\uff1b2. OP-GRPO\u8bad\u7ec3\uff1a\u5c06\u76f8\u4f3c\u6027\u4f30\u8ba1\u5668\u6574\u5408\u5230\u53cc\u5956\u52b1\u7cfb\u7edf\u4e2d\uff0c\u786e\u4fdd\u771f\u5b9e\u4eba\u7c7b\u89c6\u89d2\u7684\u5e7f\u6cdb\u8986\u76d6\u548c\u6bcf\u4e2a\u89c6\u89d2\u7684\u72ec\u7279\u6027\u3002", "result": "Qwen2.5-3B-Instruct\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u57fa\u51c6\u4e0a\u76f8\u5bf920B GPT-OSS\u57fa\u7ebf\u83b7\u5f9737.4%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u76f8\u5bf9\u6a21\u5757\u5316\u67b6\u6784\u57fa\u7ebf\u83b7\u5f9719.1%\u7684\u6539\u8fdb\uff1b\u4f7f\u7528GPT-4.1\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5668\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "OP-GRPO\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u9690\u5f0fOverton Pluralism\uff0c\u4f7f\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u591a\u5143\u89c6\u89d2\u7684\u56de\u5e94\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u89c4\u6a21\u8f83\u5c0f\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5e7f\u6cdb\u7684\u89c6\u89d2\u8986\u76d6\u3002"}}
{"id": "2602.20696", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20696", "abs": "https://arxiv.org/abs/2602.20696", "authors": ["Baolong Bi", "Yuyao Ge", "Shenghua Liu", "Yuchen He", "Siqian Tong", "Lizhe Chen", "Lingrui Mei", "Zehao Li", "Yiwei Wang", "Yujun Cai", "Ming-Hsuan Yang", "Xueqi Cheng"], "title": "PromptCD: Test-Time Behavior Enhancement via Polarity-Prompt Contrastive Decoding", "comment": null, "summary": "Reliable AI systems require large language models (LLMs) to exhibit behaviors aligned with human preferences and values. However, most existing alignment approaches operate at training time and rely on additional high-quality data, incurring significant computational and annotation costs. While recent work has shown that contrastive decoding can leverage a model's internal distributions to improve specific capabilities, its applicability remains limited to narrow behavioral scopes and scenarios. In this work, we introduce Polarity-Prompt Contrastive Decoding (PromptCD), a test-time behavior control method that generalizes contrastive decoding to broader enhancement settings. PromptCD constructs paired positive and negative guiding prompts for a target behavior and contrasts model responses-specifically token-level probability distributions in LLMs and visual attention patterns in VLMs-to reinforce desirable outcomes. This formulation extends contrastive decoding to a wide range of enhancement objectives and is applicable to both LLMs and Vision-Language Models (VLMs) without additional training. For LLMs, experiments on the \"3H\" alignment objectives (helpfulness, honesty, and harmlessness) demonstrate consistent and substantial improvements, indicating that post-trained models can achieve meaningful self-enhancement purely at test time. For VLMs, we further analyze contrastive effects on visual attention, showing that PromptCD significantly improves VQA performance by reinforcing behavior-consistent visual grounding. Collectively, these results highlight PromptCD as a simple, general, and cost-efficient strategy for reliable behavior control across modalities.", "AI": {"tldr": "\u63d0\u51faPromptCD\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u6b63\u8d1f\u5f15\u5bfc\u63d0\u793a\u5bf9\u6bd4\u6a21\u578b\u54cd\u5e94\uff0c\u5b9e\u73b0\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u884c\u4e3a\u63a7\u5236", "motivation": "\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u5927\u591a\u9700\u8981\u8bad\u7ec3\u65f6\u64cd\u4f5c\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u8ba1\u7b97\u548c\u6807\u6ce8\u6210\u672c\u9ad8\uff1b\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\u9002\u7528\u8303\u56f4\u6709\u9650\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5e7f\u6cdb\u7684\u884c\u4e3a\u63a7\u5236\u573a\u666f", "method": "\u63d0\u51faPolarity-Prompt Contrastive Decoding (PromptCD)\uff1a\u4e3a\u76ee\u6807\u884c\u4e3a\u6784\u5efa\u6b63\u8d1f\u5f15\u5bfc\u63d0\u793a\u5bf9\uff0c\u5bf9\u6bd4\u6a21\u578b\u54cd\u5e94\uff08LLMs\u4e2d\u7684token\u7ea7\u6982\u7387\u5206\u5e03\u548cVLMs\u4e2d\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u6a21\u5f0f\uff09\uff0c\u5f3a\u5316\u671f\u671b\u7ed3\u679c", "result": "\u5728LLMs\u7684\"3H\"\u5bf9\u9f50\u76ee\u6807\u4e0a\u53d6\u5f97\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6539\u8fdb\uff1b\u5728VLMs\u4e2d\u663e\u8457\u63d0\u5347VQA\u6027\u80fd\uff0c\u901a\u8fc7\u5f3a\u5316\u884c\u4e3a\u4e00\u81f4\u7684\u89c6\u89c9\u57fa\u7840", "conclusion": "PromptCD\u662f\u4e00\u79cd\u7b80\u5355\u3001\u901a\u7528\u4e14\u6210\u672c\u9ad8\u6548\u7684\u7b56\u7565\uff0c\u53ef\u5728\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8de8\u6a21\u6001\u7684\u53ef\u9760\u884c\u4e3a\u63a7\u5236"}}
{"id": "2602.20816", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20816", "abs": "https://arxiv.org/abs/2602.20816", "authors": ["Sayantan Dasgupta", "Trevor Cohn", "Timothy Baldwin"], "title": "Don't Ignore the Tail: Decoupling top-K Probabilities for Efficient Language Model Distillation", "comment": null, "summary": "The core learning signal used in language model distillation is the standard Kullback-Leibler (KL) divergence between the student and teacher distributions. Traditional KL divergence tends to be dominated by the next tokens with the highest probabilities, i.e., the teacher's modes, thereby diminishing the influence of less probable yet potentially informative components of the output distribution. We propose a new tail-aware divergence that decouples the contribution of the teacher model's top-K predicted probabilities from that of lower-probability predictions, while maintaining the same computational profile as the KL Divergence. Our decoupled approach reduces the impact of the teacher modes and, consequently, increases the contribution of the tail of the distribution. Experimental results demonstrate that our modified distillation method yields competitive performance in both pre-training and supervised distillation of decoder models across various datasets. Furthermore, the distillation process is efficient and can be performed with a modest academic budget for large datasets, eliminating the need for industry-scale computing.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c3e\u90e8\u611f\u77e5\u7684KL\u6563\u5ea6\u53d8\u4f53\uff0c\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u84b8\u998f\uff0c\u901a\u8fc7\u89e3\u8026\u6559\u5e08\u6a21\u578b\u524dK\u4e2a\u9ad8\u6982\u7387\u9884\u6d4b\u4e0e\u4f4e\u6982\u7387\u9884\u6d4b\u7684\u8d21\u732e\uff0c\u51cf\u5c11\u6559\u5e08\u4e3b\u5bfc\u6a21\u5f0f\u7684\u5f71\u54cd\uff0c\u589e\u5f3a\u5206\u5e03\u5c3e\u90e8\u4fe1\u606f\u7684\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edfKL\u6563\u5ea6\u5728\u8bed\u8a00\u6a21\u578b\u84b8\u998f\u4e2d\u4e3b\u8981\u53d7\u6559\u5e08\u6a21\u578b\u6700\u9ad8\u6982\u7387\u7684token\uff08\u6a21\u5f0f\uff09\u4e3b\u5bfc\uff0c\u524a\u5f31\u4e86\u4f4e\u6982\u7387\u4f46\u53ef\u80fd\u4fe1\u606f\u4e30\u5bcc\u7684\u5206\u5e03\u5c3e\u90e8\u6210\u5206\u7684\u5f71\u54cd\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u66f4\u5168\u9762\u5730\u5229\u7528\u6559\u5e08\u5206\u5e03\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u5c3e\u90e8\u611f\u77e5\u6563\u5ea6\uff0c\u5c06\u6559\u5e08\u6a21\u578b\u7684\u524dK\u4e2a\u6700\u9ad8\u6982\u7387\u9884\u6d4b\u4e0e\u4f4e\u6982\u7387\u9884\u6d4b\u89e3\u8026\uff0c\u4fdd\u6301\u4e0eKL\u6563\u5ea6\u76f8\u540c\u7684\u8ba1\u7b97\u7279\u6027\uff0c\u4f46\u51cf\u5c11\u6559\u5e08\u6a21\u5f0f\u7684\u4e3b\u5bfc\u4f5c\u7528\uff0c\u589e\u5f3a\u5206\u5e03\u5c3e\u90e8\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6539\u8fdb\u7684\u84b8\u998f\u65b9\u6cd5\u5728\u89e3\u7801\u5668\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u84b8\u998f\u4e2d\uff0c\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u90fd\u80fd\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u4e14\u84b8\u998f\u8fc7\u7a0b\u9ad8\u6548\uff0c\u53ef\u7528\u9002\u5ea6\u7684\u5b66\u672f\u9884\u7b97\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u3002", "conclusion": "\u5c3e\u90e8\u611f\u77e5\u6563\u5ea6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8bed\u8a00\u6a21\u578b\u84b8\u998f\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u5229\u7528\u6559\u5e08\u5206\u5e03\u7684\u5b8c\u6574\u4fe1\u606f\uff0c\u51cf\u5c11\u6a21\u5f0f\u4e3b\u5bfc\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u5b66\u672f\u73af\u5883\u5e94\u7528\u3002"}}
{"id": "2602.20706", "categories": ["cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.20706", "abs": "https://arxiv.org/abs/2602.20706", "authors": ["Julien Dallot", "Yuval Emek", "Yuval Gil", "Maciej Pacut", "Stefan Schmid"], "title": "Online Algorithms with Unreliable Guidance", "comment": null, "summary": "This paper introduces a new model for ML-augmented online decision making, called online algorithms with unreliable guidance (OAG). This model completely separates between the predictive and algorithmic components, thus offering a single well-defined analysis framework that relies solely on the considered problem. Formulated through the lens of request-answer games, an OAG algorithm receives, with each incoming request, a piece of guidance which is taken from the problem's answer space; ideally, this guidance is the optimal answer for the current request, however with probability $\u03b2$, the guidance is adversarially corrupted. The goal is to develop OAG algorithms that admit good competitiveness when $\u03b2= 0$ (a.k.a. consistency) as well as when $\u03b2= 1$ (a.k.a. robustness); the appealing notion of smoothness, that in most prior work required a dedicated loss function, now arises naturally as $\u03b2$ shifts from $0$ to $1$.\n  We then describe a systematic method, called the drop or trust blindly (DTB) compiler, which transforms any online algorithm into a learning-augmented online algorithm in the OAG model. Given a prediction-oblivious online algorithm, its learning-augmented counterpart produced by applying the DTB compiler either follows the incoming guidance blindly or ignores it altogether and proceeds as the initial algorithm would have; the choice between these two alternatives is based on the outcome of a (biased) coin toss. As our main technical contribution, we prove (rigorously) that although remarkably simple, the class of algorithms produced via the DTB compiler includes algorithms with attractive consistency-robustness guarantees for three classic online problems: for caching and uniform metrical task systems our algorithms are optimal, whereas for bipartite matching (with adversarial arrival order), our algorithm outperforms the state-of-the-art.", "AI": {"tldr": "\u63d0\u51faOAG\u6a21\u578b\u5206\u79bb\u9884\u6d4b\u4e0e\u7b97\u6cd5\u7ec4\u4ef6\uff0c\u901a\u8fc7DTB\u7f16\u8bd1\u5668\u5c06\u5728\u7ebf\u7b97\u6cd5\u8f6c\u5316\u4e3a\u5b66\u4e60\u589e\u5f3a\u7b97\u6cd5\uff0c\u5728\u7f13\u5b58\u3001\u5ea6\u91cf\u4efb\u52a1\u7cfb\u7edf\u548c\u4e8c\u5206\u56fe\u5339\u914d\u95ee\u9898\u4e0a\u83b7\u5f97\u6700\u4f18\u6216\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u4fdd\u8bc1", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u7684\u5728\u7ebf\u51b3\u7b56\u6a21\u578b\u901a\u5e38\u5c06\u9884\u6d4b\u7ec4\u4ef6\u4e0e\u7b97\u6cd5\u7ec4\u4ef6\u7d27\u5bc6\u8026\u5408\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u5b8c\u5168\u5206\u79bb\u9884\u6d4b\u4e0e\u7b97\u6cd5\u7ec4\u4ef6\u7684\u6a21\u578b\uff0c\u63d0\u4f9b\u5355\u4e00\u3001\u660e\u786e\u5b9a\u4e49\u7684\u5206\u6790\u6846\u67b6\uff0c\u4f7f\u5e73\u6ed1\u6027\u6982\u5ff5\u81ea\u7136\u5730\u4ece\u4e00\u81f4\u6027\u8fc7\u6e21\u5230\u9c81\u68d2\u6027", "method": "\u63d0\u51faOAG\u6a21\u578b\uff1a\u5c06\u5728\u7ebf\u51b3\u7b56\u5efa\u6a21\u4e3a\u8bf7\u6c42-\u56de\u7b54\u6e38\u620f\uff0c\u7b97\u6cd5\u63a5\u6536\u6765\u81ea\u95ee\u9898\u7b54\u6848\u7a7a\u95f4\u7684\u6307\u5bfc\u4fe1\u606f\uff08\u53ef\u80fd\u88ab\u5bf9\u6297\u6027\u6c61\u67d3\uff09\u3002\u5f00\u53d1DTB\u7f16\u8bd1\u5668\uff1a\u5c06\u4efb\u4f55\u5728\u7ebf\u7b97\u6cd5\u8f6c\u5316\u4e3a\u5b66\u4e60\u589e\u5f3a\u7b97\u6cd5\uff0c\u901a\u8fc7\u6709\u504f\u786c\u5e01\u51b3\u5b9a\u662f\u76f2\u76ee\u8ddf\u968f\u6307\u5bfc\u8fd8\u662f\u5ffd\u7565\u6307\u5bfc\u6267\u884c\u539f\u59cb\u7b97\u6cd5", "result": "DTB\u7f16\u8bd1\u5668\u751f\u6210\u7684\u7b97\u6cd5\u5728\u4e09\u4e2a\u7ecf\u5178\u5728\u7ebf\u95ee\u9898\u4e0a\u83b7\u5f97\u4f18\u5f02\u6027\u80fd\uff1a\u5bf9\u4e8e\u7f13\u5b58\u548c\u5747\u5300\u5ea6\u91cf\u4efb\u52a1\u7cfb\u7edf\uff0c\u7b97\u6cd5\u8fbe\u5230\u6700\u4f18\uff1b\u5bf9\u4e8e\u4e8c\u5206\u56fe\u5339\u914d\uff08\u5bf9\u6297\u6027\u5230\u8fbe\u987a\u5e8f\uff09\uff0c\u7b97\u6cd5\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5", "conclusion": "OAG\u6a21\u578b\u4e3a\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u7684\u5728\u7ebf\u51b3\u7b56\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\uff0cDTB\u7f16\u8bd1\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u65b9\u6cd5\u5c06\u4f20\u7edf\u5728\u7ebf\u7b97\u6cd5\u8f6c\u5316\u4e3a\u5b66\u4e60\u589e\u5f3a\u7b97\u6cd5\uff0c\u5728\u591a\u4e2a\u91cd\u8981\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u4e00\u81f4\u6027-\u9c81\u68d2\u6027\u6743\u8861"}}
{"id": "2602.20859", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20859", "abs": "https://arxiv.org/abs/2602.20859", "authors": ["Zirui He", "Huopu Zhang", "Yanguang Liu", "Sirui Wu", "Mengnan Du"], "title": "FinAnchor: Aligned Multi-Model Representations for Financial Prediction", "comment": "11 pages, 4 figures, 5 tables", "summary": "Financial prediction from long documents involves significant challenges, as actionable signals are often sparse and obscured by noise, and the optimal LLM for generating embeddings varies across tasks and time periods. In this paper, we propose FinAnchor(Financial Anchored Representations), a lightweight framework that integrates embeddings from multiple LLMs without fine-tuning the underlying models. FinAnchor addresses the incompatibility of feature spaces by selecting an anchor embedding space and learning linear mappings to align representations from other models into this anchor. These aligned features are then aggregated to form a unified representation for downstream prediction. Across multiple financial NLP tasks, FinAnchor consistently outperforms strong single-model baselines and standard ensemble methods, demonstrating the effectiveness of anchoring heterogeneous representations for robust financial prediction.", "AI": {"tldr": "FinAnchor\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u951a\u5b9a\u5f02\u6784LLM\u5d4c\u5165\u8868\u793a\u6765\u63d0\u5347\u91d1\u878d\u6587\u6863\u9884\u6d4b\u6027\u80fd", "motivation": "\u91d1\u878d\u957f\u6587\u6863\u9884\u6d4b\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1\uff09\u6709\u6548\u4fe1\u53f7\u7a00\u758f\u4e14\u88ab\u566a\u58f0\u63a9\u76d6\uff1b2\uff09\u4e0d\u540c\u4efb\u52a1\u548c\u65f6\u95f4\u6bb5\u4e0b\u6700\u4f18\u7684LLM\u5d4c\u5165\u6a21\u578b\u5404\u4e0d\u76f8\u540c\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u6216\u7b80\u5355\u96c6\u6210\uff0c\u65e0\u6cd5\u6709\u6548\u6574\u5408\u5f02\u6784\u5d4c\u5165\u7a7a\u95f4\u7684\u4fe1\u606f\u3002", "method": "FinAnchor\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6b65\u9aa4\uff1a1\uff09\u9009\u62e9\u4e00\u4e2a\u951a\u5b9a\u5d4c\u5165\u7a7a\u95f4\uff1b2\uff09\u5b66\u4e60\u7ebf\u6027\u6620\u5c04\u5c06\u5176\u4ed6\u6a21\u578b\u7684\u8868\u793a\u5bf9\u9f50\u5230\u8be5\u951a\u5b9a\u7a7a\u95f4\uff1b3\uff09\u805a\u5408\u5bf9\u9f50\u540e\u7684\u7279\u5f81\u5f62\u6210\u7edf\u4e00\u8868\u793a\u7528\u4e8e\u4e0b\u6e38\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5fae\u8c03\u5e95\u5c42LLM\u6a21\u578b\uff0c\u4fdd\u6301\u8f7b\u91cf\u7ea7\u7279\u6027\u3002", "result": "\u5728\u591a\u4e2a\u91d1\u878dNLP\u4efb\u52a1\u4e0a\uff0cFinAnchor consistently outperforms strong single-model baselines and standard ensemble methods\uff0c\u8bc1\u660e\u4e86\u951a\u5b9a\u5f02\u6784\u8868\u793a\u5bf9\u7a33\u5065\u91d1\u878d\u9884\u6d4b\u7684\u6709\u6548\u6027\u3002", "conclusion": "FinAnchor\u901a\u8fc7\u951a\u5b9a\u548c\u6574\u5408\u591a\u4e2aLLM\u7684\u5f02\u6784\u5d4c\u5165\u8868\u793a\uff0c\u6709\u6548\u63d0\u5347\u4e86\u91d1\u878d\u957f\u6587\u6863\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u91d1\u878d\u9886\u57df\u4fe1\u53f7\u7a00\u758f\u548c\u6a21\u578b\u9009\u62e9\u96be\u9898\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.20892", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20892", "abs": "https://arxiv.org/abs/2602.20892", "authors": ["Seyed Himan Ghaderi", "Saeed Sarbazi Azad", "Mohammad Mehdi Jaziriyan", "Ahmad Akbari"], "title": "Exa-PSD: a new Persian sentiment analysis dataset on Twitter", "comment": "This is the original submitted (preprint) version of a paper published in Language Resources and Evaluation. The final published version is available at Springer via DOI: https://doi.org/10.1007/s10579-025-09886-5", "summary": "Today, Social networks such as Twitter are the most widely used platforms for communication of people. Analyzing this data has useful information to recognize the opinion of people in tweets. Sentiment analysis plays a vital role in NLP, which identifies the opinion of the individuals about a specific topic. Natural language processing in Persian has many challenges despite the adventure of strong language models. The datasets available in Persian are generally in special topics such as products, foods, hotels, etc while users may use ironies, colloquial phrases in social media To overcome these challenges, there is a necessity for having a dataset of Persian sentiment analysis on Twitter. In this paper, we introduce the Exa sentiment analysis Persian dataset, which is collected from Persian tweets. This dataset contains 12,000 tweets, annotated by 5 native Persian taggers. The aforementioned data is labeled in 3 classes: positive, neutral and negative. We present the characteristics and statistics of this dataset and use the pre-trained Pars Bert and Roberta as the base model to evaluate this dataset. Our evaluation reached a 79.87 Macro F-score, which shows the model and data can be adequately valuable for a sentiment analysis system.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86Exa\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\uff0c\u5305\u542b12,000\u6761\u6ce2\u65af\u8bed\u63a8\u6587\uff0c\u6807\u6ce8\u4e3a\u79ef\u6781\u3001\u4e2d\u6027\u548c\u6d88\u6781\u4e09\u7c7b\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8bc4\u4f30\u83b7\u5f9779.87\u7684\u5b8f\u5e73\u5747F1\u5206\u6570\u3002", "motivation": "\u6ce2\u65af\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u6570\u636e\u96c6\u591a\u96c6\u4e2d\u4e8e\u7279\u5b9a\u9886\u57df\uff08\u5982\u4ea7\u54c1\u3001\u98df\u54c1\u3001\u9152\u5e97\uff09\uff0c\u800c\u793e\u4ea4\u5a92\u4f53\u4e2d\u7528\u6237\u5e38\u4f7f\u7528\u8bbd\u523a\u3001\u53e3\u8bed\u5316\u8868\u8fbe\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u6ce2\u65af\u8bed\u63a8\u6587\u7684\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\u3002", "method": "\u4ece\u6ce2\u65af\u8bed\u63a8\u6587\u6536\u96c6\u6570\u636e\uff0c\u6784\u5efa\u5305\u542b12,000\u6761\u63a8\u6587\u7684\u6570\u636e\u96c6\uff0c\u75315\u540d\u6ce2\u65af\u8bed\u6bcd\u8bed\u6807\u6ce8\u8005\u8fdb\u884c\u6807\u6ce8\uff0c\u5206\u4e3a\u79ef\u6781\u3001\u4e2d\u6027\u548c\u6d88\u6781\u4e09\u7c7b\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684Pars Bert\u548cRoberta\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6570\u636e\u96c6\u5305\u542b12,000\u6761\u6807\u6ce8\u63a8\u6587\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8bc4\u4f30\u83b7\u5f9779.87\u7684\u5b8f\u5e73\u5747F1\u5206\u6570\uff0c\u8868\u660e\u8be5\u6570\u636e\u96c6\u548c\u6a21\u578b\u5bf9\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u6790\u7cfb\u7edf\u5177\u6709\u8db3\u591f\u4ef7\u503c\u3002", "conclusion": "Exa\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\u586b\u8865\u4e86\u6ce2\u65af\u8bed\u793e\u4ea4\u5a92\u4f53\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u4e3a\u6ce2\u65af\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u4e86\u5176\u5728\u60c5\u611f\u5206\u6790\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.20710", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20710", "abs": "https://arxiv.org/abs/2602.20710", "authors": ["Peter Hase", "Christopher Potts"], "title": "Counterfactual Simulation Training for Chain-of-Thought Faithfulness", "comment": null, "summary": "Inspecting Chain-of-Thought reasoning is among the most common means of understanding why an LLM produced its output. But well-known problems with CoT faithfulness severely limit what insights can be gained from this practice. In this paper, we introduce a training method called Counterfactual Simulation Training (CST), which aims to improve CoT faithfulness by rewarding CoTs that enable a simulator to accurately predict a model's outputs over counterfactual inputs. We apply CST in two settings: (1) CoT monitoring with cue-based counterfactuals, to detect when models rely on spurious features, reward hack, or are sycophantic, and (2) counterfactual simulation over generic model-based counterfactuals, to encourage models to produce more faithful, generalizable reasoning in the CoT. Experiments with models up to 235B parameters show that CST can substantially improve monitor accuracy on cue-based counterfactuals (by 35 accuracy points) as well as simulatability over generic counterfactuals (by 2 points). We further show that: (1) CST outperforms prompting baselines, (2) rewriting unfaithful CoTs with an LLM is 5x more efficient than RL alone, (3) faithfulness improvements do not generalize to dissuading cues (as opposed to persuading cues), and (4) larger models do not show more faithful CoT out of the box, but they do benefit more from CST. These results suggest that CST can improve CoT faithfulness in general, with promising applications for CoT monitoring. Code for experiments in this paper is available at https://github.com/peterbhase/counterfactual-simulation-training", "code_url": "https://github.com/peterbhase/counterfactual-simulation-trainin", "AI": {"tldr": "\u63d0\u51faCounterfactual Simulation Training (CST)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5956\u52b1\u80fd\u5728\u53cd\u4e8b\u5b9e\u8f93\u5165\u4e0b\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u8f93\u51fa\u7684\u601d\u7ef4\u94fe\uff0c\u63d0\u9ad8LLM\u601d\u7ef4\u94fe\u7684\u5fe0\u5b9e\u6027\u3002", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u662f\u7406\u89e3LLM\u8f93\u51fa\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u4f46\u601d\u7ef4\u94fe\u7684\u5fe0\u5b9e\u6027\u95ee\u9898\u4e25\u91cd\u9650\u5236\u4e86\u4ece\u4e2d\u83b7\u5f97\u7684\u6d1e\u5bdf\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u601d\u7ef4\u94fe\u4e0d\u5fe0\u5b9e\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u601d\u7ef4\u94fe\u7684\u5fe0\u5b9e\u6027\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u76d1\u63a7\u6a21\u578b\u884c\u4e3a\u3002", "method": "\u63d0\u51faCounterfactual Simulation Training (CST)\u8bad\u7ec3\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u7ebf\u7d22\u7684\u53cd\u4e8b\u5b9e\u601d\u7ef4\u94fe\u76d1\u63a7\uff0c\u68c0\u6d4b\u6a21\u578b\u662f\u5426\u4f9d\u8d56\u865a\u5047\u7279\u5f81\u3001\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u6216\u5949\u627f\uff1b2) \u57fa\u4e8e\u901a\u7528\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u6a21\u62df\uff0c\u9f13\u52b1\u6a21\u578b\u5728\u601d\u7ef4\u94fe\u4e2d\u4ea7\u751f\u66f4\u5fe0\u5b9e\u3001\u53ef\u6cdb\u5316\u7684\u63a8\u7406\u3002\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u80fd\u5728\u53cd\u4e8b\u5b9e\u8f93\u5165\u4e0b\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u8f93\u51fa\u7684\u601d\u7ef4\u94fe\u3002", "result": "\u5728\u9ad8\u8fbe235B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u5b9e\u9a8c\u663e\u793a\uff1aCST\u663e\u8457\u63d0\u9ad8\u57fa\u4e8e\u7ebf\u7d22\u53cd\u4e8b\u5b9e\u7684\u76d1\u63a7\u51c6\u786e\u7387\uff08\u63d0\u534735\u4e2a\u51c6\u786e\u70b9\uff09\u548c\u901a\u7528\u53cd\u4e8b\u5b9e\u7684\u53ef\u6a21\u62df\u6027\uff08\u63d0\u53472\u70b9\uff09\u3002CST\u4f18\u4e8e\u63d0\u793a\u57fa\u7ebf\uff0c\u7528LLM\u91cd\u5199\u4e0d\u5fe0\u5b9e\u601d\u7ef4\u94fe\u6bd4\u5355\u72ec\u4f7f\u7528RL\u6548\u7387\u9ad85\u500d\uff0c\u5fe0\u5b9e\u6027\u6539\u8fdb\u4e0d\u6cdb\u5316\u5230\u529d\u963b\u7ebf\u7d22\uff0c\u66f4\u5927\u6a21\u578b\u4e0d\u4f1a\u81ea\u52a8\u4ea7\u751f\u66f4\u5fe0\u5b9e\u601d\u7ef4\u94fe\u4f46\u80fd\u4eceCST\u4e2d\u83b7\u76ca\u66f4\u591a\u3002", "conclusion": "CST\u80fd\u666e\u904d\u63d0\u9ad8\u601d\u7ef4\u94fe\u7684\u5fe0\u5b9e\u6027\uff0c\u5728\u601d\u7ef4\u94fe\u76d1\u63a7\u65b9\u9762\u6709\u826f\u597d\u5e94\u7528\u524d\u666f\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.20945", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20945", "abs": "https://arxiv.org/abs/2602.20945", "authors": ["Taiqiang Wu", "Zenan Zu", "Bo Zhou", "Ngai Wong"], "title": "The Art of Efficient Reasoning: Data, Reward, and Optimization", "comment": "Tech Report, Insights on Efficient Reasoning via Reward Shaping", "summary": "Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76LLMs\u9ad8\u6548\u63a8\u7406\u673a\u5236\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u53d1\u73b0\u8bad\u7ec3\u76f8\u5bf9\u7b80\u5355\u63d0\u793a\u53ef\u907f\u514d\u957f\u5ea6\u5d29\u6e83\uff0c\u5e76\u5c06\u957f\u5ea6\u504f\u5dee\u8de8\u9886\u57df\u6cdb\u5316\uff0c\u5728Qwen3\u7cfb\u5217\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u9c81\u68d2\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u6269\u5c55\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u83b7\u5f97\u6301\u7eed\u6536\u76ca\uff0c\u4f46\u9762\u4e34\u6c89\u91cd\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u9ad8\u6548\u63a8\u7406\u65e8\u5728\u6fc0\u52b1\u77ed\u800c\u51c6\u786e\u7684\u601d\u7ef4\u8f68\u8ff9\uff0c\u901a\u5e38\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8fdb\u884c\u5956\u52b1\u5851\u9020\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u7814\u7a76LLMs\u9ad8\u6548\u63a8\u7406\u7684\u673a\u5236\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u534f\u8bae\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u9a8c\uff08\u7ea620\u4e07GPU\u5c0f\u65f6\uff09\uff0c\u89e3\u6784\u8bad\u7ec3\u63d0\u793a\u548crollouts\u3001\u5956\u52b1\u5851\u9020\u548c\u4f18\u5316\u7b56\u7565\u3002\u63d0\u51fa\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u5305\u62ec\u57fa\u4e8e\u6b63\u786e\u6027\u7684\u957f\u5ea6\u5206\u5e03\u548c\u4ece2k\u523032k\u7684\u5e7f\u6cdbtoken\u9884\u7b97\u8303\u56f4\u5185\u7684\u6027\u80fd\u3002\u5728Qwen3\u7cfb\u5217\u6a21\u578b\uff080.6B\u523030B\uff09\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u8bad\u7ec3\u8fc7\u7a0b\u9075\u5faa\u4e24\u9636\u6bb5\u8303\u5f0f\uff1a\u957f\u5ea6\u9002\u5e94\u548c\u63a8\u7406\u7cbe\u70bc\u3002\u5173\u952e\u53d1\u73b0\u662f\u8bad\u7ec3\u76f8\u5bf9\u7b80\u5355\u7684\u63d0\u793a\u53ef\u4ee5\u786e\u4fdd\u6b63\u5956\u52b1\u4fe1\u53f7\u7684\u5bc6\u5ea6\uff0c\u4ece\u800c\u907f\u514d\u957f\u5ea6\u5d29\u6e83\u3002\u540c\u65f6\uff0c\u5b66\u4e60\u5230\u7684\u957f\u5ea6\u504f\u5dee\u53ef\u4ee5\u8de8\u9886\u57df\u6cdb\u5316\u3002\u6240\u6709\u53d1\u73b0\u90fd\u8f6c\u5316\u4e3a\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u5b9e\u8df5\u6307\u5357\u3002", "conclusion": "\u8bba\u6587\u7cfb\u7edf\u63ed\u793a\u4e86LLMs\u9ad8\u6548\u63a8\u7406\u7684\u673a\u5236\uff0c\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bad\u7ec3\u6307\u5357\uff0c\u5e76\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5f00\u53d1\u8ba1\u7b97\u9ad8\u6548\u7684\u63a8\u7406\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.20722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20722", "abs": "https://arxiv.org/abs/2602.20722", "authors": ["Xu Wan", "Yansheng Wang", "Wenqi Huang", "Mingyang Sun"], "title": "Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning", "comment": null, "summary": "Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.", "AI": {"tldr": "BAPO\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u7684\u79bb\u7b56\u7565RLVR\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u8bad\u7ec3\u6279\u6b21\u548c\u91cd\u7528\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRLVR\u6846\u67b6\u7684\u7ecf\u9a8c\u6d6a\u8d39\u548c\u5956\u52b1\u540c\u8d28\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7b56\u7565\u7684RLVR\u6846\u67b6\u5b58\u5728\u7ecf\u9a8c\u6d6a\u8d39\u548c\u5956\u52b1\u540c\u8d28\u5316\u95ee\u9898\uff0c\u8fd9\u76f4\u63a5\u963b\u788d\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u4e2d\u56f0\u96be\u6837\u672c\u7684\u5b66\u4e60\u6548\u7387\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faBatch Adaptation Policy Optimization (BAPO)\uff0c\u8fd9\u662f\u4e00\u79cd\u79bb\u7b56\u7565RLVR\u6846\u67b6\u3002\u5b83\u901a\u8fc7\u91cd\u65b0\u8bc4\u4f30\u5386\u53f2\u56f0\u96be\u6837\u672c\u5e76\u91cd\u7528\u9ad8\u8d28\u91cf\u6837\u672c\u6765\u52a8\u6001\u9009\u62e9\u8bad\u7ec3\u6279\u6b21\uff0c\u540c\u65f6\u4fdd\u6301\u7b56\u7565\u6539\u8fdb\u7684\u4e0b\u754c\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBAPO\u5728\u6570\u5b66\u3001\u89c4\u5212\u548c\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u5e73\u5747\u6bd4GRPO\u63d0\u5347\u4e8612.5%\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0cBAPO\u6210\u529f\u89e3\u51b3\u4e86\u57fa\u7840\u6a21\u578b\u6301\u7eed\u65e0\u6cd5\u89e3\u51b3\u768440.7%\u7684\u95ee\u9898\u3002", "conclusion": "BAPO\u901a\u8fc7\u6539\u8fdb\u6570\u636e\u6548\u7387\u548c\u6837\u672c\u9009\u62e9\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfRLVR\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u540e\u8bad\u7ec3\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u56f0\u96be\u6837\u672c\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.20966", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20966", "abs": "https://arxiv.org/abs/2602.20966", "authors": ["Paola Merlo", "Chunyang Jiang", "Giuseppe Samo", "Vivi Nastase"], "title": "Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models", "comment": "Under review, 46 pages, 5 tables, 28 figures", "summary": "This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice problems, structured at multiple levels: within each sentence, across the input sequence, within each candidate answer. Because of their rich structure, these curated, but naturalistic datasets are key to answer some core questions about current large language models abilities: do LLMs detect linguistic objects and their properties? Do they detect and use systematic patterns across sentences? Are they more prone to linguistic or reasoning errors, and how do these interact?\n  We show that BLMs, while challenging, can be solved at good levels of performance, in more than one language, with simple baseline models or, at better performance levels, with more tailored models. We show that their representations contain the grammatical objects and attributes relevant to solve a linguistic task. We also show that these solutions are reached by detecting systematic patterns across sentences.\n  The paper supports the point of view that curated, structured datasets support multi-faceted investigations of properties of language and large language models. Because they present a curated, articulated structure, because they comprise both learning contexts and expected answers, and because they are partly built by hand, BLMs fall in the category of datasets that can support explainability investigations, and be useful to ask why large language models behave the way they do.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u667a\u529b\u6d4b\u8bd5\u542f\u53d1\u7684\u65b0\u578b\u8bed\u8a00\u4efb\u52a1\u2014\u2014Blackbird Language Matrices (BLM)\uff0c\u6784\u5efa\u4e86\u7ed3\u6784\u5316\u591a\u5c42\u7ea7\u7684\u591a\u9009\u9898\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u8bed\u8a00\u5bf9\u8c61\u3001\u5229\u7528\u7cfb\u7edf\u6027\u6a21\u5f0f\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u9700\u8981\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6765\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6838\u5fc3\u80fd\u529b\uff1a\u80fd\u5426\u68c0\u6d4b\u8bed\u8a00\u5bf9\u8c61\u53ca\u5176\u5c5e\u6027\uff1f\u80fd\u5426\u8bc6\u522b\u548c\u4f7f\u7528\u8de8\u53e5\u5b50\u7684\u7cfb\u7edf\u6027\u6a21\u5f0f\uff1f\u8bed\u8a00\u9519\u8bef\u548c\u63a8\u7406\u9519\u8bef\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\uff1f\u4f20\u7edf\u6570\u636e\u96c6\u96be\u4ee5\u652f\u6301\u8fd9\u79cd\u591a\u65b9\u9762\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002", "method": "\u521b\u5efaBLM\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u5c42\u7ea7\u7ed3\u6784\uff1a\u53e5\u5b50\u5185\u90e8\u3001\u8f93\u5165\u5e8f\u5217\u4e4b\u95f4\u3001\u5019\u9009\u7b54\u6848\u5185\u90e8\u3002\u6570\u636e\u96c6\u7ecf\u8fc7\u4eba\u5de5\u7cbe\u5fc3\u6784\u5efa\uff0c\u5305\u542b\u5b66\u4e60\u4e0a\u4e0b\u6587\u548c\u9884\u671f\u7b54\u6848\u3002\u4f7f\u7528\u7b80\u5355\u57fa\u7ebf\u6a21\u578b\u548c\u5b9a\u5236\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u5173\u6ce8\u5206\u5757\u548c\u7cfb\u7edf\u6027\u5b9e\u9a8c\u3002", "result": "BLM\u4efb\u52a1\u867d\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u4f46\u53ef\u4ee5\u5728\u591a\u79cd\u8bed\u8a00\u4e2d\u4ee5\u826f\u597d\u6027\u80fd\u89e3\u51b3\u3002\u7b80\u5355\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u5c1a\u53ef\uff0c\u5b9a\u5236\u6a21\u578b\u6027\u80fd\u66f4\u4f18\u3002\u6a21\u578b\u8868\u793a\u4e2d\u5305\u542b\u89e3\u51b3\u8bed\u8a00\u4efb\u52a1\u6240\u9700\u7684\u8bed\u6cd5\u5bf9\u8c61\u548c\u5c5e\u6027\u3002\u89e3\u51b3\u65b9\u6848\u901a\u8fc7\u68c0\u6d4b\u8de8\u53e5\u5b50\u7684\u7cfb\u7edf\u6027\u6a21\u5f0f\u5b9e\u73b0\u3002", "conclusion": "\u7cbe\u5fc3\u6784\u5efa\u7684\u7ed3\u6784\u5316\u6570\u636e\u96c6\u652f\u6301\u5bf9\u8bed\u8a00\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5c5e\u6027\u7684\u591a\u65b9\u9762\u7814\u7a76\u3002BLM\u6570\u636e\u96c6\u56e0\u5176\u7ed3\u6784\u5316\u3001\u5305\u542b\u5b66\u4e60\u4e0a\u4e0b\u6587\u548c\u7b54\u6848\u3001\u90e8\u5206\u4eba\u5de5\u6784\u5efa\u7684\u7279\u70b9\uff0c\u5c5e\u4e8e\u652f\u6301\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u7c7b\u522b\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\u673a\u5236\u3002"}}
{"id": "2602.20973", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20973", "abs": "https://arxiv.org/abs/2602.20973", "authors": ["Yuliang Ji", "Fuchen Shen", "Jian Wu", "Qiujie Xie", "Yue Zhang"], "title": "Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving", "comment": null, "summary": "To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by contradiction and proof by cases, which are crucial for investigating LLMs' reasoning abilities. To address this limitation, we first introduce a novel first-order logic (FOL) dataset named PC-FOL, annotated by professional mathematicians, focusing on case-based reasoning problems. All instances in this dataset are equipped with a manually written natural language proof, clearly distinguishing it from conventional linear reasoning datasets. Our experimental results over leading LLMs demonstrate a substantial performance gap between linear reasoning and case-based reasoning problems. To further investigate this phenomenon, we provide a theoretical analysis grounded in graphical model, which provides an explanation for the observed disparity between the two types of reasoning problems. We hope this work can reveal the core challenges in the field of automated natural language mathematical proof generation, paving the way for future research.", "AI": {"tldr": "PC-FOL\u6570\u636e\u96c6\uff1a\u4e13\u6ce8\u4e8e\u6848\u4f8b\u63a8\u7406\u7684\u4e00\u9636\u903b\u8f91\u6570\u636e\u96c6\uff0c\u63ed\u793aLLMs\u5728\u7ebf\u6027\u63a8\u7406\u4e0e\u6848\u4f8b\u63a8\u7406\u95f4\u7684\u6027\u80fd\u5dee\u8ddd", "motivation": "\u73b0\u6709\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e3b\u8981\u5173\u6ce8\u7ebf\u6027\u63a8\u7406\uff0c\u5ffd\u89c6\u4e86\u53cd\u8bc1\u6cd5\u3001\u5206\u60c5\u51b5\u8bc1\u660e\u7b49\u5176\u4ed6\u91cd\u8981\u63a8\u7406\u5f62\u5f0f\uff0c\u8fd9\u4e9b\u5bf9\u7814\u7a76LLMs\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981", "method": "\u5f15\u5165\u7531\u4e13\u4e1a\u6570\u5b66\u5bb6\u6807\u6ce8\u7684PC-FOL\u4e00\u9636\u903b\u8f91\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u6848\u4f8b\u63a8\u7406\u95ee\u9898\uff0c\u6240\u6709\u5b9e\u4f8b\u90fd\u914d\u5907\u624b\u5199\u7684\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\uff1b\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e3b\u6d41LLMs\u6027\u80fd\uff0c\u5e76\u4f7f\u7528\u56fe\u6a21\u578b\u8fdb\u884c\u7406\u8bba\u5206\u6790", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e3b\u6d41LLMs\u5728\u7ebf\u6027\u63a8\u7406\u548c\u6848\u4f8b\u63a8\u7406\u95ee\u9898\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff1b\u56fe\u6a21\u578b\u7406\u8bba\u5206\u6790\u4e3a\u8fd9\u79cd\u5dee\u5f02\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca", "conclusion": "PC-FOL\u6570\u636e\u96c6\u63ed\u793a\u4e86\u81ea\u52a8\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u8bc1\u660e\u751f\u6210\u9886\u57df\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u94fa\u5e73\u9053\u8def\uff0c\u5f3a\u8c03\u4e86\u6848\u4f8b\u63a8\u7406\u5728\u8bc4\u4f30LLMs\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e2d\u7684\u91cd\u8981\u6027"}}
{"id": "2602.20728", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20728", "abs": "https://arxiv.org/abs/2602.20728", "authors": ["Chenyang Zhao", "Vinny Cahill", "Ivana Dusparic"], "title": "Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback", "comment": null, "summary": "Reward design has been one of the central challenges for real world reinforcement learning (RL) deployment, especially in settings with multiple objectives. Preference-based RL offers an appealing alternative by learning from human preferences over pairs of behavioural outcomes. More recently, RL from AI feedback (RLAIF) has demonstrated that large language models (LLMs) can generate preference labels at scale, mitigating the reliance on human annotators. However, existing RLAIF work typically focuses only on single-objective tasks, leaving the open question of how RLAIF handles systems that involve multiple objectives. In such systems trade-offs among conflicting objectives are difficult to specify, and policies risk collapsing into optimizing for a dominant goal. In this paper, we explore the extension of the RLAIF paradigm to multi-objective self-adaptive systems. We show that multi-objective RLAIF can produce policies that yield balanced trade-offs reflecting different user priorities without laborious reward engineering. We argue that integrating RLAIF into multi-objective RL offers a scalable path toward user-aligned policy learning in domains with inherently conflicting objectives.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u57fa\u4e8eAI\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLAIF\uff09\u6269\u5c55\u5230\u591a\u76ee\u6807\u81ea\u9002\u5e94\u6027\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u504f\u597d\u6807\u7b7e\u6765\u5e73\u8861\u51b2\u7a81\u76ee\u6807\uff0c\u907f\u514d\u7e41\u7410\u7684\u5956\u52b1\u5de5\u7a0b\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u5f3a\u5316\u5b66\u4e60\u90e8\u7f72\u4e2d\u7684\u5956\u52b1\u8bbe\u8ba1\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u591a\u76ee\u6807\u8bbe\u7f6e\u4e2d\u3002\u73b0\u6709\u7684RLAIF\u5de5\u4f5c\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u76ee\u6807\u4efb\u52a1\uff0c\u800c\u591a\u76ee\u6807\u7cfb\u7edf\u4e2d\u51b2\u7a81\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\u96be\u4ee5\u660e\u786e\u6307\u5b9a\uff0c\u7b56\u7565\u5bb9\u6613\u504f\u5411\u4f18\u5316\u4e3b\u5bfc\u76ee\u6807\u3002\u9700\u8981\u63a2\u7d22RLAIF\u5728\u591a\u76ee\u6807\u81ea\u9002\u5e94\u6027\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5c06RLAIF\u8303\u5f0f\u6269\u5c55\u5230\u591a\u76ee\u6807\u81ea\u9002\u5e94\u6027\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u504f\u597d\u6807\u7b7e\u6765\u66ff\u4ee3\u4eba\u5de5\u6807\u6ce8\u3002\u901a\u8fc7AI\u53cd\u9988\u5b66\u4e60\u7528\u6237\u5bf9\u4e0d\u540c\u884c\u4e3a\u7ed3\u679c\u7684\u504f\u597d\uff0c\u4ece\u800c\u5728\u591a\u76ee\u6807\u73af\u5883\u4e2d\u5b9e\u73b0\u5e73\u8861\u7684\u6743\u8861\u3002", "result": "\u591a\u76ee\u6807RLAIF\u80fd\u591f\u4ea7\u751f\u53cd\u6620\u4e0d\u540c\u7528\u6237\u4f18\u5148\u7ea7\u7684\u5e73\u8861\u6743\u8861\u7b56\u7565\uff0c\u65e0\u9700\u7e41\u7410\u7684\u5956\u52b1\u5de5\u7a0b\u3002\u8fd9\u8868\u660eRLAIF\u53ef\u4ee5\u6709\u6548\u5730\u5904\u7406\u5177\u6709\u5185\u5728\u51b2\u7a81\u76ee\u6807\u7684\u7cfb\u7edf\u3002", "conclusion": "\u5c06RLAIF\u96c6\u6210\u5230\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u4e3a\u5728\u5177\u6709\u5185\u5728\u51b2\u7a81\u76ee\u6807\u7684\u9886\u57df\u4e2d\u5b9e\u73b0\u7528\u6237\u5bf9\u9f50\u7684\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002\u8fd9\u79cd\u65b9\u6cd5\u907f\u514d\u4e86\u4f20\u7edf\u5956\u52b1\u5de5\u7a0b\u7684\u590d\u6742\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u53cd\u6620\u7528\u6237\u504f\u597d\u3002"}}
{"id": "2602.20976", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.20976", "abs": "https://arxiv.org/abs/2602.20976", "authors": ["Xuan Luo", "Yubin Chen", "Zhiyu Hou", "Linpu Yu", "Geng Tu", "Jing Li", "Ruifeng Xu"], "title": "Evaluating Proactive Risk Awareness of Large Language Models", "comment": null, "summary": "As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness evaluation framework that measures whether LLMs can anticipate potential harms and provide warnings before damage occurs. We construct the Butterfly dataset to instantiate this framework in the environmental and ecological domain. It contains 1,094 queries that simulate ordinary solution-seeking activities whose responses may induce latent ecological impact. Through experiments across five widely used LLMs, we analyze the effects of response length, languages, and modality. Experimental results reveal consistent, significant declines in proactive awareness under length-restricted responses, cross-lingual similarities, and persistent blind spots in (multimodal) species protection. These findings highlight a critical gap between current safety alignment and the requirements of real-world ecological responsibility, underscoring the need for proactive safeguards in LLM deployment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u98ce\u9669\u610f\u8bc6\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8861\u91cfLLMs\u662f\u5426\u80fd\u9884\u89c1\u6f5c\u5728\u5371\u5bb3\u5e76\u5728\u635f\u5bb3\u53d1\u751f\u524d\u63d0\u4f9b\u8b66\u544a\uff0c\u6784\u5efa\u4e86Butterfly\u6570\u636e\u96c6\u5728\u73af\u5883\u751f\u6001\u9886\u57df\u8fdb\u884c\u9a8c\u8bc1\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u957f\u5ea6\u9650\u5236\u3001\u8de8\u8bed\u8a00\u548c\u7269\u79cd\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u663e\u8457\u76f2\u533a\u3002", "motivation": "\u968f\u7740LLMs\u5728\u65e5\u5e38\u51b3\u7b56\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5b89\u5168\u8d23\u4efb\u5df2\u4ece\u5e94\u5bf9\u660e\u786e\u6709\u5bb3\u610f\u56fe\u6269\u5c55\u5230\u9884\u89c1\u975e\u610f\u56fe\u4f46\u540e\u679c\u4e25\u91cd\u7684\u98ce\u9669\u3002\u9700\u8981\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u4e3b\u52a8\u8bc6\u522b\u6f5c\u5728\u5371\u5bb3\u5e76\u63d0\u4f9b\u9884\u8b66\uff0c\u7279\u522b\u662f\u5728\u73af\u5883\u751f\u6001\u7b49\u5173\u952e\u9886\u57df\u3002", "method": "1. \u63d0\u51fa\u4e3b\u52a8\u98ce\u9669\u610f\u8bc6\u8bc4\u4f30\u6846\u67b6\uff1b2. \u6784\u5efaButterfly\u6570\u636e\u96c6\uff081,094\u4e2a\u67e5\u8be2\uff09\uff0c\u6a21\u62df\u53ef\u80fd\u4ea7\u751f\u6f5c\u5728\u751f\u6001\u5f71\u54cd\u7684\u666e\u901a\u89e3\u51b3\u65b9\u6848\u5bfb\u6c42\u6d3b\u52a8\uff1b3. \u5728\u4e94\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLMs\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff1b4. \u5206\u6790\u54cd\u5e94\u957f\u5ea6\u3001\u8bed\u8a00\u548c\u591a\u6a21\u6001\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1. \u957f\u5ea6\u9650\u5236\u4e0b\u4e3b\u52a8\u610f\u8bc6\u663e\u8457\u4e0b\u964d\uff1b2. \u8de8\u8bed\u8a00\u8868\u73b0\u76f8\u4f3c\uff1b3. \uff08\u591a\u6a21\u6001\uff09\u7269\u79cd\u4fdd\u62a4\u5b58\u5728\u6301\u7eed\u76f2\u70b9\u3002\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86\u5f53\u524d\u5b89\u5168\u5bf9\u9f50\u4e0e\u5b9e\u9645\u751f\u6001\u8d23\u4efb\u8981\u6c42\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u524dLLMs\u7684\u5b89\u5168\u5bf9\u9f50\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u73b0\u5b9e\u4e16\u754c\u751f\u6001\u8d23\u4efb\u8981\u6c42\uff0c\u7a81\u663e\u4e86\u5728LLM\u90e8\u7f72\u4e2d\u9700\u8981\u4e3b\u52a8\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u7684\u91cd\u8981\u6027\u3002\u7814\u7a76\u4e3a\u8bc4\u4f30\u548c\u63d0\u5347LLMs\u7684\u4e3b\u52a8\u98ce\u9669\u610f\u8bc6\u63d0\u4f9b\u4e86\u6846\u67b6\u548c\u57fa\u51c6\u3002"}}
{"id": "2602.20732", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20732", "abs": "https://arxiv.org/abs/2602.20732", "authors": ["Chao Fei", "Guozhong Li", "Chenxi Liu", "Panos Kalnis"], "title": "CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference", "comment": null, "summary": "Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \\textbf{CHESS}, an \\textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \\textbf{1\\%} of the KV cache, delivers low-latency stable inference with up to \\textbf{4.56$\\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \\href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.", "AI": {"tldr": "CHESS\u662f\u4e00\u4e2a\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u7684KV\u7f13\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5206\u5c42\u9009\u62e9\u7b56\u7565\u52a8\u6001\u91cd\u6784\u89e3\u7801\u4e0a\u4e0b\u6587\uff0c\u4ec5\u4f7f\u75281%\u7684KV\u7f13\u5b58\u5c31\u80fd\u8d85\u8d8aFull-KV\u8d28\u91cf\uff0c\u5b9e\u73b0\u9ad8\u8fbe4.56\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587LLM\u9700\u8981\u4f4e\u5ef6\u8fdf\u7684\u51c6\u786e\u63a8\u7406\uff0c\u4f46\u968f\u7740\u4e0a\u4e0b\u6587\u589e\u957f\uff0c\u89e3\u7801\u4e3b\u8981\u53d7KV\u7f13\u5b58\u7ea6\u675f\u3002\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u5927\u591a\u662f\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\uff1a\u5176token\u9009\u62e9\u5ffd\u7565\u4e86\u6b65\u7ea7\u76f8\u5173\u6027\u548c\u5c40\u90e8\u8bed\u4e49\uff0c\u635f\u5bb3\u4e86\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u7684\u4e0d\u89c4\u5219\u8bbf\u95ee\u548c\u9009\u62e9\u5f00\u9500\u4ec5\u5e26\u6765\u6709\u9650\u7684\u5b9e\u65f6\u52a0\u901f\u3002", "method": "CHESS\u91c7\u7528\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u3002\u7b97\u6cd5\u5c42\u9762\uff1a\u5f15\u5165\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5206\u5c42\u9009\u62e9\u7b56\u7565\uff0c\u52a8\u6001\u91cd\u6784\u5f53\u524d\u89e3\u7801\u7684\u8fde\u8d2f\u4e0a\u4e0b\u6587\u3002\u7cfb\u7edf\u5c42\u9762\uff1a\u7c97\u7c92\u5ea6\u9009\u62e9\u6d88\u9664\u4e86\u6602\u8d35\u7684\u6570\u636e\u79fb\u52a8\uff0c\u5145\u5206\u5b9e\u73b0\u7406\u8bba\u7a00\u758f\u6027\u7684\u5b9e\u9645\u52a0\u901f\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cCHESS\u4ec5\u4f7f\u75281%\u7684KV\u7f13\u5b58\u5c31\u80fd\u8d85\u8d8aFull-KV\u8d28\u91cf\uff0c\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u7a33\u5b9a\u63a8\u7406\uff0c\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53474.56\u500d\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u5f3a\u57fa\u7ebf\u3002", "conclusion": "CHESS\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u4e2dKV\u7f13\u5b58\u7ea6\u675f\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u4f4e\u5ef6\u8fdf\u7684\u63a8\u7406\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21082", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.21082", "abs": "https://arxiv.org/abs/2602.21082", "authors": ["Vishal Patil", "Shree Vaishnavi Bacha", "Revanth Yamani", "Yidan Sun", "Mayank Kejriwal"], "title": "Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification", "comment": null, "summary": "Customer-provided reviews have become an important source of information for business owners and other customers alike. However, effectively analyzing millions of unstructured reviews remains challenging. While large language models (LLMs) show promise for natural language understanding, their application to large-scale review analysis has been limited by computational costs and scalability concerns. This study proposes a hybrid approach that uses LLMs for aspect identification while employing classic machine-learning methods for sentiment classification at scale. Using ChatGPT to analyze sampled restaurant reviews, we identified key aspects of dining experiences and developed sentiment classifiers using human-labeled reviews, which we subsequently applied to 4.7 million reviews collected over 17 years from a major online platform. Regression analysis reveals that our machine-labeled aspects significantly explain variance in overall restaurant ratings across different aspects of dining experiences, cuisines, and geographical regions. Our findings demonstrate that combining LLMs with traditional machine learning approaches can effectively automate aspect-based sentiment analysis of large-scale customer feedback, suggesting a practical framework for both researchers and practitioners in the hospitality industry and potentially, other service sectors.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65b9\u9762\u8bc6\u522b\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\uff0c\u4ee5\u5206\u6790\u5927\u89c4\u6a21\u5ba2\u6237\u8bc4\u8bba\uff0c\u5e76\u5728470\u4e07\u6761\u9910\u5385\u8bc4\u8bba\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5ba2\u6237\u8bc4\u8bba\u5df2\u6210\u4e3a\u4f01\u4e1a\u548c\u987e\u5ba2\u7684\u91cd\u8981\u4fe1\u606f\u6765\u6e90\uff0c\u4f46\u5206\u6790\u6570\u767e\u4e07\u6761\u975e\u7ed3\u6784\u5316\u8bc4\u8bba\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u5927\u89c4\u6a21\u8bc4\u8bba\u5206\u6790\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u8ba1\u7b97\u6210\u672c\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\uff1a\u4f7f\u7528ChatGPT\u5206\u6790\u9910\u5385\u8bc4\u8bba\u6837\u672c\u8fdb\u884c\u65b9\u9762\u8bc6\u522b\uff0c\u7136\u540e\u57fa\u4e8e\u4eba\u5de5\u6807\u6ce8\u7684\u8bc4\u8bba\u5f00\u53d1\u60c5\u611f\u5206\u7c7b\u5668\uff0c\u6700\u540e\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u4ece\u4e3b\u8981\u5728\u7ebf\u5e73\u53f0\u6536\u96c6\u768417\u5e74\u95f4\u7684470\u4e07\u6761\u8bc4\u8bba\u3002\u4f7f\u7528\u56de\u5f52\u5206\u6790\u9a8c\u8bc1\u673a\u5668\u6807\u6ce8\u7684\u65b9\u9762\u5bf9\u9910\u5385\u603b\u4f53\u8bc4\u5206\u7684\u89e3\u91ca\u80fd\u529b\u3002", "result": "\u673a\u5668\u6807\u6ce8\u7684\u65b9\u9762\u80fd\u591f\u663e\u8457\u89e3\u91ca\u9910\u5385\u603b\u4f53\u8bc4\u5206\u7684\u65b9\u5dee\uff0c\u6db5\u76d6\u4e0d\u540c\u7528\u9910\u4f53\u9a8c\u65b9\u9762\u3001\u83dc\u7cfb\u548c\u5730\u7406\u533a\u57df\u3002\u6df7\u5408\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u5927\u89c4\u6a21\u5ba2\u6237\u53cd\u9988\u7684\u57fa\u4e8e\u65b9\u9762\u7684\u60c5\u611f\u5206\u6790\u3002", "conclusion": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u81ea\u52a8\u5316\u5927\u89c4\u6a21\u5ba2\u6237\u53cd\u9988\u7684\u57fa\u4e8e\u65b9\u9762\u7684\u60c5\u611f\u5206\u6790\uff0c\u4e3a\u9152\u5e97\u4e1a\u53ca\u5176\u4ed6\u670d\u52a1\u884c\u4e1a\u7684\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2602.20739", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.20739", "abs": "https://arxiv.org/abs/2602.20739", "authors": ["Shitian Zhao", "Shaoheng Lin", "Ming Li", "Haoquan Zhang", "Wenshuo Peng", "Kaipeng Zhang", "Chen Wei"], "title": "PyVision-RL: Forging Open Agentic Vision Models via RL", "comment": "preprint", "summary": "Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.", "AI": {"tldr": "PyVision-RL\u662f\u4e00\u4e2a\u7528\u4e8e\u5f00\u653e\u6743\u91cd\u591a\u6a21\u6001\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fc7\u91c7\u6837-\u8fc7\u6ee4-\u6392\u5e8f\u7b56\u7565\u548c\u7d2f\u79ef\u5de5\u5177\u5956\u52b1\u6765\u9632\u6b62\u4ea4\u4e92\u5d29\u6e83\uff0c\u7ef4\u6301\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\uff0c\u5e76\u5f00\u53d1\u4e86\u56fe\u50cf\u548c\u89c6\u9891\u7406\u89e3\u6a21\u578b\uff0c\u5176\u4e2d\u89c6\u9891\u6a21\u578b\u91c7\u7528\u6309\u9700\u4e0a\u4e0b\u6587\u6784\u5efa\u6765\u51cf\u5c11\u89c6\u89c9\u6807\u8bb0\u4f7f\u7528\u3002", "motivation": "\u591a\u6a21\u6001\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7ecf\u5e38\u9762\u4e34\u4ea4\u4e92\u5d29\u6e83\u95ee\u9898\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u51cf\u5c11\u5de5\u5177\u4f7f\u7528\u548c\u591a\u8f6e\u63a8\u7406\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u4f18\u52bf\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7a33\u5b9a\u8bad\u7ec3\u5e76\u7ef4\u6301\u4ea4\u4e92\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faPyVision-RL\u6846\u67b6\uff0c\u7ed3\u5408\u8fc7\u91c7\u6837-\u8fc7\u6ee4-\u6392\u5e8f\u7b56\u7565\u548c\u7d2f\u79ef\u5de5\u5177\u5956\u52b1\u6765\u9632\u6b62\u4ea4\u4e92\u5d29\u6e83\u5e76\u9f13\u52b1\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u3002\u91c7\u7528\u7edf\u4e00\u8bad\u7ec3\u6d41\u7a0b\u5f00\u53d1PyVision-Image\u548cPyVision-Video\u6a21\u578b\u3002\u5bf9\u4e8e\u89c6\u9891\u63a8\u7406\uff0cPyVision-Video\u91c7\u7528\u6309\u9700\u4e0a\u4e0b\u6587\u6784\u5efa\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9009\u62e9\u6027\u91c7\u6837\u4efb\u52a1\u76f8\u5173\u5e27\u4ee5\u51cf\u5c11\u89c6\u89c9\u6807\u8bb0\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u663e\u793aPyVision\u6a21\u578b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\u548c\u6539\u8fdb\u7684\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u6301\u7eed\u4ea4\u4e92\u548c\u6309\u9700\u89c6\u89c9\u5904\u7406\u5bf9\u4e8e\u53ef\u6269\u5c55\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u6301\u7eed\u4ea4\u4e92\u548c\u6309\u9700\u89c6\u89c9\u5904\u7406\u662f\u6784\u5efa\u53ef\u6269\u5c55\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u5173\u952e\u8981\u7d20\uff0cPyVision-RL\u6846\u67b6\u901a\u8fc7\u9632\u6b62\u4ea4\u4e92\u5d29\u6e83\u548c\u4f18\u5316\u89c6\u89c9\u5904\u7406\uff0c\u4e3a\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21165", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21165", "abs": "https://arxiv.org/abs/2602.21165", "authors": ["Samah Fodeh", "Linhai Ma", "Yan Wang", "Srivani Talakokkul", "Ganesh Puthiaraju", "Afshan Khan", "Ashley Hagaman", "Sarah Lowe", "Aimee Roundtree"], "title": "PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data", "comment": null, "summary": "Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language. We introduce PVminer, a domain-adapted NLP framework for structuring patient voice in secure patient-provider communication. PVminer formulates PV detection as a multi-label, multi-class prediction task integrating patient-specific BERT encoders (PV-BERT-base and PV-BERT-large), unsupervised topic modeling for thematic augmentation (PV-Topic-BERT), and fine-tuned classifiers for Code, Subcode, and Combo-level labels. Topic representations are incorporated during fine-tuning and inference to enrich semantic inputs. PVminer achieves strong performance across hierarchical tasks and outperforms biomedical and clinical pre-trained baselines, achieving F1 scores of 82.25% (Code), 80.14% (Subcode), and up to 77.87% (Combo). An ablation study further shows that author identity and topic-based augmentation each contribute meaningful gains. Pre-trained models, source code, and documentation will be publicly released, with annotated datasets available upon request for research use.", "AI": {"tldr": "PVminer\uff1a\u4e00\u4e2a\u9886\u57df\u9002\u5e94\u7684NLP\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u60a3\u8005-\u63d0\u4f9b\u8005\u5b89\u5168\u901a\u4fe1\u4e2d\u7684\u60a3\u8005\u58f0\u97f3\uff0c\u901a\u8fc7\u591a\u6807\u7b7e\u591a\u5206\u7c7b\u9884\u6d4b\u6574\u5408\u60a3\u8005\u7279\u5b9aBERT\u7f16\u7801\u5668\u548c\u4e3b\u9898\u5efa\u6a21\uff0c\u5728\u5206\u5c42\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002", "motivation": "\u60a3\u8005\u751f\u6210\u7684\u6587\u672c\uff08\u5982\u5b89\u5168\u6d88\u606f\u3001\u8c03\u67e5\u3001\u8bbf\u8c08\uff09\u5305\u542b\u4e30\u5bcc\u7684\u60a3\u8005\u58f0\u97f3\u8868\u8fbe\uff0c\u53cd\u6620\u4e86\u6c9f\u901a\u884c\u4e3a\u548c\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u3002\u4f20\u7edf\u7684\u5b9a\u6027\u7f16\u7801\u6846\u67b6\u52b3\u52a8\u5bc6\u96c6\uff0c\u65e0\u6cd5\u6269\u5c55\u5230\u533b\u7597\u7cfb\u7edf\u4e2d\u7684\u5927\u91cf\u60a3\u8005\u64b0\u5199\u6d88\u606f\u3002\u73b0\u6709\u7684ML/NLP\u65b9\u6cd5\u63d0\u4f9b\u90e8\u5206\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u901a\u5e38\u5c06\u60a3\u8005\u4e2d\u5fc3\u6c9f\u901a\u548c\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u89c6\u4e3a\u72ec\u7acb\u4efb\u52a1\uff0c\u6216\u4f9d\u8d56\u4e0d\u9002\u5408\u60a3\u8005\u9762\u5411\u8bed\u8a00\u7684\u6a21\u578b\u3002", "method": "PVminer\u5c06\u60a3\u8005\u58f0\u97f3\u68c0\u6d4b\u5236\u5b9a\u4e3a\u591a\u6807\u7b7e\u591a\u5206\u7c7b\u9884\u6d4b\u4efb\u52a1\uff0c\u6574\u5408\u60a3\u8005\u7279\u5b9aBERT\u7f16\u7801\u5668\uff08PV-BERT-base\u548cPV-BERT-large\uff09\u3001\u7528\u4e8e\u4e3b\u9898\u589e\u5f3a\u7684\u65e0\u76d1\u7763\u4e3b\u9898\u5efa\u6a21\uff08PV-Topic-BERT\uff09\uff0c\u4ee5\u53ca\u9488\u5bf9Code\u3001Subcode\u548cCombo\u7ea7\u6807\u7b7e\u7684\u5fae\u8c03\u5206\u7c7b\u5668\u3002\u5728\u5fae\u8c03\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u878d\u5165\u4e3b\u9898\u8868\u793a\u4ee5\u4e30\u5bcc\u8bed\u4e49\u8f93\u5165\u3002", "result": "PVminer\u5728\u5206\u5c42\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5f3a\u52b2\u6027\u80fd\uff0c\u4f18\u4e8e\u751f\u7269\u533b\u5b66\u548c\u4e34\u5e8a\u9884\u8bad\u7ec3\u57fa\u7ebf\uff0cF1\u5206\u6570\u8fbe\u523082.25%\uff08Code\uff09\u300180.14%\uff08Subcode\uff09\u548c\u6700\u9ad877.87%\uff08Combo\uff09\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u663e\u793a\u4f5c\u8005\u8eab\u4efd\u548c\u57fa\u4e8e\u4e3b\u9898\u7684\u589e\u5f3a\u5404\u81ea\u8d21\u732e\u4e86\u6709\u610f\u4e49\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "PVminer\u662f\u4e00\u4e2a\u6709\u6548\u7684\u9886\u57df\u9002\u5e94NLP\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u60a3\u8005\u58f0\u97f3\uff0c\u5728\u60a3\u8005-\u63d0\u4f9b\u8005\u901a\u4fe1\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u60a3\u8005\u58f0\u97f3\u68c0\u6d4b\u3002\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u6e90\u4ee3\u7801\u548c\u6587\u6863\u5c06\u516c\u5f00\u53d1\u5e03\uff0c\u6807\u6ce8\u6570\u636e\u96c6\u53ef\u6839\u636e\u7814\u7a76\u8bf7\u6c42\u63d0\u4f9b\u3002"}}
{"id": "2602.20810", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20810", "abs": "https://arxiv.org/abs/2602.20810", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "POMDPPlanners: Open-Source Package for POMDP Planning", "comment": null, "summary": "We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to enable scalable, reproducible research on decision-making under uncertainty, with particular emphasis on risk-sensitive settings where standard toolkits fall short.", "AI": {"tldr": "POMDPPlanners\u662f\u4e00\u4e2a\u7528\u4e8ePOMDP\u89c4\u5212\u7b97\u6cd5\u5b9e\u8bc1\u8bc4\u4f30\u7684\u5f00\u6e90Python\u5305\uff0c\u96c6\u6210\u4e86\u5148\u8fdb\u7b97\u6cd5\u3001\u57fa\u51c6\u73af\u5883\u3001\u81ea\u52a8\u8d85\u53c2\u6570\u4f18\u5316\u548c\u5e76\u884c\u4eff\u771f\u529f\u80fd", "motivation": "\u73b0\u6709\u7684POMDP\u5de5\u5177\u5305\u5728\u98ce\u9669\u654f\u611f\u8bbe\u7f6e\u4e0b\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u884c\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u51b3\u7b56\u7814\u7a76\uff0c\u7279\u522b\u662f\u5b89\u5168\u5173\u952e\u573a\u666f\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u51b3\u7b56", "method": "\u5f00\u53d1\u5f00\u6e90Python\u5305\uff0c\u96c6\u6210\u6700\u5148\u8fdb\u7684\u89c4\u5212\u7b97\u6cd5\uff0c\u63d0\u4f9b\u57fa\u51c6\u73af\u5883\uff08\u5305\u62ec\u5b89\u5168\u5173\u952e\u53d8\u4f53\uff09\uff0c\u901a\u8fc7Optuna\u5b9e\u73b0\u81ea\u52a8\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u652f\u6301\u6301\u4e45\u5316\u7f13\u5b58\u548c\u6545\u969c\u6062\u590d\uff0c\u914d\u7f6e\u5e76\u884c\u4eff\u771f", "result": "\u521b\u5efa\u4e86POMDPPlanners\u5305\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5927\u89c4\u6a21\u4eff\u771f\u7814\u7a76\u7684\u5f00\u9500\uff0c\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u51b3\u7b56\u7684\u89c4\u6a21\u5316\u53ef\u590d\u73b0\u7814\u7a76", "conclusion": "POMDPPlanners\u4e3aPOMDP\u89c4\u5212\u7b97\u6cd5\u7684\u5b9e\u8bc1\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5168\u9762\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u98ce\u9669\u654f\u611f\u8bbe\u7f6e\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u5305\u7684\u4e0d\u8db3"}}
{"id": "2602.20812", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20812", "abs": "https://arxiv.org/abs/2602.20812", "authors": ["Jia-Rui Lin", "Yun-Hong Cai", "Xiang-Rui Ni", "Shaojie Zhou", "Peng Pan"], "title": "Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset", "comment": null, "summary": "As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with corresponding quantitative indicators to evaluate the performance of LLMs, 2) a method for generating textual data from BIM and constructing corresponding BIM-derived datasets for LLM evaluation and fine-tuning, and 3) a fine-tuning strategy to adapt LLMs for BIM-based design. Results demonstrate that the proposed domain-specific benchmark effectively and comprehensively assesses LLM capabilities, highlighting that general LLMs are still incompetent for domain-specific tasks. Meanwhile, with the proposed benchmark and datasets, Qwen-BIM is developed and achieves a 21.0% average increase in G-Eval score compared to the base LLM model. Notably, with only 14B parameters, performance of Qwen-BIM is comparable to that of general LLMs with 671B parameters for BIM-based design tasks. Overall, this study develops the first domain-specific LLM for BIM-based design by introducing a comprehensive benchmark and high-quality dataset, which provide a solid foundation for developing BIM-related LLMs in various fields.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9BIM\uff08\u5efa\u7b51\u4fe1\u606f\u6a21\u578b\uff09\u8bbe\u8ba1\u9886\u57df\u7f3a\u4e4f\u4e13\u95e8\u6570\u636e\u96c6\u548cLLM\u8bc4\u4f30\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9996\u4e2aBIM\u8bbe\u8ba1\u4e13\u7528\u8bc4\u4f30\u57fa\u51c6\u3001\u6570\u636e\u751f\u6210\u65b9\u6cd5\u548cLLM\u5fae\u8c03\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u4e86Qwen-BIM\u6a21\u578b\uff0c\u5728\u4ec514B\u53c2\u6570\u4e0b\u8fbe\u5230\u4e0e671B\u901a\u7528LLM\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u5efa\u7b51\u884c\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u4e2d\uff0cBIM\u8bbe\u8ba1\u6210\u4e3a\u667a\u80fd\u5efa\u9020\u7684\u5173\u952e\u9a71\u52a8\u529b\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4fc3\u8fdbBIM\u8bbe\u8ba1\u65b9\u9762\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7279\u5b9a\u9886\u57df\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u57fa\u51c6\u4e25\u91cd\u9650\u5236\u4e86LLM\u5728BIM\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "1) \u63d0\u51faBIM\u8bbe\u8ba1\u8bc4\u4f30\u57fa\u51c6\u53ca\u5b9a\u91cf\u6307\u6807\uff1b2) \u5f00\u53d1\u4eceBIM\u751f\u6210\u6587\u672c\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u7528\u4e8eLLM\u8bc4\u4f30\u548c\u5fae\u8c03\u7684BIM\u884d\u751f\u6570\u636e\u96c6\uff1b3) \u8bbe\u8ba1LLM\u5fae\u8c03\u7b56\u7565\u4ee5\u9002\u5e94BIM\u8bbe\u8ba1\u4efb\u52a1\u3002", "result": "\u63d0\u51fa\u7684\u9886\u57df\u4e13\u7528\u57fa\u51c6\u80fd\u5168\u9762\u8bc4\u4f30LLM\u80fd\u529b\uff0c\u663e\u793a\u901a\u7528LLM\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\u4ecd\u4e0d\u79f0\u804c\u3002\u57fa\u4e8e\u8be5\u57fa\u51c6\u548c\u6570\u636e\u96c6\u5f00\u53d1\u7684Qwen-BIM\u6a21\u578b\uff0c\u76f8\u6bd4\u57fa\u7840LLM\u5728G-Eval\u5f97\u5206\u4e0a\u5e73\u5747\u63d0\u534721.0%\u3002\u4ec514B\u53c2\u6570\u7684Qwen-BIM\u5728BIM\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0e671B\u53c2\u6570\u7684\u901a\u7528LLM\u76f8\u5f53\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u4e86\u9996\u4e2aBIM\u8bbe\u8ba1\u4e13\u7528LLM\uff0c\u4e3a\u5404\u9886\u57df\u5f00\u53d1BIM\u76f8\u5173LLM\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.20813", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20813", "abs": "https://arxiv.org/abs/2602.20813", "authors": ["Nora Petrova", "John Burden"], "title": "Pressure Reveals Character: Behavioural Alignment Evaluation at Depth", "comment": "Preprint", "summary": "Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenarios place models under conflicting instructions, simulated tool access, and multi-turn escalation to reveal behavioural tendencies that single-turn evaluations miss. Evaluating 24 frontier models using LLM judges validated against human annotations, we find that even top-performing models exhibit gaps in specific categories, while the majority of models show consistent weaknesses across the board. Factor analysis reveals that alignment behaves as a unified construct (analogous to the g-factor in cognitive research) with models scoring high on one category tending to score high on others. We publicly release the benchmark and an interactive leaderboard to support ongoing evaluation, with plans to expand scenarios in areas where we observe persistent weaknesses and to add new models as they are released.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b904\u4e2a\u573a\u666f\u30016\u4e2a\u7c7b\u522b\u7684\u5bf9\u9f50\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u538b\u529b\u4e0b\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u5bf9\u9f50\u8868\u73b0\u5448\u73b0\u7edf\u4e00\u6784\u9020\u7279\u5f81\uff0c\u591a\u6570\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u5f31\u70b9\u3002", "motivation": "\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u6027\u9700\u8981\u6d4b\u8bd5\u5176\u5728\u73b0\u5b9e\u538b\u529b\u4e0b\u7684\u5b9e\u9645\u884c\u4e3a\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u58f0\u79f0\u7684\u610f\u56fe\u3002\u5f53\u524d\u7f3a\u4e4f\u5305\u542b\u73b0\u5b9e\u591a\u8f6e\u573a\u666f\u7684\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u800c\u5bf9\u9f50\u5931\u8d25\u6b63\u5bfc\u81f4\u8d8a\u6765\u8d8a\u591a\u7684\u73b0\u5b9e\u5371\u5bb3\u3002", "method": "1) \u6784\u5efa\u5305\u542b904\u4e2a\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u8bda\u5b9e\u6027\u3001\u5b89\u5168\u6027\u3001\u975e\u64cd\u7eb5\u6027\u3001\u9c81\u68d2\u6027\u3001\u53ef\u4fee\u6b63\u6027\u548c\u9634\u8c0b\u60276\u4e2a\u7c7b\u522b\uff0c\u7ecf\u4eba\u7c7b\u8bc4\u4f30\u8005\u9a8c\u8bc1\u4e3a\u73b0\u5b9e\u573a\u666f\uff1b2) \u573a\u666f\u8bbe\u8ba1\u5305\u542b\u51b2\u7a81\u6307\u4ee4\u3001\u6a21\u62df\u5de5\u5177\u8bbf\u95ee\u548c\u591a\u8f6e\u5347\u7ea7\uff1b3) \u4f7f\u7528\u7ecf\u4eba\u7c7b\u6807\u6ce8\u9a8c\u8bc1\u7684LLM\u8bc4\u4f30\u5668\u5bf924\u4e2a\u524d\u6cbf\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "1) \u5373\u4f7f\u662f\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u5728\u7279\u5b9a\u7c7b\u522b\u4e2d\u4e5f\u5b58\u5728\u5dee\u8ddd\uff1b2) \u5927\u591a\u6570\u6a21\u578b\u5728\u6240\u6709\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u5f31\u70b9\uff1b3) \u56e0\u5b50\u5206\u6790\u663e\u793a\u5bf9\u9f50\u6027\u8868\u73b0\u4e3a\u7edf\u4e00\u6784\u9020\uff08\u7c7b\u4f3c\u4e8e\u8ba4\u77e5\u7814\u7a76\u4e2d\u7684g\u56e0\u5b50\uff09\uff0c\u6a21\u578b\u5728\u4e00\u4e2a\u7c7b\u522b\u5f97\u5206\u9ad8\u65f6\u5728\u5176\u4ed6\u7c7b\u522b\u4e5f\u503e\u5411\u4e8e\u5f97\u5206\u9ad8\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5bf9\u9f50\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u538b\u529b\u4e0b\u7684\u884c\u4e3a\u6a21\u5f0f\u3002\u5bf9\u9f50\u6027\u8868\u73b0\u4e3a\u7edf\u4e00\u6784\u9020\u7279\u5f81\uff0c\u591a\u6570\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u5f31\u70b9\u3002\u4f5c\u8005\u516c\u5f00\u4e86\u57fa\u51c6\u6d4b\u8bd5\u548c\u4ea4\u4e92\u5f0f\u6392\u884c\u699c\uff0c\u8ba1\u5212\u5728\u89c2\u5bdf\u5230\u6301\u7eed\u5f31\u70b9\u7684\u9886\u57df\u6269\u5c55\u573a\u666f\uff0c\u5e76\u6dfb\u52a0\u65b0\u53d1\u5e03\u7684\u6a21\u578b\u3002"}}
{"id": "2602.20878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20878", "abs": "https://arxiv.org/abs/2602.20878", "authors": ["Dhita Putri Pratama", "Soyeon Caren Han", "Yihao Ding"], "title": "Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs", "comment": null, "summary": "Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly encodes causally relevant objects, attributes, relations, and scene-grounded assumptions. Building on this representation, we present ViLCaR, a diagnostic benchmark comprising tasks for Causal Attribution, Causal Inference, and Question Answering, along with graph-aligned evaluation metrics that assess relevance identification beyond final answer accuracy. Experiments in state-of-the-art LVLMs show that injecting structured relevance information significantly improves attribution and inference consistency compared to zero-shot and standard in-context learning. These findings suggest that current limitations in LVLM causal reasoning stem primarily from insufficient structural guidance rather than a lack of reasoning capacity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVision-Language Causal Graphs (VLCGs)\u7ed3\u6784\u5316\u8868\u793a\u548cViLCaR\u8bca\u65ad\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u4e3b\u8981\u7f3a\u4e4f\u7ed3\u6784\u5316\u6307\u5bfc\u800c\u975e\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f80\u5f80\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u7684\u56e0\u679c\u63a8\u7406\u3002\u5f53\u524d\u7684\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u65e0\u6cd5\u533a\u5206\u5931\u8d25\u662f\u7531\u4e8e\u63a8\u7406\u80fd\u529b\u6709\u9650\u8fd8\u662f\u672a\u80fd\u8bc6\u522b\u56e0\u679c\u76f8\u5173\u4fe1\u606f\u3002", "method": "\u63d0\u51faVision-Language Causal Graphs (VLCGs)\u2014\u2014\u4e00\u79cd\u7ed3\u6784\u5316\u3001\u67e5\u8be2\u6761\u4ef6\u5316\u7684\u8868\u793a\u65b9\u6cd5\uff0c\u663e\u5f0f\u7f16\u7801\u56e0\u679c\u76f8\u5173\u7684\u5bf9\u8c61\u3001\u5c5e\u6027\u3001\u5173\u7cfb\u548c\u573a\u666f\u57fa\u7840\u5047\u8bbe\u3002\u57fa\u4e8e\u6b64\u6784\u5efaViLCaR\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b\u56e0\u679c\u5f52\u56e0\u3001\u56e0\u679c\u63a8\u7406\u548c\u95ee\u7b54\u4efb\u52a1\uff0c\u4ee5\u53ca\u56fe\u5bf9\u9f50\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6ce8\u5165\u7ed3\u6784\u5316\u76f8\u5173\u6027\u4fe1\u606f\u76f8\u6bd4\u96f6\u6837\u672c\u548c\u6807\u51c6\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u5f52\u56e0\u548c\u63a8\u7406\u7684\u4e00\u81f4\u6027\u3002\u8fd9\u8868\u660e\u5f53\u524dLVLM\u5728\u56e0\u679c\u63a8\u7406\u65b9\u9762\u7684\u9650\u5236\u4e3b\u8981\u6e90\u4e8e\u7ed3\u6784\u5316\u6307\u5bfc\u4e0d\u8db3\uff0c\u800c\u975e\u63a8\u7406\u80fd\u529b\u7f3a\u4e4f\u3002", "conclusion": "\u5f53\u524d\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u56e0\u679c\u63a8\u7406\u5c40\u9650\u4e3b\u8981\u6765\u81ea\u7f3a\u4e4f\u7ed3\u6784\u5316\u6307\u5bfc\uff0c\u800c\u975e\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002VLCGs\u548cViLCaR\u4e3a\u8bca\u65ad\u548c\u6539\u8fdb\u6a21\u578b\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.20926", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20926", "abs": "https://arxiv.org/abs/2602.20926", "authors": ["Yuqi Huang", "Ning Liao", "Kai Yang", "Anning Hu", "Shengchao Hu", "Xiaoxing Wang", "Junchi Yan"], "title": "HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG", "comment": null, "summary": "Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic noise in LLM-generated summaries. In this paper, we propose HyperNode Expansion and Logical Path-Guided Evidence Localization strategies for GraphRAG (HELP), a novel framework designed to balance accuracy with practical efficiency through two core strategies: 1) HyperNode Expansion, which iteratively chains knowledge triplets into coherent reasoning paths abstracted as HyperNodes to capture complex structural dependencies and ensure retrieval accuracy; and 2) Logical Path-Guided Evidence Localization, which leverages precomputed graph-text correlations to map these paths directly to the corpus for superior efficiency. HELP avoids expensive random walks and semantic distortion, preserving knowledge integrity while drastically reducing retrieval latency. Extensive experiments demonstrate that HELP achieves competitive performance across multiple simple and multi-hop QA benchmarks and up to a 28.8$\\times$ speedup over leading Graph-based RAG baselines.", "AI": {"tldr": "HELP\u6846\u67b6\u901a\u8fc7\u8d85\u8282\u70b9\u6269\u5c55\u548c\u903b\u8f91\u8def\u5f84\u5f15\u5bfc\u7684\u8bc1\u636e\u5b9a\u4f4d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u68c0\u7d22\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u56fe\u589e\u5f3a\u68c0\u7d22\u751f\u6210\u6548\u7387", "motivation": "\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u5904\u7406\u591a\u8df3\u63a8\u7406\u65f6\u5ffd\u89c6\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff0c\u800c\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9762\u4e34\u56fe\u904d\u5386\u6210\u672c\u9ad8\u548cLLM\u751f\u6210\u6458\u8981\u8bed\u4e49\u566a\u58f0\u7b49\u95ee\u9898", "method": "\u63d0\u51faHELP\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7b56\u7565\uff1a1) \u8d85\u8282\u70b9\u6269\u5c55\uff1a\u8fed\u4ee3\u5730\u5c06\u77e5\u8bc6\u4e09\u5143\u7ec4\u94fe\u63a5\u4e3a\u8fde\u8d2f\u63a8\u7406\u8def\u5f84\u5e76\u62bd\u8c61\u4e3a\u8d85\u8282\u70b9\uff0c\u6355\u6349\u590d\u6742\u7ed3\u6784\u4f9d\u8d56\uff1b2) \u903b\u8f91\u8def\u5f84\u5f15\u5bfc\u7684\u8bc1\u636e\u5b9a\u4f4d\uff1a\u5229\u7528\u9884\u8ba1\u7b97\u7684\u56fe-\u6587\u672c\u76f8\u5173\u6027\u5c06\u8def\u5f84\u76f4\u63a5\u6620\u5c04\u5230\u8bed\u6599\u5e93\uff0c\u907f\u514d\u6602\u8d35\u7684\u968f\u673a\u6e38\u8d70", "result": "\u5728\u591a\u4e2a\u7b80\u5355\u548c\u591a\u8df3QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u76f8\u6bd4\u9886\u5148\u7684\u57fa\u4e8e\u56fe\u7684RAG\u57fa\u7ebf\u5b9e\u73b0\u9ad8\u8fbe28.8\u500d\u7684\u52a0\u901f", "conclusion": "HELP\u6846\u67b6\u901a\u8fc7\u5e73\u8861\u51c6\u786e\u6027\u548c\u5b9e\u9645\u6548\u7387\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u589e\u5f3a\u68c0\u7d22\u751f\u6210\u4e2d\u7684\u7ed3\u6784\u4f9d\u8d56\u6355\u6349\u548c\u6548\u7387\u74f6\u9888\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u4e86\u8bed\u4e49\u5931\u771f\u5e76\u4fdd\u6301\u77e5\u8bc6\u5b8c\u6574\u6027"}}
{"id": "2602.20934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20934", "abs": "https://arxiv.org/abs/2602.20934", "authors": ["ChengYou Li", "XiaoDong Liu", "XiangBao Meng", "XinYu Zhao"], "title": "Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence", "comment": "16 pages,9 figures", "summary": "The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a \"Reasoning Kernel\" governed by structured operating system logic.Central to this architecture is Deep Context Management which conceptualizes the context window as an Addressable Semantic Space rather than a passive buffer.We systematically deconstruct the transition from discrete sequences to coherent cognitive states introducing mechanisms for Semantic Slicing and Temporal Alignment to mitigate cognitive drift in multi-agent orchestration.By mapping classical OS abstractions such as memory paging interrupt handling and process scheduling onto LLM native constructs, this review provides a rigorous roadmap for architecting resilient scalable and self-evolving cognitive environments.Our analysis asserts that the next frontier of AGI development lies in the architectural efficiency of system-level coordination.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAgentOS\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u65b0\u5b9a\u4e49\u4e3a\"\u63a8\u7406\u5185\u6838\"\uff0c\u91c7\u7528\u64cd\u4f5c\u7cfb\u7edf\u903b\u8f91\u7ba1\u7406\uff0c\u901a\u8fc7\u6df1\u5ea6\u4e0a\u4e0b\u6587\u7ba1\u7406\u5c06\u4e0a\u4e0b\u6587\u7a97\u53e3\u89c6\u4e3a\u53ef\u5bfb\u5740\u8bed\u4e49\u7a7a\u95f4\uff0c\u89e3\u51b3\u5fae\u89c2token\u5904\u7406\u4e0e\u5b8f\u89c2\u7cfb\u7edf\u667a\u80fd\u4e4b\u95f4\u7684\u7406\u8bba\u9e3f\u6c9f\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e3\u6216\u4f18\u5316\u63d0\u793a\u5de5\u7a0b\uff0c\u4f46\u5fae\u89c2token\u5904\u7406\u4e0e\u5b8f\u89c2\u7cfb\u7edf\u667a\u80fd\u4e4b\u95f4\u7684\u7406\u8bba\u6865\u6881\u4ecd\u7136\u788e\u7247\u5316\u3002\u9700\u8981\u4ece\u9759\u6001\u63a8\u7406\u5f15\u64ce\u5411\u52a8\u6001\u81ea\u4e3b\u8ba4\u77e5\u7cfb\u7edf\u8fdb\u884c\u6839\u672c\u6027\u8f6c\u53d8\u3002", "method": "\u63d0\u51faAgentOS\u6574\u4f53\u6982\u5ff5\u6846\u67b6\uff0c\u5c06LLM\u91cd\u65b0\u5b9a\u4e49\u4e3a\"\u63a8\u7406\u5185\u6838\"\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u64cd\u4f5c\u7cfb\u7edf\u903b\u8f91\u7ba1\u7406\u3002\u6838\u5fc3\u662f\u6df1\u5ea6\u4e0a\u4e0b\u6587\u7ba1\u7406\uff0c\u5c06\u4e0a\u4e0b\u6587\u7a97\u53e3\u6982\u5ff5\u5316\u4e3a\u53ef\u5bfb\u5740\u8bed\u4e49\u7a7a\u95f4\u800c\u975e\u88ab\u52a8\u7f13\u51b2\u533a\u3002\u5f15\u5165\u8bed\u4e49\u5207\u7247\u548c\u65f6\u95f4\u5bf9\u9f50\u673a\u5236\u6765\u7f13\u89e3\u591a\u667a\u80fd\u4f53\u7f16\u6392\u4e2d\u7684\u8ba4\u77e5\u6f02\u79fb\uff0c\u5e76\u5c06\u7ecf\u5178\u64cd\u4f5c\u7cfb\u7edf\u62bd\u8c61\uff08\u5185\u5b58\u5206\u9875\u3001\u4e2d\u65ad\u5904\u7406\u3001\u8fdb\u7a0b\u8c03\u5ea6\uff09\u6620\u5c04\u5230LLM\u539f\u751f\u6784\u9020\u4e0a\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u7684\u8def\u7ebf\u56fe\uff0c\u7528\u4e8e\u6784\u5efa\u5f39\u6027\u3001\u53ef\u6269\u5c55\u548c\u81ea\u6211\u8fdb\u5316\u7684\u8ba4\u77e5\u73af\u5883\u3002\u5206\u6790\u8868\u660eAGI\u53d1\u5c55\u7684\u4e0b\u4e00\u4e2a\u524d\u6cbf\u5728\u4e8e\u7cfb\u7edf\u7ea7\u534f\u8c03\u7684\u67b6\u6784\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u64cd\u4f5c\u7cfb\u7edf\u539f\u7406\u5e94\u7528\u4e8eLLM\u67b6\u6784\uff0cAgentOS\u6846\u67b6\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u3001\u66f4\u534f\u8c03\u7684\u8ba4\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u7cfb\u7edf\u7ea7\u534f\u8c03\u7684\u67b6\u6784\u6548\u7387\u662fAGI\u53d1\u5c55\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2602.21044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21044", "abs": "https://arxiv.org/abs/2602.21044", "authors": ["Yanrui Wu", "Lingling Zhang", "Xinyu Zhang", "Jiayu Chang", "Pengyu Li", "Xu Jiang", "Jingtao Hu", "Jun Liu"], "title": "LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification", "comment": "24 pages, 17 figures", "summary": "Evaluations of large language models (LLMs) primarily emphasize convergent logical reasoning, where success is defined by producing a single correct proof. However, many real-world reasoning problems admit multiple valid derivations, requiring models to explore diverse logical paths rather than committing to one route. To address this limitation, we introduce LogicGraph, the first benchmark aimed to systematically evaluate multi-path logical reasoning, constructed via a neuro-symbolic framework that leverages backward logic generation and semantic instantiation. This pipeline yields solver-verified reasoning problems formalized by high-depth multi-path reasoning and inherent logical distractions, where each instance is associated with an exhaustive set of minimal proofs. We further propose a reference-free evaluation framework to rigorously assess model performance in both convergent and divergent regimes. Experiments on state-of-the-art language models reveal a common limitation: models tend to commit early to a single route and fail to explore alternatives, and the coverage gap grows substantially with reasoning depth. LogicGraph exposes this divergence gap and provides actionable insights to motivate future improvements. Our code and data will be released at https://github.com/kkkkarry/LogicGraph.", "code_url": "https://github.com/kkkkarry/LogicGraph", "code_stars": 1, "code_last_update": "2026-02-24", "AI": {"tldr": "LogicGraph\u662f\u9996\u4e2a\u8bc4\u4f30\u591a\u8def\u5f84\u903b\u8f91\u63a8\u7406\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u6784\u5efa\u5305\u542b\u6df1\u5ea6\u591a\u8def\u5f84\u63a8\u7406\u548c\u903b\u8f91\u5e72\u6270\u7684\u95ee\u9898\uff0c\u63ed\u793aLLM\u503e\u5411\u4e8e\u8fc7\u65e9\u56fa\u5b9a\u5355\u4e00\u63a8\u7406\u8def\u5f84\u800c\u65e0\u6cd5\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6536\u655b\u6027\u903b\u8f91\u63a8\u7406\uff08\u4ea7\u751f\u5355\u4e00\u6b63\u786e\u8bc1\u660e\uff09\uff0c\u4f46\u8bb8\u591a\u73b0\u5b9e\u63a8\u7406\u95ee\u9898\u5b58\u5728\u591a\u79cd\u6709\u6548\u63a8\u5bfc\u8def\u5f84\uff0c\u9700\u8981\u6a21\u578b\u63a2\u7d22\u591a\u6837\u903b\u8f91\u8def\u5f84\u800c\u975e\u56fa\u5b88\u5355\u4e00\u8def\u7ebf\u3002", "method": "\u63d0\u51faLogicGraph\u57fa\u51c6\uff0c\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u7ed3\u5408\u540e\u5411\u903b\u8f91\u751f\u6210\u548c\u8bed\u4e49\u5b9e\u4f8b\u5316\uff0c\u6784\u5efa\u7ecf\u8fc7\u6c42\u89e3\u5668\u9a8c\u8bc1\u7684\u63a8\u7406\u95ee\u9898\uff0c\u5305\u542b\u9ad8\u6df1\u5ea6\u591a\u8def\u5f84\u63a8\u7406\u548c\u5185\u5728\u903b\u8f91\u5e72\u6270\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5173\u8054\u4e00\u7ec4\u6700\u5c0f\u8bc1\u660e\u7684\u7a77\u4e3e\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u5171\u540c\u5c40\u9650\uff1a\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u65e9\u56fa\u5b9a\u5355\u4e00\u63a8\u7406\u8def\u5f84\u800c\u65e0\u6cd5\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\uff0c\u4e14\u968f\u7740\u63a8\u7406\u6df1\u5ea6\u589e\u52a0\uff0c\u8986\u76d6\u5dee\u8ddd\u663e\u8457\u6269\u5927\u3002LogicGraph\u63ed\u793a\u4e86\u8fd9\u79cd\u53d1\u6563\u5dee\u8ddd\u3002", "conclusion": "LogicGraph\u66b4\u9732\u4e86LLM\u5728\u591a\u8def\u5f84\u903b\u8f91\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.21061", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21061", "abs": "https://arxiv.org/abs/2602.21061", "authors": ["David Koplow", "Tomer Galanti", "Tomaso Poggio"], "title": "Tool Building as a Path to \"Superintelligence\"", "comment": null, "summary": "The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $\u03b3$. In this work, we design a benchmark to measure $\u03b3$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the information provided. Our analysis demonstrates that while the $\u03b3$ value for small LLMs declines superlinearly as depth increases, frontier models exhibit partial robustness on this task. Furthermore, we find that successful reasoning at scale is contingent upon precise tool calls, identifying tool design as a critical capability for LLMs to achieve general superintelligence through the Diligent Learner framework.", "AI": {"tldr": "\u8bba\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u51c6\u6765\u6d4b\u91cfLLMs\u5728\u903b\u8f91\u5206\u5e03\u5916\u63a8\u7406\u4e2d\u7684\u6b65\u9aa4\u6210\u529f\u6982\u7387\u03b3\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u90e8\u5206\u9c81\u68d2\u6027\uff0c\u7cbe\u786e\u7684\u5de5\u5177\u8c03\u7528\u662f\u5b9e\u73b0\u901a\u7528\u8d85\u667a\u80fd\u7684\u5173\u952e\u80fd\u529b\u3002", "motivation": "Diligent Learner\u6846\u67b6\u8ba4\u4e3aLLMs\u53ef\u4ee5\u901a\u8fc7\u6d4b\u8bd5\u65f6\u641c\u7d22\u5b9e\u73b0\u8d85\u667a\u80fd\uff0c\u524d\u63d0\u662f\u6709\u8db3\u591f\u7684\u6b65\u9aa4\u6210\u529f\u6982\u7387\u03b3\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u57fa\u51c6\u6765\u6d4b\u91cf\u03b3\u503c\uff0c\u7279\u522b\u662f\u5728\u903b\u8f91\u5206\u5e03\u5916\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u4ee5\u8bc4\u4f30LLMs\u5b9e\u73b0\u8d85\u667a\u80fd\u7684\u53ef\u884c\u6027\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u7c7b\u6d89\u53caGF(2)\u7535\u8def\u91cd\u5efa\u7684\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u968f\u7740\u63a8\u7406\u6b65\u9aa4\u7684\u589e\u52a0\u800c\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\uff0c\u5e76\u4e14\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u770b\uff0c\u9664\u975eLLM\u4ed4\u7ec6\u6574\u5408\u6240\u6709\u63d0\u4f9b\u7684\u4fe1\u606f\uff0c\u5426\u5219\u65e0\u6cd5\u53ef\u9760\u89e3\u51b3\u3002\u901a\u8fc7\u8fd9\u4e2a\u57fa\u51c6\u6d4b\u91cf\u4e0d\u540c\u89c4\u6a21LLMs\u7684\u03b3\u503c\u3002", "result": "\u5c0f\u578bLLMs\u7684\u03b3\u503c\u968f\u7740\u6df1\u5ea6\u589e\u52a0\u5448\u8d85\u7ebf\u6027\u4e0b\u964d\uff0c\u800c\u524d\u6cbf\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u90e8\u5206\u9c81\u68d2\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6210\u529f\u7684\u89c4\u6a21\u5316\u63a8\u7406\u4f9d\u8d56\u4e8e\u7cbe\u786e\u7684\u5de5\u5177\u8c03\u7528\uff0c\u5de5\u5177\u8bbe\u8ba1\u88ab\u786e\u5b9a\u4e3aLLMs\u901a\u8fc7Diligent Learner\u6846\u67b6\u5b9e\u73b0\u901a\u7528\u8d85\u667a\u80fd\u7684\u5173\u952e\u80fd\u529b\u3002", "conclusion": "\u5de5\u5177\u8bbe\u8ba1\u662fLLMs\u901a\u8fc7Diligent Learner\u6846\u67b6\u5b9e\u73b0\u901a\u7528\u8d85\u667a\u80fd\u7684\u5173\u952e\u74f6\u9888\u3002\u867d\u7136\u524d\u6cbf\u6a21\u578b\u5728\u903b\u8f91\u5206\u5e03\u5916\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u90e8\u5206\u9c81\u68d2\u6027\uff0c\u4f46\u7cbe\u786e\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u5bf9\u4e8e\u5b9e\u73b0\u53ef\u9760\u7684\u89c4\u6a21\u5316\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.21066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21066", "abs": "https://arxiv.org/abs/2602.21066", "authors": ["Claire McNamara", "Lucy Hederman", "Declan O'Sullivan"], "title": "The Initial Exploration Problem in Knowledge Graph Exploration", "comment": "13 pages", "summary": "Knowledge Graphs (KGs) enable the integration and representation of complex information across domains, but their semantic richness and structural complexity create substantial barriers for lay users without expertise in semantic web technologies. When encountering an unfamiliar KG, such users face a distinct orientation challenge: they do not know what questions are possible, how the knowledge is structured, or how to begin exploration. This paper identifies and theorises this phenomenon as the Initial Exploration Problem (IEP). Drawing on theories from information behaviour and human-computer interaction, including ASK, exploratory search, information foraging, and cognitive load theory, we develop a conceptual framing of the IEP characterised by three interdependent barriers: scope uncertainty, ontology opacity, and query incapacity. We argue that these barriers converge at the moment of first contact, distinguishing the IEP from related concepts that presuppose an existing starting point or information goal. Analysing KG exploration interfaces at the level of interaction primitives, we suggest that many systems rely on epistemic assumptions that do not hold at first contact. This reveals a structural gap in the design space: the absence of interaction primitives for scope revelation, mechanisms that communicate what a KG contains without requiring users to formulate queries or interpret ontological structures. In articulating the IEP, this paper provides a theoretical lens for evaluating KG interfaces and for designing entry-point scaffolding that supports initial exploration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u521d\u59cb\u63a2\u7d22\u95ee\u9898\"\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u77e5\u8bc6\u56fe\u8c31\u9762\u5411\u975e\u4e13\u5bb6\u7528\u6237\u65f6\u7684\u5165\u95e8\u969c\u788d\uff0c\u6307\u51fa\u5f53\u524d\u754c\u9762\u8bbe\u8ba1\u7f3a\u4e4f\u8303\u56f4\u63ed\u793a\u673a\u5236", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u867d\u7136\u80fd\u6574\u5408\u590d\u6742\u4fe1\u606f\uff0c\u4f46\u5176\u8bed\u4e49\u4e30\u5bcc\u6027\u548c\u7ed3\u6784\u590d\u6742\u6027\u4e3a\u975e\u4e13\u5bb6\u7528\u6237\u8bbe\u7f6e\u4e86\u663e\u8457\u969c\u788d\u3002\u7528\u6237\u5728\u9996\u6b21\u63a5\u89e6\u964c\u751f\u77e5\u8bc6\u56fe\u8c31\u65f6\u9762\u4e34\u72ec\u7279\u7684\u5b9a\u5411\u6311\u6218\uff1a\u4e0d\u77e5\u9053\u53ef\u4ee5\u63d0\u51fa\u4ec0\u4e48\u95ee\u9898\u3001\u77e5\u8bc6\u5982\u4f55\u7ec4\u7ec7\u3001\u5982\u4f55\u5f00\u59cb\u63a2\u7d22\u3002\u73b0\u6709\u7814\u7a76\u591a\u5047\u8bbe\u7528\u6237\u5df2\u6709\u8d77\u70b9\u6216\u4fe1\u606f\u76ee\u6807\uff0c\u800c\u5ffd\u89c6\u4e86\u9996\u6b21\u63a5\u89e6\u65f6\u7684\u7279\u6b8a\u56f0\u96be\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u884c\u4e3a\u548c\u4eba\u673a\u4ea4\u4e92\u7406\u8bba\uff08\u5305\u62ecASK\u7406\u8bba\u3001\u63a2\u7d22\u6027\u641c\u7d22\u3001\u4fe1\u606f\u89c5\u98df\u3001\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\uff09\uff0c\u6784\u5efaIEP\u6982\u5ff5\u6846\u67b6\uff0c\u8bc6\u522b\u4e09\u4e2a\u76f8\u4e92\u4f9d\u5b58\u7684\u969c\u788d\uff1a\u8303\u56f4\u4e0d\u786e\u5b9a\u6027\u3001\u672c\u4f53\u4e0d\u900f\u660e\u6027\u3001\u67e5\u8be2\u80fd\u529b\u4e0d\u8db3\u3002\u901a\u8fc7\u5206\u6790\u77e5\u8bc6\u56fe\u8c31\u63a2\u7d22\u754c\u9762\u7684\u4ea4\u4e92\u539f\u8bed\uff0c\u63ed\u793a\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u6027\u7f3a\u53e3\u3002", "result": "\u63d0\u51fa\u4e86\"\u521d\u59cb\u63a2\u7d22\u95ee\u9898\"\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5176\u7279\u5f81\u5316\u4e3a\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u969c\u788d\u3002\u53d1\u73b0\u8bb8\u591a\u7cfb\u7edf\u4f9d\u8d56\u7684\u8ba4\u77e5\u5047\u8bbe\u5728\u9996\u6b21\u63a5\u89e6\u65f6\u4e0d\u6210\u7acb\uff0c\u63ed\u793a\u4e86\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u6027\u7f3a\u53e3\uff1a\u7f3a\u4e4f\"\u8303\u56f4\u63ed\u793a\"\u4ea4\u4e92\u539f\u8bed\u2014\u2014\u5373\u5728\u4e0d\u8981\u6c42\u7528\u6237\u5236\u5b9a\u67e5\u8be2\u6216\u89e3\u91ca\u672c\u4f53\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u4f20\u8fbe\u77e5\u8bc6\u56fe\u8c31\u5185\u5bb9\u7684\u673a\u5236\u3002", "conclusion": "IEP\u6846\u67b6\u4e3a\u8bc4\u4f30\u77e5\u8bc6\u56fe\u8c31\u754c\u9762\u548c\u8bbe\u8ba1\u652f\u6301\u521d\u59cb\u63a2\u7d22\u7684\u5165\u53e3\u652f\u67b6\u63d0\u4f9b\u4e86\u7406\u8bba\u89c6\u89d2\u3002\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u4ea4\u4e92\u539f\u8bed\u6765\u5e2e\u52a9\u7528\u6237\u5728\u9996\u6b21\u63a5\u89e6\u65f6\u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u8303\u56f4\u548c\u53ef\u80fd\u6027\uff0c\u4ece\u800c\u964d\u4f4e\u5165\u95e8\u95e8\u69db\u3002"}}
{"id": "2602.21154", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21154", "abs": "https://arxiv.org/abs/2602.21154", "authors": ["Ziwei Niu", "Hao Sun", "Shujun Bian", "Xihong Yang", "Lanfen Lin", "Yuxin Liu", "Yueming Jin"], "title": "CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning", "comment": "Accepted by ICASSP 2026", "summary": "Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing modality-specific biases due to the free-text nature of the reports. In light of these two issues, we propose CG-DMER, a contrastive-generative framework for disentangled multimodal ECG representation learning, powered by two key designs: (1) Spatial-temporal masked modeling is designed to better capture fine-grained temporal dynamics and inter-lead spatial dependencies by applying masking across both spatial and temporal dimensions and reconstructing the missing information. (2) A representation disentanglement and alignment strategy is designed to mitigate unnecessary noise and modality-specific biases by introducing modality-specific and modality-shared encoders, ensuring a clearer separation between modality-invariant and modality-specific representations. Experiments on three public datasets demonstrate that CG-DMER achieves state-of-the-art performance across diverse downstream tasks.", "AI": {"tldr": "CG-DMER\uff1a\u4e00\u79cd\u7528\u4e8e\u89e3\u8026\u591a\u6a21\u6001\u5fc3\u7535\u56fe\u8868\u793a\u5b66\u4e60\u7684\u5bf9\u6bd4\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4-\u65f6\u95f4\u63a9\u7801\u5efa\u6a21\u548c\u8868\u793a\u89e3\u8026\u5bf9\u9f50\u7b56\u7565\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u6001\u5185\u548c\u6a21\u6001\u95f4\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5fc3\u7535\u56fe\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u6a21\u6001\u5185\uff1a\u73b0\u6709\u6a21\u578b\u4ee5\u5bfc\u8054\u65e0\u5173\u7684\u65b9\u5f0f\u5904\u7406\u5fc3\u7535\u56fe\uff0c\u5ffd\u7565\u4e86\u5bfc\u8054\u95f4\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u7ec6\u7c92\u5ea6\u8bca\u65ad\u6a21\u5f0f\u7684\u5efa\u6a21\u80fd\u529b\uff1b2\uff09\u6a21\u6001\u95f4\uff1a\u73b0\u6709\u65b9\u6cd5\u76f4\u63a5\u5c06\u5fc3\u7535\u56fe\u4fe1\u53f7\u4e0e\u4e34\u5e8a\u62a5\u544a\u5bf9\u9f50\uff0c\u7531\u4e8e\u62a5\u544a\u7684\u81ea\u7531\u6587\u672c\u6027\u8d28\u5f15\u5165\u4e86\u6a21\u6001\u7279\u5b9a\u504f\u5dee\u3002", "method": "\u63d0\u51faCG-DMER\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u8bbe\u8ba1\uff1a1\uff09\u7a7a\u95f4-\u65f6\u95f4\u63a9\u7801\u5efa\u6a21\uff1a\u901a\u8fc7\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5e94\u7528\u63a9\u7801\u5e76\u91cd\u5efa\u7f3a\u5931\u4fe1\u606f\uff0c\u66f4\u597d\u5730\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u95f4\u52a8\u6001\u548c\u5bfc\u8054\u95f4\u7a7a\u95f4\u4f9d\u8d56\u6027\uff1b2\uff09\u8868\u793a\u89e3\u8026\u548c\u5bf9\u9f50\u7b56\u7565\uff1a\u5f15\u5165\u6a21\u6001\u7279\u5b9a\u548c\u6a21\u6001\u5171\u4eab\u7f16\u7801\u5668\uff0c\u786e\u4fdd\u6a21\u6001\u4e0d\u53d8\u548c\u6a21\u6001\u7279\u5b9a\u8868\u793a\u4e4b\u95f4\u7684\u6e05\u6670\u5206\u79bb\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u566a\u58f0\u548c\u6a21\u6001\u7279\u5b9a\u504f\u5dee\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCG-DMER\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "CG-DMER\u901a\u8fc7\u89e3\u51b3\u591a\u6a21\u6001\u5fc3\u7535\u56fe\u5206\u6790\u4e2d\u7684\u6a21\u6001\u5185\u548c\u6a21\u6001\u95f4\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u8026\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5fc3\u7535\u56fe\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.21172", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21172", "abs": "https://arxiv.org/abs/2602.21172", "authors": ["Ishaan Rawal", "Shubh Gupta", "Yihan Hu", "Wei Zhan"], "title": "NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning", "comment": "Accepted to CVPR 2026", "summary": "Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \\modelname (\\textbf{No} \\textbf{R}easoning for \\textbf{D}riving). Compared to existing VLAs, \\modelname achieves competitive performance while being fine-tuned on $<$60\\% of the data and no reasoning annotations, resulting in 3$\\times$ fewer tokens. We identify that standard Group Relative Policy Optimization (GRPO) fails to yield significant improvements when applied to policies trained on such small, reasoning-free datasets. We show that this limitation stems from difficulty bias, which disproportionately penalizes reward signals from scenarios that produce high-variance rollouts within GRPO. \\modelname overcomes this by incorporating Dr.~GRPO, a recent algorithm designed to mitigate difficulty bias in LLMs. As a result, \\modelname achieves competitive performance on Waymo and NAVSIM with a fraction of the training data and no reasoning overhead, enabling more efficient autonomous systems.", "AI": {"tldr": "NoRD\u6a21\u578b\u901a\u8fc7\u6d88\u9664\u63a8\u7406\u6807\u6ce8\u9700\u6c42\uff0c\u5728\u4ec5\u4f7f\u752860%\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709VLA\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u51cf\u5c11\u4e863\u500dtoken\u4f7f\u7528\uff0c\u5e76\u901a\u8fc7Dr. GRPO\u7b97\u6cd5\u89e3\u51b3\u4e86\u96be\u5ea6\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u5e94\u7528\u4e2d\u9762\u4e34\u4e24\u5927\u6602\u8d35\u9700\u6c42\uff1a1\uff09\u9700\u8981\u5927\u91cf\u6570\u636e\u96c6\u6536\u96c6\uff1b2\uff09\u9700\u8981\u5bc6\u96c6\u7684\u63a8\u7406\u6807\u6ce8\u3002\u8fd9\u4e9b\u8981\u6c42\u9650\u5236\u4e86VLA\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u6548\u7387\u3002", "method": "\u63d0\u51faNoRD\u6a21\u578b\uff0c\u91c7\u7528\u65e0\u63a8\u7406\u6807\u6ce8\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528<60%\u7684\u6570\u636e\u91cf\u3002\u9488\u5bf9\u6807\u51c6GRPO\u5728\u5c0f\u89c4\u6a21\u65e0\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u5f15\u5165Dr. GRPO\u7b97\u6cd5\u6765\u7f13\u89e3\u96be\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5904\u7406\u9ad8\u65b9\u5deerollout\u573a\u666f\u4e2d\u7684\u5956\u52b1\u4fe1\u53f7\u60e9\u7f5a\u95ee\u9898\u3002", "result": "NoRD\u5728Waymo\u548cNAVSIM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709VLA\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8bad\u7ec3\u6570\u636e\u91cf\u51cf\u5c1140%\u4ee5\u4e0a\uff0ctoken\u4f7f\u7528\u91cf\u51cf\u5c113\u500d\uff0c\u4e14\u5b8c\u5168\u4e0d\u9700\u8981\u63a8\u7406\u6807\u6ce8\u3002", "conclusion": "NoRD\u901a\u8fc7\u6d88\u9664\u63a8\u7406\u6807\u6ce8\u9700\u6c42\u5e76\u5927\u5e45\u51cf\u5c11\u6570\u636e\u9700\u6c42\uff0c\u4e3a\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0cDr. GRPO\u7b97\u6cd5\u7684\u5f15\u5165\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u89c4\u6a21\u65e0\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2601.12815", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12815", "abs": "https://arxiv.org/abs/2601.12815", "authors": ["Zhaolu Kang", "Junhao Gong", "Qingxi Chen", "Hao Zhang", "Jiaxin Liu", "Rong Fu", "Zhiyuan Feng", "Yuan Wang", "Simon Fong", "Kaiyue Zhou"], "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction", "comment": "Accepted to the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.", "AI": {"tldr": "\u63d0\u51faJurisMMA\u6846\u67b6\u7528\u4e8e\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u6d41\u7a0b\u6807\u51c6\u5316\u5904\u7406\u591a\u6307\u63a7\u3001\u591a\u6837\u5316\u8bc1\u636e\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u5305\u542b10\u4e07+\u4e2d\u6587\u53f8\u6cd5\u8bb0\u5f55\u7684JurisMM\u591a\u6a21\u6001\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6307\u63a7\u3001\u591a\u6837\u5316\u8bc1\u636e\u65f6\u9762\u4e34\u6311\u6218\u4e14\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u63a8\u52a8\u6cd5\u5f8b\u7cfb\u7edf\u53d1\u5c55\u3002", "method": "\u63d0\u51faJurisMMA\u6846\u67b6\uff0c\u6709\u6548\u5206\u89e3\u5ba1\u5224\u4efb\u52a1\u3001\u6807\u51c6\u5316\u6d41\u7a0b\u5e76\u7ec4\u7ec7\u4e3a\u4e0d\u540c\u9636\u6bb5\uff1b\u6784\u5efa\u5305\u542b\u6587\u672c\u548c\u591a\u6a21\u6001\u89c6\u9891-\u6587\u672c\u6570\u636e\u7684JurisMM\u5927\u578b\u6570\u636e\u96c6\u3002", "result": "\u5728JurisMM\u548c\u57fa\u51c6\u6570\u636e\u96c6LawBench\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\uff0c\u8fd8\u53ef\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6cd5\u5f8b\u5e94\u7528\u3002", "conclusion": "JurisMMA\u6846\u67b6\u4e3a\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5176\u591a\u9636\u6bb5\u6807\u51c6\u5316\u65b9\u6cd5\u548c\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e3a\u672a\u6765\u6cd5\u5f8b\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u7684\u53d1\u5c55\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
